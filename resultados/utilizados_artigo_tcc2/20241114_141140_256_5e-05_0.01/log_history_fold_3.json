[
    {
        "loss": 0.669,
        "grad_norm": 5.106559753417969,
        "learning_rate": 4.9778761061946906e-05,
        "epoch": 0.04424778761061947,
        "step": 10
    },
    {
        "loss": 0.6045,
        "grad_norm": 29.221128463745117,
        "learning_rate": 4.955752212389381e-05,
        "epoch": 0.08849557522123894,
        "step": 20
    },
    {
        "loss": 0.6983,
        "grad_norm": 2.07669734954834,
        "learning_rate": 4.9336283185840707e-05,
        "epoch": 0.13274336283185842,
        "step": 30
    },
    {
        "loss": 0.6632,
        "grad_norm": 4.687766075134277,
        "learning_rate": 4.911504424778761e-05,
        "epoch": 0.17699115044247787,
        "step": 40
    },
    {
        "loss": 0.596,
        "grad_norm": 4.573942184448242,
        "learning_rate": 4.8893805309734514e-05,
        "epoch": 0.22123893805309736,
        "step": 50
    },
    {
        "loss": 0.6179,
        "grad_norm": 2.701474666595459,
        "learning_rate": 4.867256637168142e-05,
        "epoch": 0.26548672566371684,
        "step": 60
    },
    {
        "loss": 0.5868,
        "grad_norm": 1.8439106941223145,
        "learning_rate": 4.845132743362832e-05,
        "epoch": 0.30973451327433627,
        "step": 70
    },
    {
        "loss": 0.5906,
        "grad_norm": 4.175143718719482,
        "learning_rate": 4.823008849557522e-05,
        "epoch": 0.35398230088495575,
        "step": 80
    },
    {
        "loss": 0.574,
        "grad_norm": 3.3644800186157227,
        "learning_rate": 4.800884955752213e-05,
        "epoch": 0.39823008849557523,
        "step": 90
    },
    {
        "loss": 0.6078,
        "grad_norm": 1.6495918035507202,
        "learning_rate": 4.778761061946903e-05,
        "epoch": 0.4424778761061947,
        "step": 100
    },
    {
        "loss": 0.6748,
        "grad_norm": 2.495022773742676,
        "learning_rate": 4.7566371681415936e-05,
        "epoch": 0.48672566371681414,
        "step": 110
    },
    {
        "loss": 0.6556,
        "grad_norm": 2.7401516437530518,
        "learning_rate": 4.734513274336283e-05,
        "epoch": 0.5309734513274337,
        "step": 120
    },
    {
        "loss": 0.6325,
        "grad_norm": 3.3510727882385254,
        "learning_rate": 4.7123893805309736e-05,
        "epoch": 0.5752212389380531,
        "step": 130
    },
    {
        "loss": 0.6091,
        "grad_norm": 1.2193996906280518,
        "learning_rate": 4.690265486725664e-05,
        "epoch": 0.6194690265486725,
        "step": 140
    },
    {
        "loss": 0.5655,
        "grad_norm": 2.176146984100342,
        "learning_rate": 4.668141592920354e-05,
        "epoch": 0.6637168141592921,
        "step": 150
    },
    {
        "loss": 0.641,
        "grad_norm": 3.662311553955078,
        "learning_rate": 4.646017699115045e-05,
        "epoch": 0.7079646017699115,
        "step": 160
    },
    {
        "loss": 0.6438,
        "grad_norm": 1.7337394952774048,
        "learning_rate": 4.6238938053097344e-05,
        "epoch": 0.7522123893805309,
        "step": 170
    },
    {
        "loss": 0.52,
        "grad_norm": 3.9674465656280518,
        "learning_rate": 4.601769911504425e-05,
        "epoch": 0.7964601769911505,
        "step": 180
    },
    {
        "loss": 0.6234,
        "grad_norm": 3.083606481552124,
        "learning_rate": 4.579646017699115e-05,
        "epoch": 0.8407079646017699,
        "step": 190
    },
    {
        "loss": 0.5404,
        "grad_norm": 1.2112376689910889,
        "learning_rate": 4.5575221238938055e-05,
        "epoch": 0.8849557522123894,
        "step": 200
    },
    {
        "loss": 0.5964,
        "grad_norm": 1.8063796758651733,
        "learning_rate": 4.535398230088496e-05,
        "epoch": 0.9292035398230089,
        "step": 210
    },
    {
        "loss": 0.5882,
        "grad_norm": 1.2799128293991089,
        "learning_rate": 4.5132743362831855e-05,
        "epoch": 0.9734513274336283,
        "step": 220
    },
    {
        "eval_loss": 0.6150375008583069,
        "eval_accuracy": 0.67829,
        "eval_precision": 0.68636,
        "eval_recall": 0.66447,
        "eval_f1": 0.67524,
        "eval_runtime": 29.8327,
        "eval_samples_per_second": 60.538,
        "eval_steps_per_second": 3.788,
        "epoch": 1.0,
        "step": 226
    },
    {
        "loss": 0.5985,
        "grad_norm": 4.430933952331543,
        "learning_rate": 4.491150442477876e-05,
        "epoch": 1.0176991150442478,
        "step": 230
    },
    {
        "loss": 0.523,
        "grad_norm": 2.7036855220794678,
        "learning_rate": 4.469026548672566e-05,
        "epoch": 1.0619469026548674,
        "step": 240
    },
    {
        "loss": 0.5897,
        "grad_norm": 2.1106035709381104,
        "learning_rate": 4.446902654867257e-05,
        "epoch": 1.1061946902654867,
        "step": 250
    },
    {
        "loss": 0.603,
        "grad_norm": 1.2374964952468872,
        "learning_rate": 4.4247787610619477e-05,
        "epoch": 1.1504424778761062,
        "step": 260
    },
    {
        "loss": 0.6674,
        "grad_norm": 4.596018314361572,
        "learning_rate": 4.4026548672566373e-05,
        "epoch": 1.1946902654867257,
        "step": 270
    },
    {
        "loss": 0.5628,
        "grad_norm": 3.6557576656341553,
        "learning_rate": 4.380530973451328e-05,
        "epoch": 1.238938053097345,
        "step": 280
    },
    {
        "loss": 0.6174,
        "grad_norm": 2.185741662979126,
        "learning_rate": 4.358407079646018e-05,
        "epoch": 1.2831858407079646,
        "step": 290
    },
    {
        "loss": 0.555,
        "grad_norm": 2.4037747383117676,
        "learning_rate": 4.3362831858407084e-05,
        "epoch": 1.3274336283185841,
        "step": 300
    },
    {
        "loss": 0.5676,
        "grad_norm": 1.419310212135315,
        "learning_rate": 4.314159292035399e-05,
        "epoch": 1.3716814159292037,
        "step": 310
    },
    {
        "loss": 0.5518,
        "grad_norm": 1.9633300304412842,
        "learning_rate": 4.2920353982300885e-05,
        "epoch": 1.415929203539823,
        "step": 320
    },
    {
        "loss": 0.5792,
        "grad_norm": 2.320913553237915,
        "learning_rate": 4.269911504424779e-05,
        "epoch": 1.4601769911504425,
        "step": 330
    },
    {
        "loss": 0.6125,
        "grad_norm": 2.098329544067383,
        "learning_rate": 4.247787610619469e-05,
        "epoch": 1.504424778761062,
        "step": 340
    },
    {
        "loss": 0.6125,
        "grad_norm": 6.429701328277588,
        "learning_rate": 4.2256637168141596e-05,
        "epoch": 1.5486725663716814,
        "step": 350
    },
    {
        "loss": 0.579,
        "grad_norm": 4.350850582122803,
        "learning_rate": 4.20353982300885e-05,
        "epoch": 1.592920353982301,
        "step": 360
    },
    {
        "loss": 0.5934,
        "grad_norm": 4.851888179779053,
        "learning_rate": 4.1814159292035396e-05,
        "epoch": 1.6371681415929205,
        "step": 370
    },
    {
        "loss": 0.4992,
        "grad_norm": 3.270747661590576,
        "learning_rate": 4.15929203539823e-05,
        "epoch": 1.6814159292035398,
        "step": 380
    },
    {
        "loss": 0.6201,
        "grad_norm": 3.144291877746582,
        "learning_rate": 4.1371681415929203e-05,
        "epoch": 1.7256637168141593,
        "step": 390
    },
    {
        "loss": 0.6142,
        "grad_norm": 1.5643600225448608,
        "learning_rate": 4.115044247787611e-05,
        "epoch": 1.7699115044247788,
        "step": 400
    },
    {
        "loss": 0.6131,
        "grad_norm": 3.7861058712005615,
        "learning_rate": 4.092920353982301e-05,
        "epoch": 1.8141592920353982,
        "step": 410
    },
    {
        "loss": 0.5638,
        "grad_norm": 2.463092803955078,
        "learning_rate": 4.0707964601769914e-05,
        "epoch": 1.8584070796460177,
        "step": 420
    },
    {
        "loss": 0.5845,
        "grad_norm": 3.4589462280273438,
        "learning_rate": 4.048672566371682e-05,
        "epoch": 1.9026548672566372,
        "step": 430
    },
    {
        "loss": 0.545,
        "grad_norm": 3.684190034866333,
        "learning_rate": 4.026548672566372e-05,
        "epoch": 1.9469026548672566,
        "step": 440
    },
    {
        "loss": 0.5823,
        "grad_norm": 4.579009056091309,
        "learning_rate": 4.0044247787610625e-05,
        "epoch": 1.991150442477876,
        "step": 450
    },
    {
        "eval_loss": 0.5897422432899475,
        "eval_accuracy": 0.69989,
        "eval_precision": 0.68079,
        "eval_recall": 0.76018,
        "eval_f1": 0.7183,
        "eval_runtime": 29.966,
        "eval_samples_per_second": 60.268,
        "eval_steps_per_second": 3.771,
        "epoch": 2.0,
        "step": 452
    },
    {
        "loss": 0.501,
        "grad_norm": 2.9642295837402344,
        "learning_rate": 3.982300884955752e-05,
        "epoch": 2.0353982300884956,
        "step": 460
    },
    {
        "loss": 0.5047,
        "grad_norm": 10.847216606140137,
        "learning_rate": 3.9601769911504426e-05,
        "epoch": 2.079646017699115,
        "step": 470
    },
    {
        "loss": 0.5175,
        "grad_norm": 2.915260076522827,
        "learning_rate": 3.938053097345133e-05,
        "epoch": 2.1238938053097347,
        "step": 480
    },
    {
        "loss": 0.4431,
        "grad_norm": 6.3848748207092285,
        "learning_rate": 3.915929203539823e-05,
        "epoch": 2.168141592920354,
        "step": 490
    },
    {
        "loss": 0.5234,
        "grad_norm": 5.504650592803955,
        "learning_rate": 3.893805309734514e-05,
        "epoch": 2.2123893805309733,
        "step": 500
    },
    {
        "loss": 0.5174,
        "grad_norm": 3.804041862487793,
        "learning_rate": 3.8716814159292034e-05,
        "epoch": 2.256637168141593,
        "step": 510
    },
    {
        "loss": 0.4625,
        "grad_norm": 2.7195041179656982,
        "learning_rate": 3.849557522123894e-05,
        "epoch": 2.3008849557522124,
        "step": 520
    },
    {
        "loss": 0.5498,
        "grad_norm": 3.701676845550537,
        "learning_rate": 3.827433628318584e-05,
        "epoch": 2.3451327433628317,
        "step": 530
    },
    {
        "loss": 0.4892,
        "grad_norm": 9.5442533493042,
        "learning_rate": 3.8053097345132744e-05,
        "epoch": 2.3893805309734515,
        "step": 540
    },
    {
        "loss": 0.4879,
        "grad_norm": 2.6267895698547363,
        "learning_rate": 3.783185840707965e-05,
        "epoch": 2.433628318584071,
        "step": 550
    },
    {
        "loss": 0.4604,
        "grad_norm": 6.394708633422852,
        "learning_rate": 3.7610619469026545e-05,
        "epoch": 2.47787610619469,
        "step": 560
    },
    {
        "loss": 0.3827,
        "grad_norm": 4.798505783081055,
        "learning_rate": 3.7389380530973455e-05,
        "epoch": 2.52212389380531,
        "step": 570
    },
    {
        "loss": 0.4648,
        "grad_norm": 369.8525695800781,
        "learning_rate": 3.716814159292036e-05,
        "epoch": 2.566371681415929,
        "step": 580
    },
    {
        "loss": 0.5864,
        "grad_norm": 9.260677337646484,
        "learning_rate": 3.694690265486726e-05,
        "epoch": 2.6106194690265485,
        "step": 590
    },
    {
        "loss": 0.5328,
        "grad_norm": 9.654809951782227,
        "learning_rate": 3.672566371681416e-05,
        "epoch": 2.6548672566371683,
        "step": 600
    },
    {
        "loss": 0.3765,
        "grad_norm": 5.226686954498291,
        "learning_rate": 3.650442477876106e-05,
        "epoch": 2.6991150442477876,
        "step": 610
    },
    {
        "loss": 0.515,
        "grad_norm": 6.779311656951904,
        "learning_rate": 3.628318584070797e-05,
        "epoch": 2.7433628318584073,
        "step": 620
    },
    {
        "loss": 0.4761,
        "grad_norm": 5.3264079093933105,
        "learning_rate": 3.606194690265487e-05,
        "epoch": 2.7876106194690267,
        "step": 630
    },
    {
        "loss": 0.5171,
        "grad_norm": 4.0452446937561035,
        "learning_rate": 3.5840707964601774e-05,
        "epoch": 2.831858407079646,
        "step": 640
    },
    {
        "loss": 0.5256,
        "grad_norm": 12.8280668258667,
        "learning_rate": 3.561946902654867e-05,
        "epoch": 2.8761061946902657,
        "step": 650
    },
    {
        "loss": 0.4732,
        "grad_norm": 4.827126979827881,
        "learning_rate": 3.5398230088495574e-05,
        "epoch": 2.920353982300885,
        "step": 660
    },
    {
        "loss": 0.4862,
        "grad_norm": 4.823591232299805,
        "learning_rate": 3.517699115044248e-05,
        "epoch": 2.9646017699115044,
        "step": 670
    },
    {
        "eval_loss": 0.6414074301719666,
        "eval_accuracy": 0.6866,
        "eval_precision": 0.69919,
        "eval_recall": 0.66227,
        "eval_f1": 0.68023,
        "eval_runtime": 29.9719,
        "eval_samples_per_second": 60.256,
        "eval_steps_per_second": 3.77,
        "epoch": 3.0,
        "step": 678
    },
    {
        "loss": 0.5254,
        "grad_norm": 4.85380220413208,
        "learning_rate": 3.495575221238938e-05,
        "epoch": 3.0088495575221237,
        "step": 680
    },
    {
        "loss": 0.3687,
        "grad_norm": 9.026748657226562,
        "learning_rate": 3.4734513274336285e-05,
        "epoch": 3.0530973451327434,
        "step": 690
    },
    {
        "loss": 0.3846,
        "grad_norm": 4.504420757293701,
        "learning_rate": 3.451327433628319e-05,
        "epoch": 3.0973451327433628,
        "step": 700
    },
    {
        "loss": 0.4002,
        "grad_norm": 10.759641647338867,
        "learning_rate": 3.4292035398230086e-05,
        "epoch": 3.1415929203539825,
        "step": 710
    },
    {
        "loss": 0.3134,
        "grad_norm": 13.919236183166504,
        "learning_rate": 3.407079646017699e-05,
        "epoch": 3.185840707964602,
        "step": 720
    },
    {
        "loss": 0.3854,
        "grad_norm": 21.36490821838379,
        "learning_rate": 3.38495575221239e-05,
        "epoch": 3.230088495575221,
        "step": 730
    },
    {
        "loss": 0.4076,
        "grad_norm": 11.273758888244629,
        "learning_rate": 3.3628318584070804e-05,
        "epoch": 3.274336283185841,
        "step": 740
    },
    {
        "loss": 0.2915,
        "grad_norm": 8.912016868591309,
        "learning_rate": 3.34070796460177e-05,
        "epoch": 3.3185840707964602,
        "step": 750
    },
    {
        "loss": 0.344,
        "grad_norm": 10.173179626464844,
        "learning_rate": 3.3185840707964604e-05,
        "epoch": 3.3628318584070795,
        "step": 760
    },
    {
        "loss": 0.4248,
        "grad_norm": 35.51472091674805,
        "learning_rate": 3.296460176991151e-05,
        "epoch": 3.4070796460176993,
        "step": 770
    },
    {
        "loss": 0.2912,
        "grad_norm": 4.761916637420654,
        "learning_rate": 3.274336283185841e-05,
        "epoch": 3.4513274336283186,
        "step": 780
    },
    {
        "loss": 0.3074,
        "grad_norm": 11.4181489944458,
        "learning_rate": 3.2522123893805315e-05,
        "epoch": 3.495575221238938,
        "step": 790
    },
    {
        "loss": 0.3127,
        "grad_norm": 27.028615951538086,
        "learning_rate": 3.230088495575221e-05,
        "epoch": 3.5398230088495577,
        "step": 800
    },
    {
        "loss": 0.3916,
        "grad_norm": 11.337882995605469,
        "learning_rate": 3.2079646017699115e-05,
        "epoch": 3.584070796460177,
        "step": 810
    },
    {
        "loss": 0.3984,
        "grad_norm": 13.623298645019531,
        "learning_rate": 3.185840707964602e-05,
        "epoch": 3.6283185840707963,
        "step": 820
    },
    {
        "loss": 0.4119,
        "grad_norm": 14.526001930236816,
        "learning_rate": 3.163716814159292e-05,
        "epoch": 3.672566371681416,
        "step": 830
    },
    {
        "loss": 0.4208,
        "grad_norm": 10.741580963134766,
        "learning_rate": 3.1415929203539826e-05,
        "epoch": 3.7168141592920354,
        "step": 840
    },
    {
        "loss": 0.3543,
        "grad_norm": 6.959499835968018,
        "learning_rate": 3.119469026548672e-05,
        "epoch": 3.7610619469026547,
        "step": 850
    },
    {
        "loss": 0.3626,
        "grad_norm": 15.960796356201172,
        "learning_rate": 3.097345132743363e-05,
        "epoch": 3.8053097345132745,
        "step": 860
    },
    {
        "loss": 0.3612,
        "grad_norm": 5.838225364685059,
        "learning_rate": 3.075221238938053e-05,
        "epoch": 3.849557522123894,
        "step": 870
    },
    {
        "loss": 0.3028,
        "grad_norm": 7.040249347686768,
        "learning_rate": 3.0530973451327434e-05,
        "epoch": 3.893805309734513,
        "step": 880
    },
    {
        "loss": 0.3423,
        "grad_norm": 7.509162902832031,
        "learning_rate": 3.030973451327434e-05,
        "epoch": 3.938053097345133,
        "step": 890
    },
    {
        "loss": 0.3159,
        "grad_norm": 12.062051773071289,
        "learning_rate": 3.008849557522124e-05,
        "epoch": 3.982300884955752,
        "step": 900
    },
    {
        "eval_loss": 0.7555652260780334,
        "eval_accuracy": 0.67608,
        "eval_precision": 0.6875,
        "eval_recall": 0.65347,
        "eval_f1": 0.67005,
        "eval_runtime": 29.9678,
        "eval_samples_per_second": 60.265,
        "eval_steps_per_second": 3.771,
        "epoch": 4.0,
        "step": 904
    },
    {
        "loss": 0.29,
        "grad_norm": 13.087112426757812,
        "learning_rate": 2.9867256637168145e-05,
        "epoch": 4.0265486725663715,
        "step": 910
    },
    {
        "loss": 0.2559,
        "grad_norm": 6.36848258972168,
        "learning_rate": 2.964601769911505e-05,
        "epoch": 4.070796460176991,
        "step": 920
    },
    {
        "loss": 0.2374,
        "grad_norm": 3.8244922161102295,
        "learning_rate": 2.942477876106195e-05,
        "epoch": 4.115044247787611,
        "step": 930
    },
    {
        "loss": 0.1277,
        "grad_norm": 2.971836805343628,
        "learning_rate": 2.9203539823008852e-05,
        "epoch": 4.15929203539823,
        "step": 940
    },
    {
        "loss": 0.1456,
        "grad_norm": 2.358017683029175,
        "learning_rate": 2.8982300884955753e-05,
        "epoch": 4.20353982300885,
        "step": 950
    },
    {
        "loss": 0.2212,
        "grad_norm": 42.97520446777344,
        "learning_rate": 2.8761061946902656e-05,
        "epoch": 4.247787610619469,
        "step": 960
    },
    {
        "loss": 0.2265,
        "grad_norm": 38.17410659790039,
        "learning_rate": 2.853982300884956e-05,
        "epoch": 4.292035398230088,
        "step": 970
    },
    {
        "loss": 0.2357,
        "grad_norm": 50.36465072631836,
        "learning_rate": 2.831858407079646e-05,
        "epoch": 4.336283185840708,
        "step": 980
    },
    {
        "loss": 0.201,
        "grad_norm": 13.735518455505371,
        "learning_rate": 2.8097345132743364e-05,
        "epoch": 4.380530973451328,
        "step": 990
    },
    {
        "loss": 0.3554,
        "grad_norm": 58.48150634765625,
        "learning_rate": 2.7876106194690264e-05,
        "epoch": 4.424778761061947,
        "step": 1000
    },
    {
        "loss": 0.1185,
        "grad_norm": 53.001670837402344,
        "learning_rate": 2.7654867256637168e-05,
        "epoch": 4.469026548672566,
        "step": 1010
    },
    {
        "loss": 0.2618,
        "grad_norm": 37.99840545654297,
        "learning_rate": 2.743362831858407e-05,
        "epoch": 4.513274336283186,
        "step": 1020
    },
    {
        "loss": 0.3147,
        "grad_norm": 27.71025848388672,
        "learning_rate": 2.721238938053097e-05,
        "epoch": 4.557522123893805,
        "step": 1030
    },
    {
        "loss": 0.2765,
        "grad_norm": 18.707427978515625,
        "learning_rate": 2.6991150442477875e-05,
        "epoch": 4.601769911504425,
        "step": 1040
    },
    {
        "loss": 0.2274,
        "grad_norm": 1.1088714599609375,
        "learning_rate": 2.6769911504424782e-05,
        "epoch": 4.646017699115045,
        "step": 1050
    },
    {
        "loss": 0.1705,
        "grad_norm": 22.408708572387695,
        "learning_rate": 2.6548672566371686e-05,
        "epoch": 4.6902654867256635,
        "step": 1060
    },
    {
        "loss": 0.254,
        "grad_norm": 40.36017990112305,
        "learning_rate": 2.6327433628318586e-05,
        "epoch": 4.734513274336283,
        "step": 1070
    },
    {
        "loss": 0.2081,
        "grad_norm": 20.992603302001953,
        "learning_rate": 2.610619469026549e-05,
        "epoch": 4.778761061946903,
        "step": 1080
    },
    {
        "loss": 0.3091,
        "grad_norm": 12.790807723999023,
        "learning_rate": 2.5884955752212393e-05,
        "epoch": 4.823008849557522,
        "step": 1090
    },
    {
        "loss": 0.3421,
        "grad_norm": 16.82550048828125,
        "learning_rate": 2.5663716814159294e-05,
        "epoch": 4.867256637168142,
        "step": 1100
    },
    {
        "loss": 0.2483,
        "grad_norm": 14.322338104248047,
        "learning_rate": 2.5442477876106197e-05,
        "epoch": 4.911504424778761,
        "step": 1110
    },
    {
        "loss": 0.1929,
        "grad_norm": 20.070133209228516,
        "learning_rate": 2.5221238938053098e-05,
        "epoch": 4.95575221238938,
        "step": 1120
    },
    {
        "loss": 0.2509,
        "grad_norm": 11.10204792022705,
        "learning_rate": 2.5e-05,
        "epoch": 5.0,
        "step": 1130
    },
    {
        "eval_loss": 1.1440587043762207,
        "eval_accuracy": 0.68494,
        "eval_precision": 0.68398,
        "eval_recall": 0.69527,
        "eval_f1": 0.68958,
        "eval_runtime": 29.8894,
        "eval_samples_per_second": 60.423,
        "eval_steps_per_second": 3.781,
        "epoch": 5.0,
        "step": 1130
    },
    {
        "loss": 0.2056,
        "grad_norm": 7.879397869110107,
        "learning_rate": 2.4778761061946905e-05,
        "epoch": 5.04424778761062,
        "step": 1140
    },
    {
        "loss": 0.1455,
        "grad_norm": 0.6435123682022095,
        "learning_rate": 2.4557522123893805e-05,
        "epoch": 5.088495575221239,
        "step": 1150
    },
    {
        "loss": 0.135,
        "grad_norm": 36.68644714355469,
        "learning_rate": 2.433628318584071e-05,
        "epoch": 5.132743362831858,
        "step": 1160
    },
    {
        "loss": 0.1082,
        "grad_norm": 85.92411804199219,
        "learning_rate": 2.411504424778761e-05,
        "epoch": 5.176991150442478,
        "step": 1170
    },
    {
        "loss": 0.1732,
        "grad_norm": 64.29378509521484,
        "learning_rate": 2.3893805309734516e-05,
        "epoch": 5.221238938053097,
        "step": 1180
    },
    {
        "loss": 0.1427,
        "grad_norm": 41.401283264160156,
        "learning_rate": 2.3672566371681416e-05,
        "epoch": 5.265486725663717,
        "step": 1190
    },
    {
        "loss": 0.1846,
        "grad_norm": 10.21262264251709,
        "learning_rate": 2.345132743362832e-05,
        "epoch": 5.3097345132743365,
        "step": 1200
    },
    {
        "loss": 0.1716,
        "grad_norm": 45.090301513671875,
        "learning_rate": 2.3230088495575223e-05,
        "epoch": 5.353982300884955,
        "step": 1210
    },
    {
        "loss": 0.2247,
        "grad_norm": 0.8590862154960632,
        "learning_rate": 2.3008849557522124e-05,
        "epoch": 5.398230088495575,
        "step": 1220
    },
    {
        "loss": 0.125,
        "grad_norm": 3.6679766178131104,
        "learning_rate": 2.2787610619469027e-05,
        "epoch": 5.442477876106195,
        "step": 1230
    },
    {
        "loss": 0.2271,
        "grad_norm": 20.24567985534668,
        "learning_rate": 2.2566371681415928e-05,
        "epoch": 5.486725663716814,
        "step": 1240
    },
    {
        "loss": 0.1098,
        "grad_norm": 28.493587493896484,
        "learning_rate": 2.234513274336283e-05,
        "epoch": 5.530973451327434,
        "step": 1250
    },
    {
        "loss": 0.1287,
        "grad_norm": 36.20862579345703,
        "learning_rate": 2.2123893805309738e-05,
        "epoch": 5.575221238938053,
        "step": 1260
    },
    {
        "loss": 0.365,
        "grad_norm": 30.346426010131836,
        "learning_rate": 2.190265486725664e-05,
        "epoch": 5.619469026548672,
        "step": 1270
    },
    {
        "loss": 0.1721,
        "grad_norm": 27.01171112060547,
        "learning_rate": 2.1681415929203542e-05,
        "epoch": 5.663716814159292,
        "step": 1280
    },
    {
        "loss": 0.2377,
        "grad_norm": 8.046164512634277,
        "learning_rate": 2.1460176991150442e-05,
        "epoch": 5.707964601769912,
        "step": 1290
    },
    {
        "loss": 0.1378,
        "grad_norm": 9.91010570526123,
        "learning_rate": 2.1238938053097346e-05,
        "epoch": 5.752212389380531,
        "step": 1300
    },
    {
        "loss": 0.0809,
        "grad_norm": 0.4354226887226105,
        "learning_rate": 2.101769911504425e-05,
        "epoch": 5.79646017699115,
        "step": 1310
    },
    {
        "loss": 0.1053,
        "grad_norm": 8.121129035949707,
        "learning_rate": 2.079646017699115e-05,
        "epoch": 5.84070796460177,
        "step": 1320
    },
    {
        "loss": 0.2381,
        "grad_norm": 15.188624382019043,
        "learning_rate": 2.0575221238938054e-05,
        "epoch": 5.88495575221239,
        "step": 1330
    },
    {
        "loss": 0.126,
        "grad_norm": 2.842609405517578,
        "learning_rate": 2.0353982300884957e-05,
        "epoch": 5.929203539823009,
        "step": 1340
    },
    {
        "loss": 0.12,
        "grad_norm": 14.523808479309082,
        "learning_rate": 2.013274336283186e-05,
        "epoch": 5.9734513274336285,
        "step": 1350
    },
    {
        "eval_loss": 1.6104464530944824,
        "eval_accuracy": 0.65891,
        "eval_precision": 0.72926,
        "eval_recall": 0.51265,
        "eval_f1": 0.60207,
        "eval_runtime": 29.9353,
        "eval_samples_per_second": 60.33,
        "eval_steps_per_second": 3.775,
        "epoch": 6.0,
        "step": 1356
    },
    {
        "train_runtime": 1287.1526,
        "train_samples_per_second": 28.07,
        "train_steps_per_second": 1.756,
        "total_flos": 2851860729047040.0,
        "train_loss": 0.4083269229241177,
        "epoch": 6.0,
        "step": 1356
    }
]