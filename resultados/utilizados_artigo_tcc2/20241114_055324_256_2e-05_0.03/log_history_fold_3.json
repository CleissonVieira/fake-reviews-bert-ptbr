[
    {
        "loss": 0.6896,
        "grad_norm": 1.378922462463379,
        "learning_rate": 1.991150442477876e-05,
        "epoch": 0.04424778761061947,
        "step": 10
    },
    {
        "loss": 0.669,
        "grad_norm": 2.110928773880005,
        "learning_rate": 1.9823008849557524e-05,
        "epoch": 0.08849557522123894,
        "step": 20
    },
    {
        "loss": 0.6385,
        "grad_norm": 2.5557568073272705,
        "learning_rate": 1.9734513274336283e-05,
        "epoch": 0.13274336283185842,
        "step": 30
    },
    {
        "loss": 0.6224,
        "grad_norm": 3.107085704803467,
        "learning_rate": 1.9646017699115046e-05,
        "epoch": 0.17699115044247787,
        "step": 40
    },
    {
        "loss": 0.6133,
        "grad_norm": 3.51582407951355,
        "learning_rate": 1.9557522123893806e-05,
        "epoch": 0.22123893805309736,
        "step": 50
    },
    {
        "loss": 0.6333,
        "grad_norm": 3.4255566596984863,
        "learning_rate": 1.946902654867257e-05,
        "epoch": 0.26548672566371684,
        "step": 60
    },
    {
        "loss": 0.6434,
        "grad_norm": 3.2803308963775635,
        "learning_rate": 1.9380530973451328e-05,
        "epoch": 0.30973451327433627,
        "step": 70
    },
    {
        "loss": 0.5797,
        "grad_norm": 4.772900581359863,
        "learning_rate": 1.929203539823009e-05,
        "epoch": 0.35398230088495575,
        "step": 80
    },
    {
        "loss": 0.5906,
        "grad_norm": 4.5462493896484375,
        "learning_rate": 1.9203539823008853e-05,
        "epoch": 0.39823008849557523,
        "step": 90
    },
    {
        "loss": 0.614,
        "grad_norm": 3.154690742492676,
        "learning_rate": 1.9115044247787613e-05,
        "epoch": 0.4424778761061947,
        "step": 100
    },
    {
        "loss": 0.6637,
        "grad_norm": 3.0146045684814453,
        "learning_rate": 1.9026548672566376e-05,
        "epoch": 0.48672566371681414,
        "step": 110
    },
    {
        "loss": 0.6314,
        "grad_norm": 4.228650093078613,
        "learning_rate": 1.8938053097345135e-05,
        "epoch": 0.5309734513274337,
        "step": 120
    },
    {
        "loss": 0.6202,
        "grad_norm": 3.1467719078063965,
        "learning_rate": 1.8849557522123894e-05,
        "epoch": 0.5752212389380531,
        "step": 130
    },
    {
        "loss": 0.5806,
        "grad_norm": 1.713770866394043,
        "learning_rate": 1.8761061946902657e-05,
        "epoch": 0.6194690265486725,
        "step": 140
    },
    {
        "loss": 0.5524,
        "grad_norm": 3.132392644882202,
        "learning_rate": 1.8672566371681417e-05,
        "epoch": 0.6637168141592921,
        "step": 150
    },
    {
        "loss": 0.5789,
        "grad_norm": 5.230546474456787,
        "learning_rate": 1.858407079646018e-05,
        "epoch": 0.7079646017699115,
        "step": 160
    },
    {
        "loss": 0.5874,
        "grad_norm": 2.35497784614563,
        "learning_rate": 1.849557522123894e-05,
        "epoch": 0.7522123893805309,
        "step": 170
    },
    {
        "loss": 0.5005,
        "grad_norm": 5.796062469482422,
        "learning_rate": 1.8407079646017702e-05,
        "epoch": 0.7964601769911505,
        "step": 180
    },
    {
        "loss": 0.6183,
        "grad_norm": 6.213762283325195,
        "learning_rate": 1.831858407079646e-05,
        "epoch": 0.8407079646017699,
        "step": 190
    },
    {
        "loss": 0.5518,
        "grad_norm": 2.063544273376465,
        "learning_rate": 1.823008849557522e-05,
        "epoch": 0.8849557522123894,
        "step": 200
    },
    {
        "loss": 0.5852,
        "grad_norm": 2.7797019481658936,
        "learning_rate": 1.8141592920353983e-05,
        "epoch": 0.9292035398230089,
        "step": 210
    },
    {
        "loss": 0.5538,
        "grad_norm": 3.1300673484802246,
        "learning_rate": 1.8053097345132743e-05,
        "epoch": 0.9734513274336283,
        "step": 220
    },
    {
        "eval_loss": 0.5932934880256653,
        "eval_accuracy": 0.68051,
        "eval_precision": 0.69258,
        "eval_recall": 0.65677,
        "eval_f1": 0.6742,
        "eval_runtime": 29.8107,
        "eval_samples_per_second": 60.582,
        "eval_steps_per_second": 3.791,
        "epoch": 1.0,
        "step": 226
    },
    {
        "loss": 0.5931,
        "grad_norm": 2.858776330947876,
        "learning_rate": 1.7964601769911506e-05,
        "epoch": 1.0176991150442478,
        "step": 230
    },
    {
        "loss": 0.4702,
        "grad_norm": 2.5118234157562256,
        "learning_rate": 1.7876106194690265e-05,
        "epoch": 1.0619469026548674,
        "step": 240
    },
    {
        "loss": 0.5693,
        "grad_norm": 3.1459169387817383,
        "learning_rate": 1.7787610619469028e-05,
        "epoch": 1.1061946902654867,
        "step": 250
    },
    {
        "loss": 0.5673,
        "grad_norm": 2.424657106399536,
        "learning_rate": 1.769911504424779e-05,
        "epoch": 1.1504424778761062,
        "step": 260
    },
    {
        "loss": 0.5709,
        "grad_norm": 4.4001874923706055,
        "learning_rate": 1.761061946902655e-05,
        "epoch": 1.1946902654867257,
        "step": 270
    },
    {
        "loss": 0.5075,
        "grad_norm": 3.2423245906829834,
        "learning_rate": 1.7522123893805313e-05,
        "epoch": 1.238938053097345,
        "step": 280
    },
    {
        "loss": 0.6005,
        "grad_norm": 3.3974509239196777,
        "learning_rate": 1.7433628318584072e-05,
        "epoch": 1.2831858407079646,
        "step": 290
    },
    {
        "loss": 0.556,
        "grad_norm": 4.279959201812744,
        "learning_rate": 1.7345132743362835e-05,
        "epoch": 1.3274336283185841,
        "step": 300
    },
    {
        "loss": 0.534,
        "grad_norm": 4.769069194793701,
        "learning_rate": 1.7256637168141594e-05,
        "epoch": 1.3716814159292037,
        "step": 310
    },
    {
        "loss": 0.5439,
        "grad_norm": 5.352370262145996,
        "learning_rate": 1.7168141592920354e-05,
        "epoch": 1.415929203539823,
        "step": 320
    },
    {
        "loss": 0.5939,
        "grad_norm": 3.644176721572876,
        "learning_rate": 1.7079646017699117e-05,
        "epoch": 1.4601769911504425,
        "step": 330
    },
    {
        "loss": 0.6035,
        "grad_norm": 3.8853464126586914,
        "learning_rate": 1.6991150442477876e-05,
        "epoch": 1.504424778761062,
        "step": 340
    },
    {
        "loss": 0.5869,
        "grad_norm": 3.657442092895508,
        "learning_rate": 1.690265486725664e-05,
        "epoch": 1.5486725663716814,
        "step": 350
    },
    {
        "loss": 0.5437,
        "grad_norm": 3.6297123432159424,
        "learning_rate": 1.68141592920354e-05,
        "epoch": 1.592920353982301,
        "step": 360
    },
    {
        "loss": 0.4984,
        "grad_norm": 3.2319371700286865,
        "learning_rate": 1.672566371681416e-05,
        "epoch": 1.6371681415929205,
        "step": 370
    },
    {
        "loss": 0.4722,
        "grad_norm": 3.538379669189453,
        "learning_rate": 1.663716814159292e-05,
        "epoch": 1.6814159292035398,
        "step": 380
    },
    {
        "loss": 0.6454,
        "grad_norm": 7.649139881134033,
        "learning_rate": 1.6548672566371683e-05,
        "epoch": 1.7256637168141593,
        "step": 390
    },
    {
        "loss": 0.5367,
        "grad_norm": 3.4216763973236084,
        "learning_rate": 1.6460176991150443e-05,
        "epoch": 1.7699115044247788,
        "step": 400
    },
    {
        "loss": 0.5643,
        "grad_norm": 5.4062347412109375,
        "learning_rate": 1.6371681415929206e-05,
        "epoch": 1.8141592920353982,
        "step": 410
    },
    {
        "loss": 0.5433,
        "grad_norm": 4.73309850692749,
        "learning_rate": 1.628318584070797e-05,
        "epoch": 1.8584070796460177,
        "step": 420
    },
    {
        "loss": 0.5503,
        "grad_norm": 5.945583820343018,
        "learning_rate": 1.6194690265486728e-05,
        "epoch": 1.9026548672566372,
        "step": 430
    },
    {
        "loss": 0.5021,
        "grad_norm": 3.9851863384246826,
        "learning_rate": 1.6106194690265487e-05,
        "epoch": 1.9469026548672566,
        "step": 440
    },
    {
        "loss": 0.5162,
        "grad_norm": 10.285449981689453,
        "learning_rate": 1.601769911504425e-05,
        "epoch": 1.991150442477876,
        "step": 450
    },
    {
        "eval_loss": 0.5907337665557861,
        "eval_accuracy": 0.70155,
        "eval_precision": 0.68031,
        "eval_recall": 0.76788,
        "eval_f1": 0.72145,
        "eval_runtime": 29.864,
        "eval_samples_per_second": 60.474,
        "eval_steps_per_second": 3.784,
        "epoch": 2.0,
        "step": 452
    },
    {
        "loss": 0.4528,
        "grad_norm": 5.58422327041626,
        "learning_rate": 1.592920353982301e-05,
        "epoch": 2.0353982300884956,
        "step": 460
    },
    {
        "loss": 0.4373,
        "grad_norm": 10.951345443725586,
        "learning_rate": 1.5840707964601772e-05,
        "epoch": 2.079646017699115,
        "step": 470
    },
    {
        "loss": 0.4454,
        "grad_norm": 6.505581378936768,
        "learning_rate": 1.5752212389380532e-05,
        "epoch": 2.1238938053097347,
        "step": 480
    },
    {
        "loss": 0.3938,
        "grad_norm": 7.773599624633789,
        "learning_rate": 1.5663716814159295e-05,
        "epoch": 2.168141592920354,
        "step": 490
    },
    {
        "loss": 0.4347,
        "grad_norm": 7.251905918121338,
        "learning_rate": 1.5575221238938054e-05,
        "epoch": 2.2123893805309733,
        "step": 500
    },
    {
        "loss": 0.438,
        "grad_norm": 12.90919017791748,
        "learning_rate": 1.5486725663716813e-05,
        "epoch": 2.256637168141593,
        "step": 510
    },
    {
        "loss": 0.4302,
        "grad_norm": 8.148600578308105,
        "learning_rate": 1.5398230088495576e-05,
        "epoch": 2.3008849557522124,
        "step": 520
    },
    {
        "loss": 0.4528,
        "grad_norm": 7.1492085456848145,
        "learning_rate": 1.5309734513274336e-05,
        "epoch": 2.3451327433628317,
        "step": 530
    },
    {
        "loss": 0.4584,
        "grad_norm": 8.95380973815918,
        "learning_rate": 1.5221238938053098e-05,
        "epoch": 2.3893805309734515,
        "step": 540
    },
    {
        "loss": 0.4439,
        "grad_norm": 4.209139823913574,
        "learning_rate": 1.513274336283186e-05,
        "epoch": 2.433628318584071,
        "step": 550
    },
    {
        "loss": 0.4707,
        "grad_norm": 9.008843421936035,
        "learning_rate": 1.5044247787610619e-05,
        "epoch": 2.47787610619469,
        "step": 560
    },
    {
        "loss": 0.3685,
        "grad_norm": 7.091449737548828,
        "learning_rate": 1.4955752212389383e-05,
        "epoch": 2.52212389380531,
        "step": 570
    },
    {
        "loss": 0.5128,
        "grad_norm": 7.470545768737793,
        "learning_rate": 1.4867256637168143e-05,
        "epoch": 2.566371681415929,
        "step": 580
    },
    {
        "loss": 0.4955,
        "grad_norm": 8.086627006530762,
        "learning_rate": 1.4778761061946904e-05,
        "epoch": 2.6106194690265485,
        "step": 590
    },
    {
        "loss": 0.4573,
        "grad_norm": 6.156955242156982,
        "learning_rate": 1.4690265486725665e-05,
        "epoch": 2.6548672566371683,
        "step": 600
    },
    {
        "loss": 0.3243,
        "grad_norm": 6.086957931518555,
        "learning_rate": 1.4601769911504426e-05,
        "epoch": 2.6991150442477876,
        "step": 610
    },
    {
        "loss": 0.4624,
        "grad_norm": 9.618743896484375,
        "learning_rate": 1.4513274336283187e-05,
        "epoch": 2.7433628318584073,
        "step": 620
    },
    {
        "loss": 0.543,
        "grad_norm": 11.4583101272583,
        "learning_rate": 1.4424778761061948e-05,
        "epoch": 2.7876106194690267,
        "step": 630
    },
    {
        "loss": 0.4666,
        "grad_norm": 3.8638975620269775,
        "learning_rate": 1.433628318584071e-05,
        "epoch": 2.831858407079646,
        "step": 640
    },
    {
        "loss": 0.4995,
        "grad_norm": 12.866717338562012,
        "learning_rate": 1.424778761061947e-05,
        "epoch": 2.8761061946902657,
        "step": 650
    },
    {
        "loss": 0.4305,
        "grad_norm": 14.054179191589355,
        "learning_rate": 1.4159292035398232e-05,
        "epoch": 2.920353982300885,
        "step": 660
    },
    {
        "loss": 0.4576,
        "grad_norm": 8.04820442199707,
        "learning_rate": 1.4070796460176991e-05,
        "epoch": 2.9646017699115044,
        "step": 670
    },
    {
        "eval_loss": 0.674240231513977,
        "eval_accuracy": 0.67608,
        "eval_precision": 0.71204,
        "eval_recall": 0.59846,
        "eval_f1": 0.65033,
        "eval_runtime": 29.8399,
        "eval_samples_per_second": 60.523,
        "eval_steps_per_second": 3.787,
        "epoch": 3.0,
        "step": 678
    },
    {
        "loss": 0.4988,
        "grad_norm": 7.680391788482666,
        "learning_rate": 1.3982300884955752e-05,
        "epoch": 3.0088495575221237,
        "step": 680
    },
    {
        "loss": 0.3229,
        "grad_norm": 5.637457847595215,
        "learning_rate": 1.3893805309734513e-05,
        "epoch": 3.0530973451327434,
        "step": 690
    },
    {
        "loss": 0.3046,
        "grad_norm": 12.704851150512695,
        "learning_rate": 1.3805309734513275e-05,
        "epoch": 3.0973451327433628,
        "step": 700
    },
    {
        "loss": 0.3594,
        "grad_norm": 14.674311637878418,
        "learning_rate": 1.3716814159292036e-05,
        "epoch": 3.1415929203539825,
        "step": 710
    },
    {
        "loss": 0.2475,
        "grad_norm": 8.518125534057617,
        "learning_rate": 1.3628318584070797e-05,
        "epoch": 3.185840707964602,
        "step": 720
    },
    {
        "loss": 0.364,
        "grad_norm": 20.990503311157227,
        "learning_rate": 1.353982300884956e-05,
        "epoch": 3.230088495575221,
        "step": 730
    },
    {
        "loss": 0.3823,
        "grad_norm": 17.514488220214844,
        "learning_rate": 1.345132743362832e-05,
        "epoch": 3.274336283185841,
        "step": 740
    },
    {
        "loss": 0.4076,
        "grad_norm": 11.049613952636719,
        "learning_rate": 1.3362831858407082e-05,
        "epoch": 3.3185840707964602,
        "step": 750
    },
    {
        "loss": 0.3025,
        "grad_norm": 9.279314994812012,
        "learning_rate": 1.3274336283185843e-05,
        "epoch": 3.3628318584070795,
        "step": 760
    },
    {
        "loss": 0.3405,
        "grad_norm": 12.739473342895508,
        "learning_rate": 1.3185840707964604e-05,
        "epoch": 3.4070796460176993,
        "step": 770
    },
    {
        "loss": 0.2905,
        "grad_norm": 11.922855377197266,
        "learning_rate": 1.3097345132743363e-05,
        "epoch": 3.4513274336283186,
        "step": 780
    },
    {
        "loss": 0.3407,
        "grad_norm": 15.241058349609375,
        "learning_rate": 1.3008849557522125e-05,
        "epoch": 3.495575221238938,
        "step": 790
    },
    {
        "loss": 0.2772,
        "grad_norm": 13.236101150512695,
        "learning_rate": 1.2920353982300886e-05,
        "epoch": 3.5398230088495577,
        "step": 800
    },
    {
        "loss": 0.336,
        "grad_norm": 12.547592163085938,
        "learning_rate": 1.2831858407079647e-05,
        "epoch": 3.584070796460177,
        "step": 810
    },
    {
        "loss": 0.4069,
        "grad_norm": 19.744070053100586,
        "learning_rate": 1.2743362831858408e-05,
        "epoch": 3.6283185840707963,
        "step": 820
    },
    {
        "loss": 0.3139,
        "grad_norm": 16.622196197509766,
        "learning_rate": 1.2654867256637169e-05,
        "epoch": 3.672566371681416,
        "step": 830
    },
    {
        "loss": 0.3208,
        "grad_norm": 20.79415512084961,
        "learning_rate": 1.256637168141593e-05,
        "epoch": 3.7168141592920354,
        "step": 840
    },
    {
        "loss": 0.3283,
        "grad_norm": 11.099504470825195,
        "learning_rate": 1.2477876106194691e-05,
        "epoch": 3.7610619469026547,
        "step": 850
    },
    {
        "loss": 0.2965,
        "grad_norm": 22.912717819213867,
        "learning_rate": 1.2389380530973452e-05,
        "epoch": 3.8053097345132745,
        "step": 860
    },
    {
        "loss": 0.2714,
        "grad_norm": 4.56047248840332,
        "learning_rate": 1.2300884955752212e-05,
        "epoch": 3.849557522123894,
        "step": 870
    },
    {
        "loss": 0.3246,
        "grad_norm": 15.935495376586914,
        "learning_rate": 1.2212389380530973e-05,
        "epoch": 3.893805309734513,
        "step": 880
    },
    {
        "loss": 0.3236,
        "grad_norm": 17.134119033813477,
        "learning_rate": 1.2123893805309736e-05,
        "epoch": 3.938053097345133,
        "step": 890
    },
    {
        "loss": 0.3271,
        "grad_norm": 7.667174816131592,
        "learning_rate": 1.2035398230088497e-05,
        "epoch": 3.982300884955752,
        "step": 900
    },
    {
        "eval_loss": 0.8211169838905334,
        "eval_accuracy": 0.68605,
        "eval_precision": 0.68791,
        "eval_recall": 0.68867,
        "eval_f1": 0.68829,
        "eval_runtime": 29.8765,
        "eval_samples_per_second": 60.449,
        "eval_steps_per_second": 3.782,
        "epoch": 4.0,
        "step": 904
    },
    {
        "loss": 0.1989,
        "grad_norm": 17.479860305786133,
        "learning_rate": 1.1946902654867258e-05,
        "epoch": 4.0265486725663715,
        "step": 910
    },
    {
        "loss": 0.1252,
        "grad_norm": 15.718963623046875,
        "learning_rate": 1.1858407079646019e-05,
        "epoch": 4.070796460176991,
        "step": 920
    },
    {
        "loss": 0.2001,
        "grad_norm": 20.77357292175293,
        "learning_rate": 1.176991150442478e-05,
        "epoch": 4.115044247787611,
        "step": 930
    },
    {
        "loss": 0.1653,
        "grad_norm": 11.784941673278809,
        "learning_rate": 1.1681415929203541e-05,
        "epoch": 4.15929203539823,
        "step": 940
    },
    {
        "loss": 0.1322,
        "grad_norm": 20.726682662963867,
        "learning_rate": 1.1592920353982302e-05,
        "epoch": 4.20353982300885,
        "step": 950
    },
    {
        "loss": 0.2025,
        "grad_norm": 21.06009292602539,
        "learning_rate": 1.1504424778761064e-05,
        "epoch": 4.247787610619469,
        "step": 960
    },
    {
        "loss": 0.1914,
        "grad_norm": 13.024680137634277,
        "learning_rate": 1.1415929203539825e-05,
        "epoch": 4.292035398230088,
        "step": 970
    },
    {
        "loss": 0.1186,
        "grad_norm": 30.822071075439453,
        "learning_rate": 1.1327433628318584e-05,
        "epoch": 4.336283185840708,
        "step": 980
    },
    {
        "loss": 0.1723,
        "grad_norm": 28.911813735961914,
        "learning_rate": 1.1238938053097345e-05,
        "epoch": 4.380530973451328,
        "step": 990
    },
    {
        "loss": 0.2362,
        "grad_norm": 26.446935653686523,
        "learning_rate": 1.1150442477876106e-05,
        "epoch": 4.424778761061947,
        "step": 1000
    },
    {
        "loss": 0.1835,
        "grad_norm": 36.66255187988281,
        "learning_rate": 1.1061946902654867e-05,
        "epoch": 4.469026548672566,
        "step": 1010
    },
    {
        "loss": 0.1674,
        "grad_norm": 11.941747665405273,
        "learning_rate": 1.0973451327433629e-05,
        "epoch": 4.513274336283186,
        "step": 1020
    },
    {
        "loss": 0.1949,
        "grad_norm": 5.496427059173584,
        "learning_rate": 1.088495575221239e-05,
        "epoch": 4.557522123893805,
        "step": 1030
    },
    {
        "loss": 0.1347,
        "grad_norm": 13.856266975402832,
        "learning_rate": 1.079646017699115e-05,
        "epoch": 4.601769911504425,
        "step": 1040
    },
    {
        "loss": 0.2018,
        "grad_norm": 19.878828048706055,
        "learning_rate": 1.0707964601769914e-05,
        "epoch": 4.646017699115045,
        "step": 1050
    },
    {
        "loss": 0.1758,
        "grad_norm": 24.266109466552734,
        "learning_rate": 1.0619469026548675e-05,
        "epoch": 4.6902654867256635,
        "step": 1060
    },
    {
        "loss": 0.1664,
        "grad_norm": 31.2722110748291,
        "learning_rate": 1.0530973451327436e-05,
        "epoch": 4.734513274336283,
        "step": 1070
    },
    {
        "loss": 0.1936,
        "grad_norm": 20.303678512573242,
        "learning_rate": 1.0442477876106197e-05,
        "epoch": 4.778761061946903,
        "step": 1080
    },
    {
        "loss": 0.2949,
        "grad_norm": 26.12456703186035,
        "learning_rate": 1.0353982300884956e-05,
        "epoch": 4.823008849557522,
        "step": 1090
    },
    {
        "loss": 0.276,
        "grad_norm": 22.0974063873291,
        "learning_rate": 1.0265486725663717e-05,
        "epoch": 4.867256637168142,
        "step": 1100
    },
    {
        "loss": 0.2747,
        "grad_norm": 45.88972473144531,
        "learning_rate": 1.0176991150442479e-05,
        "epoch": 4.911504424778761,
        "step": 1110
    },
    {
        "loss": 0.1654,
        "grad_norm": 13.99993896484375,
        "learning_rate": 1.008849557522124e-05,
        "epoch": 4.95575221238938,
        "step": 1120
    },
    {
        "loss": 0.2328,
        "grad_norm": 48.91421890258789,
        "learning_rate": 1e-05,
        "epoch": 5.0,
        "step": 1130
    },
    {
        "eval_loss": 1.0912891626358032,
        "eval_accuracy": 0.6639,
        "eval_precision": 0.67681,
        "eval_recall": 0.63586,
        "eval_f1": 0.6557,
        "eval_runtime": 29.7744,
        "eval_samples_per_second": 60.656,
        "eval_steps_per_second": 3.795,
        "epoch": 5.0,
        "step": 1130
    },
    {
        "loss": 0.1066,
        "grad_norm": 33.19968032836914,
        "learning_rate": 9.911504424778762e-06,
        "epoch": 5.04424778761062,
        "step": 1140
    },
    {
        "loss": 0.1393,
        "grad_norm": 11.380915641784668,
        "learning_rate": 9.823008849557523e-06,
        "epoch": 5.088495575221239,
        "step": 1150
    },
    {
        "loss": 0.063,
        "grad_norm": 14.411410331726074,
        "learning_rate": 9.734513274336284e-06,
        "epoch": 5.132743362831858,
        "step": 1160
    },
    {
        "loss": 0.2062,
        "grad_norm": 25.078933715820312,
        "learning_rate": 9.646017699115045e-06,
        "epoch": 5.176991150442478,
        "step": 1170
    },
    {
        "loss": 0.0964,
        "grad_norm": 31.523305892944336,
        "learning_rate": 9.557522123893806e-06,
        "epoch": 5.221238938053097,
        "step": 1180
    },
    {
        "loss": 0.0828,
        "grad_norm": 23.064653396606445,
        "learning_rate": 9.469026548672568e-06,
        "epoch": 5.265486725663717,
        "step": 1190
    },
    {
        "loss": 0.0742,
        "grad_norm": 0.5269845128059387,
        "learning_rate": 9.380530973451329e-06,
        "epoch": 5.3097345132743365,
        "step": 1200
    },
    {
        "loss": 0.0761,
        "grad_norm": 2.5561769008636475,
        "learning_rate": 9.29203539823009e-06,
        "epoch": 5.353982300884955,
        "step": 1210
    },
    {
        "loss": 0.1092,
        "grad_norm": 0.6241825222969055,
        "learning_rate": 9.203539823008851e-06,
        "epoch": 5.398230088495575,
        "step": 1220
    },
    {
        "loss": 0.1003,
        "grad_norm": 0.49791744351387024,
        "learning_rate": 9.11504424778761e-06,
        "epoch": 5.442477876106195,
        "step": 1230
    },
    {
        "loss": 0.2219,
        "grad_norm": 16.20440101623535,
        "learning_rate": 9.026548672566371e-06,
        "epoch": 5.486725663716814,
        "step": 1240
    },
    {
        "loss": 0.0885,
        "grad_norm": 1.1427373886108398,
        "learning_rate": 8.938053097345133e-06,
        "epoch": 5.530973451327434,
        "step": 1250
    },
    {
        "loss": 0.1792,
        "grad_norm": 10.80092716217041,
        "learning_rate": 8.849557522123895e-06,
        "epoch": 5.575221238938053,
        "step": 1260
    },
    {
        "loss": 0.1542,
        "grad_norm": 5.028635025024414,
        "learning_rate": 8.761061946902656e-06,
        "epoch": 5.619469026548672,
        "step": 1270
    },
    {
        "loss": 0.1811,
        "grad_norm": 40.9279670715332,
        "learning_rate": 8.672566371681418e-06,
        "epoch": 5.663716814159292,
        "step": 1280
    },
    {
        "loss": 0.1433,
        "grad_norm": 48.853092193603516,
        "learning_rate": 8.584070796460177e-06,
        "epoch": 5.707964601769912,
        "step": 1290
    },
    {
        "loss": 0.1345,
        "grad_norm": 52.00262451171875,
        "learning_rate": 8.495575221238938e-06,
        "epoch": 5.752212389380531,
        "step": 1300
    },
    {
        "loss": 0.0395,
        "grad_norm": 22.994421005249023,
        "learning_rate": 8.4070796460177e-06,
        "epoch": 5.79646017699115,
        "step": 1310
    },
    {
        "loss": 0.1412,
        "grad_norm": 35.23837661743164,
        "learning_rate": 8.31858407079646e-06,
        "epoch": 5.84070796460177,
        "step": 1320
    },
    {
        "loss": 0.0994,
        "grad_norm": 55.43368148803711,
        "learning_rate": 8.230088495575221e-06,
        "epoch": 5.88495575221239,
        "step": 1330
    },
    {
        "loss": 0.1977,
        "grad_norm": 103.77197265625,
        "learning_rate": 8.141592920353984e-06,
        "epoch": 5.929203539823009,
        "step": 1340
    },
    {
        "loss": 0.2072,
        "grad_norm": 18.704360961914062,
        "learning_rate": 8.053097345132744e-06,
        "epoch": 5.9734513274336285,
        "step": 1350
    },
    {
        "eval_loss": 1.741441249847412,
        "eval_accuracy": 0.64507,
        "eval_precision": 0.72483,
        "eval_recall": 0.47525,
        "eval_f1": 0.57409,
        "eval_runtime": 29.818,
        "eval_samples_per_second": 60.567,
        "eval_steps_per_second": 3.79,
        "epoch": 6.0,
        "step": 1356
    },
    {
        "train_runtime": 1283.6572,
        "train_samples_per_second": 28.146,
        "train_steps_per_second": 1.761,
        "total_flos": 2851860729047040.0,
        "train_loss": 0.3758380958991768,
        "epoch": 6.0,
        "step": 1356
    }
]