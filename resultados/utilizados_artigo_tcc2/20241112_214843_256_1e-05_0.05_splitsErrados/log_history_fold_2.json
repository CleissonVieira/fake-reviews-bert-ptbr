[
    {
        "loss": 0.6789,
        "grad_norm": 2.131793737411499,
        "learning_rate": 9.991142604074402e-06,
        "epoch": 0.008857395925597875,
        "step": 10
    },
    {
        "loss": 0.6631,
        "grad_norm": 5.762000560760498,
        "learning_rate": 9.982285208148806e-06,
        "epoch": 0.01771479185119575,
        "step": 20
    },
    {
        "loss": 0.5984,
        "grad_norm": 6.892683506011963,
        "learning_rate": 9.973427812223207e-06,
        "epoch": 0.026572187776793623,
        "step": 30
    },
    {
        "loss": 0.6366,
        "grad_norm": 2.9564208984375,
        "learning_rate": 9.964570416297609e-06,
        "epoch": 0.0354295837023915,
        "step": 40
    },
    {
        "loss": 0.5751,
        "grad_norm": 4.4999775886535645,
        "learning_rate": 9.95571302037201e-06,
        "epoch": 0.04428697962798937,
        "step": 50
    },
    {
        "loss": 0.6068,
        "grad_norm": 8.04454231262207,
        "learning_rate": 9.946855624446414e-06,
        "epoch": 0.053144375553587246,
        "step": 60
    },
    {
        "loss": 0.5874,
        "grad_norm": 8.94214916229248,
        "learning_rate": 9.937998228520815e-06,
        "epoch": 0.06200177147918512,
        "step": 70
    },
    {
        "loss": 0.5792,
        "grad_norm": 3.8758716583251953,
        "learning_rate": 9.929140832595217e-06,
        "epoch": 0.070859167404783,
        "step": 80
    },
    {
        "loss": 0.5902,
        "grad_norm": 14.900107383728027,
        "learning_rate": 9.92028343666962e-06,
        "epoch": 0.07971656333038087,
        "step": 90
    },
    {
        "loss": 0.6005,
        "grad_norm": 5.259378433227539,
        "learning_rate": 9.911426040744022e-06,
        "epoch": 0.08857395925597875,
        "step": 100
    },
    {
        "loss": 0.63,
        "grad_norm": 8.963493347167969,
        "learning_rate": 9.902568644818424e-06,
        "epoch": 0.09743135518157661,
        "step": 110
    },
    {
        "loss": 0.6427,
        "grad_norm": 5.125490665435791,
        "learning_rate": 9.893711248892827e-06,
        "epoch": 0.10628875110717449,
        "step": 120
    },
    {
        "loss": 0.5648,
        "grad_norm": 3.2462940216064453,
        "learning_rate": 9.884853852967229e-06,
        "epoch": 0.11514614703277236,
        "step": 130
    },
    {
        "loss": 0.5861,
        "grad_norm": 5.794442176818848,
        "learning_rate": 9.87599645704163e-06,
        "epoch": 0.12400354295837024,
        "step": 140
    },
    {
        "loss": 0.6146,
        "grad_norm": 7.468832492828369,
        "learning_rate": 9.867139061116032e-06,
        "epoch": 0.1328609388839681,
        "step": 150
    },
    {
        "loss": 0.5299,
        "grad_norm": 5.8229851722717285,
        "learning_rate": 9.858281665190435e-06,
        "epoch": 0.141718334809566,
        "step": 160
    },
    {
        "loss": 0.5194,
        "grad_norm": 2.513643503189087,
        "learning_rate": 9.849424269264837e-06,
        "epoch": 0.15057573073516387,
        "step": 170
    },
    {
        "loss": 0.6023,
        "grad_norm": 6.639659881591797,
        "learning_rate": 9.840566873339238e-06,
        "epoch": 0.15943312666076173,
        "step": 180
    },
    {
        "loss": 0.5434,
        "grad_norm": 8.091670989990234,
        "learning_rate": 9.831709477413642e-06,
        "epoch": 0.1682905225863596,
        "step": 190
    },
    {
        "loss": 0.6685,
        "grad_norm": 5.952939033508301,
        "learning_rate": 9.822852081488043e-06,
        "epoch": 0.1771479185119575,
        "step": 200
    },
    {
        "loss": 0.5515,
        "grad_norm": 4.7633585929870605,
        "learning_rate": 9.813994685562446e-06,
        "epoch": 0.18600531443755536,
        "step": 210
    },
    {
        "loss": 0.6196,
        "grad_norm": 5.440245151519775,
        "learning_rate": 9.805137289636848e-06,
        "epoch": 0.19486271036315322,
        "step": 220
    },
    {
        "loss": 0.5846,
        "grad_norm": 7.133761882781982,
        "learning_rate": 9.79627989371125e-06,
        "epoch": 0.20372010628875112,
        "step": 230
    },
    {
        "loss": 0.5769,
        "grad_norm": 4.412962436676025,
        "learning_rate": 9.787422497785651e-06,
        "epoch": 0.21257750221434898,
        "step": 240
    },
    {
        "loss": 0.6032,
        "grad_norm": 3.5962634086608887,
        "learning_rate": 9.778565101860053e-06,
        "epoch": 0.22143489813994685,
        "step": 250
    },
    {
        "loss": 0.5987,
        "grad_norm": 3.8829681873321533,
        "learning_rate": 9.769707705934456e-06,
        "epoch": 0.23029229406554472,
        "step": 260
    },
    {
        "loss": 0.5804,
        "grad_norm": 4.5063862800598145,
        "learning_rate": 9.760850310008858e-06,
        "epoch": 0.2391496899911426,
        "step": 270
    },
    {
        "loss": 0.6086,
        "grad_norm": 8.11036491394043,
        "learning_rate": 9.751992914083261e-06,
        "epoch": 0.24800708591674048,
        "step": 280
    },
    {
        "loss": 0.6779,
        "grad_norm": 5.939424991607666,
        "learning_rate": 9.743135518157663e-06,
        "epoch": 0.25686448184233834,
        "step": 290
    },
    {
        "loss": 0.5892,
        "grad_norm": 3.434244155883789,
        "learning_rate": 9.734278122232064e-06,
        "epoch": 0.2657218777679362,
        "step": 300
    },
    {
        "loss": 0.5819,
        "grad_norm": 7.290251731872559,
        "learning_rate": 9.725420726306468e-06,
        "epoch": 0.2745792736935341,
        "step": 310
    },
    {
        "loss": 0.6022,
        "grad_norm": 7.44912576675415,
        "learning_rate": 9.71656333038087e-06,
        "epoch": 0.283436669619132,
        "step": 320
    },
    {
        "loss": 0.5471,
        "grad_norm": 4.959347248077393,
        "learning_rate": 9.707705934455271e-06,
        "epoch": 0.29229406554472986,
        "step": 330
    },
    {
        "loss": 0.5339,
        "grad_norm": 5.106931686401367,
        "learning_rate": 9.698848538529672e-06,
        "epoch": 0.30115146147032773,
        "step": 340
    },
    {
        "loss": 0.5358,
        "grad_norm": 4.569788932800293,
        "learning_rate": 9.689991142604076e-06,
        "epoch": 0.3100088573959256,
        "step": 350
    },
    {
        "loss": 0.5494,
        "grad_norm": 9.351371765136719,
        "learning_rate": 9.681133746678477e-06,
        "epoch": 0.31886625332152346,
        "step": 360
    },
    {
        "loss": 0.6334,
        "grad_norm": 5.5718770027160645,
        "learning_rate": 9.672276350752879e-06,
        "epoch": 0.32772364924712133,
        "step": 370
    },
    {
        "loss": 0.5425,
        "grad_norm": 5.2896223068237305,
        "learning_rate": 9.663418954827282e-06,
        "epoch": 0.3365810451727192,
        "step": 380
    },
    {
        "loss": 0.5943,
        "grad_norm": 9.161746978759766,
        "learning_rate": 9.654561558901684e-06,
        "epoch": 0.3454384410983171,
        "step": 390
    },
    {
        "loss": 0.6135,
        "grad_norm": 4.3624444007873535,
        "learning_rate": 9.645704162976086e-06,
        "epoch": 0.354295837023915,
        "step": 400
    },
    {
        "loss": 0.5689,
        "grad_norm": 3.9151461124420166,
        "learning_rate": 9.636846767050489e-06,
        "epoch": 0.36315323294951285,
        "step": 410
    },
    {
        "loss": 0.5426,
        "grad_norm": 5.549218654632568,
        "learning_rate": 9.627989371124889e-06,
        "epoch": 0.3720106288751107,
        "step": 420
    },
    {
        "loss": 0.5647,
        "grad_norm": 2.985955238342285,
        "learning_rate": 9.619131975199292e-06,
        "epoch": 0.3808680248007086,
        "step": 430
    },
    {
        "loss": 0.6218,
        "grad_norm": 3.398746967315674,
        "learning_rate": 9.610274579273694e-06,
        "epoch": 0.38972542072630645,
        "step": 440
    },
    {
        "loss": 0.5976,
        "grad_norm": 2.523197650909424,
        "learning_rate": 9.601417183348097e-06,
        "epoch": 0.3985828166519043,
        "step": 450
    },
    {
        "loss": 0.5762,
        "grad_norm": 2.849853038787842,
        "learning_rate": 9.592559787422499e-06,
        "epoch": 0.40744021257750224,
        "step": 460
    },
    {
        "loss": 0.5314,
        "grad_norm": 3.6043338775634766,
        "learning_rate": 9.5837023914969e-06,
        "epoch": 0.4162976085031001,
        "step": 470
    },
    {
        "loss": 0.582,
        "grad_norm": 7.9370317459106445,
        "learning_rate": 9.574844995571303e-06,
        "epoch": 0.42515500442869797,
        "step": 480
    },
    {
        "loss": 0.5296,
        "grad_norm": 11.94564151763916,
        "learning_rate": 9.565987599645705e-06,
        "epoch": 0.43401240035429584,
        "step": 490
    },
    {
        "loss": 0.5621,
        "grad_norm": 7.087400436401367,
        "learning_rate": 9.557130203720107e-06,
        "epoch": 0.4428697962798937,
        "step": 500
    },
    {
        "loss": 0.4957,
        "grad_norm": 5.256217002868652,
        "learning_rate": 9.54827280779451e-06,
        "epoch": 0.45172719220549157,
        "step": 510
    },
    {
        "loss": 0.5366,
        "grad_norm": 12.75747013092041,
        "learning_rate": 9.539415411868912e-06,
        "epoch": 0.46058458813108943,
        "step": 520
    },
    {
        "loss": 0.5867,
        "grad_norm": 13.79471492767334,
        "learning_rate": 9.530558015943313e-06,
        "epoch": 0.46944198405668736,
        "step": 530
    },
    {
        "loss": 0.6244,
        "grad_norm": 23.513795852661133,
        "learning_rate": 9.521700620017715e-06,
        "epoch": 0.4782993799822852,
        "step": 540
    },
    {
        "loss": 0.5733,
        "grad_norm": 19.885007858276367,
        "learning_rate": 9.512843224092118e-06,
        "epoch": 0.4871567759078831,
        "step": 550
    },
    {
        "loss": 0.5235,
        "grad_norm": 5.390566349029541,
        "learning_rate": 9.50398582816652e-06,
        "epoch": 0.49601417183348095,
        "step": 560
    },
    {
        "loss": 0.5676,
        "grad_norm": 5.183101177215576,
        "learning_rate": 9.495128432240921e-06,
        "epoch": 0.5048715677590788,
        "step": 570
    },
    {
        "loss": 0.5981,
        "grad_norm": 8.229988098144531,
        "learning_rate": 9.486271036315325e-06,
        "epoch": 0.5137289636846767,
        "step": 580
    },
    {
        "loss": 0.5617,
        "grad_norm": 7.08094596862793,
        "learning_rate": 9.477413640389726e-06,
        "epoch": 0.5225863596102746,
        "step": 590
    },
    {
        "loss": 0.5376,
        "grad_norm": 4.088123798370361,
        "learning_rate": 9.46855624446413e-06,
        "epoch": 0.5314437555358724,
        "step": 600
    },
    {
        "loss": 0.523,
        "grad_norm": 7.651963710784912,
        "learning_rate": 9.45969884853853e-06,
        "epoch": 0.5403011514614703,
        "step": 610
    },
    {
        "loss": 0.4507,
        "grad_norm": 5.620057582855225,
        "learning_rate": 9.450841452612933e-06,
        "epoch": 0.5491585473870682,
        "step": 620
    },
    {
        "loss": 0.5701,
        "grad_norm": 7.997212886810303,
        "learning_rate": 9.441984056687334e-06,
        "epoch": 0.5580159433126661,
        "step": 630
    },
    {
        "loss": 0.5167,
        "grad_norm": 6.782510757446289,
        "learning_rate": 9.433126660761736e-06,
        "epoch": 0.566873339238264,
        "step": 640
    },
    {
        "loss": 0.4809,
        "grad_norm": 8.52464771270752,
        "learning_rate": 9.42426926483614e-06,
        "epoch": 0.5757307351638619,
        "step": 650
    },
    {
        "loss": 0.5854,
        "grad_norm": 9.209430694580078,
        "learning_rate": 9.415411868910541e-06,
        "epoch": 0.5845881310894597,
        "step": 660
    },
    {
        "loss": 0.5257,
        "grad_norm": 5.522932052612305,
        "learning_rate": 9.406554472984944e-06,
        "epoch": 0.5934455270150576,
        "step": 670
    },
    {
        "loss": 0.4734,
        "grad_norm": 11.096184730529785,
        "learning_rate": 9.397697077059346e-06,
        "epoch": 0.6023029229406555,
        "step": 680
    },
    {
        "loss": 0.6457,
        "grad_norm": 8.428594589233398,
        "learning_rate": 9.388839681133747e-06,
        "epoch": 0.6111603188662533,
        "step": 690
    },
    {
        "loss": 0.536,
        "grad_norm": 6.548008441925049,
        "learning_rate": 9.379982285208149e-06,
        "epoch": 0.6200177147918512,
        "step": 700
    },
    {
        "loss": 0.6405,
        "grad_norm": 4.198294639587402,
        "learning_rate": 9.37112488928255e-06,
        "epoch": 0.6288751107174491,
        "step": 710
    },
    {
        "loss": 0.5145,
        "grad_norm": 4.2086591720581055,
        "learning_rate": 9.362267493356954e-06,
        "epoch": 0.6377325066430469,
        "step": 720
    },
    {
        "loss": 0.4813,
        "grad_norm": 3.2767539024353027,
        "learning_rate": 9.353410097431356e-06,
        "epoch": 0.6465899025686448,
        "step": 730
    },
    {
        "loss": 0.5324,
        "grad_norm": 12.705453872680664,
        "learning_rate": 9.344552701505759e-06,
        "epoch": 0.6554472984942427,
        "step": 740
    },
    {
        "loss": 0.5908,
        "grad_norm": 22.23560905456543,
        "learning_rate": 9.33569530558016e-06,
        "epoch": 0.6643046944198405,
        "step": 750
    },
    {
        "loss": 0.5172,
        "grad_norm": 8.260805130004883,
        "learning_rate": 9.326837909654562e-06,
        "epoch": 0.6731620903454384,
        "step": 760
    },
    {
        "loss": 0.5539,
        "grad_norm": 7.0547709465026855,
        "learning_rate": 9.317980513728965e-06,
        "epoch": 0.6820194862710364,
        "step": 770
    },
    {
        "loss": 0.5021,
        "grad_norm": 5.63179349899292,
        "learning_rate": 9.309123117803367e-06,
        "epoch": 0.6908768821966342,
        "step": 780
    },
    {
        "loss": 0.4756,
        "grad_norm": 6.874839782714844,
        "learning_rate": 9.300265721877769e-06,
        "epoch": 0.6997342781222321,
        "step": 790
    },
    {
        "loss": 0.4864,
        "grad_norm": 14.653729438781738,
        "learning_rate": 9.29140832595217e-06,
        "epoch": 0.70859167404783,
        "step": 800
    },
    {
        "loss": 0.5862,
        "grad_norm": 6.754891395568848,
        "learning_rate": 9.282550930026572e-06,
        "epoch": 0.7174490699734278,
        "step": 810
    },
    {
        "loss": 0.574,
        "grad_norm": 5.133734703063965,
        "learning_rate": 9.273693534100975e-06,
        "epoch": 0.7263064658990257,
        "step": 820
    },
    {
        "loss": 0.5207,
        "grad_norm": 9.1597318649292,
        "learning_rate": 9.264836138175377e-06,
        "epoch": 0.7351638618246236,
        "step": 830
    },
    {
        "loss": 0.5112,
        "grad_norm": 13.956146240234375,
        "learning_rate": 9.25597874224978e-06,
        "epoch": 0.7440212577502214,
        "step": 840
    },
    {
        "loss": 0.5352,
        "grad_norm": 4.7061028480529785,
        "learning_rate": 9.247121346324182e-06,
        "epoch": 0.7528786536758193,
        "step": 850
    },
    {
        "loss": 0.482,
        "grad_norm": 10.501891136169434,
        "learning_rate": 9.238263950398583e-06,
        "epoch": 0.7617360496014172,
        "step": 860
    },
    {
        "loss": 0.5459,
        "grad_norm": 9.753889083862305,
        "learning_rate": 9.229406554472987e-06,
        "epoch": 0.770593445527015,
        "step": 870
    },
    {
        "loss": 0.4995,
        "grad_norm": 9.370018005371094,
        "learning_rate": 9.220549158547388e-06,
        "epoch": 0.7794508414526129,
        "step": 880
    },
    {
        "loss": 0.5158,
        "grad_norm": 8.272852897644043,
        "learning_rate": 9.21169176262179e-06,
        "epoch": 0.7883082373782108,
        "step": 890
    },
    {
        "loss": 0.499,
        "grad_norm": 5.8227620124816895,
        "learning_rate": 9.202834366696191e-06,
        "epoch": 0.7971656333038086,
        "step": 900
    },
    {
        "loss": 0.5175,
        "grad_norm": 15.441286087036133,
        "learning_rate": 9.193976970770595e-06,
        "epoch": 0.8060230292294066,
        "step": 910
    },
    {
        "loss": 0.4596,
        "grad_norm": 9.170910835266113,
        "learning_rate": 9.185119574844996e-06,
        "epoch": 0.8148804251550045,
        "step": 920
    },
    {
        "loss": 0.5264,
        "grad_norm": 11.007050514221191,
        "learning_rate": 9.176262178919398e-06,
        "epoch": 0.8237378210806023,
        "step": 930
    },
    {
        "loss": 0.4751,
        "grad_norm": 11.08064079284668,
        "learning_rate": 9.167404782993801e-06,
        "epoch": 0.8325952170062002,
        "step": 940
    },
    {
        "loss": 0.4726,
        "grad_norm": 8.671485900878906,
        "learning_rate": 9.158547387068203e-06,
        "epoch": 0.8414526129317981,
        "step": 950
    },
    {
        "loss": 0.5151,
        "grad_norm": 7.593786239624023,
        "learning_rate": 9.149689991142604e-06,
        "epoch": 0.8503100088573959,
        "step": 960
    },
    {
        "loss": 0.4552,
        "grad_norm": 6.784701824188232,
        "learning_rate": 9.140832595217008e-06,
        "epoch": 0.8591674047829938,
        "step": 970
    },
    {
        "loss": 0.489,
        "grad_norm": 6.325350761413574,
        "learning_rate": 9.13197519929141e-06,
        "epoch": 0.8680248007085917,
        "step": 980
    },
    {
        "loss": 0.4335,
        "grad_norm": 11.914634704589844,
        "learning_rate": 9.123117803365811e-06,
        "epoch": 0.8768821966341895,
        "step": 990
    },
    {
        "loss": 0.4593,
        "grad_norm": 9.83838939666748,
        "learning_rate": 9.114260407440213e-06,
        "epoch": 0.8857395925597874,
        "step": 1000
    },
    {
        "loss": 0.4168,
        "grad_norm": 8.116704940795898,
        "learning_rate": 9.105403011514616e-06,
        "epoch": 0.8945969884853853,
        "step": 1010
    },
    {
        "loss": 0.4131,
        "grad_norm": 17.705322265625,
        "learning_rate": 9.096545615589017e-06,
        "epoch": 0.9034543844109831,
        "step": 1020
    },
    {
        "loss": 0.4928,
        "grad_norm": 26.747034072875977,
        "learning_rate": 9.087688219663419e-06,
        "epoch": 0.912311780336581,
        "step": 1030
    },
    {
        "loss": 0.5366,
        "grad_norm": 22.771488189697266,
        "learning_rate": 9.078830823737822e-06,
        "epoch": 0.9211691762621789,
        "step": 1040
    },
    {
        "loss": 0.4457,
        "grad_norm": 6.348330020904541,
        "learning_rate": 9.069973427812224e-06,
        "epoch": 0.9300265721877768,
        "step": 1050
    },
    {
        "loss": 0.5548,
        "grad_norm": 24.241098403930664,
        "learning_rate": 9.061116031886627e-06,
        "epoch": 0.9388839681133747,
        "step": 1060
    },
    {
        "loss": 0.4176,
        "grad_norm": 5.44514274597168,
        "learning_rate": 9.052258635961029e-06,
        "epoch": 0.9477413640389726,
        "step": 1070
    },
    {
        "loss": 0.4137,
        "grad_norm": 21.783733367919922,
        "learning_rate": 9.04340124003543e-06,
        "epoch": 0.9565987599645704,
        "step": 1080
    },
    {
        "loss": 0.512,
        "grad_norm": 15.460172653198242,
        "learning_rate": 9.034543844109832e-06,
        "epoch": 0.9654561558901683,
        "step": 1090
    },
    {
        "loss": 0.4547,
        "grad_norm": 16.605661392211914,
        "learning_rate": 9.025686448184234e-06,
        "epoch": 0.9743135518157662,
        "step": 1100
    },
    {
        "loss": 0.4904,
        "grad_norm": 12.09757137298584,
        "learning_rate": 9.016829052258637e-06,
        "epoch": 0.983170947741364,
        "step": 1110
    },
    {
        "loss": 0.4737,
        "grad_norm": 23.324920654296875,
        "learning_rate": 9.007971656333039e-06,
        "epoch": 0.9920283436669619,
        "step": 1120
    },
    {
        "eval_loss": 0.4190616309642792,
        "eval_accuracy": 0.82584,
        "eval_precision": 0.81625,
        "eval_recall": 0.84101,
        "eval_f1": 0.82844,
        "eval_runtime": 149.4965,
        "eval_samples_per_second": 60.416,
        "eval_steps_per_second": 3.779,
        "epoch": 1.0,
        "step": 1129
    },
    {
        "loss": 0.4629,
        "grad_norm": 11.000929832458496,
        "learning_rate": 8.999114260407442e-06,
        "epoch": 1.0008857395925599,
        "step": 1130
    },
    {
        "loss": 0.4433,
        "grad_norm": 14.248015403747559,
        "learning_rate": 8.990256864481844e-06,
        "epoch": 1.0097431355181576,
        "step": 1140
    },
    {
        "loss": 0.3879,
        "grad_norm": 13.393694877624512,
        "learning_rate": 8.981399468556245e-06,
        "epoch": 1.0186005314437556,
        "step": 1150
    },
    {
        "loss": 0.3812,
        "grad_norm": 33.05775833129883,
        "learning_rate": 8.972542072630648e-06,
        "epoch": 1.0274579273693534,
        "step": 1160
    },
    {
        "loss": 0.4926,
        "grad_norm": 18.69073486328125,
        "learning_rate": 8.963684676705048e-06,
        "epoch": 1.0363153232949514,
        "step": 1170
    },
    {
        "loss": 0.3381,
        "grad_norm": 10.921982765197754,
        "learning_rate": 8.954827280779452e-06,
        "epoch": 1.045172719220549,
        "step": 1180
    },
    {
        "loss": 0.3975,
        "grad_norm": 17.18718910217285,
        "learning_rate": 8.945969884853853e-06,
        "epoch": 1.054030115146147,
        "step": 1190
    },
    {
        "loss": 0.4139,
        "grad_norm": 16.512508392333984,
        "learning_rate": 8.937112488928255e-06,
        "epoch": 1.0628875110717448,
        "step": 1200
    },
    {
        "loss": 0.4501,
        "grad_norm": 16.834186553955078,
        "learning_rate": 8.928255093002658e-06,
        "epoch": 1.0717449069973428,
        "step": 1210
    },
    {
        "loss": 0.3688,
        "grad_norm": 6.8630852699279785,
        "learning_rate": 8.91939769707706e-06,
        "epoch": 1.0806023029229406,
        "step": 1220
    },
    {
        "loss": 0.3582,
        "grad_norm": 11.670074462890625,
        "learning_rate": 8.910540301151463e-06,
        "epoch": 1.0894596988485385,
        "step": 1230
    },
    {
        "loss": 0.3632,
        "grad_norm": 18.846759796142578,
        "learning_rate": 8.901682905225865e-06,
        "epoch": 1.0983170947741363,
        "step": 1240
    },
    {
        "loss": 0.3241,
        "grad_norm": 18.4102783203125,
        "learning_rate": 8.892825509300266e-06,
        "epoch": 1.1071744906997343,
        "step": 1250
    },
    {
        "loss": 0.3384,
        "grad_norm": 24.8637752532959,
        "learning_rate": 8.883968113374668e-06,
        "epoch": 1.1160318866253323,
        "step": 1260
    },
    {
        "loss": 0.4553,
        "grad_norm": 17.248661041259766,
        "learning_rate": 8.87511071744907e-06,
        "epoch": 1.12488928255093,
        "step": 1270
    },
    {
        "loss": 0.3887,
        "grad_norm": 16.675838470458984,
        "learning_rate": 8.866253321523473e-06,
        "epoch": 1.133746678476528,
        "step": 1280
    },
    {
        "loss": 0.4801,
        "grad_norm": 24.54753875732422,
        "learning_rate": 8.857395925597874e-06,
        "epoch": 1.1426040744021257,
        "step": 1290
    },
    {
        "loss": 0.3473,
        "grad_norm": 24.20963478088379,
        "learning_rate": 8.848538529672278e-06,
        "epoch": 1.1514614703277237,
        "step": 1300
    },
    {
        "loss": 0.4052,
        "grad_norm": 18.784801483154297,
        "learning_rate": 8.83968113374668e-06,
        "epoch": 1.1603188662533215,
        "step": 1310
    },
    {
        "loss": 0.4086,
        "grad_norm": 16.15940284729004,
        "learning_rate": 8.830823737821081e-06,
        "epoch": 1.1691762621789195,
        "step": 1320
    },
    {
        "loss": 0.4401,
        "grad_norm": 6.136381149291992,
        "learning_rate": 8.821966341895484e-06,
        "epoch": 1.1780336581045172,
        "step": 1330
    },
    {
        "loss": 0.3968,
        "grad_norm": 17.920608520507812,
        "learning_rate": 8.813108945969886e-06,
        "epoch": 1.1868910540301152,
        "step": 1340
    },
    {
        "loss": 0.429,
        "grad_norm": 25.65110206604004,
        "learning_rate": 8.804251550044287e-06,
        "epoch": 1.195748449955713,
        "step": 1350
    },
    {
        "loss": 0.3341,
        "grad_norm": 42.8504524230957,
        "learning_rate": 8.795394154118689e-06,
        "epoch": 1.204605845881311,
        "step": 1360
    },
    {
        "loss": 0.3337,
        "grad_norm": 16.585596084594727,
        "learning_rate": 8.786536758193092e-06,
        "epoch": 1.2134632418069087,
        "step": 1370
    },
    {
        "loss": 0.3591,
        "grad_norm": 20.04253387451172,
        "learning_rate": 8.777679362267494e-06,
        "epoch": 1.2223206377325067,
        "step": 1380
    },
    {
        "loss": 0.3924,
        "grad_norm": 17.073686599731445,
        "learning_rate": 8.768821966341896e-06,
        "epoch": 1.2311780336581046,
        "step": 1390
    },
    {
        "loss": 0.4754,
        "grad_norm": 12.025830268859863,
        "learning_rate": 8.759964570416299e-06,
        "epoch": 1.2400354295837024,
        "step": 1400
    },
    {
        "loss": 0.3375,
        "grad_norm": 33.67641067504883,
        "learning_rate": 8.7511071744907e-06,
        "epoch": 1.2488928255093001,
        "step": 1410
    },
    {
        "loss": 0.4324,
        "grad_norm": 30.241832733154297,
        "learning_rate": 8.742249778565102e-06,
        "epoch": 1.2577502214348981,
        "step": 1420
    },
    {
        "loss": 0.2765,
        "grad_norm": 18.530981063842773,
        "learning_rate": 8.733392382639505e-06,
        "epoch": 1.266607617360496,
        "step": 1430
    },
    {
        "loss": 0.3325,
        "grad_norm": 20.602935791015625,
        "learning_rate": 8.724534986713907e-06,
        "epoch": 1.2754650132860939,
        "step": 1440
    },
    {
        "loss": 0.3358,
        "grad_norm": 35.093082427978516,
        "learning_rate": 8.715677590788309e-06,
        "epoch": 1.2843224092116918,
        "step": 1450
    },
    {
        "loss": 0.3323,
        "grad_norm": 17.26580810546875,
        "learning_rate": 8.70682019486271e-06,
        "epoch": 1.2931798051372896,
        "step": 1460
    },
    {
        "loss": 0.3991,
        "grad_norm": 16.208213806152344,
        "learning_rate": 8.697962798937114e-06,
        "epoch": 1.3020372010628876,
        "step": 1470
    },
    {
        "loss": 0.3418,
        "grad_norm": 28.077096939086914,
        "learning_rate": 8.689105403011515e-06,
        "epoch": 1.3108945969884853,
        "step": 1480
    },
    {
        "loss": 0.3881,
        "grad_norm": 10.115863800048828,
        "learning_rate": 8.680248007085917e-06,
        "epoch": 1.3197519929140833,
        "step": 1490
    },
    {
        "loss": 0.407,
        "grad_norm": 25.39185905456543,
        "learning_rate": 8.67139061116032e-06,
        "epoch": 1.328609388839681,
        "step": 1500
    },
    {
        "loss": 0.3058,
        "grad_norm": 18.845123291015625,
        "learning_rate": 8.662533215234722e-06,
        "epoch": 1.337466784765279,
        "step": 1510
    },
    {
        "loss": 0.4073,
        "grad_norm": 13.142386436462402,
        "learning_rate": 8.653675819309125e-06,
        "epoch": 1.346324180690877,
        "step": 1520
    },
    {
        "loss": 0.3075,
        "grad_norm": 19.478099822998047,
        "learning_rate": 8.644818423383527e-06,
        "epoch": 1.3551815766164748,
        "step": 1530
    },
    {
        "loss": 0.4051,
        "grad_norm": 22.59376335144043,
        "learning_rate": 8.635961027457928e-06,
        "epoch": 1.3640389725420725,
        "step": 1540
    },
    {
        "loss": 0.2776,
        "grad_norm": 21.86456298828125,
        "learning_rate": 8.62710363153233e-06,
        "epoch": 1.3728963684676705,
        "step": 1550
    },
    {
        "loss": 0.3386,
        "grad_norm": 36.098838806152344,
        "learning_rate": 8.618246235606731e-06,
        "epoch": 1.3817537643932685,
        "step": 1560
    },
    {
        "loss": 0.243,
        "grad_norm": 27.18753433227539,
        "learning_rate": 8.609388839681135e-06,
        "epoch": 1.3906111603188662,
        "step": 1570
    },
    {
        "loss": 0.2803,
        "grad_norm": 23.507081985473633,
        "learning_rate": 8.600531443755536e-06,
        "epoch": 1.3994685562444642,
        "step": 1580
    },
    {
        "loss": 0.3286,
        "grad_norm": 15.694595336914062,
        "learning_rate": 8.591674047829938e-06,
        "epoch": 1.408325952170062,
        "step": 1590
    },
    {
        "loss": 0.3661,
        "grad_norm": 35.96022415161133,
        "learning_rate": 8.582816651904341e-06,
        "epoch": 1.41718334809566,
        "step": 1600
    },
    {
        "loss": 0.4389,
        "grad_norm": 32.600074768066406,
        "learning_rate": 8.573959255978743e-06,
        "epoch": 1.4260407440212577,
        "step": 1610
    },
    {
        "loss": 0.3805,
        "grad_norm": 6.709097862243652,
        "learning_rate": 8.565101860053146e-06,
        "epoch": 1.4348981399468557,
        "step": 1620
    },
    {
        "loss": 0.366,
        "grad_norm": 13.584232330322266,
        "learning_rate": 8.556244464127548e-06,
        "epoch": 1.4437555358724534,
        "step": 1630
    },
    {
        "loss": 0.2444,
        "grad_norm": 22.36233901977539,
        "learning_rate": 8.54738706820195e-06,
        "epoch": 1.4526129317980514,
        "step": 1640
    },
    {
        "loss": 0.4784,
        "grad_norm": 22.35277557373047,
        "learning_rate": 8.538529672276351e-06,
        "epoch": 1.4614703277236494,
        "step": 1650
    },
    {
        "loss": 0.3371,
        "grad_norm": 12.623096466064453,
        "learning_rate": 8.529672276350753e-06,
        "epoch": 1.4703277236492471,
        "step": 1660
    },
    {
        "loss": 0.3024,
        "grad_norm": 9.770956039428711,
        "learning_rate": 8.520814880425156e-06,
        "epoch": 1.4791851195748449,
        "step": 1670
    },
    {
        "loss": 0.3333,
        "grad_norm": 24.436670303344727,
        "learning_rate": 8.511957484499558e-06,
        "epoch": 1.4880425155004429,
        "step": 1680
    },
    {
        "loss": 0.3125,
        "grad_norm": 21.73771858215332,
        "learning_rate": 8.50310008857396e-06,
        "epoch": 1.4968999114260408,
        "step": 1690
    },
    {
        "loss": 0.3107,
        "grad_norm": 44.285030364990234,
        "learning_rate": 8.494242692648362e-06,
        "epoch": 1.5057573073516386,
        "step": 1700
    },
    {
        "loss": 0.4182,
        "grad_norm": 33.45600509643555,
        "learning_rate": 8.485385296722764e-06,
        "epoch": 1.5146147032772364,
        "step": 1710
    },
    {
        "loss": 0.3409,
        "grad_norm": 16.88319969177246,
        "learning_rate": 8.476527900797167e-06,
        "epoch": 1.5234720992028343,
        "step": 1720
    },
    {
        "loss": 0.3188,
        "grad_norm": 16.837194442749023,
        "learning_rate": 8.467670504871567e-06,
        "epoch": 1.5323294951284323,
        "step": 1730
    },
    {
        "loss": 0.2947,
        "grad_norm": 5.660601615905762,
        "learning_rate": 8.45881310894597e-06,
        "epoch": 1.54118689105403,
        "step": 1740
    },
    {
        "loss": 0.3249,
        "grad_norm": 13.630049705505371,
        "learning_rate": 8.449955713020372e-06,
        "epoch": 1.550044286979628,
        "step": 1750
    },
    {
        "loss": 0.3927,
        "grad_norm": 25.037771224975586,
        "learning_rate": 8.441098317094775e-06,
        "epoch": 1.5589016829052258,
        "step": 1760
    },
    {
        "loss": 0.3038,
        "grad_norm": 15.963958740234375,
        "learning_rate": 8.432240921169177e-06,
        "epoch": 1.5677590788308238,
        "step": 1770
    },
    {
        "loss": 0.444,
        "grad_norm": 16.163124084472656,
        "learning_rate": 8.423383525243579e-06,
        "epoch": 1.5766164747564217,
        "step": 1780
    },
    {
        "loss": 0.3281,
        "grad_norm": 7.017532825469971,
        "learning_rate": 8.414526129317982e-06,
        "epoch": 1.5854738706820195,
        "step": 1790
    },
    {
        "loss": 0.2867,
        "grad_norm": 8.802480697631836,
        "learning_rate": 8.405668733392384e-06,
        "epoch": 1.5943312666076173,
        "step": 1800
    },
    {
        "loss": 0.2906,
        "grad_norm": 7.8817138671875,
        "learning_rate": 8.396811337466785e-06,
        "epoch": 1.6031886625332152,
        "step": 1810
    },
    {
        "loss": 0.2966,
        "grad_norm": 11.603353500366211,
        "learning_rate": 8.387953941541187e-06,
        "epoch": 1.6120460584588132,
        "step": 1820
    },
    {
        "loss": 0.2996,
        "grad_norm": 11.501582145690918,
        "learning_rate": 8.37909654561559e-06,
        "epoch": 1.620903454384411,
        "step": 1830
    },
    {
        "loss": 0.2854,
        "grad_norm": 8.211430549621582,
        "learning_rate": 8.370239149689992e-06,
        "epoch": 1.6297608503100087,
        "step": 1840
    },
    {
        "loss": 0.3938,
        "grad_norm": 10.39229965209961,
        "learning_rate": 8.361381753764393e-06,
        "epoch": 1.6386182462356067,
        "step": 1850
    },
    {
        "loss": 0.3847,
        "grad_norm": 29.414413452148438,
        "learning_rate": 8.352524357838797e-06,
        "epoch": 1.6474756421612047,
        "step": 1860
    },
    {
        "loss": 0.2555,
        "grad_norm": 11.721184730529785,
        "learning_rate": 8.343666961913198e-06,
        "epoch": 1.6563330380868024,
        "step": 1870
    },
    {
        "loss": 0.3278,
        "grad_norm": 30.3521785736084,
        "learning_rate": 8.3348095659876e-06,
        "epoch": 1.6651904340124002,
        "step": 1880
    },
    {
        "loss": 0.3472,
        "grad_norm": 10.936179161071777,
        "learning_rate": 8.325952170062003e-06,
        "epoch": 1.6740478299379982,
        "step": 1890
    },
    {
        "loss": 0.3501,
        "grad_norm": 20.83977699279785,
        "learning_rate": 8.317094774136405e-06,
        "epoch": 1.6829052258635961,
        "step": 1900
    },
    {
        "loss": 0.2525,
        "grad_norm": 17.30182647705078,
        "learning_rate": 8.308237378210808e-06,
        "epoch": 1.6917626217891941,
        "step": 1910
    },
    {
        "loss": 0.3286,
        "grad_norm": 23.186338424682617,
        "learning_rate": 8.299379982285208e-06,
        "epoch": 1.7006200177147919,
        "step": 1920
    },
    {
        "loss": 0.2274,
        "grad_norm": 20.528362274169922,
        "learning_rate": 8.290522586359611e-06,
        "epoch": 1.7094774136403896,
        "step": 1930
    },
    {
        "loss": 0.3161,
        "grad_norm": 23.576148986816406,
        "learning_rate": 8.281665190434013e-06,
        "epoch": 1.7183348095659876,
        "step": 1940
    },
    {
        "loss": 0.3517,
        "grad_norm": 41.90971755981445,
        "learning_rate": 8.272807794508414e-06,
        "epoch": 1.7271922054915856,
        "step": 1950
    },
    {
        "loss": 0.2496,
        "grad_norm": 11.908696174621582,
        "learning_rate": 8.263950398582818e-06,
        "epoch": 1.7360496014171833,
        "step": 1960
    },
    {
        "loss": 0.2521,
        "grad_norm": 16.710628509521484,
        "learning_rate": 8.25509300265722e-06,
        "epoch": 1.744906997342781,
        "step": 1970
    },
    {
        "loss": 0.3957,
        "grad_norm": 39.6743049621582,
        "learning_rate": 8.246235606731621e-06,
        "epoch": 1.753764393268379,
        "step": 1980
    },
    {
        "loss": 0.3332,
        "grad_norm": 23.404396057128906,
        "learning_rate": 8.237378210806024e-06,
        "epoch": 1.762621789193977,
        "step": 1990
    },
    {
        "loss": 0.2781,
        "grad_norm": 3.0074076652526855,
        "learning_rate": 8.228520814880426e-06,
        "epoch": 1.7714791851195748,
        "step": 2000
    },
    {
        "loss": 0.269,
        "grad_norm": 39.83864974975586,
        "learning_rate": 8.219663418954828e-06,
        "epoch": 1.7803365810451726,
        "step": 2010
    },
    {
        "loss": 0.3257,
        "grad_norm": 46.11489486694336,
        "learning_rate": 8.210806023029229e-06,
        "epoch": 1.7891939769707705,
        "step": 2020
    },
    {
        "loss": 0.3076,
        "grad_norm": 11.920884132385254,
        "learning_rate": 8.201948627103632e-06,
        "epoch": 1.7980513728963685,
        "step": 2030
    },
    {
        "loss": 0.237,
        "grad_norm": 18.27501678466797,
        "learning_rate": 8.193091231178034e-06,
        "epoch": 1.8069087688219665,
        "step": 2040
    },
    {
        "loss": 0.3226,
        "grad_norm": 18.685426712036133,
        "learning_rate": 8.184233835252436e-06,
        "epoch": 1.8157661647475642,
        "step": 2050
    },
    {
        "loss": 0.3654,
        "grad_norm": 17.991756439208984,
        "learning_rate": 8.175376439326839e-06,
        "epoch": 1.824623560673162,
        "step": 2060
    },
    {
        "loss": 0.2211,
        "grad_norm": 11.52173900604248,
        "learning_rate": 8.16651904340124e-06,
        "epoch": 1.83348095659876,
        "step": 2070
    },
    {
        "loss": 0.3325,
        "grad_norm": 16.99673080444336,
        "learning_rate": 8.157661647475644e-06,
        "epoch": 1.842338352524358,
        "step": 2080
    },
    {
        "loss": 0.3137,
        "grad_norm": 22.153621673583984,
        "learning_rate": 8.148804251550045e-06,
        "epoch": 1.8511957484499557,
        "step": 2090
    },
    {
        "loss": 0.2756,
        "grad_norm": 38.457489013671875,
        "learning_rate": 8.139946855624447e-06,
        "epoch": 1.8600531443755535,
        "step": 2100
    },
    {
        "loss": 0.2568,
        "grad_norm": 15.562655448913574,
        "learning_rate": 8.131089459698849e-06,
        "epoch": 1.8689105403011514,
        "step": 2110
    },
    {
        "loss": 0.245,
        "grad_norm": 7.610385417938232,
        "learning_rate": 8.12223206377325e-06,
        "epoch": 1.8777679362267494,
        "step": 2120
    },
    {
        "loss": 0.3385,
        "grad_norm": 29.676918029785156,
        "learning_rate": 8.113374667847654e-06,
        "epoch": 1.8866253321523472,
        "step": 2130
    },
    {
        "loss": 0.2374,
        "grad_norm": 27.525833129882812,
        "learning_rate": 8.104517271922055e-06,
        "epoch": 1.895482728077945,
        "step": 2140
    },
    {
        "loss": 0.3203,
        "grad_norm": 37.322776794433594,
        "learning_rate": 8.095659875996459e-06,
        "epoch": 1.904340124003543,
        "step": 2150
    },
    {
        "loss": 0.3385,
        "grad_norm": 27.588794708251953,
        "learning_rate": 8.08680248007086e-06,
        "epoch": 1.9131975199291409,
        "step": 2160
    },
    {
        "loss": 0.3233,
        "grad_norm": 15.594470024108887,
        "learning_rate": 8.077945084145262e-06,
        "epoch": 1.9220549158547389,
        "step": 2170
    },
    {
        "loss": 0.262,
        "grad_norm": 33.9783821105957,
        "learning_rate": 8.069087688219665e-06,
        "epoch": 1.9309123117803366,
        "step": 2180
    },
    {
        "loss": 0.2576,
        "grad_norm": 18.620954513549805,
        "learning_rate": 8.060230292294067e-06,
        "epoch": 1.9397697077059344,
        "step": 2190
    },
    {
        "loss": 0.2337,
        "grad_norm": 16.97373390197754,
        "learning_rate": 8.051372896368468e-06,
        "epoch": 1.9486271036315324,
        "step": 2200
    },
    {
        "loss": 0.3357,
        "grad_norm": 40.7059440612793,
        "learning_rate": 8.04251550044287e-06,
        "epoch": 1.9574844995571303,
        "step": 2210
    },
    {
        "loss": 0.2439,
        "grad_norm": 20.437021255493164,
        "learning_rate": 8.033658104517273e-06,
        "epoch": 1.966341895482728,
        "step": 2220
    },
    {
        "loss": 0.2968,
        "grad_norm": 22.951244354248047,
        "learning_rate": 8.024800708591675e-06,
        "epoch": 1.9751992914083258,
        "step": 2230
    },
    {
        "loss": 0.2756,
        "grad_norm": 29.30205535888672,
        "learning_rate": 8.015943312666076e-06,
        "epoch": 1.9840566873339238,
        "step": 2240
    },
    {
        "loss": 0.2196,
        "grad_norm": 9.66994571685791,
        "learning_rate": 8.00708591674048e-06,
        "epoch": 1.9929140832595218,
        "step": 2250
    },
    {
        "eval_loss": 0.23804621398448944,
        "eval_accuracy": 0.92527,
        "eval_precision": 0.92763,
        "eval_recall": 0.9225,
        "eval_f1": 0.92506,
        "eval_runtime": 149.4524,
        "eval_samples_per_second": 60.434,
        "eval_steps_per_second": 3.78,
        "epoch": 2.0,
        "step": 2258
    },
    {
        "loss": 0.2064,
        "grad_norm": 8.659653663635254,
        "learning_rate": 7.998228520814881e-06,
        "epoch": 2.0017714791851198,
        "step": 2260
    },
    {
        "loss": 0.1826,
        "grad_norm": 44.14305877685547,
        "learning_rate": 7.989371124889283e-06,
        "epoch": 2.0106288751107173,
        "step": 2270
    },
    {
        "loss": 0.3288,
        "grad_norm": 7.2282023429870605,
        "learning_rate": 7.980513728963686e-06,
        "epoch": 2.0194862710363153,
        "step": 2280
    },
    {
        "loss": 0.2343,
        "grad_norm": 32.45024490356445,
        "learning_rate": 7.971656333038086e-06,
        "epoch": 2.0283436669619133,
        "step": 2290
    },
    {
        "loss": 0.2064,
        "grad_norm": 65.19071197509766,
        "learning_rate": 7.96279893711249e-06,
        "epoch": 2.0372010628875112,
        "step": 2300
    },
    {
        "loss": 0.223,
        "grad_norm": 21.297500610351562,
        "learning_rate": 7.953941541186891e-06,
        "epoch": 2.0460584588131088,
        "step": 2310
    },
    {
        "loss": 0.1614,
        "grad_norm": 36.57603073120117,
        "learning_rate": 7.945084145261294e-06,
        "epoch": 2.0549158547387067,
        "step": 2320
    },
    {
        "loss": 0.1426,
        "grad_norm": 2.393709182739258,
        "learning_rate": 7.936226749335696e-06,
        "epoch": 2.0637732506643047,
        "step": 2330
    },
    {
        "loss": 0.3101,
        "grad_norm": 50.53459167480469,
        "learning_rate": 7.927369353410098e-06,
        "epoch": 2.0726306465899027,
        "step": 2340
    },
    {
        "loss": 0.1706,
        "grad_norm": 53.68636703491211,
        "learning_rate": 7.918511957484501e-06,
        "epoch": 2.0814880425155002,
        "step": 2350
    },
    {
        "loss": 0.144,
        "grad_norm": 32.41859436035156,
        "learning_rate": 7.909654561558902e-06,
        "epoch": 2.090345438441098,
        "step": 2360
    },
    {
        "loss": 0.1476,
        "grad_norm": 17.332618713378906,
        "learning_rate": 7.900797165633304e-06,
        "epoch": 2.099202834366696,
        "step": 2370
    },
    {
        "loss": 0.1933,
        "grad_norm": 53.33665084838867,
        "learning_rate": 7.891939769707706e-06,
        "epoch": 2.108060230292294,
        "step": 2380
    },
    {
        "loss": 0.2006,
        "grad_norm": 26.244905471801758,
        "learning_rate": 7.883082373782109e-06,
        "epoch": 2.116917626217892,
        "step": 2390
    },
    {
        "loss": 0.162,
        "grad_norm": 0.9003196954727173,
        "learning_rate": 7.87422497785651e-06,
        "epoch": 2.1257750221434897,
        "step": 2400
    },
    {
        "loss": 0.1562,
        "grad_norm": 2.9399516582489014,
        "learning_rate": 7.865367581930912e-06,
        "epoch": 2.1346324180690877,
        "step": 2410
    },
    {
        "loss": 0.2974,
        "grad_norm": 77.89854431152344,
        "learning_rate": 7.856510186005316e-06,
        "epoch": 2.1434898139946856,
        "step": 2420
    },
    {
        "loss": 0.2544,
        "grad_norm": 21.144929885864258,
        "learning_rate": 7.847652790079717e-06,
        "epoch": 2.1523472099202836,
        "step": 2430
    },
    {
        "loss": 0.1874,
        "grad_norm": 41.7742805480957,
        "learning_rate": 7.838795394154119e-06,
        "epoch": 2.161204605845881,
        "step": 2440
    },
    {
        "loss": 0.2566,
        "grad_norm": 3.1773157119750977,
        "learning_rate": 7.829937998228522e-06,
        "epoch": 2.170062001771479,
        "step": 2450
    },
    {
        "loss": 0.278,
        "grad_norm": 14.715764999389648,
        "learning_rate": 7.821080602302924e-06,
        "epoch": 2.178919397697077,
        "step": 2460
    },
    {
        "loss": 0.1948,
        "grad_norm": 14.505041122436523,
        "learning_rate": 7.812223206377327e-06,
        "epoch": 2.187776793622675,
        "step": 2470
    },
    {
        "loss": 0.2062,
        "grad_norm": 87.32006072998047,
        "learning_rate": 7.803365810451727e-06,
        "epoch": 2.1966341895482726,
        "step": 2480
    },
    {
        "loss": 0.1823,
        "grad_norm": 2.9273080825805664,
        "learning_rate": 7.79450841452613e-06,
        "epoch": 2.2054915854738706,
        "step": 2490
    },
    {
        "loss": 0.1017,
        "grad_norm": 3.6459126472473145,
        "learning_rate": 7.785651018600532e-06,
        "epoch": 2.2143489813994686,
        "step": 2500
    },
    {
        "loss": 0.2243,
        "grad_norm": 13.124661445617676,
        "learning_rate": 7.776793622674933e-06,
        "epoch": 2.2232063773250665,
        "step": 2510
    },
    {
        "loss": 0.2986,
        "grad_norm": 19.10190200805664,
        "learning_rate": 7.767936226749337e-06,
        "epoch": 2.2320637732506645,
        "step": 2520
    },
    {
        "loss": 0.2597,
        "grad_norm": 0.9998299479484558,
        "learning_rate": 7.759078830823738e-06,
        "epoch": 2.240921169176262,
        "step": 2530
    },
    {
        "loss": 0.2419,
        "grad_norm": 0.7881039977073669,
        "learning_rate": 7.750221434898142e-06,
        "epoch": 2.24977856510186,
        "step": 2540
    },
    {
        "loss": 0.1613,
        "grad_norm": 47.12453079223633,
        "learning_rate": 7.741364038972543e-06,
        "epoch": 2.258635961027458,
        "step": 2550
    },
    {
        "loss": 0.3052,
        "grad_norm": 27.777759552001953,
        "learning_rate": 7.732506643046945e-06,
        "epoch": 2.267493356953056,
        "step": 2560
    },
    {
        "loss": 0.1547,
        "grad_norm": 14.994616508483887,
        "learning_rate": 7.723649247121346e-06,
        "epoch": 2.2763507528786535,
        "step": 2570
    },
    {
        "loss": 0.1046,
        "grad_norm": 64.42556762695312,
        "learning_rate": 7.714791851195748e-06,
        "epoch": 2.2852081488042515,
        "step": 2580
    },
    {
        "loss": 0.2477,
        "grad_norm": 29.833105087280273,
        "learning_rate": 7.705934455270151e-06,
        "epoch": 2.2940655447298495,
        "step": 2590
    },
    {
        "loss": 0.3124,
        "grad_norm": 10.63606071472168,
        "learning_rate": 7.697077059344553e-06,
        "epoch": 2.3029229406554474,
        "step": 2600
    },
    {
        "loss": 0.1757,
        "grad_norm": 2.2581467628479004,
        "learning_rate": 7.688219663418956e-06,
        "epoch": 2.311780336581045,
        "step": 2610
    },
    {
        "loss": 0.2159,
        "grad_norm": 50.145263671875,
        "learning_rate": 7.679362267493358e-06,
        "epoch": 2.320637732506643,
        "step": 2620
    },
    {
        "loss": 0.289,
        "grad_norm": 100.15591430664062,
        "learning_rate": 7.67050487156776e-06,
        "epoch": 2.329495128432241,
        "step": 2630
    },
    {
        "loss": 0.15,
        "grad_norm": 51.31973648071289,
        "learning_rate": 7.661647475642163e-06,
        "epoch": 2.338352524357839,
        "step": 2640
    },
    {
        "loss": 0.1493,
        "grad_norm": 53.02395248413086,
        "learning_rate": 7.652790079716564e-06,
        "epoch": 2.3472099202834364,
        "step": 2650
    },
    {
        "loss": 0.3327,
        "grad_norm": 6.25432825088501,
        "learning_rate": 7.643932683790966e-06,
        "epoch": 2.3560673162090344,
        "step": 2660
    },
    {
        "loss": 0.2621,
        "grad_norm": 21.51657485961914,
        "learning_rate": 7.635075287865368e-06,
        "epoch": 2.3649247121346324,
        "step": 2670
    },
    {
        "loss": 0.2142,
        "grad_norm": 27.186983108520508,
        "learning_rate": 7.62621789193977e-06,
        "epoch": 2.3737821080602304,
        "step": 2680
    },
    {
        "loss": 0.2091,
        "grad_norm": 25.12012481689453,
        "learning_rate": 7.6173604960141725e-06,
        "epoch": 2.3826395039858284,
        "step": 2690
    },
    {
        "loss": 0.1568,
        "grad_norm": 0.6129029393196106,
        "learning_rate": 7.608503100088574e-06,
        "epoch": 2.391496899911426,
        "step": 2700
    },
    {
        "loss": 0.2743,
        "grad_norm": 17.74945068359375,
        "learning_rate": 7.599645704162977e-06,
        "epoch": 2.400354295837024,
        "step": 2710
    },
    {
        "loss": 0.2106,
        "grad_norm": 2.598003625869751,
        "learning_rate": 7.590788308237379e-06,
        "epoch": 2.409211691762622,
        "step": 2720
    },
    {
        "loss": 0.1224,
        "grad_norm": 54.266845703125,
        "learning_rate": 7.5819309123117815e-06,
        "epoch": 2.41806908768822,
        "step": 2730
    },
    {
        "loss": 0.2253,
        "grad_norm": 34.90666961669922,
        "learning_rate": 7.573073516386183e-06,
        "epoch": 2.4269264836138174,
        "step": 2740
    },
    {
        "loss": 0.2841,
        "grad_norm": 12.167694091796875,
        "learning_rate": 7.5642161204605856e-06,
        "epoch": 2.4357838795394153,
        "step": 2750
    },
    {
        "loss": 0.2384,
        "grad_norm": 41.575897216796875,
        "learning_rate": 7.555358724534987e-06,
        "epoch": 2.4446412754650133,
        "step": 2760
    },
    {
        "loss": 0.1891,
        "grad_norm": 39.48395538330078,
        "learning_rate": 7.546501328609389e-06,
        "epoch": 2.4534986713906113,
        "step": 2770
    },
    {
        "loss": 0.2838,
        "grad_norm": 35.471927642822266,
        "learning_rate": 7.537643932683791e-06,
        "epoch": 2.4623560673162093,
        "step": 2780
    },
    {
        "loss": 0.0523,
        "grad_norm": 2.781039237976074,
        "learning_rate": 7.528786536758194e-06,
        "epoch": 2.471213463241807,
        "step": 2790
    },
    {
        "loss": 0.1772,
        "grad_norm": 0.3675241470336914,
        "learning_rate": 7.519929140832596e-06,
        "epoch": 2.4800708591674048,
        "step": 2800
    },
    {
        "loss": 0.3488,
        "grad_norm": 0.719021201133728,
        "learning_rate": 7.511071744906998e-06,
        "epoch": 2.4889282550930028,
        "step": 2810
    },
    {
        "loss": 0.2349,
        "grad_norm": 22.67919158935547,
        "learning_rate": 7.5022143489814e-06,
        "epoch": 2.4977856510186003,
        "step": 2820
    },
    {
        "loss": 0.2911,
        "grad_norm": 44.20071792602539,
        "learning_rate": 7.493356953055803e-06,
        "epoch": 2.5066430469441983,
        "step": 2830
    },
    {
        "loss": 0.255,
        "grad_norm": 0.42579594254493713,
        "learning_rate": 7.484499557130205e-06,
        "epoch": 2.5155004428697962,
        "step": 2840
    },
    {
        "loss": 0.2207,
        "grad_norm": 37.3860969543457,
        "learning_rate": 7.475642161204606e-06,
        "epoch": 2.524357838795394,
        "step": 2850
    },
    {
        "loss": 0.273,
        "grad_norm": 107.84416961669922,
        "learning_rate": 7.466784765279008e-06,
        "epoch": 2.533215234720992,
        "step": 2860
    },
    {
        "loss": 0.2057,
        "grad_norm": 56.20173263549805,
        "learning_rate": 7.457927369353411e-06,
        "epoch": 2.54207263064659,
        "step": 2870
    },
    {
        "loss": 0.2651,
        "grad_norm": 46.30427169799805,
        "learning_rate": 7.449069973427812e-06,
        "epoch": 2.5509300265721877,
        "step": 2880
    },
    {
        "loss": 0.1705,
        "grad_norm": 5.844762802124023,
        "learning_rate": 7.440212577502215e-06,
        "epoch": 2.5597874224977857,
        "step": 2890
    },
    {
        "loss": 0.1221,
        "grad_norm": 1.6448006629943848,
        "learning_rate": 7.431355181576617e-06,
        "epoch": 2.5686448184233837,
        "step": 2900
    },
    {
        "loss": 0.2231,
        "grad_norm": 3.4549999237060547,
        "learning_rate": 7.42249778565102e-06,
        "epoch": 2.577502214348981,
        "step": 2910
    },
    {
        "loss": 0.3311,
        "grad_norm": 40.61311721801758,
        "learning_rate": 7.413640389725421e-06,
        "epoch": 2.586359610274579,
        "step": 2920
    },
    {
        "loss": 0.1139,
        "grad_norm": 36.3009147644043,
        "learning_rate": 7.404782993799824e-06,
        "epoch": 2.595217006200177,
        "step": 2930
    },
    {
        "loss": 0.2057,
        "grad_norm": 45.920631408691406,
        "learning_rate": 7.3959255978742254e-06,
        "epoch": 2.604074402125775,
        "step": 2940
    },
    {
        "loss": 0.1732,
        "grad_norm": 45.50297164916992,
        "learning_rate": 7.387068201948627e-06,
        "epoch": 2.612931798051373,
        "step": 2950
    },
    {
        "loss": 0.1612,
        "grad_norm": 67.53399658203125,
        "learning_rate": 7.3782108060230295e-06,
        "epoch": 2.6217891939769706,
        "step": 2960
    },
    {
        "loss": 0.1963,
        "grad_norm": 43.91879653930664,
        "learning_rate": 7.369353410097432e-06,
        "epoch": 2.6306465899025686,
        "step": 2970
    },
    {
        "loss": 0.2178,
        "grad_norm": 51.49459457397461,
        "learning_rate": 7.3604960141718344e-06,
        "epoch": 2.6395039858281666,
        "step": 2980
    },
    {
        "loss": 0.1416,
        "grad_norm": 59.54990005493164,
        "learning_rate": 7.351638618246236e-06,
        "epoch": 2.648361381753764,
        "step": 2990
    },
    {
        "loss": 0.1256,
        "grad_norm": 50.738304138183594,
        "learning_rate": 7.3427812223206385e-06,
        "epoch": 2.657218777679362,
        "step": 3000
    },
    {
        "loss": 0.1988,
        "grad_norm": 116.0539321899414,
        "learning_rate": 7.333923826395041e-06,
        "epoch": 2.66607617360496,
        "step": 3010
    },
    {
        "loss": 0.2894,
        "grad_norm": 7.221706867218018,
        "learning_rate": 7.325066430469443e-06,
        "epoch": 2.674933569530558,
        "step": 3020
    },
    {
        "loss": 0.0614,
        "grad_norm": 129.0354461669922,
        "learning_rate": 7.316209034543845e-06,
        "epoch": 2.683790965456156,
        "step": 3030
    },
    {
        "loss": 0.3231,
        "grad_norm": 66.37293243408203,
        "learning_rate": 7.307351638618247e-06,
        "epoch": 2.692648361381754,
        "step": 3040
    },
    {
        "loss": 0.2495,
        "grad_norm": 71.90125274658203,
        "learning_rate": 7.298494242692648e-06,
        "epoch": 2.7015057573073515,
        "step": 3050
    },
    {
        "loss": 0.2467,
        "grad_norm": 0.7913832664489746,
        "learning_rate": 7.289636846767051e-06,
        "epoch": 2.7103631532329495,
        "step": 3060
    },
    {
        "loss": 0.1558,
        "grad_norm": 2.125803232192993,
        "learning_rate": 7.280779450841453e-06,
        "epoch": 2.7192205491585475,
        "step": 3070
    },
    {
        "loss": 0.1783,
        "grad_norm": 1.6521258354187012,
        "learning_rate": 7.271922054915856e-06,
        "epoch": 2.728077945084145,
        "step": 3080
    },
    {
        "loss": 0.1246,
        "grad_norm": 65.30371856689453,
        "learning_rate": 7.263064658990257e-06,
        "epoch": 2.736935341009743,
        "step": 3090
    },
    {
        "loss": 0.2391,
        "grad_norm": 18.562814712524414,
        "learning_rate": 7.25420726306466e-06,
        "epoch": 2.745792736935341,
        "step": 3100
    },
    {
        "loss": 0.2134,
        "grad_norm": 7.197257041931152,
        "learning_rate": 7.245349867139062e-06,
        "epoch": 2.754650132860939,
        "step": 3110
    },
    {
        "loss": 0.272,
        "grad_norm": 10.805925369262695,
        "learning_rate": 7.2364924712134646e-06,
        "epoch": 2.763507528786537,
        "step": 3120
    },
    {
        "loss": 0.1035,
        "grad_norm": 6.0335516929626465,
        "learning_rate": 7.227635075287865e-06,
        "epoch": 2.7723649247121345,
        "step": 3130
    },
    {
        "loss": 0.1398,
        "grad_norm": 28.862850189208984,
        "learning_rate": 7.218777679362268e-06,
        "epoch": 2.7812223206377324,
        "step": 3140
    },
    {
        "loss": 0.2225,
        "grad_norm": 16.109233856201172,
        "learning_rate": 7.20992028343667e-06,
        "epoch": 2.7900797165633304,
        "step": 3150
    },
    {
        "loss": 0.1652,
        "grad_norm": 0.3119446635246277,
        "learning_rate": 7.201062887511072e-06,
        "epoch": 2.7989371124889284,
        "step": 3160
    },
    {
        "loss": 0.1339,
        "grad_norm": 41.44453811645508,
        "learning_rate": 7.192205491585474e-06,
        "epoch": 2.807794508414526,
        "step": 3170
    },
    {
        "loss": 0.1444,
        "grad_norm": 1.227526307106018,
        "learning_rate": 7.183348095659877e-06,
        "epoch": 2.816651904340124,
        "step": 3180
    },
    {
        "loss": 0.2349,
        "grad_norm": 0.36738571524620056,
        "learning_rate": 7.174490699734279e-06,
        "epoch": 2.825509300265722,
        "step": 3190
    },
    {
        "loss": 0.149,
        "grad_norm": 34.56290817260742,
        "learning_rate": 7.165633303808681e-06,
        "epoch": 2.83436669619132,
        "step": 3200
    },
    {
        "loss": 0.3059,
        "grad_norm": 2.857433319091797,
        "learning_rate": 7.156775907883083e-06,
        "epoch": 2.843224092116918,
        "step": 3210
    },
    {
        "loss": 0.0899,
        "grad_norm": 39.83720397949219,
        "learning_rate": 7.147918511957485e-06,
        "epoch": 2.8520814880425154,
        "step": 3220
    },
    {
        "loss": 0.1674,
        "grad_norm": 14.789900779724121,
        "learning_rate": 7.1390611160318865e-06,
        "epoch": 2.8609388839681134,
        "step": 3230
    },
    {
        "loss": 0.1453,
        "grad_norm": 0.5043344497680664,
        "learning_rate": 7.130203720106289e-06,
        "epoch": 2.8697962798937113,
        "step": 3240
    },
    {
        "loss": 0.1803,
        "grad_norm": 2.1942169666290283,
        "learning_rate": 7.121346324180691e-06,
        "epoch": 2.878653675819309,
        "step": 3250
    },
    {
        "loss": 0.1679,
        "grad_norm": 19.56452178955078,
        "learning_rate": 7.112488928255094e-06,
        "epoch": 2.887511071744907,
        "step": 3260
    },
    {
        "loss": 0.2654,
        "grad_norm": 8.93530559539795,
        "learning_rate": 7.1036315323294955e-06,
        "epoch": 2.896368467670505,
        "step": 3270
    },
    {
        "loss": 0.269,
        "grad_norm": 11.3778715133667,
        "learning_rate": 7.094774136403898e-06,
        "epoch": 2.905225863596103,
        "step": 3280
    },
    {
        "loss": 0.2352,
        "grad_norm": 0.8706777095794678,
        "learning_rate": 7.0859167404783e-06,
        "epoch": 2.9140832595217008,
        "step": 3290
    },
    {
        "loss": 0.1796,
        "grad_norm": 23.01664924621582,
        "learning_rate": 7.077059344552703e-06,
        "epoch": 2.9229406554472988,
        "step": 3300
    },
    {
        "loss": 0.1838,
        "grad_norm": 9.063076972961426,
        "learning_rate": 7.0682019486271045e-06,
        "epoch": 2.9317980513728963,
        "step": 3310
    },
    {
        "loss": 0.3117,
        "grad_norm": 15.780155181884766,
        "learning_rate": 7.059344552701506e-06,
        "epoch": 2.9406554472984943,
        "step": 3320
    },
    {
        "loss": 0.3248,
        "grad_norm": 77.55887603759766,
        "learning_rate": 7.0504871567759085e-06,
        "epoch": 2.9495128432240922,
        "step": 3330
    },
    {
        "loss": 0.1868,
        "grad_norm": 1.1340818405151367,
        "learning_rate": 7.04162976085031e-06,
        "epoch": 2.9583702391496898,
        "step": 3340
    },
    {
        "loss": 0.2208,
        "grad_norm": 47.784812927246094,
        "learning_rate": 7.032772364924713e-06,
        "epoch": 2.9672276350752878,
        "step": 3350
    },
    {
        "loss": 0.2825,
        "grad_norm": 1.2220537662506104,
        "learning_rate": 7.023914968999115e-06,
        "epoch": 2.9760850310008857,
        "step": 3360
    },
    {
        "loss": 0.111,
        "grad_norm": 41.50095748901367,
        "learning_rate": 7.0150575730735175e-06,
        "epoch": 2.9849424269264837,
        "step": 3370
    },
    {
        "loss": 0.0774,
        "grad_norm": 0.2669633626937866,
        "learning_rate": 7.006200177147919e-06,
        "epoch": 2.9937998228520817,
        "step": 3380
    },
    {
        "eval_loss": 0.2233857363462448,
        "eval_accuracy": 0.9473,
        "eval_precision": 0.93181,
        "eval_recall": 0.96523,
        "eval_f1": 0.94823,
        "eval_runtime": 149.4744,
        "eval_samples_per_second": 60.425,
        "eval_steps_per_second": 3.78,
        "epoch": 3.0,
        "step": 3387
    },
    {
        "loss": 0.1693,
        "grad_norm": 0.3391109108924866,
        "learning_rate": 6.9973427812223216e-06,
        "epoch": 3.002657218777679,
        "step": 3390
    },
    {
        "loss": 0.1428,
        "grad_norm": 8.395120620727539,
        "learning_rate": 6.988485385296724e-06,
        "epoch": 3.011514614703277,
        "step": 3400
    },
    {
        "loss": 0.1119,
        "grad_norm": 21.640920639038086,
        "learning_rate": 6.979627989371125e-06,
        "epoch": 3.020372010628875,
        "step": 3410
    },
    {
        "loss": 0.0987,
        "grad_norm": 6.513425827026367,
        "learning_rate": 6.970770593445527e-06,
        "epoch": 3.029229406554473,
        "step": 3420
    },
    {
        "loss": 0.1053,
        "grad_norm": 26.771038055419922,
        "learning_rate": 6.96191319751993e-06,
        "epoch": 3.0380868024800707,
        "step": 3430
    },
    {
        "loss": 0.1406,
        "grad_norm": 0.384491503238678,
        "learning_rate": 6.953055801594331e-06,
        "epoch": 3.0469441984056687,
        "step": 3440
    },
    {
        "loss": 0.1986,
        "grad_norm": 49.28145980834961,
        "learning_rate": 6.944198405668734e-06,
        "epoch": 3.0558015943312666,
        "step": 3450
    },
    {
        "loss": 0.1797,
        "grad_norm": 87.29702758789062,
        "learning_rate": 6.935341009743136e-06,
        "epoch": 3.0646589902568646,
        "step": 3460
    },
    {
        "loss": 0.2212,
        "grad_norm": 108.47579193115234,
        "learning_rate": 6.926483613817539e-06,
        "epoch": 3.073516386182462,
        "step": 3470
    },
    {
        "loss": 0.116,
        "grad_norm": 77.1873779296875,
        "learning_rate": 6.91762621789194e-06,
        "epoch": 3.08237378210806,
        "step": 3480
    },
    {
        "loss": 0.1528,
        "grad_norm": 74.26181030273438,
        "learning_rate": 6.908768821966343e-06,
        "epoch": 3.091231178033658,
        "step": 3490
    },
    {
        "loss": 0.1616,
        "grad_norm": 46.267066955566406,
        "learning_rate": 6.899911426040744e-06,
        "epoch": 3.100088573959256,
        "step": 3500
    },
    {
        "loss": 0.2279,
        "grad_norm": 6.907604217529297,
        "learning_rate": 6.891054030115146e-06,
        "epoch": 3.108945969884854,
        "step": 3510
    },
    {
        "loss": 0.2089,
        "grad_norm": 0.3711321949958801,
        "learning_rate": 6.882196634189548e-06,
        "epoch": 3.1178033658104516,
        "step": 3520
    },
    {
        "loss": 0.1105,
        "grad_norm": 136.791015625,
        "learning_rate": 6.873339238263951e-06,
        "epoch": 3.1266607617360496,
        "step": 3530
    },
    {
        "loss": 0.2162,
        "grad_norm": 0.7073172926902771,
        "learning_rate": 6.864481842338353e-06,
        "epoch": 3.1355181576616475,
        "step": 3540
    },
    {
        "loss": 0.0658,
        "grad_norm": 69.77378845214844,
        "learning_rate": 6.855624446412755e-06,
        "epoch": 3.1443755535872455,
        "step": 3550
    },
    {
        "loss": 0.1313,
        "grad_norm": 2.5154569149017334,
        "learning_rate": 6.846767050487157e-06,
        "epoch": 3.153232949512843,
        "step": 3560
    },
    {
        "loss": 0.131,
        "grad_norm": 77.36113739013672,
        "learning_rate": 6.83790965456156e-06,
        "epoch": 3.162090345438441,
        "step": 3570
    },
    {
        "loss": 0.2163,
        "grad_norm": 36.84474182128906,
        "learning_rate": 6.829052258635962e-06,
        "epoch": 3.170947741364039,
        "step": 3580
    },
    {
        "loss": 0.111,
        "grad_norm": 2.380441665649414,
        "learning_rate": 6.820194862710364e-06,
        "epoch": 3.179805137289637,
        "step": 3590
    },
    {
        "loss": 0.1752,
        "grad_norm": 11.753228187561035,
        "learning_rate": 6.8113374667847655e-06,
        "epoch": 3.1886625332152345,
        "step": 3600
    },
    {
        "loss": 0.0963,
        "grad_norm": 41.21177673339844,
        "learning_rate": 6.802480070859168e-06,
        "epoch": 3.1975199291408325,
        "step": 3610
    },
    {
        "loss": 0.102,
        "grad_norm": 66.68975067138672,
        "learning_rate": 6.79362267493357e-06,
        "epoch": 3.2063773250664305,
        "step": 3620
    },
    {
        "loss": 0.1706,
        "grad_norm": 29.424781799316406,
        "learning_rate": 6.784765279007972e-06,
        "epoch": 3.2152347209920284,
        "step": 3630
    },
    {
        "loss": 0.3133,
        "grad_norm": 11.87099552154541,
        "learning_rate": 6.7759078830823745e-06,
        "epoch": 3.2240921169176264,
        "step": 3640
    },
    {
        "loss": 0.1594,
        "grad_norm": 2.8353805541992188,
        "learning_rate": 6.767050487156777e-06,
        "epoch": 3.232949512843224,
        "step": 3650
    },
    {
        "loss": 0.1045,
        "grad_norm": 42.20501708984375,
        "learning_rate": 6.7581930912311786e-06,
        "epoch": 3.241806908768822,
        "step": 3660
    },
    {
        "loss": 0.2496,
        "grad_norm": 15.478352546691895,
        "learning_rate": 6.749335695305581e-06,
        "epoch": 3.25066430469442,
        "step": 3670
    },
    {
        "loss": 0.0695,
        "grad_norm": 0.7272865176200867,
        "learning_rate": 6.7404782993799835e-06,
        "epoch": 3.259521700620018,
        "step": 3680
    },
    {
        "loss": 0.1784,
        "grad_norm": 0.20058368146419525,
        "learning_rate": 6.731620903454384e-06,
        "epoch": 3.2683790965456154,
        "step": 3690
    },
    {
        "loss": 0.1548,
        "grad_norm": 0.32095590233802795,
        "learning_rate": 6.722763507528787e-06,
        "epoch": 3.2772364924712134,
        "step": 3700
    },
    {
        "loss": 0.1869,
        "grad_norm": 0.6385638117790222,
        "learning_rate": 6.713906111603189e-06,
        "epoch": 3.2860938883968114,
        "step": 3710
    },
    {
        "loss": 0.1351,
        "grad_norm": 0.29000961780548096,
        "learning_rate": 6.705048715677592e-06,
        "epoch": 3.2949512843224094,
        "step": 3720
    },
    {
        "loss": 0.1141,
        "grad_norm": 22.767913818359375,
        "learning_rate": 6.696191319751993e-06,
        "epoch": 3.3038086802480073,
        "step": 3730
    },
    {
        "loss": 0.0842,
        "grad_norm": 1.5153002738952637,
        "learning_rate": 6.687333923826396e-06,
        "epoch": 3.312666076173605,
        "step": 3740
    },
    {
        "loss": 0.2014,
        "grad_norm": 3.3073880672454834,
        "learning_rate": 6.678476527900798e-06,
        "epoch": 3.321523472099203,
        "step": 3750
    },
    {
        "loss": 0.0786,
        "grad_norm": 71.31764221191406,
        "learning_rate": 6.6696191319752006e-06,
        "epoch": 3.330380868024801,
        "step": 3760
    },
    {
        "loss": 0.0807,
        "grad_norm": 9.950465202331543,
        "learning_rate": 6.660761736049602e-06,
        "epoch": 3.3392382639503984,
        "step": 3770
    },
    {
        "loss": 0.1189,
        "grad_norm": 3.4609251022338867,
        "learning_rate": 6.651904340124004e-06,
        "epoch": 3.3480956598759963,
        "step": 3780
    },
    {
        "loss": 0.1258,
        "grad_norm": 0.32424771785736084,
        "learning_rate": 6.643046944198405e-06,
        "epoch": 3.3569530558015943,
        "step": 3790
    },
    {
        "loss": 0.1586,
        "grad_norm": 3.4734034538269043,
        "learning_rate": 6.634189548272808e-06,
        "epoch": 3.3658104517271923,
        "step": 3800
    },
    {
        "loss": 0.0969,
        "grad_norm": 0.16524609923362732,
        "learning_rate": 6.62533215234721e-06,
        "epoch": 3.3746678476527903,
        "step": 3810
    },
    {
        "loss": 0.1429,
        "grad_norm": 131.2930450439453,
        "learning_rate": 6.616474756421613e-06,
        "epoch": 3.383525243578388,
        "step": 3820
    },
    {
        "loss": 0.1532,
        "grad_norm": 0.15284813940525055,
        "learning_rate": 6.607617360496014e-06,
        "epoch": 3.3923826395039858,
        "step": 3830
    },
    {
        "loss": 0.1336,
        "grad_norm": 7.2884392738342285,
        "learning_rate": 6.598759964570417e-06,
        "epoch": 3.4012400354295838,
        "step": 3840
    },
    {
        "loss": 0.1035,
        "grad_norm": 45.724159240722656,
        "learning_rate": 6.589902568644819e-06,
        "epoch": 3.4100974313551817,
        "step": 3850
    },
    {
        "loss": 0.2664,
        "grad_norm": 46.3464241027832,
        "learning_rate": 6.581045172719222e-06,
        "epoch": 3.4189548272807793,
        "step": 3860
    },
    {
        "loss": 0.06,
        "grad_norm": 31.04559326171875,
        "learning_rate": 6.572187776793623e-06,
        "epoch": 3.4278122232063772,
        "step": 3870
    },
    {
        "loss": 0.2363,
        "grad_norm": 78.68907165527344,
        "learning_rate": 6.563330380868025e-06,
        "epoch": 3.436669619131975,
        "step": 3880
    },
    {
        "loss": 0.1411,
        "grad_norm": 3.9823122024536133,
        "learning_rate": 6.554472984942427e-06,
        "epoch": 3.445527015057573,
        "step": 3890
    },
    {
        "loss": 0.0931,
        "grad_norm": 12.855416297912598,
        "learning_rate": 6.545615589016829e-06,
        "epoch": 3.454384410983171,
        "step": 3900
    },
    {
        "loss": 0.0888,
        "grad_norm": 25.839813232421875,
        "learning_rate": 6.5367581930912315e-06,
        "epoch": 3.4632418069087687,
        "step": 3910
    },
    {
        "loss": 0.0719,
        "grad_norm": 0.7567892074584961,
        "learning_rate": 6.527900797165634e-06,
        "epoch": 3.4720992028343667,
        "step": 3920
    },
    {
        "loss": 0.1189,
        "grad_norm": 0.2559311091899872,
        "learning_rate": 6.519043401240036e-06,
        "epoch": 3.4809565987599647,
        "step": 3930
    },
    {
        "loss": 0.1124,
        "grad_norm": 45.4189338684082,
        "learning_rate": 6.510186005314438e-06,
        "epoch": 3.4898139946855626,
        "step": 3940
    },
    {
        "loss": 0.1975,
        "grad_norm": 29.77071762084961,
        "learning_rate": 6.5013286093888405e-06,
        "epoch": 3.49867139061116,
        "step": 3950
    },
    {
        "loss": 0.2534,
        "grad_norm": 55.56386947631836,
        "learning_rate": 6.492471213463243e-06,
        "epoch": 3.507528786536758,
        "step": 3960
    },
    {
        "loss": 0.1918,
        "grad_norm": 93.36780548095703,
        "learning_rate": 6.483613817537644e-06,
        "epoch": 3.516386182462356,
        "step": 3970
    },
    {
        "loss": 0.0895,
        "grad_norm": 99.36231994628906,
        "learning_rate": 6.474756421612046e-06,
        "epoch": 3.525243578387954,
        "step": 3980
    },
    {
        "loss": 0.119,
        "grad_norm": 0.27983763813972473,
        "learning_rate": 6.465899025686449e-06,
        "epoch": 3.534100974313552,
        "step": 3990
    },
    {
        "loss": 0.2903,
        "grad_norm": 3.567474842071533,
        "learning_rate": 6.457041629760851e-06,
        "epoch": 3.5429583702391496,
        "step": 4000
    },
    {
        "loss": 0.3327,
        "grad_norm": 81.19712829589844,
        "learning_rate": 6.448184233835253e-06,
        "epoch": 3.5518157661647476,
        "step": 4010
    },
    {
        "loss": 0.1053,
        "grad_norm": 80.51126861572266,
        "learning_rate": 6.439326837909655e-06,
        "epoch": 3.5606731620903456,
        "step": 4020
    },
    {
        "loss": 0.0893,
        "grad_norm": 2.162485361099243,
        "learning_rate": 6.4304694419840576e-06,
        "epoch": 3.569530558015943,
        "step": 4030
    },
    {
        "loss": 0.1824,
        "grad_norm": 141.60238647460938,
        "learning_rate": 6.42161204605846e-06,
        "epoch": 3.578387953941541,
        "step": 4040
    },
    {
        "loss": 0.1852,
        "grad_norm": 6.250248432159424,
        "learning_rate": 6.412754650132862e-06,
        "epoch": 3.587245349867139,
        "step": 4050
    },
    {
        "loss": 0.165,
        "grad_norm": 0.18980926275253296,
        "learning_rate": 6.403897254207263e-06,
        "epoch": 3.596102745792737,
        "step": 4060
    },
    {
        "loss": 0.0388,
        "grad_norm": 7.435976982116699,
        "learning_rate": 6.395039858281666e-06,
        "epoch": 3.604960141718335,
        "step": 4070
    },
    {
        "loss": 0.1701,
        "grad_norm": 0.14202915132045746,
        "learning_rate": 6.386182462356067e-06,
        "epoch": 3.6138175376439325,
        "step": 4080
    },
    {
        "loss": 0.1631,
        "grad_norm": 9.028483390808105,
        "learning_rate": 6.37732506643047e-06,
        "epoch": 3.6226749335695305,
        "step": 4090
    },
    {
        "loss": 0.1369,
        "grad_norm": 6.569558143615723,
        "learning_rate": 6.368467670504872e-06,
        "epoch": 3.6315323294951285,
        "step": 4100
    },
    {
        "loss": 0.134,
        "grad_norm": 55.0430793762207,
        "learning_rate": 6.359610274579275e-06,
        "epoch": 3.640389725420726,
        "step": 4110
    },
    {
        "loss": 0.1525,
        "grad_norm": 0.14525702595710754,
        "learning_rate": 6.350752878653676e-06,
        "epoch": 3.649247121346324,
        "step": 4120
    },
    {
        "loss": 0.2943,
        "grad_norm": 100.82830047607422,
        "learning_rate": 6.341895482728079e-06,
        "epoch": 3.658104517271922,
        "step": 4130
    },
    {
        "loss": 0.1552,
        "grad_norm": 8.08703327178955,
        "learning_rate": 6.333038086802481e-06,
        "epoch": 3.66696191319752,
        "step": 4140
    },
    {
        "loss": 0.111,
        "grad_norm": 0.1657375693321228,
        "learning_rate": 6.324180690876884e-06,
        "epoch": 3.675819309123118,
        "step": 4150
    },
    {
        "loss": 0.0578,
        "grad_norm": 0.21962837874889374,
        "learning_rate": 6.315323294951284e-06,
        "epoch": 3.684676705048716,
        "step": 4160
    },
    {
        "loss": 0.1046,
        "grad_norm": 3.2141549587249756,
        "learning_rate": 6.306465899025687e-06,
        "epoch": 3.6935341009743134,
        "step": 4170
    },
    {
        "loss": 0.0983,
        "grad_norm": 0.3978215754032135,
        "learning_rate": 6.2976085031000885e-06,
        "epoch": 3.7023914968999114,
        "step": 4180
    },
    {
        "loss": 0.1395,
        "grad_norm": 0.16110588610172272,
        "learning_rate": 6.288751107174491e-06,
        "epoch": 3.7112488928255094,
        "step": 4190
    },
    {
        "loss": 0.2377,
        "grad_norm": 6.690345764160156,
        "learning_rate": 6.279893711248893e-06,
        "epoch": 3.720106288751107,
        "step": 4200
    },
    {
        "loss": 0.0776,
        "grad_norm": 4.714240074157715,
        "learning_rate": 6.271036315323296e-06,
        "epoch": 3.728963684676705,
        "step": 4210
    },
    {
        "loss": 0.1313,
        "grad_norm": 5.4714579582214355,
        "learning_rate": 6.2621789193976975e-06,
        "epoch": 3.737821080602303,
        "step": 4220
    },
    {
        "loss": 0.0603,
        "grad_norm": 0.40457531809806824,
        "learning_rate": 6.2533215234721e-06,
        "epoch": 3.746678476527901,
        "step": 4230
    },
    {
        "loss": 0.0944,
        "grad_norm": 3.465336561203003,
        "learning_rate": 6.244464127546502e-06,
        "epoch": 3.755535872453499,
        "step": 4240
    },
    {
        "loss": 0.1965,
        "grad_norm": 104.43314361572266,
        "learning_rate": 6.235606731620903e-06,
        "epoch": 3.7643932683790964,
        "step": 4250
    },
    {
        "loss": 0.1043,
        "grad_norm": 4.297647953033447,
        "learning_rate": 6.226749335695306e-06,
        "epoch": 3.7732506643046944,
        "step": 4260
    },
    {
        "loss": 0.1308,
        "grad_norm": 47.36833190917969,
        "learning_rate": 6.217891939769708e-06,
        "epoch": 3.7821080602302923,
        "step": 4270
    },
    {
        "loss": 0.1975,
        "grad_norm": 0.23590531945228577,
        "learning_rate": 6.2090345438441105e-06,
        "epoch": 3.7909654561558903,
        "step": 4280
    },
    {
        "loss": 0.1998,
        "grad_norm": 107.21859741210938,
        "learning_rate": 6.200177147918512e-06,
        "epoch": 3.799822852081488,
        "step": 4290
    },
    {
        "loss": 0.1202,
        "grad_norm": 17.683788299560547,
        "learning_rate": 6.1913197519929146e-06,
        "epoch": 3.808680248007086,
        "step": 4300
    },
    {
        "loss": 0.159,
        "grad_norm": 5.327332019805908,
        "learning_rate": 6.182462356067317e-06,
        "epoch": 3.817537643932684,
        "step": 4310
    },
    {
        "loss": 0.0922,
        "grad_norm": 0.20318585634231567,
        "learning_rate": 6.1736049601417195e-06,
        "epoch": 3.8263950398582818,
        "step": 4320
    },
    {
        "loss": 0.0989,
        "grad_norm": 0.34139034152030945,
        "learning_rate": 6.164747564216121e-06,
        "epoch": 3.8352524357838798,
        "step": 4330
    },
    {
        "loss": 0.1974,
        "grad_norm": 1.0233715772628784,
        "learning_rate": 6.155890168290523e-06,
        "epoch": 3.8441098317094773,
        "step": 4340
    },
    {
        "loss": 0.1156,
        "grad_norm": 0.22528406977653503,
        "learning_rate": 6.147032772364925e-06,
        "epoch": 3.8529672276350753,
        "step": 4350
    },
    {
        "loss": 0.1738,
        "grad_norm": 141.74859619140625,
        "learning_rate": 6.138175376439327e-06,
        "epoch": 3.8618246235606732,
        "step": 4360
    },
    {
        "loss": 0.139,
        "grad_norm": 56.612754821777344,
        "learning_rate": 6.129317980513729e-06,
        "epoch": 3.8706820194862708,
        "step": 4370
    },
    {
        "loss": 0.0797,
        "grad_norm": 0.20773494243621826,
        "learning_rate": 6.120460584588132e-06,
        "epoch": 3.8795394154118688,
        "step": 4380
    },
    {
        "loss": 0.0768,
        "grad_norm": 15.064399719238281,
        "learning_rate": 6.111603188662534e-06,
        "epoch": 3.8883968113374667,
        "step": 4390
    },
    {
        "loss": 0.1782,
        "grad_norm": 6.65407133102417,
        "learning_rate": 6.102745792736936e-06,
        "epoch": 3.8972542072630647,
        "step": 4400
    },
    {
        "loss": 0.1104,
        "grad_norm": 59.68177795410156,
        "learning_rate": 6.093888396811338e-06,
        "epoch": 3.9061116031886627,
        "step": 4410
    },
    {
        "loss": 0.2291,
        "grad_norm": 0.20982545614242554,
        "learning_rate": 6.085031000885741e-06,
        "epoch": 3.9149689991142607,
        "step": 4420
    },
    {
        "loss": 0.0747,
        "grad_norm": 0.28707775473594666,
        "learning_rate": 6.076173604960143e-06,
        "epoch": 3.923826395039858,
        "step": 4430
    },
    {
        "loss": 0.0879,
        "grad_norm": 0.27176791429519653,
        "learning_rate": 6.067316209034544e-06,
        "epoch": 3.932683790965456,
        "step": 4440
    },
    {
        "loss": 0.1049,
        "grad_norm": 40.734920501708984,
        "learning_rate": 6.058458813108946e-06,
        "epoch": 3.941541186891054,
        "step": 4450
    },
    {
        "loss": 0.1012,
        "grad_norm": 0.2718855142593384,
        "learning_rate": 6.049601417183349e-06,
        "epoch": 3.9503985828166517,
        "step": 4460
    },
    {
        "loss": 0.2013,
        "grad_norm": 73.85447692871094,
        "learning_rate": 6.04074402125775e-06,
        "epoch": 3.9592559787422497,
        "step": 4470
    },
    {
        "loss": 0.1424,
        "grad_norm": 182.4008026123047,
        "learning_rate": 6.031886625332153e-06,
        "epoch": 3.9681133746678476,
        "step": 4480
    },
    {
        "loss": 0.0464,
        "grad_norm": 55.710174560546875,
        "learning_rate": 6.023029229406555e-06,
        "epoch": 3.9769707705934456,
        "step": 4490
    },
    {
        "loss": 0.0569,
        "grad_norm": 142.38873291015625,
        "learning_rate": 6.014171833480958e-06,
        "epoch": 3.9858281665190436,
        "step": 4500
    },
    {
        "loss": 0.055,
        "grad_norm": 103.91053771972656,
        "learning_rate": 6.005314437555359e-06,
        "epoch": 3.994685562444641,
        "step": 4510
    },
    {
        "eval_loss": 0.17275528609752655,
        "eval_accuracy": 0.96568,
        "eval_precision": 0.96159,
        "eval_recall": 0.97011,
        "eval_f1": 0.96583,
        "eval_runtime": 149.5603,
        "eval_samples_per_second": 60.39,
        "eval_steps_per_second": 3.778,
        "epoch": 4.0,
        "step": 4516
    },
    {
        "loss": 0.1681,
        "grad_norm": 21.916927337646484,
        "learning_rate": 5.996457041629762e-06,
        "epoch": 4.0035429583702395,
        "step": 4520
    },
    {
        "loss": 0.0417,
        "grad_norm": 118.73684692382812,
        "learning_rate": 5.9875996457041626e-06,
        "epoch": 4.012400354295837,
        "step": 4530
    },
    {
        "loss": 0.0501,
        "grad_norm": 61.5660400390625,
        "learning_rate": 5.978742249778565e-06,
        "epoch": 4.021257750221435,
        "step": 4540
    },
    {
        "loss": 0.2628,
        "grad_norm": 27.897180557250977,
        "learning_rate": 5.9698848538529675e-06,
        "epoch": 4.030115146147033,
        "step": 4550
    },
    {
        "loss": 0.2398,
        "grad_norm": 288.8659973144531,
        "learning_rate": 5.96102745792737e-06,
        "epoch": 4.038972542072631,
        "step": 4560
    },
    {
        "loss": 0.042,
        "grad_norm": 0.4822910726070404,
        "learning_rate": 5.9521700620017716e-06,
        "epoch": 4.0478299379982285,
        "step": 4570
    },
    {
        "loss": 0.1522,
        "grad_norm": 3.414560079574585,
        "learning_rate": 5.943312666076174e-06,
        "epoch": 4.0566873339238265,
        "step": 4580
    },
    {
        "loss": 0.1522,
        "grad_norm": 0.2697417438030243,
        "learning_rate": 5.9344552701505765e-06,
        "epoch": 4.0655447298494245,
        "step": 4590
    },
    {
        "loss": 0.0463,
        "grad_norm": 2.8536813259124756,
        "learning_rate": 5.925597874224979e-06,
        "epoch": 4.0744021257750225,
        "step": 4600
    },
    {
        "loss": 0.0482,
        "grad_norm": 0.11989768594503403,
        "learning_rate": 5.9167404782993805e-06,
        "epoch": 4.0832595217006205,
        "step": 4610
    },
    {
        "loss": 0.1507,
        "grad_norm": 0.12312602251768112,
        "learning_rate": 5.907883082373782e-06,
        "epoch": 4.0921169176262175,
        "step": 4620
    },
    {
        "loss": 0.1332,
        "grad_norm": 14.586310386657715,
        "learning_rate": 5.899025686448185e-06,
        "epoch": 4.1009743135518155,
        "step": 4630
    },
    {
        "loss": 0.0895,
        "grad_norm": 96.5276107788086,
        "learning_rate": 5.890168290522586e-06,
        "epoch": 4.1098317094774135,
        "step": 4640
    },
    {
        "loss": 0.198,
        "grad_norm": 0.2365555316209793,
        "learning_rate": 5.881310894596989e-06,
        "epoch": 4.1186891054030115,
        "step": 4650
    },
    {
        "loss": 0.1438,
        "grad_norm": 12.290070533752441,
        "learning_rate": 5.872453498671391e-06,
        "epoch": 4.1275465013286095,
        "step": 4660
    },
    {
        "loss": 0.0526,
        "grad_norm": 0.1499185562133789,
        "learning_rate": 5.8635961027457936e-06,
        "epoch": 4.136403897254207,
        "step": 4670
    },
    {
        "loss": 0.0571,
        "grad_norm": 1.4573405981063843,
        "learning_rate": 5.854738706820195e-06,
        "epoch": 4.145261293179805,
        "step": 4680
    },
    {
        "loss": 0.147,
        "grad_norm": 1.9497222900390625,
        "learning_rate": 5.845881310894598e-06,
        "epoch": 4.154118689105403,
        "step": 4690
    },
    {
        "loss": 0.2118,
        "grad_norm": 79.51600646972656,
        "learning_rate": 5.837023914969e-06,
        "epoch": 4.1629760850310005,
        "step": 4700
    },
    {
        "loss": 0.0789,
        "grad_norm": 0.2628452181816101,
        "learning_rate": 5.8281665190434025e-06,
        "epoch": 4.1718334809565985,
        "step": 4710
    },
    {
        "loss": 0.1409,
        "grad_norm": 1.9825085401535034,
        "learning_rate": 5.819309123117803e-06,
        "epoch": 4.180690876882196,
        "step": 4720
    },
    {
        "loss": 0.0054,
        "grad_norm": 0.15514640510082245,
        "learning_rate": 5.810451727192206e-06,
        "epoch": 4.189548272807794,
        "step": 4730
    },
    {
        "loss": 0.0766,
        "grad_norm": 0.8137553334236145,
        "learning_rate": 5.801594331266608e-06,
        "epoch": 4.198405668733392,
        "step": 4740
    },
    {
        "loss": 0.0427,
        "grad_norm": 1.2055307626724243,
        "learning_rate": 5.79273693534101e-06,
        "epoch": 4.20726306465899,
        "step": 4750
    },
    {
        "loss": 0.0673,
        "grad_norm": 12.018447875976562,
        "learning_rate": 5.783879539415412e-06,
        "epoch": 4.216120460584588,
        "step": 4760
    },
    {
        "loss": 0.0538,
        "grad_norm": 0.07817988842725754,
        "learning_rate": 5.775022143489815e-06,
        "epoch": 4.224977856510186,
        "step": 4770
    },
    {
        "loss": 0.0959,
        "grad_norm": 12.06698989868164,
        "learning_rate": 5.766164747564217e-06,
        "epoch": 4.233835252435784,
        "step": 4780
    },
    {
        "loss": 0.1519,
        "grad_norm": 107.18683624267578,
        "learning_rate": 5.757307351638619e-06,
        "epoch": 4.242692648361381,
        "step": 4790
    },
    {
        "loss": 0.1007,
        "grad_norm": 43.57947540283203,
        "learning_rate": 5.748449955713021e-06,
        "epoch": 4.251550044286979,
        "step": 4800
    },
    {
        "loss": 0.2182,
        "grad_norm": 0.6945489048957825,
        "learning_rate": 5.739592559787423e-06,
        "epoch": 4.260407440212577,
        "step": 4810
    },
    {
        "loss": 0.1053,
        "grad_norm": 0.11543263494968414,
        "learning_rate": 5.7307351638618245e-06,
        "epoch": 4.269264836138175,
        "step": 4820
    },
    {
        "loss": 0.1169,
        "grad_norm": 0.17556384205818176,
        "learning_rate": 5.721877767936227e-06,
        "epoch": 4.278122232063773,
        "step": 4830
    },
    {
        "loss": 0.1155,
        "grad_norm": 87.23262786865234,
        "learning_rate": 5.713020372010629e-06,
        "epoch": 4.286979627989371,
        "step": 4840
    },
    {
        "loss": 0.0375,
        "grad_norm": 1.3834483623504639,
        "learning_rate": 5.704162976085032e-06,
        "epoch": 4.295837023914969,
        "step": 4850
    },
    {
        "loss": 0.0051,
        "grad_norm": 0.11550068855285645,
        "learning_rate": 5.6953055801594335e-06,
        "epoch": 4.304694419840567,
        "step": 4860
    },
    {
        "loss": 0.0319,
        "grad_norm": 0.11638585478067398,
        "learning_rate": 5.686448184233836e-06,
        "epoch": 4.313551815766164,
        "step": 4870
    },
    {
        "loss": 0.0667,
        "grad_norm": 0.10849916934967041,
        "learning_rate": 5.677590788308238e-06,
        "epoch": 4.322409211691762,
        "step": 4880
    },
    {
        "loss": 0.1304,
        "grad_norm": 96.11929321289062,
        "learning_rate": 5.668733392382641e-06,
        "epoch": 4.33126660761736,
        "step": 4890
    },
    {
        "loss": 0.094,
        "grad_norm": 15.762747764587402,
        "learning_rate": 5.659875996457042e-06,
        "epoch": 4.340124003542958,
        "step": 4900
    },
    {
        "loss": 0.1254,
        "grad_norm": 0.8807557821273804,
        "learning_rate": 5.651018600531444e-06,
        "epoch": 4.348981399468556,
        "step": 4910
    },
    {
        "loss": 0.0462,
        "grad_norm": 10.62702751159668,
        "learning_rate": 5.642161204605846e-06,
        "epoch": 4.357838795394154,
        "step": 4920
    },
    {
        "loss": 0.1416,
        "grad_norm": 0.10498028993606567,
        "learning_rate": 5.633303808680248e-06,
        "epoch": 4.366696191319752,
        "step": 4930
    },
    {
        "loss": 0.006,
        "grad_norm": 0.07803378999233246,
        "learning_rate": 5.6244464127546506e-06,
        "epoch": 4.37555358724535,
        "step": 4940
    },
    {
        "loss": 0.0996,
        "grad_norm": 0.0806722566485405,
        "learning_rate": 5.615589016829053e-06,
        "epoch": 4.384410983170948,
        "step": 4950
    },
    {
        "loss": 0.0725,
        "grad_norm": 0.1244470477104187,
        "learning_rate": 5.606731620903455e-06,
        "epoch": 4.393268379096545,
        "step": 4960
    },
    {
        "loss": 0.1499,
        "grad_norm": 0.0998963937163353,
        "learning_rate": 5.597874224977857e-06,
        "epoch": 4.402125775022143,
        "step": 4970
    },
    {
        "loss": 0.1566,
        "grad_norm": 4.940255165100098,
        "learning_rate": 5.5890168290522595e-06,
        "epoch": 4.410983170947741,
        "step": 4980
    },
    {
        "loss": 0.0745,
        "grad_norm": 0.1570095717906952,
        "learning_rate": 5.580159433126662e-06,
        "epoch": 4.419840566873339,
        "step": 4990
    },
    {
        "loss": 0.184,
        "grad_norm": 130.5906219482422,
        "learning_rate": 5.571302037201063e-06,
        "epoch": 4.428697962798937,
        "step": 5000
    },
    {
        "loss": 0.0399,
        "grad_norm": 0.19126152992248535,
        "learning_rate": 5.562444641275465e-06,
        "epoch": 4.437555358724535,
        "step": 5010
    },
    {
        "loss": 0.174,
        "grad_norm": 2.7355668544769287,
        "learning_rate": 5.553587245349868e-06,
        "epoch": 4.446412754650133,
        "step": 5020
    },
    {
        "loss": 0.0498,
        "grad_norm": 8.234580039978027,
        "learning_rate": 5.544729849424269e-06,
        "epoch": 4.455270150575731,
        "step": 5030
    },
    {
        "loss": 0.1061,
        "grad_norm": 2.4890565872192383,
        "learning_rate": 5.535872453498672e-06,
        "epoch": 4.464127546501329,
        "step": 5040
    },
    {
        "loss": 0.1171,
        "grad_norm": 0.6518575549125671,
        "learning_rate": 5.527015057573074e-06,
        "epoch": 4.472984942426926,
        "step": 5050
    },
    {
        "loss": 0.0727,
        "grad_norm": 5.071357727050781,
        "learning_rate": 5.518157661647477e-06,
        "epoch": 4.481842338352524,
        "step": 5060
    },
    {
        "loss": 0.0729,
        "grad_norm": 4.181596279144287,
        "learning_rate": 5.509300265721878e-06,
        "epoch": 4.490699734278122,
        "step": 5070
    },
    {
        "loss": 0.0457,
        "grad_norm": 0.19392003118991852,
        "learning_rate": 5.500442869796281e-06,
        "epoch": 4.49955713020372,
        "step": 5080
    },
    {
        "loss": 0.0671,
        "grad_norm": 8.145600318908691,
        "learning_rate": 5.491585473870682e-06,
        "epoch": 4.508414526129318,
        "step": 5090
    },
    {
        "loss": 0.029,
        "grad_norm": 0.10477744042873383,
        "learning_rate": 5.482728077945084e-06,
        "epoch": 4.517271922054916,
        "step": 5100
    },
    {
        "loss": 0.1807,
        "grad_norm": 135.80052185058594,
        "learning_rate": 5.473870682019486e-06,
        "epoch": 4.526129317980514,
        "step": 5110
    },
    {
        "loss": 0.2024,
        "grad_norm": 0.08790416270494461,
        "learning_rate": 5.465013286093889e-06,
        "epoch": 4.534986713906112,
        "step": 5120
    },
    {
        "loss": 0.0354,
        "grad_norm": 0.15722613036632538,
        "learning_rate": 5.456155890168291e-06,
        "epoch": 4.54384410983171,
        "step": 5130
    },
    {
        "loss": 0.101,
        "grad_norm": 121.46121215820312,
        "learning_rate": 5.447298494242693e-06,
        "epoch": 4.552701505757307,
        "step": 5140
    },
    {
        "loss": 0.0449,
        "grad_norm": 25.093698501586914,
        "learning_rate": 5.438441098317095e-06,
        "epoch": 4.561558901682905,
        "step": 5150
    },
    {
        "loss": 0.0745,
        "grad_norm": 0.2788080871105194,
        "learning_rate": 5.429583702391498e-06,
        "epoch": 4.570416297608503,
        "step": 5160
    },
    {
        "loss": 0.1968,
        "grad_norm": 0.8139598369598389,
        "learning_rate": 5.4207263064659e-06,
        "epoch": 4.579273693534101,
        "step": 5170
    },
    {
        "loss": 0.0394,
        "grad_norm": 6.193310260772705,
        "learning_rate": 5.411868910540301e-06,
        "epoch": 4.588131089459699,
        "step": 5180
    },
    {
        "loss": 0.058,
        "grad_norm": 0.07863900810480118,
        "learning_rate": 5.4030115146147035e-06,
        "epoch": 4.596988485385297,
        "step": 5190
    },
    {
        "loss": 0.0747,
        "grad_norm": 0.4841141402721405,
        "learning_rate": 5.394154118689106e-06,
        "epoch": 4.605845881310895,
        "step": 5200
    },
    {
        "loss": 0.1797,
        "grad_norm": 3.2721524238586426,
        "learning_rate": 5.3852967227635076e-06,
        "epoch": 4.614703277236492,
        "step": 5210
    },
    {
        "loss": 0.0038,
        "grad_norm": 0.10973191261291504,
        "learning_rate": 5.37643932683791e-06,
        "epoch": 4.62356067316209,
        "step": 5220
    },
    {
        "loss": 0.2581,
        "grad_norm": 6.739013671875,
        "learning_rate": 5.3675819309123125e-06,
        "epoch": 4.632418069087688,
        "step": 5230
    },
    {
        "loss": 0.0245,
        "grad_norm": 0.102286197245121,
        "learning_rate": 5.358724534986715e-06,
        "epoch": 4.641275465013286,
        "step": 5240
    },
    {
        "loss": 0.0752,
        "grad_norm": 0.1075497567653656,
        "learning_rate": 5.3498671390611165e-06,
        "epoch": 4.650132860938884,
        "step": 5250
    },
    {
        "loss": 0.1475,
        "grad_norm": 0.11528856307268143,
        "learning_rate": 5.341009743135519e-06,
        "epoch": 4.658990256864482,
        "step": 5260
    },
    {
        "loss": 0.0245,
        "grad_norm": 0.34991541504859924,
        "learning_rate": 5.3321523472099214e-06,
        "epoch": 4.66784765279008,
        "step": 5270
    },
    {
        "loss": 0.0789,
        "grad_norm": 15.294561386108398,
        "learning_rate": 5.323294951284322e-06,
        "epoch": 4.676705048715678,
        "step": 5280
    },
    {
        "loss": 0.0862,
        "grad_norm": 134.84559631347656,
        "learning_rate": 5.314437555358725e-06,
        "epoch": 4.685562444641276,
        "step": 5290
    },
    {
        "loss": 0.0379,
        "grad_norm": 35.84708023071289,
        "learning_rate": 5.305580159433127e-06,
        "epoch": 4.694419840566873,
        "step": 5300
    },
    {
        "loss": 0.1662,
        "grad_norm": 40.78369140625,
        "learning_rate": 5.296722763507529e-06,
        "epoch": 4.703277236492471,
        "step": 5310
    },
    {
        "loss": 0.07,
        "grad_norm": 0.09697223454713821,
        "learning_rate": 5.287865367581931e-06,
        "epoch": 4.712134632418069,
        "step": 5320
    },
    {
        "loss": 0.142,
        "grad_norm": 1.0672982931137085,
        "learning_rate": 5.279007971656334e-06,
        "epoch": 4.720992028343667,
        "step": 5330
    },
    {
        "loss": 0.1073,
        "grad_norm": 0.061700597405433655,
        "learning_rate": 5.270150575730736e-06,
        "epoch": 4.729849424269265,
        "step": 5340
    },
    {
        "loss": 0.1273,
        "grad_norm": 0.14853255450725555,
        "learning_rate": 5.261293179805138e-06,
        "epoch": 4.738706820194863,
        "step": 5350
    },
    {
        "loss": 0.1324,
        "grad_norm": 0.0666702389717102,
        "learning_rate": 5.25243578387954e-06,
        "epoch": 4.747564216120461,
        "step": 5360
    },
    {
        "loss": 0.1093,
        "grad_norm": 2.522630453109741,
        "learning_rate": 5.243578387953942e-06,
        "epoch": 4.756421612046059,
        "step": 5370
    },
    {
        "loss": 0.1225,
        "grad_norm": 39.82213592529297,
        "learning_rate": 5.234720992028343e-06,
        "epoch": 4.765279007971657,
        "step": 5380
    },
    {
        "loss": 0.1361,
        "grad_norm": 17.532520294189453,
        "learning_rate": 5.225863596102746e-06,
        "epoch": 4.774136403897254,
        "step": 5390
    },
    {
        "loss": 0.0768,
        "grad_norm": 0.07318533957004547,
        "learning_rate": 5.217006200177148e-06,
        "epoch": 4.782993799822852,
        "step": 5400
    },
    {
        "loss": 0.0405,
        "grad_norm": 0.07487957179546356,
        "learning_rate": 5.208148804251551e-06,
        "epoch": 4.79185119574845,
        "step": 5410
    },
    {
        "loss": 0.0719,
        "grad_norm": 4.973552227020264,
        "learning_rate": 5.199291408325952e-06,
        "epoch": 4.800708591674048,
        "step": 5420
    },
    {
        "loss": 0.0026,
        "grad_norm": 0.10949438810348511,
        "learning_rate": 5.190434012400355e-06,
        "epoch": 4.809565987599646,
        "step": 5430
    },
    {
        "loss": 0.2341,
        "grad_norm": 120.17536163330078,
        "learning_rate": 5.181576616474757e-06,
        "epoch": 4.818423383525244,
        "step": 5440
    },
    {
        "loss": 0.0289,
        "grad_norm": 0.5999411940574646,
        "learning_rate": 5.17271922054916e-06,
        "epoch": 4.827280779450842,
        "step": 5450
    },
    {
        "loss": 0.1589,
        "grad_norm": 182.25938415527344,
        "learning_rate": 5.1638618246235605e-06,
        "epoch": 4.83613817537644,
        "step": 5460
    },
    {
        "loss": 0.1352,
        "grad_norm": 0.9737338423728943,
        "learning_rate": 5.155004428697963e-06,
        "epoch": 4.844995571302038,
        "step": 5470
    },
    {
        "loss": 0.07,
        "grad_norm": 0.08929746598005295,
        "learning_rate": 5.146147032772365e-06,
        "epoch": 4.853852967227635,
        "step": 5480
    },
    {
        "loss": 0.1455,
        "grad_norm": 11.503080368041992,
        "learning_rate": 5.137289636846767e-06,
        "epoch": 4.862710363153233,
        "step": 5490
    },
    {
        "loss": 0.1087,
        "grad_norm": 0.11442670226097107,
        "learning_rate": 5.1284322409211695e-06,
        "epoch": 4.871567759078831,
        "step": 5500
    },
    {
        "loss": 0.1346,
        "grad_norm": 60.293392181396484,
        "learning_rate": 5.119574844995572e-06,
        "epoch": 4.880425155004429,
        "step": 5510
    },
    {
        "loss": 0.17,
        "grad_norm": 0.8631533980369568,
        "learning_rate": 5.110717449069974e-06,
        "epoch": 4.889282550930027,
        "step": 5520
    },
    {
        "loss": 0.1743,
        "grad_norm": 108.1187973022461,
        "learning_rate": 5.101860053144376e-06,
        "epoch": 4.898139946855625,
        "step": 5530
    },
    {
        "loss": 0.0864,
        "grad_norm": 0.09440750628709793,
        "learning_rate": 5.0930026572187784e-06,
        "epoch": 4.906997342781223,
        "step": 5540
    },
    {
        "loss": 0.1099,
        "grad_norm": 0.08807305991649628,
        "learning_rate": 5.084145261293181e-06,
        "epoch": 4.9158547387068205,
        "step": 5550
    },
    {
        "loss": 0.1094,
        "grad_norm": 0.24193871021270752,
        "learning_rate": 5.075287865367582e-06,
        "epoch": 4.9247121346324185,
        "step": 5560
    },
    {
        "loss": 0.0677,
        "grad_norm": 88.36737823486328,
        "learning_rate": 5.066430469441984e-06,
        "epoch": 4.933569530558016,
        "step": 5570
    },
    {
        "loss": 0.0994,
        "grad_norm": 2.592421054840088,
        "learning_rate": 5.0575730735163866e-06,
        "epoch": 4.942426926483614,
        "step": 5580
    },
    {
        "loss": 0.1033,
        "grad_norm": 0.0648559108376503,
        "learning_rate": 5.048715677590789e-06,
        "epoch": 4.951284322409212,
        "step": 5590
    },
    {
        "loss": 0.0846,
        "grad_norm": 4.575162887573242,
        "learning_rate": 5.039858281665191e-06,
        "epoch": 4.9601417183348095,
        "step": 5600
    },
    {
        "loss": 0.1068,
        "grad_norm": 11.696330070495605,
        "learning_rate": 5.031000885739593e-06,
        "epoch": 4.9689991142604075,
        "step": 5610
    },
    {
        "loss": 0.0737,
        "grad_norm": 0.13685116171836853,
        "learning_rate": 5.0221434898139955e-06,
        "epoch": 4.9778565101860055,
        "step": 5620
    },
    {
        "loss": 0.1074,
        "grad_norm": 3.3264284133911133,
        "learning_rate": 5.013286093888398e-06,
        "epoch": 4.9867139061116035,
        "step": 5630
    },
    {
        "loss": 0.2051,
        "grad_norm": 1.3159921169281006,
        "learning_rate": 5.0044286979628e-06,
        "epoch": 4.995571302037201,
        "step": 5640
    },
    {
        "eval_loss": 0.1600537896156311,
        "eval_accuracy": 0.96878,
        "eval_precision": 0.96568,
        "eval_recall": 0.9721,
        "eval_f1": 0.96888,
        "eval_runtime": 149.5036,
        "eval_samples_per_second": 60.413,
        "eval_steps_per_second": 3.779,
        "epoch": 5.0,
        "step": 5645
    },
    {
        "loss": 0.0208,
        "grad_norm": 0.5833612680435181,
        "learning_rate": 4.995571302037201e-06,
        "epoch": 5.0044286979627985,
        "step": 5650
    },
    {
        "loss": 0.072,
        "grad_norm": 0.13005203008651733,
        "learning_rate": 4.986713906111604e-06,
        "epoch": 5.0132860938883965,
        "step": 5660
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.15169574320316315,
        "learning_rate": 4.977856510186005e-06,
        "epoch": 5.0221434898139945,
        "step": 5670
    },
    {
        "loss": 0.0324,
        "grad_norm": 0.10846147686243057,
        "learning_rate": 4.968999114260408e-06,
        "epoch": 5.0310008857395925,
        "step": 5680
    },
    {
        "loss": 0.1003,
        "grad_norm": 0.09531215578317642,
        "learning_rate": 4.96014171833481e-06,
        "epoch": 5.0398582816651905,
        "step": 5690
    },
    {
        "loss": 0.022,
        "grad_norm": 6.45603609085083,
        "learning_rate": 4.951284322409212e-06,
        "epoch": 5.048715677590788,
        "step": 5700
    },
    {
        "loss": 0.1611,
        "grad_norm": 120.73710632324219,
        "learning_rate": 4.942426926483614e-06,
        "epoch": 5.057573073516386,
        "step": 5710
    },
    {
        "loss": 0.0042,
        "grad_norm": 0.07928801327943802,
        "learning_rate": 4.933569530558016e-06,
        "epoch": 5.066430469441984,
        "step": 5720
    },
    {
        "loss": 0.0356,
        "grad_norm": 0.04967132955789566,
        "learning_rate": 4.924712134632418e-06,
        "epoch": 5.075287865367582,
        "step": 5730
    },
    {
        "loss": 0.0628,
        "grad_norm": 0.04724683240056038,
        "learning_rate": 4.915854738706821e-06,
        "epoch": 5.0841452612931795,
        "step": 5740
    },
    {
        "loss": 0.1071,
        "grad_norm": 131.96255493164062,
        "learning_rate": 4.906997342781223e-06,
        "epoch": 5.093002657218777,
        "step": 5750
    },
    {
        "loss": 0.0188,
        "grad_norm": 46.04450607299805,
        "learning_rate": 4.898139946855625e-06,
        "epoch": 5.101860053144375,
        "step": 5760
    },
    {
        "loss": 0.0757,
        "grad_norm": 61.027587890625,
        "learning_rate": 4.8892825509300264e-06,
        "epoch": 5.110717449069973,
        "step": 5770
    },
    {
        "loss": 0.1872,
        "grad_norm": 0.11384311318397522,
        "learning_rate": 4.880425155004429e-06,
        "epoch": 5.119574844995571,
        "step": 5780
    },
    {
        "loss": 0.1062,
        "grad_norm": 0.25804761052131653,
        "learning_rate": 4.871567759078831e-06,
        "epoch": 5.128432240921169,
        "step": 5790
    },
    {
        "loss": 0.0462,
        "grad_norm": 66.38569641113281,
        "learning_rate": 4.862710363153234e-06,
        "epoch": 5.137289636846767,
        "step": 5800
    },
    {
        "loss": 0.0167,
        "grad_norm": 0.2178225964307785,
        "learning_rate": 4.8538529672276354e-06,
        "epoch": 5.146147032772365,
        "step": 5810
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.09659253060817719,
        "learning_rate": 4.844995571302038e-06,
        "epoch": 5.155004428697962,
        "step": 5820
    },
    {
        "loss": 0.0594,
        "grad_norm": 3.4436397552490234,
        "learning_rate": 4.8361381753764395e-06,
        "epoch": 5.16386182462356,
        "step": 5830
    },
    {
        "loss": 0.0621,
        "grad_norm": 0.10983869433403015,
        "learning_rate": 4.827280779450842e-06,
        "epoch": 5.172719220549158,
        "step": 5840
    },
    {
        "loss": 0.0048,
        "grad_norm": 1.141602873802185,
        "learning_rate": 4.818423383525244e-06,
        "epoch": 5.181576616474756,
        "step": 5850
    },
    {
        "loss": 0.0695,
        "grad_norm": 0.07901854068040848,
        "learning_rate": 4.809565987599646e-06,
        "epoch": 5.190434012400354,
        "step": 5860
    },
    {
        "loss": 0.0642,
        "grad_norm": 0.22529856860637665,
        "learning_rate": 4.8007085916740485e-06,
        "epoch": 5.199291408325952,
        "step": 5870
    },
    {
        "loss": 0.0189,
        "grad_norm": 0.2021508365869522,
        "learning_rate": 4.79185119574845e-06,
        "epoch": 5.20814880425155,
        "step": 5880
    },
    {
        "loss": 0.1473,
        "grad_norm": 142.00927734375,
        "learning_rate": 4.7829937998228525e-06,
        "epoch": 5.217006200177148,
        "step": 5890
    },
    {
        "loss": 0.0542,
        "grad_norm": 0.1422790288925171,
        "learning_rate": 4.774136403897255e-06,
        "epoch": 5.225863596102746,
        "step": 5900
    },
    {
        "loss": 0.0206,
        "grad_norm": 8.96712875366211,
        "learning_rate": 4.765279007971657e-06,
        "epoch": 5.234720992028343,
        "step": 5910
    },
    {
        "loss": 0.0643,
        "grad_norm": 0.6523796916007996,
        "learning_rate": 4.756421612046059e-06,
        "epoch": 5.243578387953941,
        "step": 5920
    },
    {
        "loss": 0.0973,
        "grad_norm": 52.4430046081543,
        "learning_rate": 4.747564216120461e-06,
        "epoch": 5.252435783879539,
        "step": 5930
    },
    {
        "loss": 0.1038,
        "grad_norm": 0.07202685624361038,
        "learning_rate": 4.738706820194863e-06,
        "epoch": 5.261293179805137,
        "step": 5940
    },
    {
        "loss": 0.1812,
        "grad_norm": 246.27032470703125,
        "learning_rate": 4.729849424269265e-06,
        "epoch": 5.270150575730735,
        "step": 5950
    },
    {
        "loss": 0.0562,
        "grad_norm": 3.451633930206299,
        "learning_rate": 4.720992028343667e-06,
        "epoch": 5.279007971656333,
        "step": 5960
    },
    {
        "loss": 0.0095,
        "grad_norm": 0.09534188359975815,
        "learning_rate": 4.71213463241807e-06,
        "epoch": 5.287865367581931,
        "step": 5970
    },
    {
        "loss": 0.153,
        "grad_norm": 0.11460192501544952,
        "learning_rate": 4.703277236492472e-06,
        "epoch": 5.296722763507529,
        "step": 5980
    },
    {
        "loss": 0.2214,
        "grad_norm": 68.5347671508789,
        "learning_rate": 4.694419840566874e-06,
        "epoch": 5.305580159433127,
        "step": 5990
    },
    {
        "loss": 0.1789,
        "grad_norm": 3.9518415927886963,
        "learning_rate": 4.685562444641275e-06,
        "epoch": 5.314437555358724,
        "step": 6000
    },
    {
        "loss": 0.1562,
        "grad_norm": 0.08584582805633545,
        "learning_rate": 4.676705048715678e-06,
        "epoch": 5.323294951284322,
        "step": 6010
    },
    {
        "loss": 0.0841,
        "grad_norm": 0.15357603132724762,
        "learning_rate": 4.66784765279008e-06,
        "epoch": 5.33215234720992,
        "step": 6020
    },
    {
        "loss": 0.061,
        "grad_norm": 0.12626920640468597,
        "learning_rate": 4.658990256864483e-06,
        "epoch": 5.341009743135518,
        "step": 6030
    },
    {
        "loss": 0.0381,
        "grad_norm": 0.2838292419910431,
        "learning_rate": 4.650132860938884e-06,
        "epoch": 5.349867139061116,
        "step": 6040
    },
    {
        "loss": 0.1597,
        "grad_norm": 0.26251456141471863,
        "learning_rate": 4.641275465013286e-06,
        "epoch": 5.358724534986714,
        "step": 6050
    },
    {
        "loss": 0.0571,
        "grad_norm": 0.10791899263858795,
        "learning_rate": 4.632418069087688e-06,
        "epoch": 5.367581930912312,
        "step": 6060
    },
    {
        "loss": 0.0613,
        "grad_norm": 0.2557900846004486,
        "learning_rate": 4.623560673162091e-06,
        "epoch": 5.37643932683791,
        "step": 6070
    },
    {
        "loss": 0.1621,
        "grad_norm": 130.85513305664062,
        "learning_rate": 4.614703277236493e-06,
        "epoch": 5.385296722763507,
        "step": 6080
    },
    {
        "loss": 0.0707,
        "grad_norm": 2.383153200149536,
        "learning_rate": 4.605845881310895e-06,
        "epoch": 5.394154118689105,
        "step": 6090
    },
    {
        "loss": 0.0291,
        "grad_norm": 0.07197503745555878,
        "learning_rate": 4.596988485385297e-06,
        "epoch": 5.403011514614703,
        "step": 6100
    },
    {
        "loss": 0.0028,
        "grad_norm": 0.12044130265712738,
        "learning_rate": 4.588131089459699e-06,
        "epoch": 5.411868910540301,
        "step": 6110
    },
    {
        "loss": 0.0311,
        "grad_norm": 0.045813243836164474,
        "learning_rate": 4.579273693534101e-06,
        "epoch": 5.420726306465899,
        "step": 6120
    },
    {
        "loss": 0.0092,
        "grad_norm": 3.692549705505371,
        "learning_rate": 4.570416297608504e-06,
        "epoch": 5.429583702391497,
        "step": 6130
    },
    {
        "loss": 0.1534,
        "grad_norm": 14.26154899597168,
        "learning_rate": 4.5615589016829055e-06,
        "epoch": 5.438441098317095,
        "step": 6140
    },
    {
        "loss": 0.0708,
        "grad_norm": 28.738008499145508,
        "learning_rate": 4.552701505757308e-06,
        "epoch": 5.447298494242693,
        "step": 6150
    },
    {
        "loss": 0.1195,
        "grad_norm": 36.18049240112305,
        "learning_rate": 4.5438441098317095e-06,
        "epoch": 5.45615589016829,
        "step": 6160
    },
    {
        "loss": 0.0366,
        "grad_norm": 0.14848287403583527,
        "learning_rate": 4.534986713906112e-06,
        "epoch": 5.465013286093888,
        "step": 6170
    },
    {
        "loss": 0.0998,
        "grad_norm": 3.135761022567749,
        "learning_rate": 4.5261293179805144e-06,
        "epoch": 5.473870682019486,
        "step": 6180
    },
    {
        "loss": 0.1114,
        "grad_norm": 0.09229465574026108,
        "learning_rate": 4.517271922054916e-06,
        "epoch": 5.482728077945084,
        "step": 6190
    },
    {
        "loss": 0.0506,
        "grad_norm": 0.12205677479505539,
        "learning_rate": 4.5084145261293185e-06,
        "epoch": 5.491585473870682,
        "step": 6200
    },
    {
        "loss": 0.0135,
        "grad_norm": 0.569310188293457,
        "learning_rate": 4.499557130203721e-06,
        "epoch": 5.50044286979628,
        "step": 6210
    },
    {
        "loss": 0.0801,
        "grad_norm": 0.1691511571407318,
        "learning_rate": 4.4906997342781226e-06,
        "epoch": 5.509300265721878,
        "step": 6220
    },
    {
        "loss": 0.0349,
        "grad_norm": 0.20403653383255005,
        "learning_rate": 4.481842338352524e-06,
        "epoch": 5.518157661647476,
        "step": 6230
    },
    {
        "loss": 0.0818,
        "grad_norm": 0.1435880810022354,
        "learning_rate": 4.472984942426927e-06,
        "epoch": 5.527015057573074,
        "step": 6240
    },
    {
        "loss": 0.0104,
        "grad_norm": 0.7229412198066711,
        "learning_rate": 4.464127546501329e-06,
        "epoch": 5.535872453498671,
        "step": 6250
    },
    {
        "loss": 0.0613,
        "grad_norm": 0.024425910785794258,
        "learning_rate": 4.4552701505757315e-06,
        "epoch": 5.544729849424269,
        "step": 6260
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.18043112754821777,
        "learning_rate": 4.446412754650133e-06,
        "epoch": 5.553587245349867,
        "step": 6270
    },
    {
        "loss": 0.0338,
        "grad_norm": 7.279362678527832,
        "learning_rate": 4.437555358724535e-06,
        "epoch": 5.562444641275465,
        "step": 6280
    },
    {
        "loss": 0.0481,
        "grad_norm": 0.09991516917943954,
        "learning_rate": 4.428697962798937e-06,
        "epoch": 5.571302037201063,
        "step": 6290
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.07850179076194763,
        "learning_rate": 4.41984056687334e-06,
        "epoch": 5.580159433126661,
        "step": 6300
    },
    {
        "loss": 0.0678,
        "grad_norm": 0.42625948786735535,
        "learning_rate": 4.410983170947742e-06,
        "epoch": 5.589016829052259,
        "step": 6310
    },
    {
        "loss": 0.0592,
        "grad_norm": 14.1292085647583,
        "learning_rate": 4.402125775022144e-06,
        "epoch": 5.597874224977857,
        "step": 6320
    },
    {
        "loss": 0.1547,
        "grad_norm": 0.18729516863822937,
        "learning_rate": 4.393268379096546e-06,
        "epoch": 5.606731620903455,
        "step": 6330
    },
    {
        "loss": 0.0727,
        "grad_norm": 181.91690063476562,
        "learning_rate": 4.384410983170948e-06,
        "epoch": 5.615589016829052,
        "step": 6340
    },
    {
        "loss": 0.1037,
        "grad_norm": 2.549928903579712,
        "learning_rate": 4.37555358724535e-06,
        "epoch": 5.62444641275465,
        "step": 6350
    },
    {
        "loss": 0.1069,
        "grad_norm": 64.90037536621094,
        "learning_rate": 4.366696191319753e-06,
        "epoch": 5.633303808680248,
        "step": 6360
    },
    {
        "loss": 0.0825,
        "grad_norm": 0.21377310156822205,
        "learning_rate": 4.357838795394154e-06,
        "epoch": 5.642161204605846,
        "step": 6370
    },
    {
        "loss": 0.2203,
        "grad_norm": 14.686180114746094,
        "learning_rate": 4.348981399468557e-06,
        "epoch": 5.651018600531444,
        "step": 6380
    },
    {
        "loss": 0.0222,
        "grad_norm": 0.845051109790802,
        "learning_rate": 4.340124003542958e-06,
        "epoch": 5.659875996457042,
        "step": 6390
    },
    {
        "loss": 0.1006,
        "grad_norm": 11.66036319732666,
        "learning_rate": 4.331266607617361e-06,
        "epoch": 5.66873339238264,
        "step": 6400
    },
    {
        "loss": 0.1533,
        "grad_norm": 147.0570526123047,
        "learning_rate": 4.322409211691763e-06,
        "epoch": 5.677590788308238,
        "step": 6410
    },
    {
        "loss": 0.1005,
        "grad_norm": 54.80975341796875,
        "learning_rate": 4.313551815766165e-06,
        "epoch": 5.686448184233836,
        "step": 6420
    },
    {
        "loss": 0.0486,
        "grad_norm": 0.33236223459243774,
        "learning_rate": 4.304694419840567e-06,
        "epoch": 5.695305580159433,
        "step": 6430
    },
    {
        "loss": 0.0857,
        "grad_norm": 0.07088969647884369,
        "learning_rate": 4.295837023914969e-06,
        "epoch": 5.704162976085031,
        "step": 6440
    },
    {
        "loss": 0.0733,
        "grad_norm": 152.33987426757812,
        "learning_rate": 4.2869796279893714e-06,
        "epoch": 5.713020372010629,
        "step": 6450
    },
    {
        "loss": 0.0301,
        "grad_norm": 1.05482017993927,
        "learning_rate": 4.278122232063774e-06,
        "epoch": 5.721877767936227,
        "step": 6460
    },
    {
        "loss": 0.2116,
        "grad_norm": 136.32986450195312,
        "learning_rate": 4.2692648361381755e-06,
        "epoch": 5.730735163861825,
        "step": 6470
    },
    {
        "loss": 0.0424,
        "grad_norm": 0.13890916109085083,
        "learning_rate": 4.260407440212578e-06,
        "epoch": 5.739592559787423,
        "step": 6480
    },
    {
        "loss": 0.0775,
        "grad_norm": 0.09535585343837738,
        "learning_rate": 4.25155004428698e-06,
        "epoch": 5.748449955713021,
        "step": 6490
    },
    {
        "loss": 0.0617,
        "grad_norm": 0.07919086515903473,
        "learning_rate": 4.242692648361382e-06,
        "epoch": 5.757307351638619,
        "step": 6500
    },
    {
        "loss": 0.1071,
        "grad_norm": 0.617066502571106,
        "learning_rate": 4.233835252435784e-06,
        "epoch": 5.766164747564217,
        "step": 6510
    },
    {
        "loss": 0.1086,
        "grad_norm": 2.6757378578186035,
        "learning_rate": 4.224977856510186e-06,
        "epoch": 5.775022143489814,
        "step": 6520
    },
    {
        "loss": 0.0157,
        "grad_norm": 0.07484780251979828,
        "learning_rate": 4.2161204605845885e-06,
        "epoch": 5.783879539415412,
        "step": 6530
    },
    {
        "loss": 0.0914,
        "grad_norm": 58.8079719543457,
        "learning_rate": 4.207263064658991e-06,
        "epoch": 5.79273693534101,
        "step": 6540
    },
    {
        "loss": 0.0238,
        "grad_norm": 0.16817867755889893,
        "learning_rate": 4.198405668733393e-06,
        "epoch": 5.801594331266608,
        "step": 6550
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.08254711329936981,
        "learning_rate": 4.189548272807795e-06,
        "epoch": 5.810451727192206,
        "step": 6560
    },
    {
        "loss": 0.0813,
        "grad_norm": 6.930983066558838,
        "learning_rate": 4.180690876882197e-06,
        "epoch": 5.819309123117804,
        "step": 6570
    },
    {
        "loss": 0.015,
        "grad_norm": 48.52976608276367,
        "learning_rate": 4.171833480956599e-06,
        "epoch": 5.8281665190434015,
        "step": 6580
    },
    {
        "loss": 0.0308,
        "grad_norm": 0.07304340600967407,
        "learning_rate": 4.1629760850310016e-06,
        "epoch": 5.837023914968999,
        "step": 6590
    },
    {
        "loss": 0.05,
        "grad_norm": 3.9091782569885254,
        "learning_rate": 4.154118689105404e-06,
        "epoch": 5.845881310894597,
        "step": 6600
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.03871110454201698,
        "learning_rate": 4.145261293179806e-06,
        "epoch": 5.854738706820195,
        "step": 6610
    },
    {
        "loss": 0.0413,
        "grad_norm": 0.06731418520212173,
        "learning_rate": 4.136403897254207e-06,
        "epoch": 5.863596102745793,
        "step": 6620
    },
    {
        "loss": 0.1298,
        "grad_norm": 0.15877926349639893,
        "learning_rate": 4.12754650132861e-06,
        "epoch": 5.8724534986713905,
        "step": 6630
    },
    {
        "loss": 0.1019,
        "grad_norm": 91.36565399169922,
        "learning_rate": 4.118689105403012e-06,
        "epoch": 5.8813108945969885,
        "step": 6640
    },
    {
        "loss": 0.0725,
        "grad_norm": 0.05298556014895439,
        "learning_rate": 4.109831709477414e-06,
        "epoch": 5.8901682905225865,
        "step": 6650
    },
    {
        "loss": 0.026,
        "grad_norm": 0.3946540057659149,
        "learning_rate": 4.100974313551816e-06,
        "epoch": 5.8990256864481845,
        "step": 6660
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.434805303812027,
        "learning_rate": 4.092116917626218e-06,
        "epoch": 5.9078830823737825,
        "step": 6670
    },
    {
        "loss": 0.0846,
        "grad_norm": 0.04473930597305298,
        "learning_rate": 4.08325952170062e-06,
        "epoch": 5.9167404782993795,
        "step": 6680
    },
    {
        "loss": 0.1387,
        "grad_norm": 5.7816643714904785,
        "learning_rate": 4.074402125775023e-06,
        "epoch": 5.9255978742249775,
        "step": 6690
    },
    {
        "loss": 0.1199,
        "grad_norm": 0.06897930800914764,
        "learning_rate": 4.065544729849424e-06,
        "epoch": 5.9344552701505755,
        "step": 6700
    },
    {
        "loss": 0.0699,
        "grad_norm": 0.2105712741613388,
        "learning_rate": 4.056687333923827e-06,
        "epoch": 5.9433126660761735,
        "step": 6710
    },
    {
        "loss": 0.0606,
        "grad_norm": 0.24596495926380157,
        "learning_rate": 4.047829937998229e-06,
        "epoch": 5.9521700620017715,
        "step": 6720
    },
    {
        "loss": 0.0995,
        "grad_norm": 0.11442294716835022,
        "learning_rate": 4.038972542072631e-06,
        "epoch": 5.961027457927369,
        "step": 6730
    },
    {
        "loss": 0.0579,
        "grad_norm": 0.09880378842353821,
        "learning_rate": 4.030115146147033e-06,
        "epoch": 5.969884853852967,
        "step": 6740
    },
    {
        "loss": 0.086,
        "grad_norm": 14.088924407958984,
        "learning_rate": 4.021257750221435e-06,
        "epoch": 5.978742249778565,
        "step": 6750
    },
    {
        "loss": 0.0839,
        "grad_norm": 0.04059465602040291,
        "learning_rate": 4.012400354295837e-06,
        "epoch": 5.987599645704163,
        "step": 6760
    },
    {
        "loss": 0.0773,
        "grad_norm": 0.5561727285385132,
        "learning_rate": 4.00354295837024e-06,
        "epoch": 5.9964570416297605,
        "step": 6770
    },
    {
        "eval_loss": 0.13530611991882324,
        "eval_accuracy": 0.97365,
        "eval_precision": 0.97533,
        "eval_recall": 0.97188,
        "eval_f1": 0.9736,
        "eval_runtime": 149.4694,
        "eval_samples_per_second": 60.427,
        "eval_steps_per_second": 3.78,
        "epoch": 6.0,
        "step": 6774
    },
    {
        "loss": 0.1042,
        "grad_norm": 0.09800183773040771,
        "learning_rate": 3.9946855624446415e-06,
        "epoch": 6.005314437555358,
        "step": 6780
    },
    {
        "loss": 0.0857,
        "grad_norm": 2.207289695739746,
        "learning_rate": 3.985828166519043e-06,
        "epoch": 6.014171833480956,
        "step": 6790
    },
    {
        "loss": 0.0373,
        "grad_norm": 0.10312323272228241,
        "learning_rate": 3.9769707705934455e-06,
        "epoch": 6.023029229406554,
        "step": 6800
    },
    {
        "loss": 0.0399,
        "grad_norm": 58.233943939208984,
        "learning_rate": 3.968113374667848e-06,
        "epoch": 6.031886625332152,
        "step": 6810
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.03464260324835777,
        "learning_rate": 3.9592559787422504e-06,
        "epoch": 6.04074402125775,
        "step": 6820
    },
    {
        "loss": 0.0924,
        "grad_norm": 0.1237720176577568,
        "learning_rate": 3.950398582816652e-06,
        "epoch": 6.049601417183348,
        "step": 6830
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.019584842026233673,
        "learning_rate": 3.9415411868910545e-06,
        "epoch": 6.058458813108946,
        "step": 6840
    },
    {
        "loss": 0.027,
        "grad_norm": 0.0970688983798027,
        "learning_rate": 3.932683790965456e-06,
        "epoch": 6.067316209034544,
        "step": 6850
    },
    {
        "loss": 0.001,
        "grad_norm": 0.03388630226254463,
        "learning_rate": 3.9238263950398586e-06,
        "epoch": 6.076173604960141,
        "step": 6860
    },
    {
        "loss": 0.0448,
        "grad_norm": 0.050245702266693115,
        "learning_rate": 3.914968999114261e-06,
        "epoch": 6.085031000885739,
        "step": 6870
    },
    {
        "loss": 0.0175,
        "grad_norm": 0.2617712914943695,
        "learning_rate": 3.9061116031886635e-06,
        "epoch": 6.093888396811337,
        "step": 6880
    },
    {
        "loss": 0.1161,
        "grad_norm": 2.3216960430145264,
        "learning_rate": 3.897254207263065e-06,
        "epoch": 6.102745792736935,
        "step": 6890
    },
    {
        "loss": 0.0777,
        "grad_norm": 0.030158210545778275,
        "learning_rate": 3.888396811337467e-06,
        "epoch": 6.111603188662533,
        "step": 6900
    },
    {
        "loss": 0.0521,
        "grad_norm": 0.1162835881114006,
        "learning_rate": 3.879539415411869e-06,
        "epoch": 6.120460584588131,
        "step": 6910
    },
    {
        "loss": 0.0493,
        "grad_norm": 26.15513038635254,
        "learning_rate": 3.870682019486272e-06,
        "epoch": 6.129317980513729,
        "step": 6920
    },
    {
        "loss": 0.041,
        "grad_norm": 0.029175294563174248,
        "learning_rate": 3.861824623560673e-06,
        "epoch": 6.138175376439327,
        "step": 6930
    },
    {
        "loss": 0.128,
        "grad_norm": 81.60160064697266,
        "learning_rate": 3.852967227635076e-06,
        "epoch": 6.147032772364924,
        "step": 6940
    },
    {
        "loss": 0.07,
        "grad_norm": 0.05993714928627014,
        "learning_rate": 3.844109831709478e-06,
        "epoch": 6.155890168290522,
        "step": 6950
    },
    {
        "loss": 0.0447,
        "grad_norm": 0.47699713706970215,
        "learning_rate": 3.83525243578388e-06,
        "epoch": 6.16474756421612,
        "step": 6960
    },
    {
        "loss": 0.1345,
        "grad_norm": 0.09363258630037308,
        "learning_rate": 3.826395039858282e-06,
        "epoch": 6.173604960141718,
        "step": 6970
    },
    {
        "loss": 0.0068,
        "grad_norm": 0.2821492850780487,
        "learning_rate": 3.817537643932684e-06,
        "epoch": 6.182462356067316,
        "step": 6980
    },
    {
        "loss": 0.0085,
        "grad_norm": 0.03570013493299484,
        "learning_rate": 3.8086802480070863e-06,
        "epoch": 6.191319751992914,
        "step": 6990
    },
    {
        "loss": 0.0269,
        "grad_norm": 0.2385900616645813,
        "learning_rate": 3.7998228520814883e-06,
        "epoch": 6.200177147918512,
        "step": 7000
    },
    {
        "loss": 0.0506,
        "grad_norm": 66.91925811767578,
        "learning_rate": 3.7909654561558907e-06,
        "epoch": 6.20903454384411,
        "step": 7010
    },
    {
        "loss": 0.0419,
        "grad_norm": 0.019460409879684448,
        "learning_rate": 3.7821080602302928e-06,
        "epoch": 6.217891939769708,
        "step": 7020
    },
    {
        "loss": 0.0384,
        "grad_norm": 183.9598846435547,
        "learning_rate": 3.7732506643046944e-06,
        "epoch": 6.226749335695305,
        "step": 7030
    },
    {
        "loss": 0.0083,
        "grad_norm": 1.8664039373397827,
        "learning_rate": 3.764393268379097e-06,
        "epoch": 6.235606731620903,
        "step": 7040
    },
    {
        "loss": 0.0808,
        "grad_norm": 0.13190945982933044,
        "learning_rate": 3.755535872453499e-06,
        "epoch": 6.244464127546501,
        "step": 7050
    },
    {
        "loss": 0.0783,
        "grad_norm": 0.06191632151603699,
        "learning_rate": 3.7466784765279013e-06,
        "epoch": 6.253321523472099,
        "step": 7060
    },
    {
        "loss": 0.0889,
        "grad_norm": 0.1860651671886444,
        "learning_rate": 3.737821080602303e-06,
        "epoch": 6.262178919397697,
        "step": 7070
    },
    {
        "loss": 0.0853,
        "grad_norm": 0.5203334093093872,
        "learning_rate": 3.7289636846767054e-06,
        "epoch": 6.271036315323295,
        "step": 7080
    },
    {
        "loss": 0.0951,
        "grad_norm": 177.2156524658203,
        "learning_rate": 3.7201062887511074e-06,
        "epoch": 6.279893711248893,
        "step": 7090
    },
    {
        "loss": 0.0167,
        "grad_norm": 0.018296431750059128,
        "learning_rate": 3.71124889282551e-06,
        "epoch": 6.288751107174491,
        "step": 7100
    },
    {
        "loss": 0.0623,
        "grad_norm": 0.02458561398088932,
        "learning_rate": 3.702391496899912e-06,
        "epoch": 6.297608503100088,
        "step": 7110
    },
    {
        "loss": 0.0243,
        "grad_norm": 0.16246163845062256,
        "learning_rate": 3.6935341009743135e-06,
        "epoch": 6.306465899025686,
        "step": 7120
    },
    {
        "loss": 0.0282,
        "grad_norm": 0.03379550203680992,
        "learning_rate": 3.684676705048716e-06,
        "epoch": 6.315323294951284,
        "step": 7130
    },
    {
        "loss": 0.0035,
        "grad_norm": 0.036540742963552475,
        "learning_rate": 3.675819309123118e-06,
        "epoch": 6.324180690876882,
        "step": 7140
    },
    {
        "loss": 0.0268,
        "grad_norm": 0.03988572955131531,
        "learning_rate": 3.6669619131975205e-06,
        "epoch": 6.33303808680248,
        "step": 7150
    },
    {
        "loss": 0.07,
        "grad_norm": 0.1496596485376358,
        "learning_rate": 3.6581045172719225e-06,
        "epoch": 6.341895482728078,
        "step": 7160
    },
    {
        "loss": 0.0868,
        "grad_norm": 118.20500183105469,
        "learning_rate": 3.649247121346324e-06,
        "epoch": 6.350752878653676,
        "step": 7170
    },
    {
        "loss": 0.0216,
        "grad_norm": 0.16112062335014343,
        "learning_rate": 3.6403897254207266e-06,
        "epoch": 6.359610274579274,
        "step": 7180
    },
    {
        "loss": 0.1033,
        "grad_norm": 0.2739042043685913,
        "learning_rate": 3.6315323294951286e-06,
        "epoch": 6.368467670504872,
        "step": 7190
    },
    {
        "loss": 0.0041,
        "grad_norm": 0.03451881185173988,
        "learning_rate": 3.622674933569531e-06,
        "epoch": 6.377325066430469,
        "step": 7200
    },
    {
        "loss": 0.0578,
        "grad_norm": 0.14196552336215973,
        "learning_rate": 3.6138175376439327e-06,
        "epoch": 6.386182462356067,
        "step": 7210
    },
    {
        "loss": 0.078,
        "grad_norm": 48.40873718261719,
        "learning_rate": 3.604960141718335e-06,
        "epoch": 6.395039858281665,
        "step": 7220
    },
    {
        "loss": 0.0175,
        "grad_norm": 0.11522975564002991,
        "learning_rate": 3.596102745792737e-06,
        "epoch": 6.403897254207263,
        "step": 7230
    },
    {
        "loss": 0.0701,
        "grad_norm": 0.09427148103713989,
        "learning_rate": 3.5872453498671396e-06,
        "epoch": 6.412754650132861,
        "step": 7240
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.042622823268175125,
        "learning_rate": 3.5783879539415416e-06,
        "epoch": 6.421612046058459,
        "step": 7250
    },
    {
        "loss": 0.0262,
        "grad_norm": 0.04322945326566696,
        "learning_rate": 3.5695305580159433e-06,
        "epoch": 6.430469441984057,
        "step": 7260
    },
    {
        "loss": 0.0092,
        "grad_norm": 0.03256827965378761,
        "learning_rate": 3.5606731620903457e-06,
        "epoch": 6.439326837909655,
        "step": 7270
    },
    {
        "loss": 0.0487,
        "grad_norm": 0.013056475669145584,
        "learning_rate": 3.5518157661647477e-06,
        "epoch": 6.448184233835253,
        "step": 7280
    },
    {
        "loss": 0.0569,
        "grad_norm": 0.0608188733458519,
        "learning_rate": 3.54295837023915e-06,
        "epoch": 6.45704162976085,
        "step": 7290
    },
    {
        "loss": 0.1109,
        "grad_norm": 0.03858402371406555,
        "learning_rate": 3.5341009743135522e-06,
        "epoch": 6.465899025686448,
        "step": 7300
    },
    {
        "loss": 0.1044,
        "grad_norm": 0.3968620002269745,
        "learning_rate": 3.5252435783879543e-06,
        "epoch": 6.474756421612046,
        "step": 7310
    },
    {
        "loss": 0.0219,
        "grad_norm": 0.21835991740226746,
        "learning_rate": 3.5163861824623563e-06,
        "epoch": 6.483613817537644,
        "step": 7320
    },
    {
        "loss": 0.079,
        "grad_norm": 0.0696244016289711,
        "learning_rate": 3.5075287865367587e-06,
        "epoch": 6.492471213463242,
        "step": 7330
    },
    {
        "loss": 0.0303,
        "grad_norm": 9.799566268920898,
        "learning_rate": 3.4986713906111608e-06,
        "epoch": 6.50132860938884,
        "step": 7340
    },
    {
        "loss": 0.0475,
        "grad_norm": 0.1834159791469574,
        "learning_rate": 3.4898139946855624e-06,
        "epoch": 6.510186005314438,
        "step": 7350
    },
    {
        "loss": 0.0079,
        "grad_norm": 0.3834597170352936,
        "learning_rate": 3.480956598759965e-06,
        "epoch": 6.519043401240036,
        "step": 7360
    },
    {
        "loss": 0.0445,
        "grad_norm": 117.5807113647461,
        "learning_rate": 3.472099202834367e-06,
        "epoch": 6.527900797165634,
        "step": 7370
    },
    {
        "loss": 0.0402,
        "grad_norm": 3.022848129272461,
        "learning_rate": 3.4632418069087693e-06,
        "epoch": 6.536758193091231,
        "step": 7380
    },
    {
        "loss": 0.0185,
        "grad_norm": 0.1696702241897583,
        "learning_rate": 3.4543844109831714e-06,
        "epoch": 6.545615589016829,
        "step": 7390
    },
    {
        "loss": 0.0407,
        "grad_norm": 0.05951735004782677,
        "learning_rate": 3.445527015057573e-06,
        "epoch": 6.554472984942427,
        "step": 7400
    },
    {
        "loss": 0.0586,
        "grad_norm": 0.25442200899124146,
        "learning_rate": 3.4366696191319754e-06,
        "epoch": 6.563330380868025,
        "step": 7410
    },
    {
        "loss": 0.0239,
        "grad_norm": 0.046205468475818634,
        "learning_rate": 3.4278122232063775e-06,
        "epoch": 6.572187776793623,
        "step": 7420
    },
    {
        "loss": 0.0701,
        "grad_norm": 0.2483416199684143,
        "learning_rate": 3.41895482728078e-06,
        "epoch": 6.581045172719221,
        "step": 7430
    },
    {
        "loss": 0.0805,
        "grad_norm": 0.12190058827400208,
        "learning_rate": 3.410097431355182e-06,
        "epoch": 6.589902568644819,
        "step": 7440
    },
    {
        "loss": 0.0441,
        "grad_norm": 0.3215802013874054,
        "learning_rate": 3.401240035429584e-06,
        "epoch": 6.598759964570416,
        "step": 7450
    },
    {
        "loss": 0.021,
        "grad_norm": 0.06436898559331894,
        "learning_rate": 3.392382639503986e-06,
        "epoch": 6.607617360496015,
        "step": 7460
    },
    {
        "loss": 0.0028,
        "grad_norm": 0.20934589207172394,
        "learning_rate": 3.3835252435783885e-06,
        "epoch": 6.616474756421612,
        "step": 7470
    },
    {
        "loss": 0.0241,
        "grad_norm": 0.2592705190181732,
        "learning_rate": 3.3746678476527905e-06,
        "epoch": 6.62533215234721,
        "step": 7480
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.029939750209450722,
        "learning_rate": 3.365810451727192e-06,
        "epoch": 6.634189548272808,
        "step": 7490
    },
    {
        "loss": 0.1251,
        "grad_norm": 0.20686522126197815,
        "learning_rate": 3.3569530558015946e-06,
        "epoch": 6.643046944198406,
        "step": 7500
    },
    {
        "loss": 0.0569,
        "grad_norm": 0.06237472966313362,
        "learning_rate": 3.3480956598759966e-06,
        "epoch": 6.651904340124004,
        "step": 7510
    },
    {
        "loss": 0.0373,
        "grad_norm": 105.21508026123047,
        "learning_rate": 3.339238263950399e-06,
        "epoch": 6.660761736049602,
        "step": 7520
    },
    {
        "loss": 0.0435,
        "grad_norm": 64.78547668457031,
        "learning_rate": 3.330380868024801e-06,
        "epoch": 6.6696191319752,
        "step": 7530
    },
    {
        "loss": 0.0019,
        "grad_norm": 0.09562902897596359,
        "learning_rate": 3.3215234720992027e-06,
        "epoch": 6.678476527900797,
        "step": 7540
    },
    {
        "loss": 0.0691,
        "grad_norm": 0.021837947890162468,
        "learning_rate": 3.312666076173605e-06,
        "epoch": 6.687333923826395,
        "step": 7550
    },
    {
        "loss": 0.0418,
        "grad_norm": 0.6164103746414185,
        "learning_rate": 3.303808680248007e-06,
        "epoch": 6.696191319751993,
        "step": 7560
    },
    {
        "loss": 0.0188,
        "grad_norm": 2.766967535018921,
        "learning_rate": 3.2949512843224096e-06,
        "epoch": 6.705048715677591,
        "step": 7570
    },
    {
        "loss": 0.0862,
        "grad_norm": 54.46204376220703,
        "learning_rate": 3.2860938883968117e-06,
        "epoch": 6.713906111603189,
        "step": 7580
    },
    {
        "loss": 0.0617,
        "grad_norm": 0.4773748219013214,
        "learning_rate": 3.2772364924712137e-06,
        "epoch": 6.722763507528787,
        "step": 7590
    },
    {
        "loss": 0.0798,
        "grad_norm": 0.06515387445688248,
        "learning_rate": 3.2683790965456157e-06,
        "epoch": 6.731620903454385,
        "step": 7600
    },
    {
        "loss": 0.0663,
        "grad_norm": 0.1068829596042633,
        "learning_rate": 3.259521700620018e-06,
        "epoch": 6.7404782993799826,
        "step": 7610
    },
    {
        "loss": 0.0394,
        "grad_norm": 0.013612386770546436,
        "learning_rate": 3.2506643046944202e-06,
        "epoch": 6.7493356953055805,
        "step": 7620
    },
    {
        "loss": 0.0803,
        "grad_norm": 0.717194676399231,
        "learning_rate": 3.241806908768822e-06,
        "epoch": 6.758193091231178,
        "step": 7630
    },
    {
        "loss": 0.0334,
        "grad_norm": 80.41876220703125,
        "learning_rate": 3.2329495128432243e-06,
        "epoch": 6.767050487156776,
        "step": 7640
    },
    {
        "loss": 0.0323,
        "grad_norm": 113.22792053222656,
        "learning_rate": 3.2240921169176263e-06,
        "epoch": 6.775907883082374,
        "step": 7650
    },
    {
        "loss": 0.0432,
        "grad_norm": 0.8686459064483643,
        "learning_rate": 3.2152347209920288e-06,
        "epoch": 6.7847652790079716,
        "step": 7660
    },
    {
        "loss": 0.0348,
        "grad_norm": 0.8303927779197693,
        "learning_rate": 3.206377325066431e-06,
        "epoch": 6.7936226749335695,
        "step": 7670
    },
    {
        "loss": 0.0295,
        "grad_norm": 0.29349759221076965,
        "learning_rate": 3.197519929140833e-06,
        "epoch": 6.8024800708591675,
        "step": 7680
    },
    {
        "loss": 0.0154,
        "grad_norm": 0.4912339746952057,
        "learning_rate": 3.188662533215235e-06,
        "epoch": 6.8113374667847655,
        "step": 7690
    },
    {
        "loss": 0.1555,
        "grad_norm": 0.12184976786375046,
        "learning_rate": 3.1798051372896373e-06,
        "epoch": 6.8201948627103635,
        "step": 7700
    },
    {
        "loss": 0.0219,
        "grad_norm": 1.475966453552246,
        "learning_rate": 3.1709477413640394e-06,
        "epoch": 6.829052258635961,
        "step": 7710
    },
    {
        "loss": 0.0304,
        "grad_norm": 0.6864662170410156,
        "learning_rate": 3.162090345438442e-06,
        "epoch": 6.8379096545615585,
        "step": 7720
    },
    {
        "loss": 0.0337,
        "grad_norm": 0.014194710180163383,
        "learning_rate": 3.1532329495128434e-06,
        "epoch": 6.8467670504871565,
        "step": 7730
    },
    {
        "loss": 0.0601,
        "grad_norm": 157.2616424560547,
        "learning_rate": 3.1443755535872455e-06,
        "epoch": 6.8556244464127545,
        "step": 7740
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.28292566537857056,
        "learning_rate": 3.135518157661648e-06,
        "epoch": 6.8644818423383525,
        "step": 7750
    },
    {
        "loss": 0.049,
        "grad_norm": 0.016990680247545242,
        "learning_rate": 3.12666076173605e-06,
        "epoch": 6.87333923826395,
        "step": 7760
    },
    {
        "loss": 0.0663,
        "grad_norm": 4.017759799957275,
        "learning_rate": 3.1178033658104516e-06,
        "epoch": 6.882196634189548,
        "step": 7770
    },
    {
        "loss": 0.0051,
        "grad_norm": 1.8598984479904175,
        "learning_rate": 3.108945969884854e-06,
        "epoch": 6.891054030115146,
        "step": 7780
    },
    {
        "loss": 0.0199,
        "grad_norm": 0.6351112127304077,
        "learning_rate": 3.100088573959256e-06,
        "epoch": 6.899911426040744,
        "step": 7790
    },
    {
        "loss": 0.0234,
        "grad_norm": 0.25783005356788635,
        "learning_rate": 3.0912311780336585e-06,
        "epoch": 6.908768821966342,
        "step": 7800
    },
    {
        "loss": 0.0423,
        "grad_norm": 7.218945026397705,
        "learning_rate": 3.0823737821080605e-06,
        "epoch": 6.917626217891939,
        "step": 7810
    },
    {
        "loss": 0.03,
        "grad_norm": 0.015622798353433609,
        "learning_rate": 3.0735163861824626e-06,
        "epoch": 6.926483613817537,
        "step": 7820
    },
    {
        "loss": 0.0556,
        "grad_norm": 0.31605008244514465,
        "learning_rate": 3.0646589902568646e-06,
        "epoch": 6.935341009743135,
        "step": 7830
    },
    {
        "loss": 0.0306,
        "grad_norm": 0.02137104421854019,
        "learning_rate": 3.055801594331267e-06,
        "epoch": 6.944198405668733,
        "step": 7840
    },
    {
        "loss": 0.1213,
        "grad_norm": 0.027040069922804832,
        "learning_rate": 3.046944198405669e-06,
        "epoch": 6.953055801594331,
        "step": 7850
    },
    {
        "loss": 0.1438,
        "grad_norm": 2.253782033920288,
        "learning_rate": 3.0380868024800715e-06,
        "epoch": 6.961913197519929,
        "step": 7860
    },
    {
        "loss": 0.0717,
        "grad_norm": 0.0705571174621582,
        "learning_rate": 3.029229406554473e-06,
        "epoch": 6.970770593445527,
        "step": 7870
    },
    {
        "loss": 0.0767,
        "grad_norm": 0.21850280463695526,
        "learning_rate": 3.020372010628875e-06,
        "epoch": 6.979627989371125,
        "step": 7880
    },
    {
        "loss": 0.0963,
        "grad_norm": 0.0669698491692543,
        "learning_rate": 3.0115146147032776e-06,
        "epoch": 6.988485385296723,
        "step": 7890
    },
    {
        "loss": 0.1358,
        "grad_norm": 0.5670929551124573,
        "learning_rate": 3.0026572187776797e-06,
        "epoch": 6.99734278122232,
        "step": 7900
    },
    {
        "eval_loss": 0.1331750899553299,
        "eval_accuracy": 0.97741,
        "eval_precision": 0.97657,
        "eval_recall": 0.9783,
        "eval_f1": 0.97743,
        "eval_runtime": 149.3962,
        "eval_samples_per_second": 60.457,
        "eval_steps_per_second": 3.782,
        "epoch": 7.0,
        "step": 7903
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.013220630586147308,
        "learning_rate": 2.9937998228520813e-06,
        "epoch": 7.006200177147918,
        "step": 7910
    },
    {
        "loss": 0.0343,
        "grad_norm": 0.03354617953300476,
        "learning_rate": 2.9849424269264837e-06,
        "epoch": 7.015057573073516,
        "step": 7920
    },
    {
        "loss": 0.0988,
        "grad_norm": 0.07294666767120361,
        "learning_rate": 2.9760850310008858e-06,
        "epoch": 7.023914968999114,
        "step": 7930
    },
    {
        "loss": 0.0702,
        "grad_norm": 0.435866117477417,
        "learning_rate": 2.9672276350752882e-06,
        "epoch": 7.032772364924712,
        "step": 7940
    },
    {
        "loss": 0.0694,
        "grad_norm": 0.2126772403717041,
        "learning_rate": 2.9583702391496903e-06,
        "epoch": 7.04162976085031,
        "step": 7950
    },
    {
        "loss": 0.0956,
        "grad_norm": 0.1061849445104599,
        "learning_rate": 2.9495128432240923e-06,
        "epoch": 7.050487156775908,
        "step": 7960
    },
    {
        "loss": 0.0087,
        "grad_norm": 0.2653002142906189,
        "learning_rate": 2.9406554472984943e-06,
        "epoch": 7.059344552701506,
        "step": 7970
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.09537473320960999,
        "learning_rate": 2.9317980513728968e-06,
        "epoch": 7.068201948627103,
        "step": 7980
    },
    {
        "loss": 0.049,
        "grad_norm": 1.447481632232666,
        "learning_rate": 2.922940655447299e-06,
        "epoch": 7.077059344552701,
        "step": 7990
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.009811598807573318,
        "learning_rate": 2.9140832595217013e-06,
        "epoch": 7.085916740478299,
        "step": 8000
    },
    {
        "loss": 0.0814,
        "grad_norm": 0.031685955822467804,
        "learning_rate": 2.905225863596103e-06,
        "epoch": 7.094774136403897,
        "step": 8010
    },
    {
        "loss": 0.0221,
        "grad_norm": 0.5122140645980835,
        "learning_rate": 2.896368467670505e-06,
        "epoch": 7.103631532329495,
        "step": 8020
    },
    {
        "loss": 0.0676,
        "grad_norm": 12.027812957763672,
        "learning_rate": 2.8875110717449074e-06,
        "epoch": 7.112488928255093,
        "step": 8030
    },
    {
        "loss": 0.0153,
        "grad_norm": 2.35923171043396,
        "learning_rate": 2.8786536758193094e-06,
        "epoch": 7.121346324180691,
        "step": 8040
    },
    {
        "loss": 0.0568,
        "grad_norm": 0.516339123249054,
        "learning_rate": 2.8697962798937114e-06,
        "epoch": 7.130203720106289,
        "step": 8050
    },
    {
        "loss": 0.0541,
        "grad_norm": 0.258689284324646,
        "learning_rate": 2.8609388839681135e-06,
        "epoch": 7.139061116031886,
        "step": 8060
    },
    {
        "loss": 0.0266,
        "grad_norm": 5.073797702789307,
        "learning_rate": 2.852081488042516e-06,
        "epoch": 7.147918511957484,
        "step": 8070
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.013685603626072407,
        "learning_rate": 2.843224092116918e-06,
        "epoch": 7.156775907883082,
        "step": 8080
    },
    {
        "loss": 0.037,
        "grad_norm": 0.01623310148715973,
        "learning_rate": 2.8343666961913204e-06,
        "epoch": 7.16563330380868,
        "step": 8090
    },
    {
        "loss": 0.0404,
        "grad_norm": 0.016403187066316605,
        "learning_rate": 2.825509300265722e-06,
        "epoch": 7.174490699734278,
        "step": 8100
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.010082877241075039,
        "learning_rate": 2.816651904340124e-06,
        "epoch": 7.183348095659876,
        "step": 8110
    },
    {
        "loss": 0.0801,
        "grad_norm": 0.045154571533203125,
        "learning_rate": 2.8077945084145265e-06,
        "epoch": 7.192205491585474,
        "step": 8120
    },
    {
        "loss": 0.0219,
        "grad_norm": 0.05596880987286568,
        "learning_rate": 2.7989371124889285e-06,
        "epoch": 7.201062887511072,
        "step": 8130
    },
    {
        "loss": 0.0428,
        "grad_norm": 0.0597839429974556,
        "learning_rate": 2.790079716563331e-06,
        "epoch": 7.20992028343667,
        "step": 8140
    },
    {
        "loss": 0.0675,
        "grad_norm": 0.051103003323078156,
        "learning_rate": 2.7812223206377326e-06,
        "epoch": 7.218777679362267,
        "step": 8150
    },
    {
        "loss": 0.0162,
        "grad_norm": 0.013752143830060959,
        "learning_rate": 2.7723649247121346e-06,
        "epoch": 7.227635075287865,
        "step": 8160
    },
    {
        "loss": 0.057,
        "grad_norm": 0.12276808172464371,
        "learning_rate": 2.763507528786537e-06,
        "epoch": 7.236492471213463,
        "step": 8170
    },
    {
        "loss": 0.0304,
        "grad_norm": 0.7085505127906799,
        "learning_rate": 2.754650132860939e-06,
        "epoch": 7.245349867139061,
        "step": 8180
    },
    {
        "loss": 0.0346,
        "grad_norm": 0.44699808955192566,
        "learning_rate": 2.745792736935341e-06,
        "epoch": 7.254207263064659,
        "step": 8190
    },
    {
        "loss": 0.0433,
        "grad_norm": 0.062042079865932465,
        "learning_rate": 2.736935341009743e-06,
        "epoch": 7.263064658990257,
        "step": 8200
    },
    {
        "loss": 0.0611,
        "grad_norm": 0.020716989412903786,
        "learning_rate": 2.7280779450841456e-06,
        "epoch": 7.271922054915855,
        "step": 8210
    },
    {
        "loss": 0.0351,
        "grad_norm": 0.35733702778816223,
        "learning_rate": 2.7192205491585477e-06,
        "epoch": 7.280779450841453,
        "step": 8220
    },
    {
        "loss": 0.0771,
        "grad_norm": 0.061341702938079834,
        "learning_rate": 2.71036315323295e-06,
        "epoch": 7.289636846767051,
        "step": 8230
    },
    {
        "loss": 0.0113,
        "grad_norm": 0.06176164746284485,
        "learning_rate": 2.7015057573073517e-06,
        "epoch": 7.298494242692648,
        "step": 8240
    },
    {
        "loss": 0.0929,
        "grad_norm": 23.703027725219727,
        "learning_rate": 2.6926483613817538e-06,
        "epoch": 7.307351638618246,
        "step": 8250
    },
    {
        "loss": 0.0187,
        "grad_norm": 0.07774803787469864,
        "learning_rate": 2.6837909654561562e-06,
        "epoch": 7.316209034543844,
        "step": 8260
    },
    {
        "loss": 0.0118,
        "grad_norm": 0.28933292627334595,
        "learning_rate": 2.6749335695305583e-06,
        "epoch": 7.325066430469442,
        "step": 8270
    },
    {
        "loss": 0.0155,
        "grad_norm": 0.0293690487742424,
        "learning_rate": 2.6660761736049607e-06,
        "epoch": 7.33392382639504,
        "step": 8280
    },
    {
        "loss": 0.0329,
        "grad_norm": 26.204803466796875,
        "learning_rate": 2.6572187776793623e-06,
        "epoch": 7.342781222320638,
        "step": 8290
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.022204112261533737,
        "learning_rate": 2.6483613817537644e-06,
        "epoch": 7.351638618246236,
        "step": 8300
    },
    {
        "loss": 0.0377,
        "grad_norm": 0.01443327683955431,
        "learning_rate": 2.639503985828167e-06,
        "epoch": 7.360496014171834,
        "step": 8310
    },
    {
        "loss": 0.0311,
        "grad_norm": 56.65690612792969,
        "learning_rate": 2.630646589902569e-06,
        "epoch": 7.369353410097431,
        "step": 8320
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.03977496549487114,
        "learning_rate": 2.621789193976971e-06,
        "epoch": 7.378210806023029,
        "step": 8330
    },
    {
        "loss": 0.0425,
        "grad_norm": 4.0409979820251465,
        "learning_rate": 2.612931798051373e-06,
        "epoch": 7.387068201948627,
        "step": 8340
    },
    {
        "loss": 0.0116,
        "grad_norm": 0.03271509334445,
        "learning_rate": 2.6040744021257754e-06,
        "epoch": 7.395925597874225,
        "step": 8350
    },
    {
        "loss": 0.0179,
        "grad_norm": 0.2396761178970337,
        "learning_rate": 2.5952170062001774e-06,
        "epoch": 7.404782993799823,
        "step": 8360
    },
    {
        "loss": 0.0143,
        "grad_norm": 0.011195436120033264,
        "learning_rate": 2.58635961027458e-06,
        "epoch": 7.413640389725421,
        "step": 8370
    },
    {
        "loss": 0.0005,
        "grad_norm": 2.582733631134033,
        "learning_rate": 2.5775022143489815e-06,
        "epoch": 7.422497785651019,
        "step": 8380
    },
    {
        "loss": 0.0055,
        "grad_norm": 0.005044636316597462,
        "learning_rate": 2.5686448184233835e-06,
        "epoch": 7.431355181576617,
        "step": 8390
    },
    {
        "loss": 0.0789,
        "grad_norm": 5.7635817527771,
        "learning_rate": 2.559787422497786e-06,
        "epoch": 7.440212577502215,
        "step": 8400
    },
    {
        "loss": 0.0289,
        "grad_norm": 9.028943061828613,
        "learning_rate": 2.550930026572188e-06,
        "epoch": 7.449069973427812,
        "step": 8410
    },
    {
        "loss": 0.0176,
        "grad_norm": 0.04273217171430588,
        "learning_rate": 2.5420726306465904e-06,
        "epoch": 7.45792736935341,
        "step": 8420
    },
    {
        "loss": 0.0004,
        "grad_norm": 2.4175665378570557,
        "learning_rate": 2.533215234720992e-06,
        "epoch": 7.466784765279008,
        "step": 8430
    },
    {
        "loss": 0.0467,
        "grad_norm": 0.03338595852255821,
        "learning_rate": 2.5243578387953945e-06,
        "epoch": 7.475642161204606,
        "step": 8440
    },
    {
        "loss": 0.0347,
        "grad_norm": 96.6053237915039,
        "learning_rate": 2.5155004428697965e-06,
        "epoch": 7.484499557130204,
        "step": 8450
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.7470954656600952,
        "learning_rate": 2.506643046944199e-06,
        "epoch": 7.493356953055802,
        "step": 8460
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.09850797057151794,
        "learning_rate": 2.4977856510186006e-06,
        "epoch": 7.5022143489814,
        "step": 8470
    },
    {
        "loss": 0.0127,
        "grad_norm": 0.009619747288525105,
        "learning_rate": 2.4889282550930026e-06,
        "epoch": 7.511071744906998,
        "step": 8480
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.005522607825696468,
        "learning_rate": 2.480070859167405e-06,
        "epoch": 7.519929140832595,
        "step": 8490
    },
    {
        "loss": 0.0607,
        "grad_norm": 0.006091887131333351,
        "learning_rate": 2.471213463241807e-06,
        "epoch": 7.528786536758193,
        "step": 8500
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.16345590353012085,
        "learning_rate": 2.462356067316209e-06,
        "epoch": 7.537643932683791,
        "step": 8510
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.01401561964303255,
        "learning_rate": 2.4534986713906116e-06,
        "epoch": 7.546501328609389,
        "step": 8520
    },
    {
        "loss": 0.0131,
        "grad_norm": 0.03395448252558708,
        "learning_rate": 2.4446412754650132e-06,
        "epoch": 7.555358724534987,
        "step": 8530
    },
    {
        "loss": 0.0152,
        "grad_norm": 0.019757689908146858,
        "learning_rate": 2.4357838795394157e-06,
        "epoch": 7.564216120460585,
        "step": 8540
    },
    {
        "loss": 0.0433,
        "grad_norm": 0.023572172969579697,
        "learning_rate": 2.4269264836138177e-06,
        "epoch": 7.573073516386183,
        "step": 8550
    },
    {
        "loss": 0.0621,
        "grad_norm": 2.4371135234832764,
        "learning_rate": 2.4180690876882197e-06,
        "epoch": 7.581930912311781,
        "step": 8560
    },
    {
        "loss": 0.0805,
        "grad_norm": 0.011115321889519691,
        "learning_rate": 2.409211691762622e-06,
        "epoch": 7.590788308237379,
        "step": 8570
    },
    {
        "loss": 0.0281,
        "grad_norm": 0.030397403985261917,
        "learning_rate": 2.4003542958370242e-06,
        "epoch": 7.599645704162976,
        "step": 8580
    },
    {
        "loss": 0.004,
        "grad_norm": 0.007476828992366791,
        "learning_rate": 2.3914968999114263e-06,
        "epoch": 7.608503100088574,
        "step": 8590
    },
    {
        "loss": 0.0763,
        "grad_norm": 0.10356462746858597,
        "learning_rate": 2.3826395039858283e-06,
        "epoch": 7.617360496014172,
        "step": 8600
    },
    {
        "loss": 0.0351,
        "grad_norm": 0.026053065434098244,
        "learning_rate": 2.3737821080602303e-06,
        "epoch": 7.62621789193977,
        "step": 8610
    },
    {
        "loss": 0.007,
        "grad_norm": 0.010411560535430908,
        "learning_rate": 2.3649247121346324e-06,
        "epoch": 7.635075287865368,
        "step": 8620
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.005896120797842741,
        "learning_rate": 2.356067316209035e-06,
        "epoch": 7.643932683790966,
        "step": 8630
    },
    {
        "loss": 0.0011,
        "grad_norm": 6.401346206665039,
        "learning_rate": 2.347209920283437e-06,
        "epoch": 7.6527900797165636,
        "step": 8640
    },
    {
        "loss": 0.039,
        "grad_norm": 0.00695571955293417,
        "learning_rate": 2.338352524357839e-06,
        "epoch": 7.6616474756421615,
        "step": 8650
    },
    {
        "loss": 0.0677,
        "grad_norm": 0.023518066853284836,
        "learning_rate": 2.3294951284322413e-06,
        "epoch": 7.6705048715677595,
        "step": 8660
    },
    {
        "loss": 0.0143,
        "grad_norm": 4.888733863830566,
        "learning_rate": 2.320637732506643e-06,
        "epoch": 7.679362267493357,
        "step": 8670
    },
    {
        "loss": 0.0012,
        "grad_norm": 0.09016509354114532,
        "learning_rate": 2.3117803365810454e-06,
        "epoch": 7.688219663418955,
        "step": 8680
    },
    {
        "loss": 0.0405,
        "grad_norm": 0.014490945264697075,
        "learning_rate": 2.3029229406554474e-06,
        "epoch": 7.6970770593445526,
        "step": 8690
    },
    {
        "loss": 0.029,
        "grad_norm": 2.2690975666046143,
        "learning_rate": 2.2940655447298495e-06,
        "epoch": 7.7059344552701505,
        "step": 8700
    },
    {
        "loss": 0.0133,
        "grad_norm": 0.006457952782511711,
        "learning_rate": 2.285208148804252e-06,
        "epoch": 7.7147918511957485,
        "step": 8710
    },
    {
        "loss": 0.0071,
        "grad_norm": 0.010097045451402664,
        "learning_rate": 2.276350752878654e-06,
        "epoch": 7.7236492471213465,
        "step": 8720
    },
    {
        "loss": 0.012,
        "grad_norm": 0.018020089715719223,
        "learning_rate": 2.267493356953056e-06,
        "epoch": 7.7325066430469445,
        "step": 8730
    },
    {
        "loss": 0.0449,
        "grad_norm": 48.20271301269531,
        "learning_rate": 2.258635961027458e-06,
        "epoch": 7.741364038972542,
        "step": 8740
    },
    {
        "loss": 0.0931,
        "grad_norm": 2.2219061851501465,
        "learning_rate": 2.2497785651018605e-06,
        "epoch": 7.75022143489814,
        "step": 8750
    },
    {
        "loss": 0.0296,
        "grad_norm": 0.01742699183523655,
        "learning_rate": 2.240921169176262e-06,
        "epoch": 7.7590788308237375,
        "step": 8760
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.23477105796337128,
        "learning_rate": 2.2320637732506645e-06,
        "epoch": 7.7679362267493355,
        "step": 8770
    },
    {
        "loss": 0.0248,
        "grad_norm": 0.10295848548412323,
        "learning_rate": 2.2232063773250666e-06,
        "epoch": 7.7767936226749335,
        "step": 8780
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.01053573191165924,
        "learning_rate": 2.2143489813994686e-06,
        "epoch": 7.785651018600531,
        "step": 8790
    },
    {
        "loss": 0.0639,
        "grad_norm": 45.410884857177734,
        "learning_rate": 2.205491585473871e-06,
        "epoch": 7.794508414526129,
        "step": 8800
    },
    {
        "loss": 0.028,
        "grad_norm": 0.009412226267158985,
        "learning_rate": 2.196634189548273e-06,
        "epoch": 7.803365810451727,
        "step": 8810
    },
    {
        "loss": 0.0114,
        "grad_norm": 0.020620072260499,
        "learning_rate": 2.187776793622675e-06,
        "epoch": 7.812223206377325,
        "step": 8820
    },
    {
        "loss": 0.0448,
        "grad_norm": 0.9826061129570007,
        "learning_rate": 2.178919397697077e-06,
        "epoch": 7.8210806023029225,
        "step": 8830
    },
    {
        "loss": 0.0311,
        "grad_norm": 0.004797330126166344,
        "learning_rate": 2.170062001771479e-06,
        "epoch": 7.82993799822852,
        "step": 8840
    },
    {
        "loss": 0.0227,
        "grad_norm": 0.03252442181110382,
        "learning_rate": 2.1612046058458816e-06,
        "epoch": 7.838795394154118,
        "step": 8850
    },
    {
        "loss": 0.0686,
        "grad_norm": 0.01811022311449051,
        "learning_rate": 2.1523472099202837e-06,
        "epoch": 7.847652790079716,
        "step": 8860
    },
    {
        "loss": 0.0177,
        "grad_norm": 0.12814176082611084,
        "learning_rate": 2.1434898139946857e-06,
        "epoch": 7.856510186005314,
        "step": 8870
    },
    {
        "loss": 0.0499,
        "grad_norm": 0.021387992426753044,
        "learning_rate": 2.1346324180690877e-06,
        "epoch": 7.865367581930912,
        "step": 8880
    },
    {
        "loss": 0.0278,
        "grad_norm": 154.62953186035156,
        "learning_rate": 2.12577502214349e-06,
        "epoch": 7.87422497785651,
        "step": 8890
    },
    {
        "loss": 0.0395,
        "grad_norm": 0.07682633399963379,
        "learning_rate": 2.116917626217892e-06,
        "epoch": 7.883082373782108,
        "step": 8900
    },
    {
        "loss": 0.0383,
        "grad_norm": 183.88987731933594,
        "learning_rate": 2.1080602302922943e-06,
        "epoch": 7.891939769707706,
        "step": 8910
    },
    {
        "loss": 0.0137,
        "grad_norm": 0.06898733973503113,
        "learning_rate": 2.0992028343666963e-06,
        "epoch": 7.900797165633303,
        "step": 8920
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.2821510434150696,
        "learning_rate": 2.0903454384410983e-06,
        "epoch": 7.909654561558901,
        "step": 8930
    },
    {
        "loss": 0.0685,
        "grad_norm": 0.02164297178387642,
        "learning_rate": 2.0814880425155008e-06,
        "epoch": 7.918511957484499,
        "step": 8940
    },
    {
        "loss": 0.0626,
        "grad_norm": 2.358078956604004,
        "learning_rate": 2.072630646589903e-06,
        "epoch": 7.927369353410097,
        "step": 8950
    },
    {
        "loss": 0.0483,
        "grad_norm": 0.007833913899958134,
        "learning_rate": 2.063773250664305e-06,
        "epoch": 7.936226749335695,
        "step": 8960
    },
    {
        "loss": 0.0261,
        "grad_norm": 36.607357025146484,
        "learning_rate": 2.054915854738707e-06,
        "epoch": 7.945084145261293,
        "step": 8970
    },
    {
        "loss": 0.0184,
        "grad_norm": 0.3564285337924957,
        "learning_rate": 2.046058458813109e-06,
        "epoch": 7.953941541186891,
        "step": 8980
    },
    {
        "loss": 0.0368,
        "grad_norm": 0.006047993898391724,
        "learning_rate": 2.0372010628875114e-06,
        "epoch": 7.962798937112489,
        "step": 8990
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.11735997349023819,
        "learning_rate": 2.0283436669619134e-06,
        "epoch": 7.971656333038087,
        "step": 9000
    },
    {
        "loss": 0.0122,
        "grad_norm": 0.09736597537994385,
        "learning_rate": 2.0194862710363154e-06,
        "epoch": 7.980513728963684,
        "step": 9010
    },
    {
        "loss": 0.0475,
        "grad_norm": 0.0207454152405262,
        "learning_rate": 2.0106288751107175e-06,
        "epoch": 7.989371124889282,
        "step": 9020
    },
    {
        "loss": 0.0738,
        "grad_norm": 0.7081934809684753,
        "learning_rate": 2.00177147918512e-06,
        "epoch": 7.99822852081488,
        "step": 9030
    },
    {
        "eval_loss": 0.12746305763721466,
        "eval_accuracy": 0.97741,
        "eval_precision": 0.98018,
        "eval_recall": 0.97453,
        "eval_f1": 0.97735,
        "eval_runtime": 149.3866,
        "eval_samples_per_second": 60.461,
        "eval_steps_per_second": 3.782,
        "epoch": 8.0,
        "step": 9032
    },
    {
        "loss": 0.0147,
        "grad_norm": 0.008568807505071163,
        "learning_rate": 1.9929140832595215e-06,
        "epoch": 8.007085916740479,
        "step": 9040
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.01812993548810482,
        "learning_rate": 1.984056687333924e-06,
        "epoch": 8.015943312666076,
        "step": 9050
    },
    {
        "loss": 0.0333,
        "grad_norm": 0.03014945238828659,
        "learning_rate": 1.975199291408326e-06,
        "epoch": 8.024800708591673,
        "step": 9060
    },
    {
        "loss": 0.0386,
        "grad_norm": 101.97404479980469,
        "learning_rate": 1.966341895482728e-06,
        "epoch": 8.033658104517272,
        "step": 9070
    },
    {
        "loss": 0.014,
        "grad_norm": 0.599249541759491,
        "learning_rate": 1.9574844995571305e-06,
        "epoch": 8.04251550044287,
        "step": 9080
    },
    {
        "loss": 0.0633,
        "grad_norm": 323.3625793457031,
        "learning_rate": 1.9486271036315325e-06,
        "epoch": 8.051372896368468,
        "step": 9090
    },
    {
        "loss": 0.0606,
        "grad_norm": 41.66372299194336,
        "learning_rate": 1.9397697077059346e-06,
        "epoch": 8.060230292294065,
        "step": 9100
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.082472063601017,
        "learning_rate": 1.9309123117803366e-06,
        "epoch": 8.069087688219664,
        "step": 9110
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.07461926341056824,
        "learning_rate": 1.922054915854739e-06,
        "epoch": 8.077945084145261,
        "step": 9120
    },
    {
        "loss": 0.057,
        "grad_norm": 104.30386352539062,
        "learning_rate": 1.913197519929141e-06,
        "epoch": 8.08680248007086,
        "step": 9130
    },
    {
        "loss": 0.0613,
        "grad_norm": 0.034134071320295334,
        "learning_rate": 1.9043401240035431e-06,
        "epoch": 8.095659875996457,
        "step": 9140
    },
    {
        "loss": 0.0332,
        "grad_norm": 111.16625213623047,
        "learning_rate": 1.8954827280779454e-06,
        "epoch": 8.104517271922054,
        "step": 9150
    },
    {
        "loss": 0.0012,
        "grad_norm": 0.035330258309841156,
        "learning_rate": 1.8866253321523472e-06,
        "epoch": 8.113374667847653,
        "step": 9160
    },
    {
        "loss": 0.0095,
        "grad_norm": 0.006789851933717728,
        "learning_rate": 1.8777679362267494e-06,
        "epoch": 8.12223206377325,
        "step": 9170
    },
    {
        "loss": 0.0432,
        "grad_norm": 0.03066275827586651,
        "learning_rate": 1.8689105403011515e-06,
        "epoch": 8.131089459698849,
        "step": 9180
    },
    {
        "loss": 0.0597,
        "grad_norm": 0.015531938523054123,
        "learning_rate": 1.8600531443755537e-06,
        "epoch": 8.139946855624446,
        "step": 9190
    },
    {
        "loss": 0.0084,
        "grad_norm": 0.004584571812301874,
        "learning_rate": 1.851195748449956e-06,
        "epoch": 8.148804251550045,
        "step": 9200
    },
    {
        "loss": 0.0227,
        "grad_norm": 2.1217386722564697,
        "learning_rate": 1.842338352524358e-06,
        "epoch": 8.157661647475642,
        "step": 9210
    },
    {
        "loss": 0.0105,
        "grad_norm": 2.103259563446045,
        "learning_rate": 1.8334809565987602e-06,
        "epoch": 8.166519043401241,
        "step": 9220
    },
    {
        "loss": 0.0278,
        "grad_norm": 0.005486182402819395,
        "learning_rate": 1.824623560673162e-06,
        "epoch": 8.175376439326838,
        "step": 9230
    },
    {
        "loss": 0.0117,
        "grad_norm": 0.0059428452514112,
        "learning_rate": 1.8157661647475643e-06,
        "epoch": 8.184233835252435,
        "step": 9240
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.02405858412384987,
        "learning_rate": 1.8069087688219663e-06,
        "epoch": 8.193091231178034,
        "step": 9250
    },
    {
        "loss": 0.0152,
        "grad_norm": 0.009811981581151485,
        "learning_rate": 1.7980513728963686e-06,
        "epoch": 8.201948627103631,
        "step": 9260
    },
    {
        "loss": 0.0075,
        "grad_norm": 0.01384675782173872,
        "learning_rate": 1.7891939769707708e-06,
        "epoch": 8.21080602302923,
        "step": 9270
    },
    {
        "loss": 0.0108,
        "grad_norm": 0.03879424184560776,
        "learning_rate": 1.7803365810451729e-06,
        "epoch": 8.219663418954827,
        "step": 9280
    },
    {
        "loss": 0.0523,
        "grad_norm": 0.047177333384752274,
        "learning_rate": 1.771479185119575e-06,
        "epoch": 8.228520814880426,
        "step": 9290
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006069753784686327,
        "learning_rate": 1.7626217891939771e-06,
        "epoch": 8.237378210806023,
        "step": 9300
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.01988508738577366,
        "learning_rate": 1.7537643932683794e-06,
        "epoch": 8.24623560673162,
        "step": 9310
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008572773076593876,
        "learning_rate": 1.7449069973427812e-06,
        "epoch": 8.255093002657219,
        "step": 9320
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.828051745891571,
        "learning_rate": 1.7360496014171834e-06,
        "epoch": 8.263950398582816,
        "step": 9330
    },
    {
        "loss": 0.0284,
        "grad_norm": 0.030370982363820076,
        "learning_rate": 1.7271922054915857e-06,
        "epoch": 8.272807794508415,
        "step": 9340
    },
    {
        "loss": 0.0115,
        "grad_norm": 17.000389099121094,
        "learning_rate": 1.7183348095659877e-06,
        "epoch": 8.281665190434012,
        "step": 9350
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.00849746260792017,
        "learning_rate": 1.70947741364039e-06,
        "epoch": 8.29052258635961,
        "step": 9360
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.027025116607546806,
        "learning_rate": 1.700620017714792e-06,
        "epoch": 8.299379982285208,
        "step": 9370
    },
    {
        "loss": 0.0659,
        "grad_norm": 1.1109516620635986,
        "learning_rate": 1.6917626217891942e-06,
        "epoch": 8.308237378210807,
        "step": 9380
    },
    {
        "loss": 0.0956,
        "grad_norm": 0.00627472810447216,
        "learning_rate": 1.682905225863596e-06,
        "epoch": 8.317094774136404,
        "step": 9390
    },
    {
        "loss": 0.1036,
        "grad_norm": 103.80005645751953,
        "learning_rate": 1.6740478299379983e-06,
        "epoch": 8.325952170062001,
        "step": 9400
    },
    {
        "loss": 0.0017,
        "grad_norm": 42.57181167602539,
        "learning_rate": 1.6651904340124005e-06,
        "epoch": 8.3348095659876,
        "step": 9410
    },
    {
        "loss": 0.0099,
        "grad_norm": 0.12968680262565613,
        "learning_rate": 1.6563330380868026e-06,
        "epoch": 8.343666961913197,
        "step": 9420
    },
    {
        "loss": 0.0273,
        "grad_norm": 0.015117082744836807,
        "learning_rate": 1.6474756421612048e-06,
        "epoch": 8.352524357838796,
        "step": 9430
    },
    {
        "loss": 0.0243,
        "grad_norm": 0.016139665618538857,
        "learning_rate": 1.6386182462356069e-06,
        "epoch": 8.361381753764393,
        "step": 9440
    },
    {
        "loss": 0.0114,
        "grad_norm": 0.693317174911499,
        "learning_rate": 1.629760850310009e-06,
        "epoch": 8.370239149689992,
        "step": 9450
    },
    {
        "loss": 0.0044,
        "grad_norm": 0.005563544109463692,
        "learning_rate": 1.620903454384411e-06,
        "epoch": 8.379096545615589,
        "step": 9460
    },
    {
        "loss": 0.0531,
        "grad_norm": 0.0121687026694417,
        "learning_rate": 1.6120460584588132e-06,
        "epoch": 8.387953941541188,
        "step": 9470
    },
    {
        "loss": 0.0467,
        "grad_norm": 0.02095889486372471,
        "learning_rate": 1.6031886625332154e-06,
        "epoch": 8.396811337466785,
        "step": 9480
    },
    {
        "loss": 0.0091,
        "grad_norm": 0.018728500232100487,
        "learning_rate": 1.5943312666076174e-06,
        "epoch": 8.405668733392382,
        "step": 9490
    },
    {
        "loss": 0.0288,
        "grad_norm": 0.04697838053107262,
        "learning_rate": 1.5854738706820197e-06,
        "epoch": 8.41452612931798,
        "step": 9500
    },
    {
        "loss": 0.0098,
        "grad_norm": 0.04303446784615517,
        "learning_rate": 1.5766164747564217e-06,
        "epoch": 8.423383525243578,
        "step": 9510
    },
    {
        "loss": 0.0444,
        "grad_norm": 0.016942819580435753,
        "learning_rate": 1.567759078830824e-06,
        "epoch": 8.432240921169177,
        "step": 9520
    },
    {
        "loss": 0.0259,
        "grad_norm": 9.059940338134766,
        "learning_rate": 1.5589016829052258e-06,
        "epoch": 8.441098317094774,
        "step": 9530
    },
    {
        "loss": 0.0099,
        "grad_norm": 0.056718941777944565,
        "learning_rate": 1.550044286979628e-06,
        "epoch": 8.449955713020373,
        "step": 9540
    },
    {
        "loss": 0.0227,
        "grad_norm": 0.015364945866167545,
        "learning_rate": 1.5411868910540303e-06,
        "epoch": 8.45881310894597,
        "step": 9550
    },
    {
        "loss": 0.0107,
        "grad_norm": 7.4248456954956055,
        "learning_rate": 1.5323294951284323e-06,
        "epoch": 8.467670504871569,
        "step": 9560
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.07891684025526047,
        "learning_rate": 1.5234720992028345e-06,
        "epoch": 8.476527900797166,
        "step": 9570
    },
    {
        "loss": 0.0182,
        "grad_norm": 0.004999624099582434,
        "learning_rate": 1.5146147032772366e-06,
        "epoch": 8.485385296722763,
        "step": 9580
    },
    {
        "loss": 0.0142,
        "grad_norm": 0.003980955574661493,
        "learning_rate": 1.5057573073516388e-06,
        "epoch": 8.494242692648362,
        "step": 9590
    },
    {
        "loss": 0.0091,
        "grad_norm": 0.006521178875118494,
        "learning_rate": 1.4968999114260406e-06,
        "epoch": 8.503100088573959,
        "step": 9600
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01907149888575077,
        "learning_rate": 1.4880425155004429e-06,
        "epoch": 8.511957484499558,
        "step": 9610
    },
    {
        "loss": 0.0096,
        "grad_norm": 0.013675890862941742,
        "learning_rate": 1.4791851195748451e-06,
        "epoch": 8.520814880425155,
        "step": 9620
    },
    {
        "loss": 0.0327,
        "grad_norm": 2.2487359046936035,
        "learning_rate": 1.4703277236492472e-06,
        "epoch": 8.529672276350754,
        "step": 9630
    },
    {
        "loss": 0.0206,
        "grad_norm": 0.041285011917352676,
        "learning_rate": 1.4614703277236494e-06,
        "epoch": 8.53852967227635,
        "step": 9640
    },
    {
        "loss": 0.0183,
        "grad_norm": 0.06476219743490219,
        "learning_rate": 1.4526129317980514e-06,
        "epoch": 8.54738706820195,
        "step": 9650
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.00815040897578001,
        "learning_rate": 1.4437555358724537e-06,
        "epoch": 8.556244464127547,
        "step": 9660
    },
    {
        "loss": 0.0101,
        "grad_norm": 0.005458045285195112,
        "learning_rate": 1.4348981399468557e-06,
        "epoch": 8.565101860053144,
        "step": 9670
    },
    {
        "loss": 0.0353,
        "grad_norm": 0.015704791992902756,
        "learning_rate": 1.426040744021258e-06,
        "epoch": 8.573959255978743,
        "step": 9680
    },
    {
        "loss": 0.0029,
        "grad_norm": 0.00530247064307332,
        "learning_rate": 1.4171833480956602e-06,
        "epoch": 8.58281665190434,
        "step": 9690
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.044715605676174164,
        "learning_rate": 1.408325952170062e-06,
        "epoch": 8.591674047829938,
        "step": 9700
    },
    {
        "loss": 0.0105,
        "grad_norm": 0.006529373582452536,
        "learning_rate": 1.3994685562444643e-06,
        "epoch": 8.600531443755536,
        "step": 9710
    },
    {
        "loss": 0.0094,
        "grad_norm": 0.0038510141894221306,
        "learning_rate": 1.3906111603188663e-06,
        "epoch": 8.609388839681134,
        "step": 9720
    },
    {
        "loss": 0.0145,
        "grad_norm": 0.13264064490795135,
        "learning_rate": 1.3817537643932685e-06,
        "epoch": 8.618246235606732,
        "step": 9730
    },
    {
        "loss": 0.0476,
        "grad_norm": 133.38308715820312,
        "learning_rate": 1.3728963684676706e-06,
        "epoch": 8.627103631532329,
        "step": 9740
    },
    {
        "loss": 0.0094,
        "grad_norm": 0.0056784008629620075,
        "learning_rate": 1.3640389725420728e-06,
        "epoch": 8.635961027457927,
        "step": 9750
    },
    {
        "loss": 0.0097,
        "grad_norm": 0.0034219890367239714,
        "learning_rate": 1.355181576616475e-06,
        "epoch": 8.644818423383525,
        "step": 9760
    },
    {
        "loss": 0.0072,
        "grad_norm": 26.15338897705078,
        "learning_rate": 1.3463241806908769e-06,
        "epoch": 8.653675819309123,
        "step": 9770
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.024037234485149384,
        "learning_rate": 1.3374667847652791e-06,
        "epoch": 8.66253321523472,
        "step": 9780
    },
    {
        "loss": 0.0118,
        "grad_norm": 0.8697295188903809,
        "learning_rate": 1.3286093888396812e-06,
        "epoch": 8.67139061116032,
        "step": 9790
    },
    {
        "loss": 0.0377,
        "grad_norm": 69.43974304199219,
        "learning_rate": 1.3197519929140834e-06,
        "epoch": 8.680248007085916,
        "step": 9800
    },
    {
        "loss": 0.0079,
        "grad_norm": 0.0022764692548662424,
        "learning_rate": 1.3108945969884854e-06,
        "epoch": 8.689105403011515,
        "step": 9810
    },
    {
        "loss": 0.0286,
        "grad_norm": 0.023732995614409447,
        "learning_rate": 1.3020372010628877e-06,
        "epoch": 8.697962798937112,
        "step": 9820
    },
    {
        "loss": 0.0109,
        "grad_norm": 0.043600086122751236,
        "learning_rate": 1.29317980513729e-06,
        "epoch": 8.706820194862711,
        "step": 9830
    },
    {
        "loss": 0.0409,
        "grad_norm": 0.0029284656047821045,
        "learning_rate": 1.2843224092116918e-06,
        "epoch": 8.715677590788308,
        "step": 9840
    },
    {
        "loss": 0.0041,
        "grad_norm": 0.005449981428682804,
        "learning_rate": 1.275465013286094e-06,
        "epoch": 8.724534986713905,
        "step": 9850
    },
    {
        "loss": 0.0326,
        "grad_norm": 0.01102009043097496,
        "learning_rate": 1.266607617360496e-06,
        "epoch": 8.733392382639504,
        "step": 9860
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.019102390855550766,
        "learning_rate": 1.2577502214348983e-06,
        "epoch": 8.742249778565101,
        "step": 9870
    },
    {
        "loss": 0.012,
        "grad_norm": 0.048116568475961685,
        "learning_rate": 1.2488928255093003e-06,
        "epoch": 8.7511071744907,
        "step": 9880
    },
    {
        "loss": 0.0091,
        "grad_norm": 0.01980372704565525,
        "learning_rate": 1.2400354295837025e-06,
        "epoch": 8.759964570416297,
        "step": 9890
    },
    {
        "loss": 0.0957,
        "grad_norm": 0.00654506916180253,
        "learning_rate": 1.2311780336581046e-06,
        "epoch": 8.768821966341896,
        "step": 9900
    },
    {
        "loss": 0.0002,
        "grad_norm": 3.1239867210388184,
        "learning_rate": 1.2223206377325066e-06,
        "epoch": 8.777679362267493,
        "step": 9910
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.004472105763852596,
        "learning_rate": 1.2134632418069089e-06,
        "epoch": 8.78653675819309,
        "step": 9920
    },
    {
        "loss": 0.0476,
        "grad_norm": 0.0040085818618535995,
        "learning_rate": 1.204605845881311e-06,
        "epoch": 8.79539415411869,
        "step": 9930
    },
    {
        "loss": 0.0103,
        "grad_norm": 14.004526138305664,
        "learning_rate": 1.1957484499557131e-06,
        "epoch": 8.804251550044286,
        "step": 9940
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.08969395607709885,
        "learning_rate": 1.1868910540301152e-06,
        "epoch": 8.813108945969885,
        "step": 9950
    },
    {
        "loss": 0.0391,
        "grad_norm": 0.17136675119400024,
        "learning_rate": 1.1780336581045174e-06,
        "epoch": 8.821966341895482,
        "step": 9960
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005563909653574228,
        "learning_rate": 1.1691762621789194e-06,
        "epoch": 8.830823737821081,
        "step": 9970
    },
    {
        "loss": 0.0073,
        "grad_norm": 0.3036932349205017,
        "learning_rate": 1.1603188662533215e-06,
        "epoch": 8.839681133746678,
        "step": 9980
    },
    {
        "loss": 0.0472,
        "grad_norm": 0.005713464226573706,
        "learning_rate": 1.1514614703277237e-06,
        "epoch": 8.848538529672277,
        "step": 9990
    },
    {
        "loss": 0.0063,
        "grad_norm": 0.010192668996751308,
        "learning_rate": 1.142604074402126e-06,
        "epoch": 8.857395925597874,
        "step": 10000
    },
    {
        "loss": 0.0454,
        "grad_norm": 0.03249429911375046,
        "learning_rate": 1.133746678476528e-06,
        "epoch": 8.866253321523471,
        "step": 10010
    },
    {
        "loss": 0.0332,
        "grad_norm": 2.202697515487671,
        "learning_rate": 1.1248892825509302e-06,
        "epoch": 8.87511071744907,
        "step": 10020
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0075468868017196655,
        "learning_rate": 1.1160318866253323e-06,
        "epoch": 8.883968113374667,
        "step": 10030
    },
    {
        "loss": 0.0187,
        "grad_norm": 0.04523086175322533,
        "learning_rate": 1.1071744906997343e-06,
        "epoch": 8.892825509300266,
        "step": 10040
    },
    {
        "loss": 0.009,
        "grad_norm": 1.9398479461669922,
        "learning_rate": 1.0983170947741365e-06,
        "epoch": 8.901682905225863,
        "step": 10050
    },
    {
        "loss": 0.0851,
        "grad_norm": 0.01833423599600792,
        "learning_rate": 1.0894596988485386e-06,
        "epoch": 8.910540301151462,
        "step": 10060
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.015129459090530872,
        "learning_rate": 1.0806023029229408e-06,
        "epoch": 8.91939769707706,
        "step": 10070
    },
    {
        "loss": 0.009,
        "grad_norm": 0.01628562994301319,
        "learning_rate": 1.0717449069973429e-06,
        "epoch": 8.928255093002658,
        "step": 10080
    },
    {
        "loss": 0.0232,
        "grad_norm": 3.664738178253174,
        "learning_rate": 1.062887511071745e-06,
        "epoch": 8.937112488928255,
        "step": 10090
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0030651232227683067,
        "learning_rate": 1.0540301151461471e-06,
        "epoch": 8.945969884853852,
        "step": 10100
    },
    {
        "loss": 0.0151,
        "grad_norm": 0.004503261763602495,
        "learning_rate": 1.0451727192205492e-06,
        "epoch": 8.954827280779451,
        "step": 10110
    },
    {
        "loss": 0.053,
        "grad_norm": 0.00833556242287159,
        "learning_rate": 1.0363153232949514e-06,
        "epoch": 8.963684676705048,
        "step": 10120
    },
    {
        "loss": 0.0058,
        "grad_norm": 0.007359477691352367,
        "learning_rate": 1.0274579273693534e-06,
        "epoch": 8.972542072630647,
        "step": 10130
    },
    {
        "loss": 0.0083,
        "grad_norm": 0.008796663954854012,
        "learning_rate": 1.0186005314437557e-06,
        "epoch": 8.981399468556244,
        "step": 10140
    },
    {
        "loss": 0.0156,
        "grad_norm": 0.0045600226148962975,
        "learning_rate": 1.0097431355181577e-06,
        "epoch": 8.990256864481843,
        "step": 10150
    },
    {
        "loss": 0.0471,
        "grad_norm": 0.3789246082305908,
        "learning_rate": 1.00088573959256e-06,
        "epoch": 8.99911426040744,
        "step": 10160
    },
    {
        "eval_loss": 0.12231077998876572,
        "eval_accuracy": 0.97808,
        "eval_precision": 0.9785,
        "eval_recall": 0.97764,
        "eval_f1": 0.97807,
        "eval_runtime": 149.361,
        "eval_samples_per_second": 60.471,
        "eval_steps_per_second": 3.783,
        "epoch": 9.0,
        "step": 10161
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.007446348201483488,
        "learning_rate": 9.92028343666962e-07,
        "epoch": 9.007971656333037,
        "step": 10170
    },
    {
        "loss": 0.0351,
        "grad_norm": 0.009141516871750355,
        "learning_rate": 9.83170947741364e-07,
        "epoch": 9.016829052258636,
        "step": 10180
    },
    {
        "loss": 0.0165,
        "grad_norm": 0.04118148237466812,
        "learning_rate": 9.743135518157663e-07,
        "epoch": 9.025686448184233,
        "step": 10190
    },
    {
        "loss": 0.0092,
        "grad_norm": 0.009050179272890091,
        "learning_rate": 9.654561558901683e-07,
        "epoch": 9.034543844109832,
        "step": 10200
    },
    {
        "loss": 0.008,
        "grad_norm": 0.010475629940629005,
        "learning_rate": 9.565987599645705e-07,
        "epoch": 9.043401240035429,
        "step": 10210
    },
    {
        "loss": 0.0076,
        "grad_norm": 0.009953301399946213,
        "learning_rate": 9.477413640389727e-07,
        "epoch": 9.052258635961028,
        "step": 10220
    },
    {
        "loss": 0.047,
        "grad_norm": 1.6442309617996216,
        "learning_rate": 9.388839681133747e-07,
        "epoch": 9.061116031886625,
        "step": 10230
    },
    {
        "loss": 0.015,
        "grad_norm": 0.29120102524757385,
        "learning_rate": 9.300265721877769e-07,
        "epoch": 9.069973427812224,
        "step": 10240
    },
    {
        "loss": 0.0581,
        "grad_norm": 0.0023701360914856195,
        "learning_rate": 9.21169176262179e-07,
        "epoch": 9.078830823737821,
        "step": 10250
    },
    {
        "loss": 0.0512,
        "grad_norm": 0.005455780308693647,
        "learning_rate": 9.12311780336581e-07,
        "epoch": 9.087688219663418,
        "step": 10260
    },
    {
        "loss": 0.0536,
        "grad_norm": 0.03474276140332222,
        "learning_rate": 9.034543844109832e-07,
        "epoch": 9.096545615589017,
        "step": 10270
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.05525306239724159,
        "learning_rate": 8.945969884853854e-07,
        "epoch": 9.105403011514614,
        "step": 10280
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005968521349132061,
        "learning_rate": 8.857395925597875e-07,
        "epoch": 9.114260407440213,
        "step": 10290
    },
    {
        "loss": 0.0273,
        "grad_norm": 0.011980557814240456,
        "learning_rate": 8.768821966341897e-07,
        "epoch": 9.12311780336581,
        "step": 10300
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.008946871384978294,
        "learning_rate": 8.680248007085917e-07,
        "epoch": 9.131975199291409,
        "step": 10310
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.588834822177887,
        "learning_rate": 8.591674047829939e-07,
        "epoch": 9.140832595217006,
        "step": 10320
    },
    {
        "loss": 0.0136,
        "grad_norm": 0.011968059465289116,
        "learning_rate": 8.50310008857396e-07,
        "epoch": 9.149689991142605,
        "step": 10330
    },
    {
        "loss": 0.0288,
        "grad_norm": 4.95833683013916,
        "learning_rate": 8.41452612931798e-07,
        "epoch": 9.158547387068202,
        "step": 10340
    },
    {
        "loss": 0.0234,
        "grad_norm": 0.009869719855487347,
        "learning_rate": 8.325952170062003e-07,
        "epoch": 9.167404782993799,
        "step": 10350
    },
    {
        "loss": 0.0054,
        "grad_norm": 3.1714820861816406,
        "learning_rate": 8.237378210806024e-07,
        "epoch": 9.176262178919398,
        "step": 10360
    },
    {
        "loss": 0.0091,
        "grad_norm": 0.023428915068507195,
        "learning_rate": 8.148804251550045e-07,
        "epoch": 9.185119574844995,
        "step": 10370
    },
    {
        "loss": 0.0241,
        "grad_norm": 0.26075974106788635,
        "learning_rate": 8.060230292294066e-07,
        "epoch": 9.193976970770594,
        "step": 10380
    },
    {
        "loss": 0.0092,
        "grad_norm": 0.001988666597753763,
        "learning_rate": 7.971656333038087e-07,
        "epoch": 9.202834366696191,
        "step": 10390
    },
    {
        "loss": 0.0084,
        "grad_norm": 0.003493898082524538,
        "learning_rate": 7.883082373782109e-07,
        "epoch": 9.21169176262179,
        "step": 10400
    },
    {
        "loss": 0.0087,
        "grad_norm": 0.019074872136116028,
        "learning_rate": 7.794508414526129e-07,
        "epoch": 9.220549158547387,
        "step": 10410
    },
    {
        "loss": 0.0772,
        "grad_norm": 0.30531325936317444,
        "learning_rate": 7.705934455270151e-07,
        "epoch": 9.229406554472986,
        "step": 10420
    },
    {
        "loss": 0.0088,
        "grad_norm": 5.6204633712768555,
        "learning_rate": 7.617360496014173e-07,
        "epoch": 9.238263950398583,
        "step": 10430
    },
    {
        "loss": 0.054,
        "grad_norm": 0.003069142811000347,
        "learning_rate": 7.528786536758194e-07,
        "epoch": 9.24712134632418,
        "step": 10440
    },
    {
        "loss": 0.064,
        "grad_norm": 0.1479930430650711,
        "learning_rate": 7.440212577502214e-07,
        "epoch": 9.255978742249779,
        "step": 10450
    },
    {
        "loss": 0.0093,
        "grad_norm": 0.003550351830199361,
        "learning_rate": 7.351638618246236e-07,
        "epoch": 9.264836138175376,
        "step": 10460
    },
    {
        "loss": 0.0116,
        "grad_norm": 0.006731757428497076,
        "learning_rate": 7.263064658990257e-07,
        "epoch": 9.273693534100975,
        "step": 10470
    },
    {
        "loss": 0.0093,
        "grad_norm": 0.01978158764541149,
        "learning_rate": 7.174490699734279e-07,
        "epoch": 9.282550930026572,
        "step": 10480
    },
    {
        "loss": 0.0249,
        "grad_norm": 0.013791658915579319,
        "learning_rate": 7.085916740478301e-07,
        "epoch": 9.29140832595217,
        "step": 10490
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0062841130420565605,
        "learning_rate": 6.997342781222321e-07,
        "epoch": 9.300265721877768,
        "step": 10500
    },
    {
        "loss": 0.0094,
        "grad_norm": 0.008776133880019188,
        "learning_rate": 6.908768821966343e-07,
        "epoch": 9.309123117803367,
        "step": 10510
    },
    {
        "loss": 0.0022,
        "grad_norm": 0.03412504866719246,
        "learning_rate": 6.820194862710364e-07,
        "epoch": 9.317980513728964,
        "step": 10520
    },
    {
        "loss": 0.0552,
        "grad_norm": 124.71530151367188,
        "learning_rate": 6.731620903454384e-07,
        "epoch": 9.32683790965456,
        "step": 10530
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.042047854512929916,
        "learning_rate": 6.643046944198406e-07,
        "epoch": 9.33569530558016,
        "step": 10540
    },
    {
        "loss": 0.0003,
        "grad_norm": 2.982438087463379,
        "learning_rate": 6.554472984942427e-07,
        "epoch": 9.344552701505757,
        "step": 10550
    },
    {
        "loss": 0.0066,
        "grad_norm": 0.021930452436208725,
        "learning_rate": 6.46589902568645e-07,
        "epoch": 9.353410097431356,
        "step": 10560
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.008161384612321854,
        "learning_rate": 6.37732506643047e-07,
        "epoch": 9.362267493356953,
        "step": 10570
    },
    {
        "loss": 0.0279,
        "grad_norm": 0.011714454740285873,
        "learning_rate": 6.288751107174491e-07,
        "epoch": 9.371124889282552,
        "step": 10580
    },
    {
        "loss": 0.0184,
        "grad_norm": 0.0021303188987076283,
        "learning_rate": 6.200177147918513e-07,
        "epoch": 9.379982285208149,
        "step": 10590
    },
    {
        "loss": 0.0315,
        "grad_norm": 3.5942862033843994,
        "learning_rate": 6.111603188662533e-07,
        "epoch": 9.388839681133746,
        "step": 10600
    },
    {
        "loss": 0.0067,
        "grad_norm": 3.8235011100769043,
        "learning_rate": 6.023029229406556e-07,
        "epoch": 9.397697077059345,
        "step": 10610
    },
    {
        "loss": 0.0214,
        "grad_norm": 0.03968453034758568,
        "learning_rate": 5.934455270150576e-07,
        "epoch": 9.406554472984942,
        "step": 10620
    },
    {
        "loss": 0.0068,
        "grad_norm": 0.003032435430213809,
        "learning_rate": 5.845881310894597e-07,
        "epoch": 9.41541186891054,
        "step": 10630
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.07536973804235458,
        "learning_rate": 5.757307351638619e-07,
        "epoch": 9.424269264836138,
        "step": 10640
    },
    {
        "loss": 0.0265,
        "grad_norm": 0.026389313861727715,
        "learning_rate": 5.66873339238264e-07,
        "epoch": 9.433126660761737,
        "step": 10650
    },
    {
        "loss": 0.0375,
        "grad_norm": 0.05764475837349892,
        "learning_rate": 5.580159433126661e-07,
        "epoch": 9.441984056687334,
        "step": 10660
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.010647464543581009,
        "learning_rate": 5.491585473870683e-07,
        "epoch": 9.450841452612933,
        "step": 10670
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019706154707819223,
        "learning_rate": 5.403011514614704e-07,
        "epoch": 9.45969884853853,
        "step": 10680
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005307900253683329,
        "learning_rate": 5.314437555358726e-07,
        "epoch": 9.468556244464127,
        "step": 10690
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0024288836866617203,
        "learning_rate": 5.225863596102746e-07,
        "epoch": 9.477413640389726,
        "step": 10700
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.016138318926095963,
        "learning_rate": 5.137289636846767e-07,
        "epoch": 9.486271036315323,
        "step": 10710
    },
    {
        "loss": 0.0217,
        "grad_norm": 0.0020039891824126244,
        "learning_rate": 5.048715677590789e-07,
        "epoch": 9.495128432240922,
        "step": 10720
    },
    {
        "loss": 0.0087,
        "grad_norm": 0.004035975784063339,
        "learning_rate": 4.96014171833481e-07,
        "epoch": 9.503985828166519,
        "step": 10730
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.013109134510159492,
        "learning_rate": 4.871567759078831e-07,
        "epoch": 9.512843224092117,
        "step": 10740
    },
    {
        "loss": 0.0233,
        "grad_norm": 0.0040020085871219635,
        "learning_rate": 4.782993799822853e-07,
        "epoch": 9.521700620017715,
        "step": 10750
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005831460934132338,
        "learning_rate": 4.6944198405668736e-07,
        "epoch": 9.530558015943313,
        "step": 10760
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.002083444269374013,
        "learning_rate": 4.605845881310895e-07,
        "epoch": 9.53941541186891,
        "step": 10770
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.014259738847613335,
        "learning_rate": 4.517271922054916e-07,
        "epoch": 9.548272807794508,
        "step": 10780
    },
    {
        "loss": 0.0398,
        "grad_norm": 0.04841209948062897,
        "learning_rate": 4.428697962798938e-07,
        "epoch": 9.557130203720106,
        "step": 10790
    },
    {
        "loss": 0.0247,
        "grad_norm": 0.02526259981095791,
        "learning_rate": 4.3401240035429586e-07,
        "epoch": 9.565987599645704,
        "step": 10800
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004827036987990141,
        "learning_rate": 4.25155004428698e-07,
        "epoch": 9.574844995571302,
        "step": 10810
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.020381592214107513,
        "learning_rate": 4.1629760850310014e-07,
        "epoch": 9.5837023914969,
        "step": 10820
    },
    {
        "loss": 0.0077,
        "grad_norm": 0.0043752603232860565,
        "learning_rate": 4.074402125775023e-07,
        "epoch": 9.592559787422498,
        "step": 10830
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006879670545458794,
        "learning_rate": 3.9858281665190436e-07,
        "epoch": 9.601417183348095,
        "step": 10840
    },
    {
        "loss": 0.0499,
        "grad_norm": 179.76710510253906,
        "learning_rate": 3.8972542072630645e-07,
        "epoch": 9.610274579273694,
        "step": 10850
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.002379168290644884,
        "learning_rate": 3.8086802480070864e-07,
        "epoch": 9.619131975199291,
        "step": 10860
    },
    {
        "loss": 0.0408,
        "grad_norm": 0.0050965300761163235,
        "learning_rate": 3.720106288751107e-07,
        "epoch": 9.627989371124889,
        "step": 10870
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.668724000453949,
        "learning_rate": 3.6315323294951286e-07,
        "epoch": 9.636846767050487,
        "step": 10880
    },
    {
        "loss": 0.0595,
        "grad_norm": 150.0318145751953,
        "learning_rate": 3.5429583702391505e-07,
        "epoch": 9.645704162976084,
        "step": 10890
    },
    {
        "loss": 0.0066,
        "grad_norm": 0.0020995624363422394,
        "learning_rate": 3.4543844109831714e-07,
        "epoch": 9.654561558901683,
        "step": 10900
    },
    {
        "loss": 0.0154,
        "grad_norm": 0.0034891588147729635,
        "learning_rate": 3.365810451727192e-07,
        "epoch": 9.66341895482728,
        "step": 10910
    },
    {
        "loss": 0.0082,
        "grad_norm": 0.02098151668906212,
        "learning_rate": 3.2772364924712136e-07,
        "epoch": 9.67227635075288,
        "step": 10920
    },
    {
        "loss": 0.0852,
        "grad_norm": 0.0043585775420069695,
        "learning_rate": 3.188662533215235e-07,
        "epoch": 9.681133746678476,
        "step": 10930
    },
    {
        "loss": 0.0233,
        "grad_norm": 0.0023795838933438063,
        "learning_rate": 3.1000885739592564e-07,
        "epoch": 9.689991142604075,
        "step": 10940
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007178123574703932,
        "learning_rate": 3.011514614703278e-07,
        "epoch": 9.698848538529672,
        "step": 10950
    },
    {
        "loss": 0.0489,
        "grad_norm": 0.014659063890576363,
        "learning_rate": 2.9229406554472986e-07,
        "epoch": 9.70770593445527,
        "step": 10960
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.015187538228929043,
        "learning_rate": 2.83436669619132e-07,
        "epoch": 9.716563330380868,
        "step": 10970
    },
    {
        "loss": 0.0067,
        "grad_norm": 0.004857032094150782,
        "learning_rate": 2.7457927369353414e-07,
        "epoch": 9.725420726306465,
        "step": 10980
    },
    {
        "loss": 0.0112,
        "grad_norm": 0.0032526510767638683,
        "learning_rate": 2.657218777679363e-07,
        "epoch": 9.734278122232064,
        "step": 10990
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0055283415131270885,
        "learning_rate": 2.5686448184233836e-07,
        "epoch": 9.743135518157661,
        "step": 11000
    },
    {
        "loss": 0.0093,
        "grad_norm": 0.004398819524794817,
        "learning_rate": 2.480070859167405e-07,
        "epoch": 9.75199291408326,
        "step": 11010
    },
    {
        "loss": 0.0425,
        "grad_norm": 2.884521007537842,
        "learning_rate": 2.3914968999114264e-07,
        "epoch": 9.760850310008857,
        "step": 11020
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.0054689012467861176,
        "learning_rate": 2.3029229406554475e-07,
        "epoch": 9.769707705934454,
        "step": 11030
    },
    {
        "loss": 0.0087,
        "grad_norm": 0.13139507174491882,
        "learning_rate": 2.214348981399469e-07,
        "epoch": 9.778565101860053,
        "step": 11040
    },
    {
        "loss": 0.0375,
        "grad_norm": 8.001521110534668,
        "learning_rate": 2.12577502214349e-07,
        "epoch": 9.78742249778565,
        "step": 11050
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007772271987050772,
        "learning_rate": 2.0372010628875114e-07,
        "epoch": 9.79627989371125,
        "step": 11060
    },
    {
        "loss": 0.0434,
        "grad_norm": 0.009121347218751907,
        "learning_rate": 1.9486271036315322e-07,
        "epoch": 9.805137289636846,
        "step": 11070
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.3791344463825226,
        "learning_rate": 1.8600531443755536e-07,
        "epoch": 9.813994685562445,
        "step": 11080
    },
    {
        "loss": 0.0531,
        "grad_norm": 105.42823028564453,
        "learning_rate": 1.7714791851195753e-07,
        "epoch": 9.822852081488042,
        "step": 11090
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0049870992079377174,
        "learning_rate": 1.682905225863596e-07,
        "epoch": 9.831709477413641,
        "step": 11100
    },
    {
        "loss": 0.0337,
        "grad_norm": 0.0026566749438643456,
        "learning_rate": 1.5943312666076175e-07,
        "epoch": 9.840566873339238,
        "step": 11110
    },
    {
        "loss": 0.0235,
        "grad_norm": 0.022546347230672836,
        "learning_rate": 1.505757307351639e-07,
        "epoch": 9.849424269264837,
        "step": 11120
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003095097839832306,
        "learning_rate": 1.41718334809566e-07,
        "epoch": 9.858281665190434,
        "step": 11130
    },
    {
        "loss": 0.0211,
        "grad_norm": 0.023645712062716484,
        "learning_rate": 1.3286093888396814e-07,
        "epoch": 9.867139061116031,
        "step": 11140
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00715061416849494,
        "learning_rate": 1.2400354295837025e-07,
        "epoch": 9.87599645704163,
        "step": 11150
    },
    {
        "loss": 0.0165,
        "grad_norm": 0.25285932421684265,
        "learning_rate": 1.1514614703277237e-07,
        "epoch": 9.884853852967227,
        "step": 11160
    },
    {
        "loss": 0.0072,
        "grad_norm": 0.001730319345369935,
        "learning_rate": 1.062887511071745e-07,
        "epoch": 9.893711248892826,
        "step": 11170
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.003740255255252123,
        "learning_rate": 9.743135518157661e-08,
        "epoch": 9.902568644818423,
        "step": 11180
    },
    {
        "loss": 0.0136,
        "grad_norm": 0.002460835501551628,
        "learning_rate": 8.857395925597876e-08,
        "epoch": 9.911426040744022,
        "step": 11190
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.1285867542028427,
        "learning_rate": 7.971656333038087e-08,
        "epoch": 9.920283436669619,
        "step": 11200
    },
    {
        "loss": 0.0308,
        "grad_norm": 67.8538818359375,
        "learning_rate": 7.0859167404783e-08,
        "epoch": 9.929140832595216,
        "step": 11210
    },
    {
        "loss": 0.0031,
        "grad_norm": 0.026170087978243828,
        "learning_rate": 6.200177147918512e-08,
        "epoch": 9.937998228520815,
        "step": 11220
    },
    {
        "loss": 0.017,
        "grad_norm": 0.020736217498779297,
        "learning_rate": 5.314437555358725e-08,
        "epoch": 9.946855624446412,
        "step": 11230
    },
    {
        "loss": 0.0247,
        "grad_norm": 0.0068170055747032166,
        "learning_rate": 4.428697962798938e-08,
        "epoch": 9.955713020372011,
        "step": 11240
    },
    {
        "loss": 0.0065,
        "grad_norm": 0.0037201859522610903,
        "learning_rate": 3.54295837023915e-08,
        "epoch": 9.964570416297608,
        "step": 11250
    },
    {
        "loss": 0.0017,
        "grad_norm": 1.7522263526916504,
        "learning_rate": 2.6572187776793625e-08,
        "epoch": 9.973427812223207,
        "step": 11260
    },
    {
        "loss": 0.0649,
        "grad_norm": 0.00277570728212595,
        "learning_rate": 1.771479185119575e-08,
        "epoch": 9.982285208148804,
        "step": 11270
    },
    {
        "loss": 0.0169,
        "grad_norm": 1.8195655345916748,
        "learning_rate": 8.857395925597875e-09,
        "epoch": 9.991142604074403,
        "step": 11280
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.004490503575652838,
        "learning_rate": 0.0,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "eval_loss": 0.12107573449611664,
        "eval_accuracy": 0.98007,
        "eval_precision": 0.98028,
        "eval_recall": 0.97985,
        "eval_f1": 0.98007,
        "eval_runtime": 149.2674,
        "eval_samples_per_second": 60.509,
        "eval_steps_per_second": 3.785,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "train_runtime": 10132.1821,
        "train_samples_per_second": 17.827,
        "train_steps_per_second": 1.114,
        "total_flos": 2.37628749648384e+16,
        "train_loss": 0.15330199831950275,
        "epoch": 10.0,
        "step": 11290
    }
]