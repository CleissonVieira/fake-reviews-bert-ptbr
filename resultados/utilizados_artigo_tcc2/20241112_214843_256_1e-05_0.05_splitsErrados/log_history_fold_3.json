[
    {
        "loss": 0.6931,
        "grad_norm": 3.5064094066619873,
        "learning_rate": 9.991142604074402e-06,
        "epoch": 0.008857395925597875,
        "step": 10
    },
    {
        "loss": 0.6593,
        "grad_norm": 3.4825279712677,
        "learning_rate": 9.982285208148806e-06,
        "epoch": 0.01771479185119575,
        "step": 20
    },
    {
        "loss": 0.6306,
        "grad_norm": 4.41895866394043,
        "learning_rate": 9.973427812223207e-06,
        "epoch": 0.026572187776793623,
        "step": 30
    },
    {
        "loss": 0.6801,
        "grad_norm": 3.5007293224334717,
        "learning_rate": 9.964570416297609e-06,
        "epoch": 0.0354295837023915,
        "step": 40
    },
    {
        "loss": 0.6015,
        "grad_norm": 3.077658176422119,
        "learning_rate": 9.95571302037201e-06,
        "epoch": 0.04428697962798937,
        "step": 50
    },
    {
        "loss": 0.5813,
        "grad_norm": 3.9550492763519287,
        "learning_rate": 9.946855624446414e-06,
        "epoch": 0.053144375553587246,
        "step": 60
    },
    {
        "loss": 0.6299,
        "grad_norm": 4.888167381286621,
        "learning_rate": 9.937998228520815e-06,
        "epoch": 0.06200177147918512,
        "step": 70
    },
    {
        "loss": 0.6412,
        "grad_norm": 6.641629219055176,
        "learning_rate": 9.929140832595217e-06,
        "epoch": 0.070859167404783,
        "step": 80
    },
    {
        "loss": 0.586,
        "grad_norm": 4.500382900238037,
        "learning_rate": 9.92028343666962e-06,
        "epoch": 0.07971656333038087,
        "step": 90
    },
    {
        "loss": 0.6058,
        "grad_norm": 3.85552716255188,
        "learning_rate": 9.911426040744022e-06,
        "epoch": 0.08857395925597875,
        "step": 100
    },
    {
        "loss": 0.6496,
        "grad_norm": 5.488349914550781,
        "learning_rate": 9.902568644818424e-06,
        "epoch": 0.09743135518157661,
        "step": 110
    },
    {
        "loss": 0.6098,
        "grad_norm": 3.6928558349609375,
        "learning_rate": 9.893711248892827e-06,
        "epoch": 0.10628875110717449,
        "step": 120
    },
    {
        "loss": 0.5887,
        "grad_norm": 4.773133277893066,
        "learning_rate": 9.884853852967229e-06,
        "epoch": 0.11514614703277236,
        "step": 130
    },
    {
        "loss": 0.6086,
        "grad_norm": 2.763746976852417,
        "learning_rate": 9.87599645704163e-06,
        "epoch": 0.12400354295837024,
        "step": 140
    },
    {
        "loss": 0.6239,
        "grad_norm": 2.989741325378418,
        "learning_rate": 9.867139061116032e-06,
        "epoch": 0.1328609388839681,
        "step": 150
    },
    {
        "loss": 0.5786,
        "grad_norm": 5.98201322555542,
        "learning_rate": 9.858281665190435e-06,
        "epoch": 0.141718334809566,
        "step": 160
    },
    {
        "loss": 0.5851,
        "grad_norm": 2.953674077987671,
        "learning_rate": 9.849424269264837e-06,
        "epoch": 0.15057573073516387,
        "step": 170
    },
    {
        "loss": 0.6163,
        "grad_norm": 3.352531671524048,
        "learning_rate": 9.840566873339238e-06,
        "epoch": 0.15943312666076173,
        "step": 180
    },
    {
        "loss": 0.5908,
        "grad_norm": 4.2989654541015625,
        "learning_rate": 9.831709477413642e-06,
        "epoch": 0.1682905225863596,
        "step": 190
    },
    {
        "loss": 0.6059,
        "grad_norm": 3.327786922454834,
        "learning_rate": 9.822852081488043e-06,
        "epoch": 0.1771479185119575,
        "step": 200
    },
    {
        "loss": 0.5577,
        "grad_norm": 6.166895866394043,
        "learning_rate": 9.813994685562446e-06,
        "epoch": 0.18600531443755536,
        "step": 210
    },
    {
        "loss": 0.5277,
        "grad_norm": 3.859147310256958,
        "learning_rate": 9.805137289636848e-06,
        "epoch": 0.19486271036315322,
        "step": 220
    },
    {
        "loss": 0.5488,
        "grad_norm": 5.552802085876465,
        "learning_rate": 9.79627989371125e-06,
        "epoch": 0.20372010628875112,
        "step": 230
    },
    {
        "loss": 0.6785,
        "grad_norm": 4.282368183135986,
        "learning_rate": 9.787422497785651e-06,
        "epoch": 0.21257750221434898,
        "step": 240
    },
    {
        "loss": 0.5973,
        "grad_norm": 5.202925205230713,
        "learning_rate": 9.778565101860053e-06,
        "epoch": 0.22143489813994685,
        "step": 250
    },
    {
        "loss": 0.585,
        "grad_norm": 5.312267780303955,
        "learning_rate": 9.769707705934456e-06,
        "epoch": 0.23029229406554472,
        "step": 260
    },
    {
        "loss": 0.5726,
        "grad_norm": 4.011716842651367,
        "learning_rate": 9.760850310008858e-06,
        "epoch": 0.2391496899911426,
        "step": 270
    },
    {
        "loss": 0.5739,
        "grad_norm": 5.757143974304199,
        "learning_rate": 9.751992914083261e-06,
        "epoch": 0.24800708591674048,
        "step": 280
    },
    {
        "loss": 0.6184,
        "grad_norm": 5.444320201873779,
        "learning_rate": 9.743135518157663e-06,
        "epoch": 0.25686448184233834,
        "step": 290
    },
    {
        "loss": 0.5956,
        "grad_norm": 5.302351474761963,
        "learning_rate": 9.734278122232064e-06,
        "epoch": 0.2657218777679362,
        "step": 300
    },
    {
        "loss": 0.5658,
        "grad_norm": 2.892561435699463,
        "learning_rate": 9.725420726306468e-06,
        "epoch": 0.2745792736935341,
        "step": 310
    },
    {
        "loss": 0.6222,
        "grad_norm": 5.100085258483887,
        "learning_rate": 9.71656333038087e-06,
        "epoch": 0.283436669619132,
        "step": 320
    },
    {
        "loss": 0.5529,
        "grad_norm": 4.837823390960693,
        "learning_rate": 9.707705934455271e-06,
        "epoch": 0.29229406554472986,
        "step": 330
    },
    {
        "loss": 0.4918,
        "grad_norm": 5.5610785484313965,
        "learning_rate": 9.698848538529672e-06,
        "epoch": 0.30115146147032773,
        "step": 340
    },
    {
        "loss": 0.6018,
        "grad_norm": 6.590065956115723,
        "learning_rate": 9.689991142604076e-06,
        "epoch": 0.3100088573959256,
        "step": 350
    },
    {
        "loss": 0.6486,
        "grad_norm": 8.395450592041016,
        "learning_rate": 9.681133746678477e-06,
        "epoch": 0.31886625332152346,
        "step": 360
    },
    {
        "loss": 0.5267,
        "grad_norm": 5.563538074493408,
        "learning_rate": 9.672276350752879e-06,
        "epoch": 0.32772364924712133,
        "step": 370
    },
    {
        "loss": 0.5653,
        "grad_norm": 3.6083271503448486,
        "learning_rate": 9.663418954827282e-06,
        "epoch": 0.3365810451727192,
        "step": 380
    },
    {
        "loss": 0.561,
        "grad_norm": 3.94767165184021,
        "learning_rate": 9.654561558901684e-06,
        "epoch": 0.3454384410983171,
        "step": 390
    },
    {
        "loss": 0.5397,
        "grad_norm": 4.078184127807617,
        "learning_rate": 9.645704162976086e-06,
        "epoch": 0.354295837023915,
        "step": 400
    },
    {
        "loss": 0.5424,
        "grad_norm": 9.986482620239258,
        "learning_rate": 9.636846767050489e-06,
        "epoch": 0.36315323294951285,
        "step": 410
    },
    {
        "loss": 0.6172,
        "grad_norm": 4.78609561920166,
        "learning_rate": 9.627989371124889e-06,
        "epoch": 0.3720106288751107,
        "step": 420
    },
    {
        "loss": 0.53,
        "grad_norm": 6.6727824211120605,
        "learning_rate": 9.619131975199292e-06,
        "epoch": 0.3808680248007086,
        "step": 430
    },
    {
        "loss": 0.5871,
        "grad_norm": 7.361201763153076,
        "learning_rate": 9.610274579273694e-06,
        "epoch": 0.38972542072630645,
        "step": 440
    },
    {
        "loss": 0.5278,
        "grad_norm": 11.159778594970703,
        "learning_rate": 9.601417183348097e-06,
        "epoch": 0.3985828166519043,
        "step": 450
    },
    {
        "loss": 0.4883,
        "grad_norm": 5.930775165557861,
        "learning_rate": 9.592559787422499e-06,
        "epoch": 0.40744021257750224,
        "step": 460
    },
    {
        "loss": 0.4983,
        "grad_norm": 6.933995723724365,
        "learning_rate": 9.5837023914969e-06,
        "epoch": 0.4162976085031001,
        "step": 470
    },
    {
        "loss": 0.525,
        "grad_norm": 7.021853446960449,
        "learning_rate": 9.574844995571303e-06,
        "epoch": 0.42515500442869797,
        "step": 480
    },
    {
        "loss": 0.5875,
        "grad_norm": 14.905559539794922,
        "learning_rate": 9.565987599645705e-06,
        "epoch": 0.43401240035429584,
        "step": 490
    },
    {
        "loss": 0.5406,
        "grad_norm": 12.27026081085205,
        "learning_rate": 9.557130203720107e-06,
        "epoch": 0.4428697962798937,
        "step": 500
    },
    {
        "loss": 0.4959,
        "grad_norm": 16.534671783447266,
        "learning_rate": 9.54827280779451e-06,
        "epoch": 0.45172719220549157,
        "step": 510
    },
    {
        "loss": 0.4905,
        "grad_norm": 7.864902496337891,
        "learning_rate": 9.539415411868912e-06,
        "epoch": 0.46058458813108943,
        "step": 520
    },
    {
        "loss": 0.6654,
        "grad_norm": 7.817150592803955,
        "learning_rate": 9.530558015943313e-06,
        "epoch": 0.46944198405668736,
        "step": 530
    },
    {
        "loss": 0.5214,
        "grad_norm": 3.937448501586914,
        "learning_rate": 9.521700620017715e-06,
        "epoch": 0.4782993799822852,
        "step": 540
    },
    {
        "loss": 0.5654,
        "grad_norm": 8.31511402130127,
        "learning_rate": 9.512843224092118e-06,
        "epoch": 0.4871567759078831,
        "step": 550
    },
    {
        "loss": 0.5542,
        "grad_norm": 5.203733444213867,
        "learning_rate": 9.50398582816652e-06,
        "epoch": 0.49601417183348095,
        "step": 560
    },
    {
        "loss": 0.5553,
        "grad_norm": 4.542927265167236,
        "learning_rate": 9.495128432240921e-06,
        "epoch": 0.5048715677590788,
        "step": 570
    },
    {
        "loss": 0.5291,
        "grad_norm": 7.070539474487305,
        "learning_rate": 9.486271036315325e-06,
        "epoch": 0.5137289636846767,
        "step": 580
    },
    {
        "loss": 0.532,
        "grad_norm": 8.431761741638184,
        "learning_rate": 9.477413640389726e-06,
        "epoch": 0.5225863596102746,
        "step": 590
    },
    {
        "loss": 0.4832,
        "grad_norm": 9.60234546661377,
        "learning_rate": 9.46855624446413e-06,
        "epoch": 0.5314437555358724,
        "step": 600
    },
    {
        "loss": 0.4512,
        "grad_norm": 4.539560794830322,
        "learning_rate": 9.45969884853853e-06,
        "epoch": 0.5403011514614703,
        "step": 610
    },
    {
        "loss": 0.4273,
        "grad_norm": 11.619267463684082,
        "learning_rate": 9.450841452612933e-06,
        "epoch": 0.5491585473870682,
        "step": 620
    },
    {
        "loss": 0.4565,
        "grad_norm": 6.52305793762207,
        "learning_rate": 9.441984056687334e-06,
        "epoch": 0.5580159433126661,
        "step": 630
    },
    {
        "loss": 0.511,
        "grad_norm": 16.585472106933594,
        "learning_rate": 9.433126660761736e-06,
        "epoch": 0.566873339238264,
        "step": 640
    },
    {
        "loss": 0.4979,
        "grad_norm": 7.94830322265625,
        "learning_rate": 9.42426926483614e-06,
        "epoch": 0.5757307351638619,
        "step": 650
    },
    {
        "loss": 0.5628,
        "grad_norm": 16.356468200683594,
        "learning_rate": 9.415411868910541e-06,
        "epoch": 0.5845881310894597,
        "step": 660
    },
    {
        "loss": 0.5728,
        "grad_norm": 11.79589557647705,
        "learning_rate": 9.406554472984944e-06,
        "epoch": 0.5934455270150576,
        "step": 670
    },
    {
        "loss": 0.6449,
        "grad_norm": 6.020732879638672,
        "learning_rate": 9.397697077059346e-06,
        "epoch": 0.6023029229406555,
        "step": 680
    },
    {
        "loss": 0.5319,
        "grad_norm": 6.3280253410339355,
        "learning_rate": 9.388839681133747e-06,
        "epoch": 0.6111603188662533,
        "step": 690
    },
    {
        "loss": 0.5416,
        "grad_norm": 7.11379861831665,
        "learning_rate": 9.379982285208149e-06,
        "epoch": 0.6200177147918512,
        "step": 700
    },
    {
        "loss": 0.5587,
        "grad_norm": 7.282015800476074,
        "learning_rate": 9.37112488928255e-06,
        "epoch": 0.6288751107174491,
        "step": 710
    },
    {
        "loss": 0.5042,
        "grad_norm": 8.107471466064453,
        "learning_rate": 9.362267493356954e-06,
        "epoch": 0.6377325066430469,
        "step": 720
    },
    {
        "loss": 0.487,
        "grad_norm": 8.786273002624512,
        "learning_rate": 9.353410097431356e-06,
        "epoch": 0.6465899025686448,
        "step": 730
    },
    {
        "loss": 0.4799,
        "grad_norm": 10.67901611328125,
        "learning_rate": 9.344552701505759e-06,
        "epoch": 0.6554472984942427,
        "step": 740
    },
    {
        "loss": 0.5479,
        "grad_norm": 4.875502109527588,
        "learning_rate": 9.33569530558016e-06,
        "epoch": 0.6643046944198405,
        "step": 750
    },
    {
        "loss": 0.5656,
        "grad_norm": 9.822894096374512,
        "learning_rate": 9.326837909654562e-06,
        "epoch": 0.6731620903454384,
        "step": 760
    },
    {
        "loss": 0.5096,
        "grad_norm": 10.93604850769043,
        "learning_rate": 9.317980513728965e-06,
        "epoch": 0.6820194862710364,
        "step": 770
    },
    {
        "loss": 0.4095,
        "grad_norm": 10.017870903015137,
        "learning_rate": 9.309123117803367e-06,
        "epoch": 0.6908768821966342,
        "step": 780
    },
    {
        "loss": 0.4921,
        "grad_norm": 10.775047302246094,
        "learning_rate": 9.300265721877769e-06,
        "epoch": 0.6997342781222321,
        "step": 790
    },
    {
        "loss": 0.5099,
        "grad_norm": 12.056032180786133,
        "learning_rate": 9.29140832595217e-06,
        "epoch": 0.70859167404783,
        "step": 800
    },
    {
        "loss": 0.6231,
        "grad_norm": 6.713217258453369,
        "learning_rate": 9.282550930026572e-06,
        "epoch": 0.7174490699734278,
        "step": 810
    },
    {
        "loss": 0.4464,
        "grad_norm": 7.799896240234375,
        "learning_rate": 9.273693534100975e-06,
        "epoch": 0.7263064658990257,
        "step": 820
    },
    {
        "loss": 0.4788,
        "grad_norm": 10.340243339538574,
        "learning_rate": 9.264836138175377e-06,
        "epoch": 0.7351638618246236,
        "step": 830
    },
    {
        "loss": 0.5528,
        "grad_norm": 13.873160362243652,
        "learning_rate": 9.25597874224978e-06,
        "epoch": 0.7440212577502214,
        "step": 840
    },
    {
        "loss": 0.5115,
        "grad_norm": 8.321410179138184,
        "learning_rate": 9.247121346324182e-06,
        "epoch": 0.7528786536758193,
        "step": 850
    },
    {
        "loss": 0.5646,
        "grad_norm": 19.018051147460938,
        "learning_rate": 9.238263950398583e-06,
        "epoch": 0.7617360496014172,
        "step": 860
    },
    {
        "loss": 0.5834,
        "grad_norm": 10.732257843017578,
        "learning_rate": 9.229406554472987e-06,
        "epoch": 0.770593445527015,
        "step": 870
    },
    {
        "loss": 0.4656,
        "grad_norm": 8.435288429260254,
        "learning_rate": 9.220549158547388e-06,
        "epoch": 0.7794508414526129,
        "step": 880
    },
    {
        "loss": 0.5,
        "grad_norm": 10.773409843444824,
        "learning_rate": 9.21169176262179e-06,
        "epoch": 0.7883082373782108,
        "step": 890
    },
    {
        "loss": 0.5112,
        "grad_norm": 12.176206588745117,
        "learning_rate": 9.202834366696191e-06,
        "epoch": 0.7971656333038086,
        "step": 900
    },
    {
        "loss": 0.4426,
        "grad_norm": 9.375731468200684,
        "learning_rate": 9.193976970770595e-06,
        "epoch": 0.8060230292294066,
        "step": 910
    },
    {
        "loss": 0.522,
        "grad_norm": 18.192005157470703,
        "learning_rate": 9.185119574844996e-06,
        "epoch": 0.8148804251550045,
        "step": 920
    },
    {
        "loss": 0.5508,
        "grad_norm": 8.01659870147705,
        "learning_rate": 9.176262178919398e-06,
        "epoch": 0.8237378210806023,
        "step": 930
    },
    {
        "loss": 0.5115,
        "grad_norm": 11.172966003417969,
        "learning_rate": 9.167404782993801e-06,
        "epoch": 0.8325952170062002,
        "step": 940
    },
    {
        "loss": 0.5303,
        "grad_norm": 12.270618438720703,
        "learning_rate": 9.158547387068203e-06,
        "epoch": 0.8414526129317981,
        "step": 950
    },
    {
        "loss": 0.4512,
        "grad_norm": 12.795300483703613,
        "learning_rate": 9.149689991142604e-06,
        "epoch": 0.8503100088573959,
        "step": 960
    },
    {
        "loss": 0.529,
        "grad_norm": 10.642882347106934,
        "learning_rate": 9.140832595217008e-06,
        "epoch": 0.8591674047829938,
        "step": 970
    },
    {
        "loss": 0.5341,
        "grad_norm": 10.16399097442627,
        "learning_rate": 9.13197519929141e-06,
        "epoch": 0.8680248007085917,
        "step": 980
    },
    {
        "loss": 0.4657,
        "grad_norm": 7.718184471130371,
        "learning_rate": 9.123117803365811e-06,
        "epoch": 0.8768821966341895,
        "step": 990
    },
    {
        "loss": 0.532,
        "grad_norm": 7.200087070465088,
        "learning_rate": 9.114260407440213e-06,
        "epoch": 0.8857395925597874,
        "step": 1000
    },
    {
        "loss": 0.4682,
        "grad_norm": 7.791935920715332,
        "learning_rate": 9.105403011514616e-06,
        "epoch": 0.8945969884853853,
        "step": 1010
    },
    {
        "loss": 0.5131,
        "grad_norm": 7.620841026306152,
        "learning_rate": 9.096545615589017e-06,
        "epoch": 0.9034543844109831,
        "step": 1020
    },
    {
        "loss": 0.4734,
        "grad_norm": 16.69329833984375,
        "learning_rate": 9.087688219663419e-06,
        "epoch": 0.912311780336581,
        "step": 1030
    },
    {
        "loss": 0.519,
        "grad_norm": 13.746103286743164,
        "learning_rate": 9.078830823737822e-06,
        "epoch": 0.9211691762621789,
        "step": 1040
    },
    {
        "loss": 0.406,
        "grad_norm": 10.829167366027832,
        "learning_rate": 9.069973427812224e-06,
        "epoch": 0.9300265721877768,
        "step": 1050
    },
    {
        "loss": 0.4521,
        "grad_norm": 16.135549545288086,
        "learning_rate": 9.061116031886627e-06,
        "epoch": 0.9388839681133747,
        "step": 1060
    },
    {
        "loss": 0.5481,
        "grad_norm": 9.758889198303223,
        "learning_rate": 9.052258635961029e-06,
        "epoch": 0.9477413640389726,
        "step": 1070
    },
    {
        "loss": 0.4788,
        "grad_norm": 15.419962882995605,
        "learning_rate": 9.04340124003543e-06,
        "epoch": 0.9565987599645704,
        "step": 1080
    },
    {
        "loss": 0.4073,
        "grad_norm": 19.24039649963379,
        "learning_rate": 9.034543844109832e-06,
        "epoch": 0.9654561558901683,
        "step": 1090
    },
    {
        "loss": 0.5065,
        "grad_norm": 15.657169342041016,
        "learning_rate": 9.025686448184234e-06,
        "epoch": 0.9743135518157662,
        "step": 1100
    },
    {
        "loss": 0.4829,
        "grad_norm": 12.823137283325195,
        "learning_rate": 9.016829052258637e-06,
        "epoch": 0.983170947741364,
        "step": 1110
    },
    {
        "loss": 0.5632,
        "grad_norm": 10.704500198364258,
        "learning_rate": 9.007971656333039e-06,
        "epoch": 0.9920283436669619,
        "step": 1120
    },
    {
        "eval_loss": 0.4353722333908081,
        "eval_accuracy": 0.81364,
        "eval_precision": 0.77973,
        "eval_recall": 0.8742,
        "eval_f1": 0.82427,
        "eval_runtime": 149.4403,
        "eval_samples_per_second": 60.432,
        "eval_steps_per_second": 3.781,
        "epoch": 1.0,
        "step": 1129
    },
    {
        "loss": 0.4544,
        "grad_norm": 18.390336990356445,
        "learning_rate": 8.999114260407442e-06,
        "epoch": 1.0008857395925599,
        "step": 1130
    },
    {
        "loss": 0.4142,
        "grad_norm": 14.232068061828613,
        "learning_rate": 8.990256864481844e-06,
        "epoch": 1.0097431355181576,
        "step": 1140
    },
    {
        "loss": 0.3999,
        "grad_norm": 21.581886291503906,
        "learning_rate": 8.981399468556245e-06,
        "epoch": 1.0186005314437556,
        "step": 1150
    },
    {
        "loss": 0.3419,
        "grad_norm": 11.015608787536621,
        "learning_rate": 8.972542072630648e-06,
        "epoch": 1.0274579273693534,
        "step": 1160
    },
    {
        "loss": 0.4424,
        "grad_norm": 18.829452514648438,
        "learning_rate": 8.963684676705048e-06,
        "epoch": 1.0363153232949514,
        "step": 1170
    },
    {
        "loss": 0.4098,
        "grad_norm": 14.674943923950195,
        "learning_rate": 8.954827280779452e-06,
        "epoch": 1.045172719220549,
        "step": 1180
    },
    {
        "loss": 0.476,
        "grad_norm": 21.123756408691406,
        "learning_rate": 8.945969884853853e-06,
        "epoch": 1.054030115146147,
        "step": 1190
    },
    {
        "loss": 0.3674,
        "grad_norm": 12.473572731018066,
        "learning_rate": 8.937112488928255e-06,
        "epoch": 1.0628875110717448,
        "step": 1200
    },
    {
        "loss": 0.4484,
        "grad_norm": 8.672704696655273,
        "learning_rate": 8.928255093002658e-06,
        "epoch": 1.0717449069973428,
        "step": 1210
    },
    {
        "loss": 0.444,
        "grad_norm": 14.394230842590332,
        "learning_rate": 8.91939769707706e-06,
        "epoch": 1.0806023029229406,
        "step": 1220
    },
    {
        "loss": 0.3773,
        "grad_norm": 16.028032302856445,
        "learning_rate": 8.910540301151463e-06,
        "epoch": 1.0894596988485385,
        "step": 1230
    },
    {
        "loss": 0.3477,
        "grad_norm": 9.860240936279297,
        "learning_rate": 8.901682905225865e-06,
        "epoch": 1.0983170947741363,
        "step": 1240
    },
    {
        "loss": 0.33,
        "grad_norm": 22.799184799194336,
        "learning_rate": 8.892825509300266e-06,
        "epoch": 1.1071744906997343,
        "step": 1250
    },
    {
        "loss": 0.3636,
        "grad_norm": 42.894569396972656,
        "learning_rate": 8.883968113374668e-06,
        "epoch": 1.1160318866253323,
        "step": 1260
    },
    {
        "loss": 0.5392,
        "grad_norm": 19.53249168395996,
        "learning_rate": 8.87511071744907e-06,
        "epoch": 1.12488928255093,
        "step": 1270
    },
    {
        "loss": 0.5002,
        "grad_norm": 20.076339721679688,
        "learning_rate": 8.866253321523473e-06,
        "epoch": 1.133746678476528,
        "step": 1280
    },
    {
        "loss": 0.4142,
        "grad_norm": 18.81566047668457,
        "learning_rate": 8.857395925597874e-06,
        "epoch": 1.1426040744021257,
        "step": 1290
    },
    {
        "loss": 0.3931,
        "grad_norm": 8.1345796585083,
        "learning_rate": 8.848538529672278e-06,
        "epoch": 1.1514614703277237,
        "step": 1300
    },
    {
        "loss": 0.3681,
        "grad_norm": 13.974943161010742,
        "learning_rate": 8.83968113374668e-06,
        "epoch": 1.1603188662533215,
        "step": 1310
    },
    {
        "loss": 0.3622,
        "grad_norm": 28.335763931274414,
        "learning_rate": 8.830823737821081e-06,
        "epoch": 1.1691762621789195,
        "step": 1320
    },
    {
        "loss": 0.3537,
        "grad_norm": 9.6693696975708,
        "learning_rate": 8.821966341895484e-06,
        "epoch": 1.1780336581045172,
        "step": 1330
    },
    {
        "loss": 0.3214,
        "grad_norm": 23.28993034362793,
        "learning_rate": 8.813108945969886e-06,
        "epoch": 1.1868910540301152,
        "step": 1340
    },
    {
        "loss": 0.4373,
        "grad_norm": 7.147921562194824,
        "learning_rate": 8.804251550044287e-06,
        "epoch": 1.195748449955713,
        "step": 1350
    },
    {
        "loss": 0.4033,
        "grad_norm": 18.87468719482422,
        "learning_rate": 8.795394154118689e-06,
        "epoch": 1.204605845881311,
        "step": 1360
    },
    {
        "loss": 0.3546,
        "grad_norm": 21.39678192138672,
        "learning_rate": 8.786536758193092e-06,
        "epoch": 1.2134632418069087,
        "step": 1370
    },
    {
        "loss": 0.4191,
        "grad_norm": 16.390071868896484,
        "learning_rate": 8.777679362267494e-06,
        "epoch": 1.2223206377325067,
        "step": 1380
    },
    {
        "loss": 0.3745,
        "grad_norm": 30.129756927490234,
        "learning_rate": 8.768821966341896e-06,
        "epoch": 1.2311780336581046,
        "step": 1390
    },
    {
        "loss": 0.3159,
        "grad_norm": 21.63361358642578,
        "learning_rate": 8.759964570416299e-06,
        "epoch": 1.2400354295837024,
        "step": 1400
    },
    {
        "loss": 0.3194,
        "grad_norm": 15.734905242919922,
        "learning_rate": 8.7511071744907e-06,
        "epoch": 1.2488928255093001,
        "step": 1410
    },
    {
        "loss": 0.4172,
        "grad_norm": 14.430549621582031,
        "learning_rate": 8.742249778565102e-06,
        "epoch": 1.2577502214348981,
        "step": 1420
    },
    {
        "loss": 0.3174,
        "grad_norm": 9.491251945495605,
        "learning_rate": 8.733392382639505e-06,
        "epoch": 1.266607617360496,
        "step": 1430
    },
    {
        "loss": 0.3292,
        "grad_norm": 16.175214767456055,
        "learning_rate": 8.724534986713907e-06,
        "epoch": 1.2754650132860939,
        "step": 1440
    },
    {
        "loss": 0.3267,
        "grad_norm": 36.806278228759766,
        "learning_rate": 8.715677590788309e-06,
        "epoch": 1.2843224092116918,
        "step": 1450
    },
    {
        "loss": 0.3768,
        "grad_norm": 34.8822135925293,
        "learning_rate": 8.70682019486271e-06,
        "epoch": 1.2931798051372896,
        "step": 1460
    },
    {
        "loss": 0.3844,
        "grad_norm": 9.137581825256348,
        "learning_rate": 8.697962798937114e-06,
        "epoch": 1.3020372010628876,
        "step": 1470
    },
    {
        "loss": 0.3359,
        "grad_norm": 20.417936325073242,
        "learning_rate": 8.689105403011515e-06,
        "epoch": 1.3108945969884853,
        "step": 1480
    },
    {
        "loss": 0.3256,
        "grad_norm": 5.19179630279541,
        "learning_rate": 8.680248007085917e-06,
        "epoch": 1.3197519929140833,
        "step": 1490
    },
    {
        "loss": 0.3115,
        "grad_norm": 27.581567764282227,
        "learning_rate": 8.67139061116032e-06,
        "epoch": 1.328609388839681,
        "step": 1500
    },
    {
        "loss": 0.3556,
        "grad_norm": 30.708017349243164,
        "learning_rate": 8.662533215234722e-06,
        "epoch": 1.337466784765279,
        "step": 1510
    },
    {
        "loss": 0.3594,
        "grad_norm": 12.433868408203125,
        "learning_rate": 8.653675819309125e-06,
        "epoch": 1.346324180690877,
        "step": 1520
    },
    {
        "loss": 0.4816,
        "grad_norm": 33.999977111816406,
        "learning_rate": 8.644818423383527e-06,
        "epoch": 1.3551815766164748,
        "step": 1530
    },
    {
        "loss": 0.3178,
        "grad_norm": 24.16563606262207,
        "learning_rate": 8.635961027457928e-06,
        "epoch": 1.3640389725420725,
        "step": 1540
    },
    {
        "loss": 0.3161,
        "grad_norm": 26.005239486694336,
        "learning_rate": 8.62710363153233e-06,
        "epoch": 1.3728963684676705,
        "step": 1550
    },
    {
        "loss": 0.3729,
        "grad_norm": 19.533367156982422,
        "learning_rate": 8.618246235606731e-06,
        "epoch": 1.3817537643932685,
        "step": 1560
    },
    {
        "loss": 0.3873,
        "grad_norm": 26.252960205078125,
        "learning_rate": 8.609388839681135e-06,
        "epoch": 1.3906111603188662,
        "step": 1570
    },
    {
        "loss": 0.4415,
        "grad_norm": 18.471200942993164,
        "learning_rate": 8.600531443755536e-06,
        "epoch": 1.3994685562444642,
        "step": 1580
    },
    {
        "loss": 0.379,
        "grad_norm": 14.120830535888672,
        "learning_rate": 8.591674047829938e-06,
        "epoch": 1.408325952170062,
        "step": 1590
    },
    {
        "loss": 0.3242,
        "grad_norm": 23.095935821533203,
        "learning_rate": 8.582816651904341e-06,
        "epoch": 1.41718334809566,
        "step": 1600
    },
    {
        "loss": 0.4097,
        "grad_norm": 21.44192123413086,
        "learning_rate": 8.573959255978743e-06,
        "epoch": 1.4260407440212577,
        "step": 1610
    },
    {
        "loss": 0.294,
        "grad_norm": 6.344865798950195,
        "learning_rate": 8.565101860053146e-06,
        "epoch": 1.4348981399468557,
        "step": 1620
    },
    {
        "loss": 0.249,
        "grad_norm": 10.626710891723633,
        "learning_rate": 8.556244464127548e-06,
        "epoch": 1.4437555358724534,
        "step": 1630
    },
    {
        "loss": 0.3465,
        "grad_norm": 21.708940505981445,
        "learning_rate": 8.54738706820195e-06,
        "epoch": 1.4526129317980514,
        "step": 1640
    },
    {
        "loss": 0.4069,
        "grad_norm": 9.019816398620605,
        "learning_rate": 8.538529672276351e-06,
        "epoch": 1.4614703277236494,
        "step": 1650
    },
    {
        "loss": 0.3598,
        "grad_norm": 21.223857879638672,
        "learning_rate": 8.529672276350753e-06,
        "epoch": 1.4703277236492471,
        "step": 1660
    },
    {
        "loss": 0.3641,
        "grad_norm": 9.44345760345459,
        "learning_rate": 8.520814880425156e-06,
        "epoch": 1.4791851195748449,
        "step": 1670
    },
    {
        "loss": 0.3388,
        "grad_norm": 14.145369529724121,
        "learning_rate": 8.511957484499558e-06,
        "epoch": 1.4880425155004429,
        "step": 1680
    },
    {
        "loss": 0.3136,
        "grad_norm": 26.873533248901367,
        "learning_rate": 8.50310008857396e-06,
        "epoch": 1.4968999114260408,
        "step": 1690
    },
    {
        "loss": 0.3774,
        "grad_norm": 49.74601745605469,
        "learning_rate": 8.494242692648362e-06,
        "epoch": 1.5057573073516386,
        "step": 1700
    },
    {
        "loss": 0.4257,
        "grad_norm": 19.21373176574707,
        "learning_rate": 8.485385296722764e-06,
        "epoch": 1.5146147032772364,
        "step": 1710
    },
    {
        "loss": 0.3433,
        "grad_norm": 19.855161666870117,
        "learning_rate": 8.476527900797167e-06,
        "epoch": 1.5234720992028343,
        "step": 1720
    },
    {
        "loss": 0.4208,
        "grad_norm": 20.23213768005371,
        "learning_rate": 8.467670504871567e-06,
        "epoch": 1.5323294951284323,
        "step": 1730
    },
    {
        "loss": 0.3054,
        "grad_norm": 24.036706924438477,
        "learning_rate": 8.45881310894597e-06,
        "epoch": 1.54118689105403,
        "step": 1740
    },
    {
        "loss": 0.4056,
        "grad_norm": 11.456196784973145,
        "learning_rate": 8.449955713020372e-06,
        "epoch": 1.550044286979628,
        "step": 1750
    },
    {
        "loss": 0.4297,
        "grad_norm": 15.742996215820312,
        "learning_rate": 8.441098317094775e-06,
        "epoch": 1.5589016829052258,
        "step": 1760
    },
    {
        "loss": 0.2791,
        "grad_norm": 19.286964416503906,
        "learning_rate": 8.432240921169177e-06,
        "epoch": 1.5677590788308238,
        "step": 1770
    },
    {
        "loss": 0.2924,
        "grad_norm": 8.146890640258789,
        "learning_rate": 8.423383525243579e-06,
        "epoch": 1.5766164747564217,
        "step": 1780
    },
    {
        "loss": 0.2398,
        "grad_norm": 8.414904594421387,
        "learning_rate": 8.414526129317982e-06,
        "epoch": 1.5854738706820195,
        "step": 1790
    },
    {
        "loss": 0.2933,
        "grad_norm": 11.836139678955078,
        "learning_rate": 8.405668733392384e-06,
        "epoch": 1.5943312666076173,
        "step": 1800
    },
    {
        "loss": 0.2297,
        "grad_norm": 18.6484317779541,
        "learning_rate": 8.396811337466785e-06,
        "epoch": 1.6031886625332152,
        "step": 1810
    },
    {
        "loss": 0.3719,
        "grad_norm": 47.116722106933594,
        "learning_rate": 8.387953941541187e-06,
        "epoch": 1.6120460584588132,
        "step": 1820
    },
    {
        "loss": 0.2816,
        "grad_norm": 11.646839141845703,
        "learning_rate": 8.37909654561559e-06,
        "epoch": 1.620903454384411,
        "step": 1830
    },
    {
        "loss": 0.4176,
        "grad_norm": 34.048377990722656,
        "learning_rate": 8.370239149689992e-06,
        "epoch": 1.6297608503100087,
        "step": 1840
    },
    {
        "loss": 0.3463,
        "grad_norm": 25.720077514648438,
        "learning_rate": 8.361381753764393e-06,
        "epoch": 1.6386182462356067,
        "step": 1850
    },
    {
        "loss": 0.3903,
        "grad_norm": 7.798325061798096,
        "learning_rate": 8.352524357838797e-06,
        "epoch": 1.6474756421612047,
        "step": 1860
    },
    {
        "loss": 0.3363,
        "grad_norm": 34.445072174072266,
        "learning_rate": 8.343666961913198e-06,
        "epoch": 1.6563330380868024,
        "step": 1870
    },
    {
        "loss": 0.2316,
        "grad_norm": 9.504859924316406,
        "learning_rate": 8.3348095659876e-06,
        "epoch": 1.6651904340124002,
        "step": 1880
    },
    {
        "loss": 0.3316,
        "grad_norm": 8.716673851013184,
        "learning_rate": 8.325952170062003e-06,
        "epoch": 1.6740478299379982,
        "step": 1890
    },
    {
        "loss": 0.4473,
        "grad_norm": 25.772193908691406,
        "learning_rate": 8.317094774136405e-06,
        "epoch": 1.6829052258635961,
        "step": 1900
    },
    {
        "loss": 0.3649,
        "grad_norm": 33.68402862548828,
        "learning_rate": 8.308237378210808e-06,
        "epoch": 1.6917626217891941,
        "step": 1910
    },
    {
        "loss": 0.2752,
        "grad_norm": 27.589508056640625,
        "learning_rate": 8.299379982285208e-06,
        "epoch": 1.7006200177147919,
        "step": 1920
    },
    {
        "loss": 0.3149,
        "grad_norm": 16.284008026123047,
        "learning_rate": 8.290522586359611e-06,
        "epoch": 1.7094774136403896,
        "step": 1930
    },
    {
        "loss": 0.218,
        "grad_norm": 29.534381866455078,
        "learning_rate": 8.281665190434013e-06,
        "epoch": 1.7183348095659876,
        "step": 1940
    },
    {
        "loss": 0.3826,
        "grad_norm": 26.732667922973633,
        "learning_rate": 8.272807794508414e-06,
        "epoch": 1.7271922054915856,
        "step": 1950
    },
    {
        "loss": 0.2985,
        "grad_norm": 42.772308349609375,
        "learning_rate": 8.263950398582818e-06,
        "epoch": 1.7360496014171833,
        "step": 1960
    },
    {
        "loss": 0.2831,
        "grad_norm": 40.54166793823242,
        "learning_rate": 8.25509300265722e-06,
        "epoch": 1.744906997342781,
        "step": 1970
    },
    {
        "loss": 0.3059,
        "grad_norm": 36.25394821166992,
        "learning_rate": 8.246235606731621e-06,
        "epoch": 1.753764393268379,
        "step": 1980
    },
    {
        "loss": 0.4011,
        "grad_norm": 50.18818283081055,
        "learning_rate": 8.237378210806024e-06,
        "epoch": 1.762621789193977,
        "step": 1990
    },
    {
        "loss": 0.3184,
        "grad_norm": 27.67878532409668,
        "learning_rate": 8.228520814880426e-06,
        "epoch": 1.7714791851195748,
        "step": 2000
    },
    {
        "loss": 0.1948,
        "grad_norm": 23.679872512817383,
        "learning_rate": 8.219663418954828e-06,
        "epoch": 1.7803365810451726,
        "step": 2010
    },
    {
        "loss": 0.2558,
        "grad_norm": 29.66109275817871,
        "learning_rate": 8.210806023029229e-06,
        "epoch": 1.7891939769707705,
        "step": 2020
    },
    {
        "loss": 0.4193,
        "grad_norm": 33.999000549316406,
        "learning_rate": 8.201948627103632e-06,
        "epoch": 1.7980513728963685,
        "step": 2030
    },
    {
        "loss": 0.1762,
        "grad_norm": 11.8630952835083,
        "learning_rate": 8.193091231178034e-06,
        "epoch": 1.8069087688219665,
        "step": 2040
    },
    {
        "loss": 0.3018,
        "grad_norm": 47.61519241333008,
        "learning_rate": 8.184233835252436e-06,
        "epoch": 1.8157661647475642,
        "step": 2050
    },
    {
        "loss": 0.3815,
        "grad_norm": 3.209712028503418,
        "learning_rate": 8.175376439326839e-06,
        "epoch": 1.824623560673162,
        "step": 2060
    },
    {
        "loss": 0.2737,
        "grad_norm": 27.214662551879883,
        "learning_rate": 8.16651904340124e-06,
        "epoch": 1.83348095659876,
        "step": 2070
    },
    {
        "loss": 0.35,
        "grad_norm": 62.62811279296875,
        "learning_rate": 8.157661647475644e-06,
        "epoch": 1.842338352524358,
        "step": 2080
    },
    {
        "loss": 0.3143,
        "grad_norm": 34.66518020629883,
        "learning_rate": 8.148804251550045e-06,
        "epoch": 1.8511957484499557,
        "step": 2090
    },
    {
        "loss": 0.2907,
        "grad_norm": 19.827699661254883,
        "learning_rate": 8.139946855624447e-06,
        "epoch": 1.8600531443755535,
        "step": 2100
    },
    {
        "loss": 0.3433,
        "grad_norm": 13.693097114562988,
        "learning_rate": 8.131089459698849e-06,
        "epoch": 1.8689105403011514,
        "step": 2110
    },
    {
        "loss": 0.1568,
        "grad_norm": 23.31781005859375,
        "learning_rate": 8.12223206377325e-06,
        "epoch": 1.8777679362267494,
        "step": 2120
    },
    {
        "loss": 0.3462,
        "grad_norm": 24.90118980407715,
        "learning_rate": 8.113374667847654e-06,
        "epoch": 1.8866253321523472,
        "step": 2130
    },
    {
        "loss": 0.3117,
        "grad_norm": 18.884023666381836,
        "learning_rate": 8.104517271922055e-06,
        "epoch": 1.895482728077945,
        "step": 2140
    },
    {
        "loss": 0.2761,
        "grad_norm": 16.535690307617188,
        "learning_rate": 8.095659875996459e-06,
        "epoch": 1.904340124003543,
        "step": 2150
    },
    {
        "loss": 0.246,
        "grad_norm": 10.743176460266113,
        "learning_rate": 8.08680248007086e-06,
        "epoch": 1.9131975199291409,
        "step": 2160
    },
    {
        "loss": 0.2759,
        "grad_norm": 12.061385154724121,
        "learning_rate": 8.077945084145262e-06,
        "epoch": 1.9220549158547389,
        "step": 2170
    },
    {
        "loss": 0.2926,
        "grad_norm": 38.96013641357422,
        "learning_rate": 8.069087688219665e-06,
        "epoch": 1.9309123117803366,
        "step": 2180
    },
    {
        "loss": 0.366,
        "grad_norm": 18.52998161315918,
        "learning_rate": 8.060230292294067e-06,
        "epoch": 1.9397697077059344,
        "step": 2190
    },
    {
        "loss": 0.243,
        "grad_norm": 10.233526229858398,
        "learning_rate": 8.051372896368468e-06,
        "epoch": 1.9486271036315324,
        "step": 2200
    },
    {
        "loss": 0.267,
        "grad_norm": 68.30561065673828,
        "learning_rate": 8.04251550044287e-06,
        "epoch": 1.9574844995571303,
        "step": 2210
    },
    {
        "loss": 0.2646,
        "grad_norm": 30.00217628479004,
        "learning_rate": 8.033658104517273e-06,
        "epoch": 1.966341895482728,
        "step": 2220
    },
    {
        "loss": 0.2304,
        "grad_norm": 50.669979095458984,
        "learning_rate": 8.024800708591675e-06,
        "epoch": 1.9751992914083258,
        "step": 2230
    },
    {
        "loss": 0.1823,
        "grad_norm": 6.716467380523682,
        "learning_rate": 8.015943312666076e-06,
        "epoch": 1.9840566873339238,
        "step": 2240
    },
    {
        "loss": 0.3626,
        "grad_norm": 21.2504940032959,
        "learning_rate": 8.00708591674048e-06,
        "epoch": 1.9929140832595218,
        "step": 2250
    },
    {
        "eval_loss": 0.2769306004047394,
        "eval_accuracy": 0.90787,
        "eval_precision": 0.89713,
        "eval_recall": 0.92137,
        "eval_f1": 0.90909,
        "eval_runtime": 149.3784,
        "eval_samples_per_second": 60.457,
        "eval_steps_per_second": 3.782,
        "epoch": 2.0,
        "step": 2258
    },
    {
        "loss": 0.4088,
        "grad_norm": 2.179448127746582,
        "learning_rate": 7.998228520814881e-06,
        "epoch": 2.0017714791851198,
        "step": 2260
    },
    {
        "loss": 0.2609,
        "grad_norm": 33.35373306274414,
        "learning_rate": 7.989371124889283e-06,
        "epoch": 2.0106288751107173,
        "step": 2270
    },
    {
        "loss": 0.3084,
        "grad_norm": 56.516902923583984,
        "learning_rate": 7.980513728963686e-06,
        "epoch": 2.0194862710363153,
        "step": 2280
    },
    {
        "loss": 0.3007,
        "grad_norm": 20.27346420288086,
        "learning_rate": 7.971656333038086e-06,
        "epoch": 2.0283436669619133,
        "step": 2290
    },
    {
        "loss": 0.2569,
        "grad_norm": 8.230806350708008,
        "learning_rate": 7.96279893711249e-06,
        "epoch": 2.0372010628875112,
        "step": 2300
    },
    {
        "loss": 0.2818,
        "grad_norm": 31.751022338867188,
        "learning_rate": 7.953941541186891e-06,
        "epoch": 2.0460584588131088,
        "step": 2310
    },
    {
        "loss": 0.2211,
        "grad_norm": 36.746299743652344,
        "learning_rate": 7.945084145261294e-06,
        "epoch": 2.0549158547387067,
        "step": 2320
    },
    {
        "loss": 0.2592,
        "grad_norm": 37.955238342285156,
        "learning_rate": 7.936226749335696e-06,
        "epoch": 2.0637732506643047,
        "step": 2330
    },
    {
        "loss": 0.3014,
        "grad_norm": 54.931541442871094,
        "learning_rate": 7.927369353410098e-06,
        "epoch": 2.0726306465899027,
        "step": 2340
    },
    {
        "loss": 0.2692,
        "grad_norm": 35.5142707824707,
        "learning_rate": 7.918511957484501e-06,
        "epoch": 2.0814880425155002,
        "step": 2350
    },
    {
        "loss": 0.2762,
        "grad_norm": 1.216334342956543,
        "learning_rate": 7.909654561558902e-06,
        "epoch": 2.090345438441098,
        "step": 2360
    },
    {
        "loss": 0.2091,
        "grad_norm": 1.1895262002944946,
        "learning_rate": 7.900797165633304e-06,
        "epoch": 2.099202834366696,
        "step": 2370
    },
    {
        "loss": 0.2405,
        "grad_norm": 42.10886001586914,
        "learning_rate": 7.891939769707706e-06,
        "epoch": 2.108060230292294,
        "step": 2380
    },
    {
        "loss": 0.2254,
        "grad_norm": 9.008217811584473,
        "learning_rate": 7.883082373782109e-06,
        "epoch": 2.116917626217892,
        "step": 2390
    },
    {
        "loss": 0.3037,
        "grad_norm": 14.302957534790039,
        "learning_rate": 7.87422497785651e-06,
        "epoch": 2.1257750221434897,
        "step": 2400
    },
    {
        "loss": 0.2881,
        "grad_norm": 27.054813385009766,
        "learning_rate": 7.865367581930912e-06,
        "epoch": 2.1346324180690877,
        "step": 2410
    },
    {
        "loss": 0.2518,
        "grad_norm": 16.473045349121094,
        "learning_rate": 7.856510186005316e-06,
        "epoch": 2.1434898139946856,
        "step": 2420
    },
    {
        "loss": 0.271,
        "grad_norm": 33.05501174926758,
        "learning_rate": 7.847652790079717e-06,
        "epoch": 2.1523472099202836,
        "step": 2430
    },
    {
        "loss": 0.238,
        "grad_norm": 10.666873931884766,
        "learning_rate": 7.838795394154119e-06,
        "epoch": 2.161204605845881,
        "step": 2440
    },
    {
        "loss": 0.3691,
        "grad_norm": 2.3550095558166504,
        "learning_rate": 7.829937998228522e-06,
        "epoch": 2.170062001771479,
        "step": 2450
    },
    {
        "loss": 0.2429,
        "grad_norm": 8.734804153442383,
        "learning_rate": 7.821080602302924e-06,
        "epoch": 2.178919397697077,
        "step": 2460
    },
    {
        "loss": 0.2195,
        "grad_norm": 15.33394718170166,
        "learning_rate": 7.812223206377327e-06,
        "epoch": 2.187776793622675,
        "step": 2470
    },
    {
        "loss": 0.2289,
        "grad_norm": 42.56144714355469,
        "learning_rate": 7.803365810451727e-06,
        "epoch": 2.1966341895482726,
        "step": 2480
    },
    {
        "loss": 0.1809,
        "grad_norm": 59.67354202270508,
        "learning_rate": 7.79450841452613e-06,
        "epoch": 2.2054915854738706,
        "step": 2490
    },
    {
        "loss": 0.3154,
        "grad_norm": 70.96051025390625,
        "learning_rate": 7.785651018600532e-06,
        "epoch": 2.2143489813994686,
        "step": 2500
    },
    {
        "loss": 0.1966,
        "grad_norm": 21.02120018005371,
        "learning_rate": 7.776793622674933e-06,
        "epoch": 2.2232063773250665,
        "step": 2510
    },
    {
        "loss": 0.4333,
        "grad_norm": 52.398948669433594,
        "learning_rate": 7.767936226749337e-06,
        "epoch": 2.2320637732506645,
        "step": 2520
    },
    {
        "loss": 0.2242,
        "grad_norm": 43.84231948852539,
        "learning_rate": 7.759078830823738e-06,
        "epoch": 2.240921169176262,
        "step": 2530
    },
    {
        "loss": 0.1272,
        "grad_norm": 42.54127883911133,
        "learning_rate": 7.750221434898142e-06,
        "epoch": 2.24977856510186,
        "step": 2540
    },
    {
        "loss": 0.2486,
        "grad_norm": 26.93767547607422,
        "learning_rate": 7.741364038972543e-06,
        "epoch": 2.258635961027458,
        "step": 2550
    },
    {
        "loss": 0.2624,
        "grad_norm": 28.99817657470703,
        "learning_rate": 7.732506643046945e-06,
        "epoch": 2.267493356953056,
        "step": 2560
    },
    {
        "loss": 0.2598,
        "grad_norm": 20.0568904876709,
        "learning_rate": 7.723649247121346e-06,
        "epoch": 2.2763507528786535,
        "step": 2570
    },
    {
        "loss": 0.1683,
        "grad_norm": 21.053468704223633,
        "learning_rate": 7.714791851195748e-06,
        "epoch": 2.2852081488042515,
        "step": 2580
    },
    {
        "loss": 0.2532,
        "grad_norm": 36.64768981933594,
        "learning_rate": 7.705934455270151e-06,
        "epoch": 2.2940655447298495,
        "step": 2590
    },
    {
        "loss": 0.2838,
        "grad_norm": 43.46635055541992,
        "learning_rate": 7.697077059344553e-06,
        "epoch": 2.3029229406554474,
        "step": 2600
    },
    {
        "loss": 0.1617,
        "grad_norm": 26.66061019897461,
        "learning_rate": 7.688219663418956e-06,
        "epoch": 2.311780336581045,
        "step": 2610
    },
    {
        "loss": 0.2156,
        "grad_norm": 4.245806694030762,
        "learning_rate": 7.679362267493358e-06,
        "epoch": 2.320637732506643,
        "step": 2620
    },
    {
        "loss": 0.2782,
        "grad_norm": 8.454327583312988,
        "learning_rate": 7.67050487156776e-06,
        "epoch": 2.329495128432241,
        "step": 2630
    },
    {
        "loss": 0.1499,
        "grad_norm": 17.513704299926758,
        "learning_rate": 7.661647475642163e-06,
        "epoch": 2.338352524357839,
        "step": 2640
    },
    {
        "loss": 0.1856,
        "grad_norm": 0.6733277440071106,
        "learning_rate": 7.652790079716564e-06,
        "epoch": 2.3472099202834364,
        "step": 2650
    },
    {
        "loss": 0.2279,
        "grad_norm": 7.597004413604736,
        "learning_rate": 7.643932683790966e-06,
        "epoch": 2.3560673162090344,
        "step": 2660
    },
    {
        "loss": 0.1704,
        "grad_norm": 47.712379455566406,
        "learning_rate": 7.635075287865368e-06,
        "epoch": 2.3649247121346324,
        "step": 2670
    },
    {
        "loss": 0.2209,
        "grad_norm": 16.59426498413086,
        "learning_rate": 7.62621789193977e-06,
        "epoch": 2.3737821080602304,
        "step": 2680
    },
    {
        "loss": 0.2666,
        "grad_norm": 16.614933013916016,
        "learning_rate": 7.6173604960141725e-06,
        "epoch": 2.3826395039858284,
        "step": 2690
    },
    {
        "loss": 0.1873,
        "grad_norm": 3.901315927505493,
        "learning_rate": 7.608503100088574e-06,
        "epoch": 2.391496899911426,
        "step": 2700
    },
    {
        "loss": 0.1809,
        "grad_norm": 15.256377220153809,
        "learning_rate": 7.599645704162977e-06,
        "epoch": 2.400354295837024,
        "step": 2710
    },
    {
        "loss": 0.2153,
        "grad_norm": 26.237539291381836,
        "learning_rate": 7.590788308237379e-06,
        "epoch": 2.409211691762622,
        "step": 2720
    },
    {
        "loss": 0.1056,
        "grad_norm": 3.1739161014556885,
        "learning_rate": 7.5819309123117815e-06,
        "epoch": 2.41806908768822,
        "step": 2730
    },
    {
        "loss": 0.2158,
        "grad_norm": 9.317971229553223,
        "learning_rate": 7.573073516386183e-06,
        "epoch": 2.4269264836138174,
        "step": 2740
    },
    {
        "loss": 0.2833,
        "grad_norm": 55.91576385498047,
        "learning_rate": 7.5642161204605856e-06,
        "epoch": 2.4357838795394153,
        "step": 2750
    },
    {
        "loss": 0.2325,
        "grad_norm": 2.935227870941162,
        "learning_rate": 7.555358724534987e-06,
        "epoch": 2.4446412754650133,
        "step": 2760
    },
    {
        "loss": 0.1546,
        "grad_norm": 4.5514631271362305,
        "learning_rate": 7.546501328609389e-06,
        "epoch": 2.4534986713906113,
        "step": 2770
    },
    {
        "loss": 0.2834,
        "grad_norm": 2.847367286682129,
        "learning_rate": 7.537643932683791e-06,
        "epoch": 2.4623560673162093,
        "step": 2780
    },
    {
        "loss": 0.222,
        "grad_norm": 4.942775249481201,
        "learning_rate": 7.528786536758194e-06,
        "epoch": 2.471213463241807,
        "step": 2790
    },
    {
        "loss": 0.3134,
        "grad_norm": 80.32074737548828,
        "learning_rate": 7.519929140832596e-06,
        "epoch": 2.4800708591674048,
        "step": 2800
    },
    {
        "loss": 0.226,
        "grad_norm": 104.91741180419922,
        "learning_rate": 7.511071744906998e-06,
        "epoch": 2.4889282550930028,
        "step": 2810
    },
    {
        "loss": 0.2363,
        "grad_norm": 36.18880081176758,
        "learning_rate": 7.5022143489814e-06,
        "epoch": 2.4977856510186003,
        "step": 2820
    },
    {
        "loss": 0.2268,
        "grad_norm": 13.434272766113281,
        "learning_rate": 7.493356953055803e-06,
        "epoch": 2.5066430469441983,
        "step": 2830
    },
    {
        "loss": 0.2758,
        "grad_norm": 1.9224332571029663,
        "learning_rate": 7.484499557130205e-06,
        "epoch": 2.5155004428697962,
        "step": 2840
    },
    {
        "loss": 0.216,
        "grad_norm": 5.732517719268799,
        "learning_rate": 7.475642161204606e-06,
        "epoch": 2.524357838795394,
        "step": 2850
    },
    {
        "loss": 0.2102,
        "grad_norm": 20.97612762451172,
        "learning_rate": 7.466784765279008e-06,
        "epoch": 2.533215234720992,
        "step": 2860
    },
    {
        "loss": 0.1909,
        "grad_norm": 0.600195586681366,
        "learning_rate": 7.457927369353411e-06,
        "epoch": 2.54207263064659,
        "step": 2870
    },
    {
        "loss": 0.1933,
        "grad_norm": 1.4519057273864746,
        "learning_rate": 7.449069973427812e-06,
        "epoch": 2.5509300265721877,
        "step": 2880
    },
    {
        "loss": 0.219,
        "grad_norm": 80.14388275146484,
        "learning_rate": 7.440212577502215e-06,
        "epoch": 2.5597874224977857,
        "step": 2890
    },
    {
        "loss": 0.2342,
        "grad_norm": 15.97203254699707,
        "learning_rate": 7.431355181576617e-06,
        "epoch": 2.5686448184233837,
        "step": 2900
    },
    {
        "loss": 0.2515,
        "grad_norm": 5.275374412536621,
        "learning_rate": 7.42249778565102e-06,
        "epoch": 2.577502214348981,
        "step": 2910
    },
    {
        "loss": 0.2577,
        "grad_norm": 97.07821655273438,
        "learning_rate": 7.413640389725421e-06,
        "epoch": 2.586359610274579,
        "step": 2920
    },
    {
        "loss": 0.3259,
        "grad_norm": 0.6283441185951233,
        "learning_rate": 7.404782993799824e-06,
        "epoch": 2.595217006200177,
        "step": 2930
    },
    {
        "loss": 0.174,
        "grad_norm": 122.9281234741211,
        "learning_rate": 7.3959255978742254e-06,
        "epoch": 2.604074402125775,
        "step": 2940
    },
    {
        "loss": 0.1254,
        "grad_norm": 15.89062786102295,
        "learning_rate": 7.387068201948627e-06,
        "epoch": 2.612931798051373,
        "step": 2950
    },
    {
        "loss": 0.2561,
        "grad_norm": 0.4999818503856659,
        "learning_rate": 7.3782108060230295e-06,
        "epoch": 2.6217891939769706,
        "step": 2960
    },
    {
        "loss": 0.2054,
        "grad_norm": 71.98792266845703,
        "learning_rate": 7.369353410097432e-06,
        "epoch": 2.6306465899025686,
        "step": 2970
    },
    {
        "loss": 0.1832,
        "grad_norm": 58.72222137451172,
        "learning_rate": 7.3604960141718344e-06,
        "epoch": 2.6395039858281666,
        "step": 2980
    },
    {
        "loss": 0.2646,
        "grad_norm": 38.4769287109375,
        "learning_rate": 7.351638618246236e-06,
        "epoch": 2.648361381753764,
        "step": 2990
    },
    {
        "loss": 0.2109,
        "grad_norm": 50.320953369140625,
        "learning_rate": 7.3427812223206385e-06,
        "epoch": 2.657218777679362,
        "step": 3000
    },
    {
        "loss": 0.2118,
        "grad_norm": 19.337474822998047,
        "learning_rate": 7.333923826395041e-06,
        "epoch": 2.66607617360496,
        "step": 3010
    },
    {
        "loss": 0.1674,
        "grad_norm": 16.273141860961914,
        "learning_rate": 7.325066430469443e-06,
        "epoch": 2.674933569530558,
        "step": 3020
    },
    {
        "loss": 0.1208,
        "grad_norm": 133.9876708984375,
        "learning_rate": 7.316209034543845e-06,
        "epoch": 2.683790965456156,
        "step": 3030
    },
    {
        "loss": 0.2413,
        "grad_norm": 12.450519561767578,
        "learning_rate": 7.307351638618247e-06,
        "epoch": 2.692648361381754,
        "step": 3040
    },
    {
        "loss": 0.2007,
        "grad_norm": 0.6509511470794678,
        "learning_rate": 7.298494242692648e-06,
        "epoch": 2.7015057573073515,
        "step": 3050
    },
    {
        "loss": 0.2899,
        "grad_norm": 21.76144790649414,
        "learning_rate": 7.289636846767051e-06,
        "epoch": 2.7103631532329495,
        "step": 3060
    },
    {
        "loss": 0.3026,
        "grad_norm": 10.320475578308105,
        "learning_rate": 7.280779450841453e-06,
        "epoch": 2.7192205491585475,
        "step": 3070
    },
    {
        "loss": 0.3978,
        "grad_norm": 42.677764892578125,
        "learning_rate": 7.271922054915856e-06,
        "epoch": 2.728077945084145,
        "step": 3080
    },
    {
        "loss": 0.2398,
        "grad_norm": 10.148332595825195,
        "learning_rate": 7.263064658990257e-06,
        "epoch": 2.736935341009743,
        "step": 3090
    },
    {
        "loss": 0.3236,
        "grad_norm": 64.23712921142578,
        "learning_rate": 7.25420726306466e-06,
        "epoch": 2.745792736935341,
        "step": 3100
    },
    {
        "loss": 0.1477,
        "grad_norm": 37.99022674560547,
        "learning_rate": 7.245349867139062e-06,
        "epoch": 2.754650132860939,
        "step": 3110
    },
    {
        "loss": 0.182,
        "grad_norm": 0.7446505427360535,
        "learning_rate": 7.2364924712134646e-06,
        "epoch": 2.763507528786537,
        "step": 3120
    },
    {
        "loss": 0.2392,
        "grad_norm": 24.71009635925293,
        "learning_rate": 7.227635075287865e-06,
        "epoch": 2.7723649247121345,
        "step": 3130
    },
    {
        "loss": 0.1601,
        "grad_norm": 16.11737632751465,
        "learning_rate": 7.218777679362268e-06,
        "epoch": 2.7812223206377324,
        "step": 3140
    },
    {
        "loss": 0.1587,
        "grad_norm": 97.36195373535156,
        "learning_rate": 7.20992028343667e-06,
        "epoch": 2.7900797165633304,
        "step": 3150
    },
    {
        "loss": 0.1438,
        "grad_norm": 48.63913345336914,
        "learning_rate": 7.201062887511072e-06,
        "epoch": 2.7989371124889284,
        "step": 3160
    },
    {
        "loss": 0.235,
        "grad_norm": 3.826239585876465,
        "learning_rate": 7.192205491585474e-06,
        "epoch": 2.807794508414526,
        "step": 3170
    },
    {
        "loss": 0.2202,
        "grad_norm": 67.70631408691406,
        "learning_rate": 7.183348095659877e-06,
        "epoch": 2.816651904340124,
        "step": 3180
    },
    {
        "loss": 0.1329,
        "grad_norm": 1.2979916334152222,
        "learning_rate": 7.174490699734279e-06,
        "epoch": 2.825509300265722,
        "step": 3190
    },
    {
        "loss": 0.1511,
        "grad_norm": 3.772617816925049,
        "learning_rate": 7.165633303808681e-06,
        "epoch": 2.83436669619132,
        "step": 3200
    },
    {
        "loss": 0.2986,
        "grad_norm": 100.23299407958984,
        "learning_rate": 7.156775907883083e-06,
        "epoch": 2.843224092116918,
        "step": 3210
    },
    {
        "loss": 0.1803,
        "grad_norm": 76.90691375732422,
        "learning_rate": 7.147918511957485e-06,
        "epoch": 2.8520814880425154,
        "step": 3220
    },
    {
        "loss": 0.1935,
        "grad_norm": 43.816776275634766,
        "learning_rate": 7.1390611160318865e-06,
        "epoch": 2.8609388839681134,
        "step": 3230
    },
    {
        "loss": 0.2878,
        "grad_norm": 9.803905487060547,
        "learning_rate": 7.130203720106289e-06,
        "epoch": 2.8697962798937113,
        "step": 3240
    },
    {
        "loss": 0.1325,
        "grad_norm": 0.8705064058303833,
        "learning_rate": 7.121346324180691e-06,
        "epoch": 2.878653675819309,
        "step": 3250
    },
    {
        "loss": 0.2325,
        "grad_norm": 23.931177139282227,
        "learning_rate": 7.112488928255094e-06,
        "epoch": 2.887511071744907,
        "step": 3260
    },
    {
        "loss": 0.3377,
        "grad_norm": 66.96507263183594,
        "learning_rate": 7.1036315323294955e-06,
        "epoch": 2.896368467670505,
        "step": 3270
    },
    {
        "loss": 0.1921,
        "grad_norm": 54.064125061035156,
        "learning_rate": 7.094774136403898e-06,
        "epoch": 2.905225863596103,
        "step": 3280
    },
    {
        "loss": 0.238,
        "grad_norm": 58.99517822265625,
        "learning_rate": 7.0859167404783e-06,
        "epoch": 2.9140832595217008,
        "step": 3290
    },
    {
        "loss": 0.1641,
        "grad_norm": 0.2931581437587738,
        "learning_rate": 7.077059344552703e-06,
        "epoch": 2.9229406554472988,
        "step": 3300
    },
    {
        "loss": 0.1347,
        "grad_norm": 33.59416961669922,
        "learning_rate": 7.0682019486271045e-06,
        "epoch": 2.9317980513728963,
        "step": 3310
    },
    {
        "loss": 0.1712,
        "grad_norm": 95.2741928100586,
        "learning_rate": 7.059344552701506e-06,
        "epoch": 2.9406554472984943,
        "step": 3320
    },
    {
        "loss": 0.2527,
        "grad_norm": 84.51664733886719,
        "learning_rate": 7.0504871567759085e-06,
        "epoch": 2.9495128432240922,
        "step": 3330
    },
    {
        "loss": 0.2397,
        "grad_norm": 0.9299087524414062,
        "learning_rate": 7.04162976085031e-06,
        "epoch": 2.9583702391496898,
        "step": 3340
    },
    {
        "loss": 0.1975,
        "grad_norm": 41.31637191772461,
        "learning_rate": 7.032772364924713e-06,
        "epoch": 2.9672276350752878,
        "step": 3350
    },
    {
        "loss": 0.3303,
        "grad_norm": 67.15995788574219,
        "learning_rate": 7.023914968999115e-06,
        "epoch": 2.9760850310008857,
        "step": 3360
    },
    {
        "loss": 0.3631,
        "grad_norm": 83.24510955810547,
        "learning_rate": 7.0150575730735175e-06,
        "epoch": 2.9849424269264837,
        "step": 3370
    },
    {
        "loss": 0.0855,
        "grad_norm": 20.91045570373535,
        "learning_rate": 7.006200177147919e-06,
        "epoch": 2.9937998228520817,
        "step": 3380
    },
    {
        "eval_loss": 0.22802183032035828,
        "eval_accuracy": 0.94286,
        "eval_precision": 0.95745,
        "eval_recall": 0.92691,
        "eval_f1": 0.94193,
        "eval_runtime": 149.3738,
        "eval_samples_per_second": 60.459,
        "eval_steps_per_second": 3.782,
        "epoch": 3.0,
        "step": 3387
    },
    {
        "loss": 0.1884,
        "grad_norm": 106.42798614501953,
        "learning_rate": 6.9973427812223216e-06,
        "epoch": 3.002657218777679,
        "step": 3390
    },
    {
        "loss": 0.2612,
        "grad_norm": 27.5653018951416,
        "learning_rate": 6.988485385296724e-06,
        "epoch": 3.011514614703277,
        "step": 3400
    },
    {
        "loss": 0.3115,
        "grad_norm": 104.73722076416016,
        "learning_rate": 6.979627989371125e-06,
        "epoch": 3.020372010628875,
        "step": 3410
    },
    {
        "loss": 0.1556,
        "grad_norm": 77.38762664794922,
        "learning_rate": 6.970770593445527e-06,
        "epoch": 3.029229406554473,
        "step": 3420
    },
    {
        "loss": 0.2294,
        "grad_norm": 19.44259262084961,
        "learning_rate": 6.96191319751993e-06,
        "epoch": 3.0380868024800707,
        "step": 3430
    },
    {
        "loss": 0.0988,
        "grad_norm": 0.35368016362190247,
        "learning_rate": 6.953055801594331e-06,
        "epoch": 3.0469441984056687,
        "step": 3440
    },
    {
        "loss": 0.0445,
        "grad_norm": 48.83659362792969,
        "learning_rate": 6.944198405668734e-06,
        "epoch": 3.0558015943312666,
        "step": 3450
    },
    {
        "loss": 0.241,
        "grad_norm": 21.573579788208008,
        "learning_rate": 6.935341009743136e-06,
        "epoch": 3.0646589902568646,
        "step": 3460
    },
    {
        "loss": 0.1391,
        "grad_norm": 0.23710671067237854,
        "learning_rate": 6.926483613817539e-06,
        "epoch": 3.073516386182462,
        "step": 3470
    },
    {
        "loss": 0.2362,
        "grad_norm": 96.75737762451172,
        "learning_rate": 6.91762621789194e-06,
        "epoch": 3.08237378210806,
        "step": 3480
    },
    {
        "loss": 0.1903,
        "grad_norm": 10.505088806152344,
        "learning_rate": 6.908768821966343e-06,
        "epoch": 3.091231178033658,
        "step": 3490
    },
    {
        "loss": 0.1661,
        "grad_norm": 7.083829402923584,
        "learning_rate": 6.899911426040744e-06,
        "epoch": 3.100088573959256,
        "step": 3500
    },
    {
        "loss": 0.152,
        "grad_norm": 45.54922103881836,
        "learning_rate": 6.891054030115146e-06,
        "epoch": 3.108945969884854,
        "step": 3510
    },
    {
        "loss": 0.158,
        "grad_norm": 2.3378522396087646,
        "learning_rate": 6.882196634189548e-06,
        "epoch": 3.1178033658104516,
        "step": 3520
    },
    {
        "loss": 0.1206,
        "grad_norm": 37.07395553588867,
        "learning_rate": 6.873339238263951e-06,
        "epoch": 3.1266607617360496,
        "step": 3530
    },
    {
        "loss": 0.1799,
        "grad_norm": 0.9372049570083618,
        "learning_rate": 6.864481842338353e-06,
        "epoch": 3.1355181576616475,
        "step": 3540
    },
    {
        "loss": 0.0785,
        "grad_norm": 34.984962463378906,
        "learning_rate": 6.855624446412755e-06,
        "epoch": 3.1443755535872455,
        "step": 3550
    },
    {
        "loss": 0.322,
        "grad_norm": 31.09950828552246,
        "learning_rate": 6.846767050487157e-06,
        "epoch": 3.153232949512843,
        "step": 3560
    },
    {
        "loss": 0.1763,
        "grad_norm": 68.25764465332031,
        "learning_rate": 6.83790965456156e-06,
        "epoch": 3.162090345438441,
        "step": 3570
    },
    {
        "loss": 0.1462,
        "grad_norm": 47.79610061645508,
        "learning_rate": 6.829052258635962e-06,
        "epoch": 3.170947741364039,
        "step": 3580
    },
    {
        "loss": 0.119,
        "grad_norm": 15.096534729003906,
        "learning_rate": 6.820194862710364e-06,
        "epoch": 3.179805137289637,
        "step": 3590
    },
    {
        "loss": 0.2004,
        "grad_norm": 4.692605018615723,
        "learning_rate": 6.8113374667847655e-06,
        "epoch": 3.1886625332152345,
        "step": 3600
    },
    {
        "loss": 0.1162,
        "grad_norm": 30.987510681152344,
        "learning_rate": 6.802480070859168e-06,
        "epoch": 3.1975199291408325,
        "step": 3610
    },
    {
        "loss": 0.1563,
        "grad_norm": 2.6080985069274902,
        "learning_rate": 6.79362267493357e-06,
        "epoch": 3.2063773250664305,
        "step": 3620
    },
    {
        "loss": 0.2399,
        "grad_norm": 13.88755989074707,
        "learning_rate": 6.784765279007972e-06,
        "epoch": 3.2152347209920284,
        "step": 3630
    },
    {
        "loss": 0.1425,
        "grad_norm": 1.3903958797454834,
        "learning_rate": 6.7759078830823745e-06,
        "epoch": 3.2240921169176264,
        "step": 3640
    },
    {
        "loss": 0.07,
        "grad_norm": 57.68373489379883,
        "learning_rate": 6.767050487156777e-06,
        "epoch": 3.232949512843224,
        "step": 3650
    },
    {
        "loss": 0.0464,
        "grad_norm": 1.0558626651763916,
        "learning_rate": 6.7581930912311786e-06,
        "epoch": 3.241806908768822,
        "step": 3660
    },
    {
        "loss": 0.145,
        "grad_norm": 0.5556997656822205,
        "learning_rate": 6.749335695305581e-06,
        "epoch": 3.25066430469442,
        "step": 3670
    },
    {
        "loss": 0.1292,
        "grad_norm": 0.2176193743944168,
        "learning_rate": 6.7404782993799835e-06,
        "epoch": 3.259521700620018,
        "step": 3680
    },
    {
        "loss": 0.146,
        "grad_norm": 70.21179962158203,
        "learning_rate": 6.731620903454384e-06,
        "epoch": 3.2683790965456154,
        "step": 3690
    },
    {
        "loss": 0.1524,
        "grad_norm": 106.80039978027344,
        "learning_rate": 6.722763507528787e-06,
        "epoch": 3.2772364924712134,
        "step": 3700
    },
    {
        "loss": 0.1979,
        "grad_norm": 13.250212669372559,
        "learning_rate": 6.713906111603189e-06,
        "epoch": 3.2860938883968114,
        "step": 3710
    },
    {
        "loss": 0.1759,
        "grad_norm": 29.297704696655273,
        "learning_rate": 6.705048715677592e-06,
        "epoch": 3.2949512843224094,
        "step": 3720
    },
    {
        "loss": 0.1871,
        "grad_norm": 0.1965734213590622,
        "learning_rate": 6.696191319751993e-06,
        "epoch": 3.3038086802480073,
        "step": 3730
    },
    {
        "loss": 0.1911,
        "grad_norm": 2.277627944946289,
        "learning_rate": 6.687333923826396e-06,
        "epoch": 3.312666076173605,
        "step": 3740
    },
    {
        "loss": 0.1595,
        "grad_norm": 10.065884590148926,
        "learning_rate": 6.678476527900798e-06,
        "epoch": 3.321523472099203,
        "step": 3750
    },
    {
        "loss": 0.2523,
        "grad_norm": 12.919551849365234,
        "learning_rate": 6.6696191319752006e-06,
        "epoch": 3.330380868024801,
        "step": 3760
    },
    {
        "loss": 0.0895,
        "grad_norm": 1.7124128341674805,
        "learning_rate": 6.660761736049602e-06,
        "epoch": 3.3392382639503984,
        "step": 3770
    },
    {
        "loss": 0.2024,
        "grad_norm": 0.594109296798706,
        "learning_rate": 6.651904340124004e-06,
        "epoch": 3.3480956598759963,
        "step": 3780
    },
    {
        "loss": 0.1605,
        "grad_norm": 52.51511764526367,
        "learning_rate": 6.643046944198405e-06,
        "epoch": 3.3569530558015943,
        "step": 3790
    },
    {
        "loss": 0.1447,
        "grad_norm": 1.1395703554153442,
        "learning_rate": 6.634189548272808e-06,
        "epoch": 3.3658104517271923,
        "step": 3800
    },
    {
        "loss": 0.1675,
        "grad_norm": 33.22233963012695,
        "learning_rate": 6.62533215234721e-06,
        "epoch": 3.3746678476527903,
        "step": 3810
    },
    {
        "loss": 0.2335,
        "grad_norm": 32.739662170410156,
        "learning_rate": 6.616474756421613e-06,
        "epoch": 3.383525243578388,
        "step": 3820
    },
    {
        "loss": 0.1216,
        "grad_norm": 116.5693588256836,
        "learning_rate": 6.607617360496014e-06,
        "epoch": 3.3923826395039858,
        "step": 3830
    },
    {
        "loss": 0.1487,
        "grad_norm": 80.60887908935547,
        "learning_rate": 6.598759964570417e-06,
        "epoch": 3.4012400354295838,
        "step": 3840
    },
    {
        "loss": 0.0643,
        "grad_norm": 49.39271926879883,
        "learning_rate": 6.589902568644819e-06,
        "epoch": 3.4100974313551817,
        "step": 3850
    },
    {
        "loss": 0.1358,
        "grad_norm": 118.95284271240234,
        "learning_rate": 6.581045172719222e-06,
        "epoch": 3.4189548272807793,
        "step": 3860
    },
    {
        "loss": 0.1034,
        "grad_norm": 38.695980072021484,
        "learning_rate": 6.572187776793623e-06,
        "epoch": 3.4278122232063772,
        "step": 3870
    },
    {
        "loss": 0.1905,
        "grad_norm": 91.25955963134766,
        "learning_rate": 6.563330380868025e-06,
        "epoch": 3.436669619131975,
        "step": 3880
    },
    {
        "loss": 0.232,
        "grad_norm": 9.229475975036621,
        "learning_rate": 6.554472984942427e-06,
        "epoch": 3.445527015057573,
        "step": 3890
    },
    {
        "loss": 0.1568,
        "grad_norm": 60.66343307495117,
        "learning_rate": 6.545615589016829e-06,
        "epoch": 3.454384410983171,
        "step": 3900
    },
    {
        "loss": 0.2187,
        "grad_norm": 2.269599199295044,
        "learning_rate": 6.5367581930912315e-06,
        "epoch": 3.4632418069087687,
        "step": 3910
    },
    {
        "loss": 0.149,
        "grad_norm": 5.851286888122559,
        "learning_rate": 6.527900797165634e-06,
        "epoch": 3.4720992028343667,
        "step": 3920
    },
    {
        "loss": 0.1535,
        "grad_norm": 0.34226685762405396,
        "learning_rate": 6.519043401240036e-06,
        "epoch": 3.4809565987599647,
        "step": 3930
    },
    {
        "loss": 0.2529,
        "grad_norm": 0.3140926659107208,
        "learning_rate": 6.510186005314438e-06,
        "epoch": 3.4898139946855626,
        "step": 3940
    },
    {
        "loss": 0.0922,
        "grad_norm": 6.736148834228516,
        "learning_rate": 6.5013286093888405e-06,
        "epoch": 3.49867139061116,
        "step": 3950
    },
    {
        "loss": 0.0599,
        "grad_norm": 3.862454652786255,
        "learning_rate": 6.492471213463243e-06,
        "epoch": 3.507528786536758,
        "step": 3960
    },
    {
        "loss": 0.2594,
        "grad_norm": 79.69718933105469,
        "learning_rate": 6.483613817537644e-06,
        "epoch": 3.516386182462356,
        "step": 3970
    },
    {
        "loss": 0.1988,
        "grad_norm": 23.714235305786133,
        "learning_rate": 6.474756421612046e-06,
        "epoch": 3.525243578387954,
        "step": 3980
    },
    {
        "loss": 0.2795,
        "grad_norm": 6.595916748046875,
        "learning_rate": 6.465899025686449e-06,
        "epoch": 3.534100974313552,
        "step": 3990
    },
    {
        "loss": 0.1427,
        "grad_norm": 0.20391248166561127,
        "learning_rate": 6.457041629760851e-06,
        "epoch": 3.5429583702391496,
        "step": 4000
    },
    {
        "loss": 0.1528,
        "grad_norm": 2.0458617210388184,
        "learning_rate": 6.448184233835253e-06,
        "epoch": 3.5518157661647476,
        "step": 4010
    },
    {
        "loss": 0.1302,
        "grad_norm": 4.748593330383301,
        "learning_rate": 6.439326837909655e-06,
        "epoch": 3.5606731620903456,
        "step": 4020
    },
    {
        "loss": 0.1063,
        "grad_norm": 0.300249844789505,
        "learning_rate": 6.4304694419840576e-06,
        "epoch": 3.569530558015943,
        "step": 4030
    },
    {
        "loss": 0.1916,
        "grad_norm": 25.34928321838379,
        "learning_rate": 6.42161204605846e-06,
        "epoch": 3.578387953941541,
        "step": 4040
    },
    {
        "loss": 0.2121,
        "grad_norm": 2.447007417678833,
        "learning_rate": 6.412754650132862e-06,
        "epoch": 3.587245349867139,
        "step": 4050
    },
    {
        "loss": 0.2152,
        "grad_norm": 86.83300018310547,
        "learning_rate": 6.403897254207263e-06,
        "epoch": 3.596102745792737,
        "step": 4060
    },
    {
        "loss": 0.1893,
        "grad_norm": 4.347067356109619,
        "learning_rate": 6.395039858281666e-06,
        "epoch": 3.604960141718335,
        "step": 4070
    },
    {
        "loss": 0.1907,
        "grad_norm": 2.310338258743286,
        "learning_rate": 6.386182462356067e-06,
        "epoch": 3.6138175376439325,
        "step": 4080
    },
    {
        "loss": 0.1062,
        "grad_norm": 89.22723388671875,
        "learning_rate": 6.37732506643047e-06,
        "epoch": 3.6226749335695305,
        "step": 4090
    },
    {
        "loss": 0.0928,
        "grad_norm": 38.17942810058594,
        "learning_rate": 6.368467670504872e-06,
        "epoch": 3.6315323294951285,
        "step": 4100
    },
    {
        "loss": 0.1268,
        "grad_norm": 7.882325649261475,
        "learning_rate": 6.359610274579275e-06,
        "epoch": 3.640389725420726,
        "step": 4110
    },
    {
        "loss": 0.1077,
        "grad_norm": 75.19005584716797,
        "learning_rate": 6.350752878653676e-06,
        "epoch": 3.649247121346324,
        "step": 4120
    },
    {
        "loss": 0.0719,
        "grad_norm": 0.9587758779525757,
        "learning_rate": 6.341895482728079e-06,
        "epoch": 3.658104517271922,
        "step": 4130
    },
    {
        "loss": 0.083,
        "grad_norm": 98.63428497314453,
        "learning_rate": 6.333038086802481e-06,
        "epoch": 3.66696191319752,
        "step": 4140
    },
    {
        "loss": 0.1583,
        "grad_norm": 0.7789375185966492,
        "learning_rate": 6.324180690876884e-06,
        "epoch": 3.675819309123118,
        "step": 4150
    },
    {
        "loss": 0.1466,
        "grad_norm": 0.5450875163078308,
        "learning_rate": 6.315323294951284e-06,
        "epoch": 3.684676705048716,
        "step": 4160
    },
    {
        "loss": 0.1666,
        "grad_norm": 137.2277374267578,
        "learning_rate": 6.306465899025687e-06,
        "epoch": 3.6935341009743134,
        "step": 4170
    },
    {
        "loss": 0.2107,
        "grad_norm": 13.920355796813965,
        "learning_rate": 6.2976085031000885e-06,
        "epoch": 3.7023914968999114,
        "step": 4180
    },
    {
        "loss": 0.4592,
        "grad_norm": 12.09156608581543,
        "learning_rate": 6.288751107174491e-06,
        "epoch": 3.7112488928255094,
        "step": 4190
    },
    {
        "loss": 0.1923,
        "grad_norm": 44.57734680175781,
        "learning_rate": 6.279893711248893e-06,
        "epoch": 3.720106288751107,
        "step": 4200
    },
    {
        "loss": 0.2333,
        "grad_norm": 2.371908664703369,
        "learning_rate": 6.271036315323296e-06,
        "epoch": 3.728963684676705,
        "step": 4210
    },
    {
        "loss": 0.0811,
        "grad_norm": 43.54026794433594,
        "learning_rate": 6.2621789193976975e-06,
        "epoch": 3.737821080602303,
        "step": 4220
    },
    {
        "loss": 0.1308,
        "grad_norm": 3.6416385173797607,
        "learning_rate": 6.2533215234721e-06,
        "epoch": 3.746678476527901,
        "step": 4230
    },
    {
        "loss": 0.178,
        "grad_norm": 26.771106719970703,
        "learning_rate": 6.244464127546502e-06,
        "epoch": 3.755535872453499,
        "step": 4240
    },
    {
        "loss": 0.0575,
        "grad_norm": 70.12556457519531,
        "learning_rate": 6.235606731620903e-06,
        "epoch": 3.7643932683790964,
        "step": 4250
    },
    {
        "loss": 0.1248,
        "grad_norm": 68.88994598388672,
        "learning_rate": 6.226749335695306e-06,
        "epoch": 3.7732506643046944,
        "step": 4260
    },
    {
        "loss": 0.1098,
        "grad_norm": 40.113224029541016,
        "learning_rate": 6.217891939769708e-06,
        "epoch": 3.7821080602302923,
        "step": 4270
    },
    {
        "loss": 0.0909,
        "grad_norm": 0.5912174582481384,
        "learning_rate": 6.2090345438441105e-06,
        "epoch": 3.7909654561558903,
        "step": 4280
    },
    {
        "loss": 0.0822,
        "grad_norm": 0.2711566686630249,
        "learning_rate": 6.200177147918512e-06,
        "epoch": 3.799822852081488,
        "step": 4290
    },
    {
        "loss": 0.1789,
        "grad_norm": 0.4704367518424988,
        "learning_rate": 6.1913197519929146e-06,
        "epoch": 3.808680248007086,
        "step": 4300
    },
    {
        "loss": 0.1991,
        "grad_norm": 5.5872297286987305,
        "learning_rate": 6.182462356067317e-06,
        "epoch": 3.817537643932684,
        "step": 4310
    },
    {
        "loss": 0.1789,
        "grad_norm": 150.0034942626953,
        "learning_rate": 6.1736049601417195e-06,
        "epoch": 3.8263950398582818,
        "step": 4320
    },
    {
        "loss": 0.1204,
        "grad_norm": 110.68872833251953,
        "learning_rate": 6.164747564216121e-06,
        "epoch": 3.8352524357838798,
        "step": 4330
    },
    {
        "loss": 0.1035,
        "grad_norm": 6.7887983322143555,
        "learning_rate": 6.155890168290523e-06,
        "epoch": 3.8441098317094773,
        "step": 4340
    },
    {
        "loss": 0.0744,
        "grad_norm": 4.717626094818115,
        "learning_rate": 6.147032772364925e-06,
        "epoch": 3.8529672276350753,
        "step": 4350
    },
    {
        "loss": 0.1707,
        "grad_norm": 49.302852630615234,
        "learning_rate": 6.138175376439327e-06,
        "epoch": 3.8618246235606732,
        "step": 4360
    },
    {
        "loss": 0.1663,
        "grad_norm": 45.50508499145508,
        "learning_rate": 6.129317980513729e-06,
        "epoch": 3.8706820194862708,
        "step": 4370
    },
    {
        "loss": 0.1418,
        "grad_norm": 92.49937438964844,
        "learning_rate": 6.120460584588132e-06,
        "epoch": 3.8795394154118688,
        "step": 4380
    },
    {
        "loss": 0.1901,
        "grad_norm": 79.87691497802734,
        "learning_rate": 6.111603188662534e-06,
        "epoch": 3.8883968113374667,
        "step": 4390
    },
    {
        "loss": 0.1962,
        "grad_norm": 8.453012466430664,
        "learning_rate": 6.102745792736936e-06,
        "epoch": 3.8972542072630647,
        "step": 4400
    },
    {
        "loss": 0.1811,
        "grad_norm": 11.135102272033691,
        "learning_rate": 6.093888396811338e-06,
        "epoch": 3.9061116031886627,
        "step": 4410
    },
    {
        "loss": 0.1673,
        "grad_norm": 177.9035186767578,
        "learning_rate": 6.085031000885741e-06,
        "epoch": 3.9149689991142607,
        "step": 4420
    },
    {
        "loss": 0.0991,
        "grad_norm": 9.59280014038086,
        "learning_rate": 6.076173604960143e-06,
        "epoch": 3.923826395039858,
        "step": 4430
    },
    {
        "loss": 0.1035,
        "grad_norm": 0.49354448914527893,
        "learning_rate": 6.067316209034544e-06,
        "epoch": 3.932683790965456,
        "step": 4440
    },
    {
        "loss": 0.1444,
        "grad_norm": 28.982776641845703,
        "learning_rate": 6.058458813108946e-06,
        "epoch": 3.941541186891054,
        "step": 4450
    },
    {
        "loss": 0.0507,
        "grad_norm": 0.4433284103870392,
        "learning_rate": 6.049601417183349e-06,
        "epoch": 3.9503985828166517,
        "step": 4460
    },
    {
        "loss": 0.1366,
        "grad_norm": 88.1513442993164,
        "learning_rate": 6.04074402125775e-06,
        "epoch": 3.9592559787422497,
        "step": 4470
    },
    {
        "loss": 0.2361,
        "grad_norm": 100.7158203125,
        "learning_rate": 6.031886625332153e-06,
        "epoch": 3.9681133746678476,
        "step": 4480
    },
    {
        "loss": 0.19,
        "grad_norm": 15.233728408813477,
        "learning_rate": 6.023029229406555e-06,
        "epoch": 3.9769707705934456,
        "step": 4490
    },
    {
        "loss": 0.0564,
        "grad_norm": 44.99626541137695,
        "learning_rate": 6.014171833480958e-06,
        "epoch": 3.9858281665190436,
        "step": 4500
    },
    {
        "loss": 0.1376,
        "grad_norm": 0.16235335171222687,
        "learning_rate": 6.005314437555359e-06,
        "epoch": 3.994685562444641,
        "step": 4510
    },
    {
        "eval_loss": 0.1773354858160019,
        "eval_accuracy": 0.96191,
        "eval_precision": 0.97024,
        "eval_recall": 0.95305,
        "eval_f1": 0.96156,
        "eval_runtime": 149.3936,
        "eval_samples_per_second": 60.451,
        "eval_steps_per_second": 3.782,
        "epoch": 4.0,
        "step": 4516
    },
    {
        "loss": 0.0748,
        "grad_norm": 0.9342439770698547,
        "learning_rate": 5.996457041629762e-06,
        "epoch": 4.0035429583702395,
        "step": 4520
    },
    {
        "loss": 0.1989,
        "grad_norm": 16.94403648376465,
        "learning_rate": 5.9875996457041626e-06,
        "epoch": 4.012400354295837,
        "step": 4530
    },
    {
        "loss": 0.0644,
        "grad_norm": 2.048762083053589,
        "learning_rate": 5.978742249778565e-06,
        "epoch": 4.021257750221435,
        "step": 4540
    },
    {
        "loss": 0.1756,
        "grad_norm": 69.71589660644531,
        "learning_rate": 5.9698848538529675e-06,
        "epoch": 4.030115146147033,
        "step": 4550
    },
    {
        "loss": 0.1634,
        "grad_norm": 163.82577514648438,
        "learning_rate": 5.96102745792737e-06,
        "epoch": 4.038972542072631,
        "step": 4560
    },
    {
        "loss": 0.1261,
        "grad_norm": 0.08761096745729446,
        "learning_rate": 5.9521700620017716e-06,
        "epoch": 4.0478299379982285,
        "step": 4570
    },
    {
        "loss": 0.1235,
        "grad_norm": 23.11001968383789,
        "learning_rate": 5.943312666076174e-06,
        "epoch": 4.0566873339238265,
        "step": 4580
    },
    {
        "loss": 0.1036,
        "grad_norm": 33.505165100097656,
        "learning_rate": 5.9344552701505765e-06,
        "epoch": 4.0655447298494245,
        "step": 4590
    },
    {
        "loss": 0.0704,
        "grad_norm": 127.65596008300781,
        "learning_rate": 5.925597874224979e-06,
        "epoch": 4.0744021257750225,
        "step": 4600
    },
    {
        "loss": 0.1536,
        "grad_norm": 19.18858528137207,
        "learning_rate": 5.9167404782993805e-06,
        "epoch": 4.0832595217006205,
        "step": 4610
    },
    {
        "loss": 0.1488,
        "grad_norm": 113.66849517822266,
        "learning_rate": 5.907883082373782e-06,
        "epoch": 4.0921169176262175,
        "step": 4620
    },
    {
        "loss": 0.1362,
        "grad_norm": 0.1310046911239624,
        "learning_rate": 5.899025686448185e-06,
        "epoch": 4.1009743135518155,
        "step": 4630
    },
    {
        "loss": 0.1327,
        "grad_norm": 0.34588998556137085,
        "learning_rate": 5.890168290522586e-06,
        "epoch": 4.1098317094774135,
        "step": 4640
    },
    {
        "loss": 0.0879,
        "grad_norm": 0.41004717350006104,
        "learning_rate": 5.881310894596989e-06,
        "epoch": 4.1186891054030115,
        "step": 4650
    },
    {
        "loss": 0.063,
        "grad_norm": 0.12366487830877304,
        "learning_rate": 5.872453498671391e-06,
        "epoch": 4.1275465013286095,
        "step": 4660
    },
    {
        "loss": 0.1297,
        "grad_norm": 1.1145888566970825,
        "learning_rate": 5.8635961027457936e-06,
        "epoch": 4.136403897254207,
        "step": 4670
    },
    {
        "loss": 0.0723,
        "grad_norm": 2.4131782054901123,
        "learning_rate": 5.854738706820195e-06,
        "epoch": 4.145261293179805,
        "step": 4680
    },
    {
        "loss": 0.1002,
        "grad_norm": 0.11448079347610474,
        "learning_rate": 5.845881310894598e-06,
        "epoch": 4.154118689105403,
        "step": 4690
    },
    {
        "loss": 0.0792,
        "grad_norm": 51.92483901977539,
        "learning_rate": 5.837023914969e-06,
        "epoch": 4.1629760850310005,
        "step": 4700
    },
    {
        "loss": 0.1288,
        "grad_norm": 0.2499377429485321,
        "learning_rate": 5.8281665190434025e-06,
        "epoch": 4.1718334809565985,
        "step": 4710
    },
    {
        "loss": 0.126,
        "grad_norm": 0.2631833553314209,
        "learning_rate": 5.819309123117803e-06,
        "epoch": 4.180690876882196,
        "step": 4720
    },
    {
        "loss": 0.0714,
        "grad_norm": 0.4416907727718353,
        "learning_rate": 5.810451727192206e-06,
        "epoch": 4.189548272807794,
        "step": 4730
    },
    {
        "loss": 0.1318,
        "grad_norm": 0.11284666508436203,
        "learning_rate": 5.801594331266608e-06,
        "epoch": 4.198405668733392,
        "step": 4740
    },
    {
        "loss": 0.0086,
        "grad_norm": 2.798921585083008,
        "learning_rate": 5.79273693534101e-06,
        "epoch": 4.20726306465899,
        "step": 4750
    },
    {
        "loss": 0.1126,
        "grad_norm": 2.6548256874084473,
        "learning_rate": 5.783879539415412e-06,
        "epoch": 4.216120460584588,
        "step": 4760
    },
    {
        "loss": 0.1443,
        "grad_norm": 135.8673858642578,
        "learning_rate": 5.775022143489815e-06,
        "epoch": 4.224977856510186,
        "step": 4770
    },
    {
        "loss": 0.0958,
        "grad_norm": 0.1491251438856125,
        "learning_rate": 5.766164747564217e-06,
        "epoch": 4.233835252435784,
        "step": 4780
    },
    {
        "loss": 0.2223,
        "grad_norm": 0.12779220938682556,
        "learning_rate": 5.757307351638619e-06,
        "epoch": 4.242692648361381,
        "step": 4790
    },
    {
        "loss": 0.1386,
        "grad_norm": 0.48972707986831665,
        "learning_rate": 5.748449955713021e-06,
        "epoch": 4.251550044286979,
        "step": 4800
    },
    {
        "loss": 0.0906,
        "grad_norm": 84.66105651855469,
        "learning_rate": 5.739592559787423e-06,
        "epoch": 4.260407440212577,
        "step": 4810
    },
    {
        "loss": 0.1771,
        "grad_norm": 110.57950592041016,
        "learning_rate": 5.7307351638618245e-06,
        "epoch": 4.269264836138175,
        "step": 4820
    },
    {
        "loss": 0.0645,
        "grad_norm": 0.748072624206543,
        "learning_rate": 5.721877767936227e-06,
        "epoch": 4.278122232063773,
        "step": 4830
    },
    {
        "loss": 0.041,
        "grad_norm": 0.6213052868843079,
        "learning_rate": 5.713020372010629e-06,
        "epoch": 4.286979627989371,
        "step": 4840
    },
    {
        "loss": 0.0497,
        "grad_norm": 0.48321014642715454,
        "learning_rate": 5.704162976085032e-06,
        "epoch": 4.295837023914969,
        "step": 4850
    },
    {
        "loss": 0.12,
        "grad_norm": 10.049406051635742,
        "learning_rate": 5.6953055801594335e-06,
        "epoch": 4.304694419840567,
        "step": 4860
    },
    {
        "loss": 0.0498,
        "grad_norm": 192.16329956054688,
        "learning_rate": 5.686448184233836e-06,
        "epoch": 4.313551815766164,
        "step": 4870
    },
    {
        "loss": 0.0898,
        "grad_norm": 30.39588165283203,
        "learning_rate": 5.677590788308238e-06,
        "epoch": 4.322409211691762,
        "step": 4880
    },
    {
        "loss": 0.0732,
        "grad_norm": 11.321769714355469,
        "learning_rate": 5.668733392382641e-06,
        "epoch": 4.33126660761736,
        "step": 4890
    },
    {
        "loss": 0.1369,
        "grad_norm": 0.1711171716451645,
        "learning_rate": 5.659875996457042e-06,
        "epoch": 4.340124003542958,
        "step": 4900
    },
    {
        "loss": 0.1352,
        "grad_norm": 0.45472824573516846,
        "learning_rate": 5.651018600531444e-06,
        "epoch": 4.348981399468556,
        "step": 4910
    },
    {
        "loss": 0.097,
        "grad_norm": 0.5849374532699585,
        "learning_rate": 5.642161204605846e-06,
        "epoch": 4.357838795394154,
        "step": 4920
    },
    {
        "loss": 0.1441,
        "grad_norm": 164.27947998046875,
        "learning_rate": 5.633303808680248e-06,
        "epoch": 4.366696191319752,
        "step": 4930
    },
    {
        "loss": 0.0762,
        "grad_norm": 2.4911646842956543,
        "learning_rate": 5.6244464127546506e-06,
        "epoch": 4.37555358724535,
        "step": 4940
    },
    {
        "loss": 0.1959,
        "grad_norm": 238.0806427001953,
        "learning_rate": 5.615589016829053e-06,
        "epoch": 4.384410983170948,
        "step": 4950
    },
    {
        "loss": 0.0791,
        "grad_norm": 124.69185638427734,
        "learning_rate": 5.606731620903455e-06,
        "epoch": 4.393268379096545,
        "step": 4960
    },
    {
        "loss": 0.1675,
        "grad_norm": 0.22477076947689056,
        "learning_rate": 5.597874224977857e-06,
        "epoch": 4.402125775022143,
        "step": 4970
    },
    {
        "loss": 0.1512,
        "grad_norm": 20.519155502319336,
        "learning_rate": 5.5890168290522595e-06,
        "epoch": 4.410983170947741,
        "step": 4980
    },
    {
        "loss": 0.0968,
        "grad_norm": 105.91163635253906,
        "learning_rate": 5.580159433126662e-06,
        "epoch": 4.419840566873339,
        "step": 4990
    },
    {
        "loss": 0.0615,
        "grad_norm": 6.827337741851807,
        "learning_rate": 5.571302037201063e-06,
        "epoch": 4.428697962798937,
        "step": 5000
    },
    {
        "loss": 0.134,
        "grad_norm": 35.69393539428711,
        "learning_rate": 5.562444641275465e-06,
        "epoch": 4.437555358724535,
        "step": 5010
    },
    {
        "loss": 0.0263,
        "grad_norm": 0.2314525842666626,
        "learning_rate": 5.553587245349868e-06,
        "epoch": 4.446412754650133,
        "step": 5020
    },
    {
        "loss": 0.1138,
        "grad_norm": 92.69197082519531,
        "learning_rate": 5.544729849424269e-06,
        "epoch": 4.455270150575731,
        "step": 5030
    },
    {
        "loss": 0.0247,
        "grad_norm": 0.17448174953460693,
        "learning_rate": 5.535872453498672e-06,
        "epoch": 4.464127546501329,
        "step": 5040
    },
    {
        "loss": 0.0078,
        "grad_norm": 8.183561325073242,
        "learning_rate": 5.527015057573074e-06,
        "epoch": 4.472984942426926,
        "step": 5050
    },
    {
        "loss": 0.0355,
        "grad_norm": 79.54937744140625,
        "learning_rate": 5.518157661647477e-06,
        "epoch": 4.481842338352524,
        "step": 5060
    },
    {
        "loss": 0.0692,
        "grad_norm": 0.323495090007782,
        "learning_rate": 5.509300265721878e-06,
        "epoch": 4.490699734278122,
        "step": 5070
    },
    {
        "loss": 0.1841,
        "grad_norm": 57.34029769897461,
        "learning_rate": 5.500442869796281e-06,
        "epoch": 4.49955713020372,
        "step": 5080
    },
    {
        "loss": 0.035,
        "grad_norm": 6.085309982299805,
        "learning_rate": 5.491585473870682e-06,
        "epoch": 4.508414526129318,
        "step": 5090
    },
    {
        "loss": 0.0713,
        "grad_norm": 2.6863009929656982,
        "learning_rate": 5.482728077945084e-06,
        "epoch": 4.517271922054916,
        "step": 5100
    },
    {
        "loss": 0.0182,
        "grad_norm": 97.04618835449219,
        "learning_rate": 5.473870682019486e-06,
        "epoch": 4.526129317980514,
        "step": 5110
    },
    {
        "loss": 0.1656,
        "grad_norm": 9.01313591003418,
        "learning_rate": 5.465013286093889e-06,
        "epoch": 4.534986713906112,
        "step": 5120
    },
    {
        "loss": 0.1359,
        "grad_norm": 3.8799898624420166,
        "learning_rate": 5.456155890168291e-06,
        "epoch": 4.54384410983171,
        "step": 5130
    },
    {
        "loss": 0.2017,
        "grad_norm": 132.13473510742188,
        "learning_rate": 5.447298494242693e-06,
        "epoch": 4.552701505757307,
        "step": 5140
    },
    {
        "loss": 0.0373,
        "grad_norm": 13.565507888793945,
        "learning_rate": 5.438441098317095e-06,
        "epoch": 4.561558901682905,
        "step": 5150
    },
    {
        "loss": 0.0965,
        "grad_norm": 0.11963992565870285,
        "learning_rate": 5.429583702391498e-06,
        "epoch": 4.570416297608503,
        "step": 5160
    },
    {
        "loss": 0.0595,
        "grad_norm": 0.21344611048698425,
        "learning_rate": 5.4207263064659e-06,
        "epoch": 4.579273693534101,
        "step": 5170
    },
    {
        "loss": 0.1044,
        "grad_norm": 0.9929937720298767,
        "learning_rate": 5.411868910540301e-06,
        "epoch": 4.588131089459699,
        "step": 5180
    },
    {
        "loss": 0.1779,
        "grad_norm": 0.9981089234352112,
        "learning_rate": 5.4030115146147035e-06,
        "epoch": 4.596988485385297,
        "step": 5190
    },
    {
        "loss": 0.0866,
        "grad_norm": 4.609131336212158,
        "learning_rate": 5.394154118689106e-06,
        "epoch": 4.605845881310895,
        "step": 5200
    },
    {
        "loss": 0.0763,
        "grad_norm": 0.08373234421014786,
        "learning_rate": 5.3852967227635076e-06,
        "epoch": 4.614703277236492,
        "step": 5210
    },
    {
        "loss": 0.0679,
        "grad_norm": 55.19772720336914,
        "learning_rate": 5.37643932683791e-06,
        "epoch": 4.62356067316209,
        "step": 5220
    },
    {
        "loss": 0.0934,
        "grad_norm": 0.46451517939567566,
        "learning_rate": 5.3675819309123125e-06,
        "epoch": 4.632418069087688,
        "step": 5230
    },
    {
        "loss": 0.0398,
        "grad_norm": 1.4840171337127686,
        "learning_rate": 5.358724534986715e-06,
        "epoch": 4.641275465013286,
        "step": 5240
    },
    {
        "loss": 0.0464,
        "grad_norm": 2.6846916675567627,
        "learning_rate": 5.3498671390611165e-06,
        "epoch": 4.650132860938884,
        "step": 5250
    },
    {
        "loss": 0.1317,
        "grad_norm": 0.18248291313648224,
        "learning_rate": 5.341009743135519e-06,
        "epoch": 4.658990256864482,
        "step": 5260
    },
    {
        "loss": 0.0603,
        "grad_norm": 0.12483531981706619,
        "learning_rate": 5.3321523472099214e-06,
        "epoch": 4.66784765279008,
        "step": 5270
    },
    {
        "loss": 0.1138,
        "grad_norm": 0.08910181373357773,
        "learning_rate": 5.323294951284322e-06,
        "epoch": 4.676705048715678,
        "step": 5280
    },
    {
        "loss": 0.0049,
        "grad_norm": 0.0713653564453125,
        "learning_rate": 5.314437555358725e-06,
        "epoch": 4.685562444641276,
        "step": 5290
    },
    {
        "loss": 0.0683,
        "grad_norm": 0.14123812317848206,
        "learning_rate": 5.305580159433127e-06,
        "epoch": 4.694419840566873,
        "step": 5300
    },
    {
        "loss": 0.0716,
        "grad_norm": 81.05670166015625,
        "learning_rate": 5.296722763507529e-06,
        "epoch": 4.703277236492471,
        "step": 5310
    },
    {
        "loss": 0.0369,
        "grad_norm": 0.615740954875946,
        "learning_rate": 5.287865367581931e-06,
        "epoch": 4.712134632418069,
        "step": 5320
    },
    {
        "loss": 0.1588,
        "grad_norm": 0.07576466351747513,
        "learning_rate": 5.279007971656334e-06,
        "epoch": 4.720992028343667,
        "step": 5330
    },
    {
        "loss": 0.0721,
        "grad_norm": 2.589510202407837,
        "learning_rate": 5.270150575730736e-06,
        "epoch": 4.729849424269265,
        "step": 5340
    },
    {
        "loss": 0.2166,
        "grad_norm": 70.42252349853516,
        "learning_rate": 5.261293179805138e-06,
        "epoch": 4.738706820194863,
        "step": 5350
    },
    {
        "loss": 0.2418,
        "grad_norm": 23.783554077148438,
        "learning_rate": 5.25243578387954e-06,
        "epoch": 4.747564216120461,
        "step": 5360
    },
    {
        "loss": 0.0556,
        "grad_norm": 92.55728912353516,
        "learning_rate": 5.243578387953942e-06,
        "epoch": 4.756421612046059,
        "step": 5370
    },
    {
        "loss": 0.0845,
        "grad_norm": 191.4224853515625,
        "learning_rate": 5.234720992028343e-06,
        "epoch": 4.765279007971657,
        "step": 5380
    },
    {
        "loss": 0.1152,
        "grad_norm": 0.04877598211169243,
        "learning_rate": 5.225863596102746e-06,
        "epoch": 4.774136403897254,
        "step": 5390
    },
    {
        "loss": 0.0679,
        "grad_norm": 1.0991506576538086,
        "learning_rate": 5.217006200177148e-06,
        "epoch": 4.782993799822852,
        "step": 5400
    },
    {
        "loss": 0.0467,
        "grad_norm": 0.10809727758169174,
        "learning_rate": 5.208148804251551e-06,
        "epoch": 4.79185119574845,
        "step": 5410
    },
    {
        "loss": 0.2068,
        "grad_norm": 85.80756378173828,
        "learning_rate": 5.199291408325952e-06,
        "epoch": 4.800708591674048,
        "step": 5420
    },
    {
        "loss": 0.0519,
        "grad_norm": 2.918491840362549,
        "learning_rate": 5.190434012400355e-06,
        "epoch": 4.809565987599646,
        "step": 5430
    },
    {
        "loss": 0.1035,
        "grad_norm": 0.06866808980703354,
        "learning_rate": 5.181576616474757e-06,
        "epoch": 4.818423383525244,
        "step": 5440
    },
    {
        "loss": 0.0514,
        "grad_norm": 0.05861732363700867,
        "learning_rate": 5.17271922054916e-06,
        "epoch": 4.827280779450842,
        "step": 5450
    },
    {
        "loss": 0.157,
        "grad_norm": 160.32627868652344,
        "learning_rate": 5.1638618246235605e-06,
        "epoch": 4.83613817537644,
        "step": 5460
    },
    {
        "loss": 0.1835,
        "grad_norm": 0.0769636482000351,
        "learning_rate": 5.155004428697963e-06,
        "epoch": 4.844995571302038,
        "step": 5470
    },
    {
        "loss": 0.0302,
        "grad_norm": 64.78968048095703,
        "learning_rate": 5.146147032772365e-06,
        "epoch": 4.853852967227635,
        "step": 5480
    },
    {
        "loss": 0.0216,
        "grad_norm": 140.81967163085938,
        "learning_rate": 5.137289636846767e-06,
        "epoch": 4.862710363153233,
        "step": 5490
    },
    {
        "loss": 0.1077,
        "grad_norm": 0.12662342190742493,
        "learning_rate": 5.1284322409211695e-06,
        "epoch": 4.871567759078831,
        "step": 5500
    },
    {
        "loss": 0.1814,
        "grad_norm": 152.8526153564453,
        "learning_rate": 5.119574844995572e-06,
        "epoch": 4.880425155004429,
        "step": 5510
    },
    {
        "loss": 0.1014,
        "grad_norm": 71.58552551269531,
        "learning_rate": 5.110717449069974e-06,
        "epoch": 4.889282550930027,
        "step": 5520
    },
    {
        "loss": 0.0632,
        "grad_norm": 0.07976970076560974,
        "learning_rate": 5.101860053144376e-06,
        "epoch": 4.898139946855625,
        "step": 5530
    },
    {
        "loss": 0.0999,
        "grad_norm": 0.08817312121391296,
        "learning_rate": 5.0930026572187784e-06,
        "epoch": 4.906997342781223,
        "step": 5540
    },
    {
        "loss": 0.0991,
        "grad_norm": 0.13410767912864685,
        "learning_rate": 5.084145261293181e-06,
        "epoch": 4.9158547387068205,
        "step": 5550
    },
    {
        "loss": 0.0446,
        "grad_norm": 0.08480586856603622,
        "learning_rate": 5.075287865367582e-06,
        "epoch": 4.9247121346324185,
        "step": 5560
    },
    {
        "loss": 0.2488,
        "grad_norm": 0.0954054445028305,
        "learning_rate": 5.066430469441984e-06,
        "epoch": 4.933569530558016,
        "step": 5570
    },
    {
        "loss": 0.1413,
        "grad_norm": 69.73397827148438,
        "learning_rate": 5.0575730735163866e-06,
        "epoch": 4.942426926483614,
        "step": 5580
    },
    {
        "loss": 0.099,
        "grad_norm": 1.9567897319793701,
        "learning_rate": 5.048715677590789e-06,
        "epoch": 4.951284322409212,
        "step": 5590
    },
    {
        "loss": 0.0659,
        "grad_norm": 0.3867936432361603,
        "learning_rate": 5.039858281665191e-06,
        "epoch": 4.9601417183348095,
        "step": 5600
    },
    {
        "loss": 0.091,
        "grad_norm": 101.45223999023438,
        "learning_rate": 5.031000885739593e-06,
        "epoch": 4.9689991142604075,
        "step": 5610
    },
    {
        "loss": 0.0592,
        "grad_norm": 1.7726811170578003,
        "learning_rate": 5.0221434898139955e-06,
        "epoch": 4.9778565101860055,
        "step": 5620
    },
    {
        "loss": 0.1931,
        "grad_norm": 0.17020577192306519,
        "learning_rate": 5.013286093888398e-06,
        "epoch": 4.9867139061116035,
        "step": 5630
    },
    {
        "loss": 0.009,
        "grad_norm": 0.08071019500494003,
        "learning_rate": 5.0044286979628e-06,
        "epoch": 4.995571302037201,
        "step": 5640
    },
    {
        "eval_loss": 0.16340099275112152,
        "eval_accuracy": 0.96988,
        "eval_precision": 0.97771,
        "eval_recall": 0.96168,
        "eval_f1": 0.96963,
        "eval_runtime": 149.3464,
        "eval_samples_per_second": 60.47,
        "eval_steps_per_second": 3.783,
        "epoch": 5.0,
        "step": 5645
    },
    {
        "loss": 0.0424,
        "grad_norm": 0.0726461187005043,
        "learning_rate": 4.995571302037201e-06,
        "epoch": 5.0044286979627985,
        "step": 5650
    },
    {
        "loss": 0.1561,
        "grad_norm": 150.81182861328125,
        "learning_rate": 4.986713906111604e-06,
        "epoch": 5.0132860938883965,
        "step": 5660
    },
    {
        "loss": 0.1411,
        "grad_norm": 148.3661346435547,
        "learning_rate": 4.977856510186005e-06,
        "epoch": 5.0221434898139945,
        "step": 5670
    },
    {
        "loss": 0.0698,
        "grad_norm": 0.1095416247844696,
        "learning_rate": 4.968999114260408e-06,
        "epoch": 5.0310008857395925,
        "step": 5680
    },
    {
        "loss": 0.0912,
        "grad_norm": 26.015729904174805,
        "learning_rate": 4.96014171833481e-06,
        "epoch": 5.0398582816651905,
        "step": 5690
    },
    {
        "loss": 0.0336,
        "grad_norm": 144.4550323486328,
        "learning_rate": 4.951284322409212e-06,
        "epoch": 5.048715677590788,
        "step": 5700
    },
    {
        "loss": 0.1058,
        "grad_norm": 1.828061580657959,
        "learning_rate": 4.942426926483614e-06,
        "epoch": 5.057573073516386,
        "step": 5710
    },
    {
        "loss": 0.088,
        "grad_norm": 0.132210373878479,
        "learning_rate": 4.933569530558016e-06,
        "epoch": 5.066430469441984,
        "step": 5720
    },
    {
        "loss": 0.0464,
        "grad_norm": 30.028493881225586,
        "learning_rate": 4.924712134632418e-06,
        "epoch": 5.075287865367582,
        "step": 5730
    },
    {
        "loss": 0.0835,
        "grad_norm": 7.946247577667236,
        "learning_rate": 4.915854738706821e-06,
        "epoch": 5.0841452612931795,
        "step": 5740
    },
    {
        "loss": 0.1074,
        "grad_norm": 168.17063903808594,
        "learning_rate": 4.906997342781223e-06,
        "epoch": 5.093002657218777,
        "step": 5750
    },
    {
        "loss": 0.0953,
        "grad_norm": 0.039773885160684586,
        "learning_rate": 4.898139946855625e-06,
        "epoch": 5.101860053144375,
        "step": 5760
    },
    {
        "loss": 0.0543,
        "grad_norm": 0.10056609660387039,
        "learning_rate": 4.8892825509300264e-06,
        "epoch": 5.110717449069973,
        "step": 5770
    },
    {
        "loss": 0.006,
        "grad_norm": 0.05886806920170784,
        "learning_rate": 4.880425155004429e-06,
        "epoch": 5.119574844995571,
        "step": 5780
    },
    {
        "loss": 0.0742,
        "grad_norm": 20.240686416625977,
        "learning_rate": 4.871567759078831e-06,
        "epoch": 5.128432240921169,
        "step": 5790
    },
    {
        "loss": 0.051,
        "grad_norm": 102.22730255126953,
        "learning_rate": 4.862710363153234e-06,
        "epoch": 5.137289636846767,
        "step": 5800
    },
    {
        "loss": 0.1025,
        "grad_norm": 0.13516943156719208,
        "learning_rate": 4.8538529672276354e-06,
        "epoch": 5.146147032772365,
        "step": 5810
    },
    {
        "loss": 0.0442,
        "grad_norm": 0.10965324193239212,
        "learning_rate": 4.844995571302038e-06,
        "epoch": 5.155004428697962,
        "step": 5820
    },
    {
        "loss": 0.1206,
        "grad_norm": 29.356739044189453,
        "learning_rate": 4.8361381753764395e-06,
        "epoch": 5.16386182462356,
        "step": 5830
    },
    {
        "loss": 0.089,
        "grad_norm": 172.09243774414062,
        "learning_rate": 4.827280779450842e-06,
        "epoch": 5.172719220549158,
        "step": 5840
    },
    {
        "loss": 0.0614,
        "grad_norm": 0.06360921263694763,
        "learning_rate": 4.818423383525244e-06,
        "epoch": 5.181576616474756,
        "step": 5850
    },
    {
        "loss": 0.1239,
        "grad_norm": 0.16728562116622925,
        "learning_rate": 4.809565987599646e-06,
        "epoch": 5.190434012400354,
        "step": 5860
    },
    {
        "loss": 0.0712,
        "grad_norm": 0.07646448165178299,
        "learning_rate": 4.8007085916740485e-06,
        "epoch": 5.199291408325952,
        "step": 5870
    },
    {
        "loss": 0.1087,
        "grad_norm": 20.33504867553711,
        "learning_rate": 4.79185119574845e-06,
        "epoch": 5.20814880425155,
        "step": 5880
    },
    {
        "loss": 0.0589,
        "grad_norm": 0.07766307890415192,
        "learning_rate": 4.7829937998228525e-06,
        "epoch": 5.217006200177148,
        "step": 5890
    },
    {
        "loss": 0.0416,
        "grad_norm": 0.1847713589668274,
        "learning_rate": 4.774136403897255e-06,
        "epoch": 5.225863596102746,
        "step": 5900
    },
    {
        "loss": 0.0771,
        "grad_norm": 0.13550618290901184,
        "learning_rate": 4.765279007971657e-06,
        "epoch": 5.234720992028343,
        "step": 5910
    },
    {
        "loss": 0.0216,
        "grad_norm": 0.2405347228050232,
        "learning_rate": 4.756421612046059e-06,
        "epoch": 5.243578387953941,
        "step": 5920
    },
    {
        "loss": 0.033,
        "grad_norm": 0.07004474103450775,
        "learning_rate": 4.747564216120461e-06,
        "epoch": 5.252435783879539,
        "step": 5930
    },
    {
        "loss": 0.0137,
        "grad_norm": 0.047486092895269394,
        "learning_rate": 4.738706820194863e-06,
        "epoch": 5.261293179805137,
        "step": 5940
    },
    {
        "loss": 0.066,
        "grad_norm": 0.06400572508573532,
        "learning_rate": 4.729849424269265e-06,
        "epoch": 5.270150575730735,
        "step": 5950
    },
    {
        "loss": 0.0754,
        "grad_norm": 156.4541473388672,
        "learning_rate": 4.720992028343667e-06,
        "epoch": 5.279007971656333,
        "step": 5960
    },
    {
        "loss": 0.0044,
        "grad_norm": 0.03305494785308838,
        "learning_rate": 4.71213463241807e-06,
        "epoch": 5.287865367581931,
        "step": 5970
    },
    {
        "loss": 0.0341,
        "grad_norm": 0.04957039654254913,
        "learning_rate": 4.703277236492472e-06,
        "epoch": 5.296722763507529,
        "step": 5980
    },
    {
        "loss": 0.1242,
        "grad_norm": 0.2039586752653122,
        "learning_rate": 4.694419840566874e-06,
        "epoch": 5.305580159433127,
        "step": 5990
    },
    {
        "loss": 0.0968,
        "grad_norm": 0.0643036961555481,
        "learning_rate": 4.685562444641275e-06,
        "epoch": 5.314437555358724,
        "step": 6000
    },
    {
        "loss": 0.117,
        "grad_norm": 0.05601852759718895,
        "learning_rate": 4.676705048715678e-06,
        "epoch": 5.323294951284322,
        "step": 6010
    },
    {
        "loss": 0.0383,
        "grad_norm": 0.0947265699505806,
        "learning_rate": 4.66784765279008e-06,
        "epoch": 5.33215234720992,
        "step": 6020
    },
    {
        "loss": 0.0153,
        "grad_norm": 0.06754016876220703,
        "learning_rate": 4.658990256864483e-06,
        "epoch": 5.341009743135518,
        "step": 6030
    },
    {
        "loss": 0.002,
        "grad_norm": 9.640714645385742,
        "learning_rate": 4.650132860938884e-06,
        "epoch": 5.349867139061116,
        "step": 6040
    },
    {
        "loss": 0.0819,
        "grad_norm": 0.05677122250199318,
        "learning_rate": 4.641275465013286e-06,
        "epoch": 5.358724534986714,
        "step": 6050
    },
    {
        "loss": 0.1069,
        "grad_norm": 0.05710044875741005,
        "learning_rate": 4.632418069087688e-06,
        "epoch": 5.367581930912312,
        "step": 6060
    },
    {
        "loss": 0.1366,
        "grad_norm": 0.0597403310239315,
        "learning_rate": 4.623560673162091e-06,
        "epoch": 5.37643932683791,
        "step": 6070
    },
    {
        "loss": 0.0728,
        "grad_norm": 100.71082305908203,
        "learning_rate": 4.614703277236493e-06,
        "epoch": 5.385296722763507,
        "step": 6080
    },
    {
        "loss": 0.0401,
        "grad_norm": 0.06861109286546707,
        "learning_rate": 4.605845881310895e-06,
        "epoch": 5.394154118689105,
        "step": 6090
    },
    {
        "loss": 0.0536,
        "grad_norm": 0.15111224353313446,
        "learning_rate": 4.596988485385297e-06,
        "epoch": 5.403011514614703,
        "step": 6100
    },
    {
        "loss": 0.1156,
        "grad_norm": 174.17886352539062,
        "learning_rate": 4.588131089459699e-06,
        "epoch": 5.411868910540301,
        "step": 6110
    },
    {
        "loss": 0.0703,
        "grad_norm": 13.484557151794434,
        "learning_rate": 4.579273693534101e-06,
        "epoch": 5.420726306465899,
        "step": 6120
    },
    {
        "loss": 0.031,
        "grad_norm": 4.427626609802246,
        "learning_rate": 4.570416297608504e-06,
        "epoch": 5.429583702391497,
        "step": 6130
    },
    {
        "loss": 0.1488,
        "grad_norm": 51.57498550415039,
        "learning_rate": 4.5615589016829055e-06,
        "epoch": 5.438441098317095,
        "step": 6140
    },
    {
        "loss": 0.0643,
        "grad_norm": 0.04926389828324318,
        "learning_rate": 4.552701505757308e-06,
        "epoch": 5.447298494242693,
        "step": 6150
    },
    {
        "loss": 0.1,
        "grad_norm": 0.052707262337207794,
        "learning_rate": 4.5438441098317095e-06,
        "epoch": 5.45615589016829,
        "step": 6160
    },
    {
        "loss": 0.0432,
        "grad_norm": 3.224501609802246,
        "learning_rate": 4.534986713906112e-06,
        "epoch": 5.465013286093888,
        "step": 6170
    },
    {
        "loss": 0.0022,
        "grad_norm": 0.04590178281068802,
        "learning_rate": 4.5261293179805144e-06,
        "epoch": 5.473870682019486,
        "step": 6180
    },
    {
        "loss": 0.1142,
        "grad_norm": 63.18971252441406,
        "learning_rate": 4.517271922054916e-06,
        "epoch": 5.482728077945084,
        "step": 6190
    },
    {
        "loss": 0.0557,
        "grad_norm": 0.1173926517367363,
        "learning_rate": 4.5084145261293185e-06,
        "epoch": 5.491585473870682,
        "step": 6200
    },
    {
        "loss": 0.0408,
        "grad_norm": 0.09278912097215652,
        "learning_rate": 4.499557130203721e-06,
        "epoch": 5.50044286979628,
        "step": 6210
    },
    {
        "loss": 0.0969,
        "grad_norm": 146.74005126953125,
        "learning_rate": 4.4906997342781226e-06,
        "epoch": 5.509300265721878,
        "step": 6220
    },
    {
        "loss": 0.0745,
        "grad_norm": 6.961718559265137,
        "learning_rate": 4.481842338352524e-06,
        "epoch": 5.518157661647476,
        "step": 6230
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.04789352789521217,
        "learning_rate": 4.472984942426927e-06,
        "epoch": 5.527015057573074,
        "step": 6240
    },
    {
        "loss": 0.0437,
        "grad_norm": 0.0970994234085083,
        "learning_rate": 4.464127546501329e-06,
        "epoch": 5.535872453498671,
        "step": 6250
    },
    {
        "loss": 0.0418,
        "grad_norm": 0.07440711557865143,
        "learning_rate": 4.4552701505757315e-06,
        "epoch": 5.544729849424269,
        "step": 6260
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.3594967722892761,
        "learning_rate": 4.446412754650133e-06,
        "epoch": 5.553587245349867,
        "step": 6270
    },
    {
        "loss": 0.087,
        "grad_norm": 0.19848790764808655,
        "learning_rate": 4.437555358724535e-06,
        "epoch": 5.562444641275465,
        "step": 6280
    },
    {
        "loss": 0.1742,
        "grad_norm": 151.00775146484375,
        "learning_rate": 4.428697962798937e-06,
        "epoch": 5.571302037201063,
        "step": 6290
    },
    {
        "loss": 0.045,
        "grad_norm": 0.0781000480055809,
        "learning_rate": 4.41984056687334e-06,
        "epoch": 5.580159433126661,
        "step": 6300
    },
    {
        "loss": 0.0392,
        "grad_norm": 0.07322202622890472,
        "learning_rate": 4.410983170947742e-06,
        "epoch": 5.589016829052259,
        "step": 6310
    },
    {
        "loss": 0.0704,
        "grad_norm": 0.06868650764226913,
        "learning_rate": 4.402125775022144e-06,
        "epoch": 5.597874224977857,
        "step": 6320
    },
    {
        "loss": 0.0724,
        "grad_norm": 0.04545537009835243,
        "learning_rate": 4.393268379096546e-06,
        "epoch": 5.606731620903455,
        "step": 6330
    },
    {
        "loss": 0.0394,
        "grad_norm": 3.278418779373169,
        "learning_rate": 4.384410983170948e-06,
        "epoch": 5.615589016829052,
        "step": 6340
    },
    {
        "loss": 0.1157,
        "grad_norm": 0.05046343803405762,
        "learning_rate": 4.37555358724535e-06,
        "epoch": 5.62444641275465,
        "step": 6350
    },
    {
        "loss": 0.0792,
        "grad_norm": 23.699831008911133,
        "learning_rate": 4.366696191319753e-06,
        "epoch": 5.633303808680248,
        "step": 6360
    },
    {
        "loss": 0.1452,
        "grad_norm": 1.0918482542037964,
        "learning_rate": 4.357838795394154e-06,
        "epoch": 5.642161204605846,
        "step": 6370
    },
    {
        "loss": 0.0201,
        "grad_norm": 285.5445861816406,
        "learning_rate": 4.348981399468557e-06,
        "epoch": 5.651018600531444,
        "step": 6380
    },
    {
        "loss": 0.1273,
        "grad_norm": 200.871826171875,
        "learning_rate": 4.340124003542958e-06,
        "epoch": 5.659875996457042,
        "step": 6390
    },
    {
        "loss": 0.0843,
        "grad_norm": 0.07348953187465668,
        "learning_rate": 4.331266607617361e-06,
        "epoch": 5.66873339238264,
        "step": 6400
    },
    {
        "loss": 0.0981,
        "grad_norm": 0.14898604154586792,
        "learning_rate": 4.322409211691763e-06,
        "epoch": 5.677590788308238,
        "step": 6410
    },
    {
        "loss": 0.003,
        "grad_norm": 0.06971444934606552,
        "learning_rate": 4.313551815766165e-06,
        "epoch": 5.686448184233836,
        "step": 6420
    },
    {
        "loss": 0.0939,
        "grad_norm": 0.2424914538860321,
        "learning_rate": 4.304694419840567e-06,
        "epoch": 5.695305580159433,
        "step": 6430
    },
    {
        "loss": 0.0018,
        "grad_norm": 0.05638108029961586,
        "learning_rate": 4.295837023914969e-06,
        "epoch": 5.704162976085031,
        "step": 6440
    },
    {
        "loss": 0.0536,
        "grad_norm": 0.1040971428155899,
        "learning_rate": 4.2869796279893714e-06,
        "epoch": 5.713020372010629,
        "step": 6450
    },
    {
        "loss": 0.046,
        "grad_norm": 0.04517309367656708,
        "learning_rate": 4.278122232063774e-06,
        "epoch": 5.721877767936227,
        "step": 6460
    },
    {
        "loss": 0.0975,
        "grad_norm": 0.05199231207370758,
        "learning_rate": 4.2692648361381755e-06,
        "epoch": 5.730735163861825,
        "step": 6470
    },
    {
        "loss": 0.0387,
        "grad_norm": 0.032730117440223694,
        "learning_rate": 4.260407440212578e-06,
        "epoch": 5.739592559787423,
        "step": 6480
    },
    {
        "loss": 0.0051,
        "grad_norm": 0.06314804404973984,
        "learning_rate": 4.25155004428698e-06,
        "epoch": 5.748449955713021,
        "step": 6490
    },
    {
        "loss": 0.0269,
        "grad_norm": 0.03335656598210335,
        "learning_rate": 4.242692648361382e-06,
        "epoch": 5.757307351638619,
        "step": 6500
    },
    {
        "loss": 0.0684,
        "grad_norm": 0.021037405356764793,
        "learning_rate": 4.233835252435784e-06,
        "epoch": 5.766164747564217,
        "step": 6510
    },
    {
        "loss": 0.0024,
        "grad_norm": 0.02522430382668972,
        "learning_rate": 4.224977856510186e-06,
        "epoch": 5.775022143489814,
        "step": 6520
    },
    {
        "loss": 0.0486,
        "grad_norm": 0.058146413415670395,
        "learning_rate": 4.2161204605845885e-06,
        "epoch": 5.783879539415412,
        "step": 6530
    },
    {
        "loss": 0.0531,
        "grad_norm": 0.18876411020755768,
        "learning_rate": 4.207263064658991e-06,
        "epoch": 5.79273693534101,
        "step": 6540
    },
    {
        "loss": 0.0811,
        "grad_norm": 0.19355100393295288,
        "learning_rate": 4.198405668733393e-06,
        "epoch": 5.801594331266608,
        "step": 6550
    },
    {
        "loss": 0.0661,
        "grad_norm": 0.027077913284301758,
        "learning_rate": 4.189548272807795e-06,
        "epoch": 5.810451727192206,
        "step": 6560
    },
    {
        "loss": 0.042,
        "grad_norm": 3.9356820583343506,
        "learning_rate": 4.180690876882197e-06,
        "epoch": 5.819309123117804,
        "step": 6570
    },
    {
        "loss": 0.1162,
        "grad_norm": 0.032989054918289185,
        "learning_rate": 4.171833480956599e-06,
        "epoch": 5.8281665190434015,
        "step": 6580
    },
    {
        "loss": 0.1309,
        "grad_norm": 67.98252868652344,
        "learning_rate": 4.1629760850310016e-06,
        "epoch": 5.837023914968999,
        "step": 6590
    },
    {
        "loss": 0.0526,
        "grad_norm": 212.4745330810547,
        "learning_rate": 4.154118689105404e-06,
        "epoch": 5.845881310894597,
        "step": 6600
    },
    {
        "loss": 0.054,
        "grad_norm": 117.85624694824219,
        "learning_rate": 4.145261293179806e-06,
        "epoch": 5.854738706820195,
        "step": 6610
    },
    {
        "loss": 0.0846,
        "grad_norm": 0.14943444728851318,
        "learning_rate": 4.136403897254207e-06,
        "epoch": 5.863596102745793,
        "step": 6620
    },
    {
        "loss": 0.081,
        "grad_norm": 0.8431034684181213,
        "learning_rate": 4.12754650132861e-06,
        "epoch": 5.8724534986713905,
        "step": 6630
    },
    {
        "loss": 0.0771,
        "grad_norm": 0.11477276682853699,
        "learning_rate": 4.118689105403012e-06,
        "epoch": 5.8813108945969885,
        "step": 6640
    },
    {
        "loss": 0.0229,
        "grad_norm": 0.05913195386528969,
        "learning_rate": 4.109831709477414e-06,
        "epoch": 5.8901682905225865,
        "step": 6650
    },
    {
        "loss": 0.0175,
        "grad_norm": 0.13058188557624817,
        "learning_rate": 4.100974313551816e-06,
        "epoch": 5.8990256864481845,
        "step": 6660
    },
    {
        "loss": 0.0787,
        "grad_norm": 0.6445364952087402,
        "learning_rate": 4.092116917626218e-06,
        "epoch": 5.9078830823737825,
        "step": 6670
    },
    {
        "loss": 0.0386,
        "grad_norm": 0.04550858959555626,
        "learning_rate": 4.08325952170062e-06,
        "epoch": 5.9167404782993795,
        "step": 6680
    },
    {
        "loss": 0.0059,
        "grad_norm": 0.051205601543188095,
        "learning_rate": 4.074402125775023e-06,
        "epoch": 5.9255978742249775,
        "step": 6690
    },
    {
        "loss": 0.2086,
        "grad_norm": 12.189517974853516,
        "learning_rate": 4.065544729849424e-06,
        "epoch": 5.9344552701505755,
        "step": 6700
    },
    {
        "loss": 0.1065,
        "grad_norm": 52.890933990478516,
        "learning_rate": 4.056687333923827e-06,
        "epoch": 5.9433126660761735,
        "step": 6710
    },
    {
        "loss": 0.1046,
        "grad_norm": 95.7055892944336,
        "learning_rate": 4.047829937998229e-06,
        "epoch": 5.9521700620017715,
        "step": 6720
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.1193992868065834,
        "learning_rate": 4.038972542072631e-06,
        "epoch": 5.961027457927369,
        "step": 6730
    },
    {
        "loss": 0.1892,
        "grad_norm": 1.745695948600769,
        "learning_rate": 4.030115146147033e-06,
        "epoch": 5.969884853852967,
        "step": 6740
    },
    {
        "loss": 0.0661,
        "grad_norm": 3.439957618713379,
        "learning_rate": 4.021257750221435e-06,
        "epoch": 5.978742249778565,
        "step": 6750
    },
    {
        "loss": 0.1251,
        "grad_norm": 0.15503615140914917,
        "learning_rate": 4.012400354295837e-06,
        "epoch": 5.987599645704163,
        "step": 6760
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.03630303218960762,
        "learning_rate": 4.00354295837024e-06,
        "epoch": 5.9964570416297605,
        "step": 6770
    },
    {
        "eval_loss": 0.14846622943878174,
        "eval_accuracy": 0.9752,
        "eval_precision": 0.97901,
        "eval_recall": 0.97121,
        "eval_f1": 0.97509,
        "eval_runtime": 149.3397,
        "eval_samples_per_second": 60.473,
        "eval_steps_per_second": 3.783,
        "epoch": 6.0,
        "step": 6774
    },
    {
        "loss": 0.0733,
        "grad_norm": 0.05435042455792427,
        "learning_rate": 3.9946855624446415e-06,
        "epoch": 6.005314437555358,
        "step": 6780
    },
    {
        "loss": 0.0319,
        "grad_norm": 0.1421479880809784,
        "learning_rate": 3.985828166519043e-06,
        "epoch": 6.014171833480956,
        "step": 6790
    },
    {
        "loss": 0.0693,
        "grad_norm": 24.084877014160156,
        "learning_rate": 3.9769707705934455e-06,
        "epoch": 6.023029229406554,
        "step": 6800
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.06074555218219757,
        "learning_rate": 3.968113374667848e-06,
        "epoch": 6.031886625332152,
        "step": 6810
    },
    {
        "loss": 0.107,
        "grad_norm": 0.033524710685014725,
        "learning_rate": 3.9592559787422504e-06,
        "epoch": 6.04074402125775,
        "step": 6820
    },
    {
        "loss": 0.0356,
        "grad_norm": 0.04724333435297012,
        "learning_rate": 3.950398582816652e-06,
        "epoch": 6.049601417183348,
        "step": 6830
    },
    {
        "loss": 0.0419,
        "grad_norm": 14.074563980102539,
        "learning_rate": 3.9415411868910545e-06,
        "epoch": 6.058458813108946,
        "step": 6840
    },
    {
        "loss": 0.1024,
        "grad_norm": 8.049543380737305,
        "learning_rate": 3.932683790965456e-06,
        "epoch": 6.067316209034544,
        "step": 6850
    },
    {
        "loss": 0.001,
        "grad_norm": 0.3580891788005829,
        "learning_rate": 3.9238263950398586e-06,
        "epoch": 6.076173604960141,
        "step": 6860
    },
    {
        "loss": 0.0477,
        "grad_norm": 0.07817773520946503,
        "learning_rate": 3.914968999114261e-06,
        "epoch": 6.085031000885739,
        "step": 6870
    },
    {
        "loss": 0.0528,
        "grad_norm": 0.06798498332500458,
        "learning_rate": 3.9061116031886635e-06,
        "epoch": 6.093888396811337,
        "step": 6880
    },
    {
        "loss": 0.0322,
        "grad_norm": 0.03581744059920311,
        "learning_rate": 3.897254207263065e-06,
        "epoch": 6.102745792736935,
        "step": 6890
    },
    {
        "loss": 0.0093,
        "grad_norm": 0.06401396542787552,
        "learning_rate": 3.888396811337467e-06,
        "epoch": 6.111603188662533,
        "step": 6900
    },
    {
        "loss": 0.0774,
        "grad_norm": 0.04214188829064369,
        "learning_rate": 3.879539415411869e-06,
        "epoch": 6.120460584588131,
        "step": 6910
    },
    {
        "loss": 0.0082,
        "grad_norm": 0.05323515459895134,
        "learning_rate": 3.870682019486272e-06,
        "epoch": 6.129317980513729,
        "step": 6920
    },
    {
        "loss": 0.0807,
        "grad_norm": 0.054094381630420685,
        "learning_rate": 3.861824623560673e-06,
        "epoch": 6.138175376439327,
        "step": 6930
    },
    {
        "loss": 0.149,
        "grad_norm": 122.45484924316406,
        "learning_rate": 3.852967227635076e-06,
        "epoch": 6.147032772364924,
        "step": 6940
    },
    {
        "loss": 0.0313,
        "grad_norm": 80.22402954101562,
        "learning_rate": 3.844109831709478e-06,
        "epoch": 6.155890168290522,
        "step": 6950
    },
    {
        "loss": 0.0319,
        "grad_norm": 0.04452988877892494,
        "learning_rate": 3.83525243578388e-06,
        "epoch": 6.16474756421612,
        "step": 6960
    },
    {
        "loss": 0.0647,
        "grad_norm": 0.03572000563144684,
        "learning_rate": 3.826395039858282e-06,
        "epoch": 6.173604960141718,
        "step": 6970
    },
    {
        "loss": 0.0799,
        "grad_norm": 20.337560653686523,
        "learning_rate": 3.817537643932684e-06,
        "epoch": 6.182462356067316,
        "step": 6980
    },
    {
        "loss": 0.1295,
        "grad_norm": 94.16234588623047,
        "learning_rate": 3.8086802480070863e-06,
        "epoch": 6.191319751992914,
        "step": 6990
    },
    {
        "loss": 0.0021,
        "grad_norm": 3.7185070514678955,
        "learning_rate": 3.7998228520814883e-06,
        "epoch": 6.200177147918512,
        "step": 7000
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.04329885542392731,
        "learning_rate": 3.7909654561558907e-06,
        "epoch": 6.20903454384411,
        "step": 7010
    },
    {
        "loss": 0.0708,
        "grad_norm": 0.04045003652572632,
        "learning_rate": 3.7821080602302928e-06,
        "epoch": 6.217891939769708,
        "step": 7020
    },
    {
        "loss": 0.0063,
        "grad_norm": 30.663450241088867,
        "learning_rate": 3.7732506643046944e-06,
        "epoch": 6.226749335695305,
        "step": 7030
    },
    {
        "loss": 0.0596,
        "grad_norm": 109.74589538574219,
        "learning_rate": 3.764393268379097e-06,
        "epoch": 6.235606731620903,
        "step": 7040
    },
    {
        "loss": 0.1622,
        "grad_norm": 0.05007239058613777,
        "learning_rate": 3.755535872453499e-06,
        "epoch": 6.244464127546501,
        "step": 7050
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.028347576037049294,
        "learning_rate": 3.7466784765279013e-06,
        "epoch": 6.253321523472099,
        "step": 7060
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.020622234791517258,
        "learning_rate": 3.737821080602303e-06,
        "epoch": 6.262178919397697,
        "step": 7070
    },
    {
        "loss": 0.0194,
        "grad_norm": 0.023639468476176262,
        "learning_rate": 3.7289636846767054e-06,
        "epoch": 6.271036315323295,
        "step": 7080
    },
    {
        "loss": 0.0483,
        "grad_norm": 0.023107249289751053,
        "learning_rate": 3.7201062887511074e-06,
        "epoch": 6.279893711248893,
        "step": 7090
    },
    {
        "loss": 0.0786,
        "grad_norm": 6.22600793838501,
        "learning_rate": 3.71124889282551e-06,
        "epoch": 6.288751107174491,
        "step": 7100
    },
    {
        "loss": 0.0807,
        "grad_norm": 0.03909981623291969,
        "learning_rate": 3.702391496899912e-06,
        "epoch": 6.297608503100088,
        "step": 7110
    },
    {
        "loss": 0.0712,
        "grad_norm": 0.031187793239951134,
        "learning_rate": 3.6935341009743135e-06,
        "epoch": 6.306465899025686,
        "step": 7120
    },
    {
        "loss": 0.0534,
        "grad_norm": 0.04183206707239151,
        "learning_rate": 3.684676705048716e-06,
        "epoch": 6.315323294951284,
        "step": 7130
    },
    {
        "loss": 0.0133,
        "grad_norm": 0.09541810303926468,
        "learning_rate": 3.675819309123118e-06,
        "epoch": 6.324180690876882,
        "step": 7140
    },
    {
        "loss": 0.0938,
        "grad_norm": 116.56646728515625,
        "learning_rate": 3.6669619131975205e-06,
        "epoch": 6.33303808680248,
        "step": 7150
    },
    {
        "loss": 0.0381,
        "grad_norm": 0.09395387768745422,
        "learning_rate": 3.6581045172719225e-06,
        "epoch": 6.341895482728078,
        "step": 7160
    },
    {
        "loss": 0.037,
        "grad_norm": 0.09392489492893219,
        "learning_rate": 3.649247121346324e-06,
        "epoch": 6.350752878653676,
        "step": 7170
    },
    {
        "loss": 0.064,
        "grad_norm": 25.304183959960938,
        "learning_rate": 3.6403897254207266e-06,
        "epoch": 6.359610274579274,
        "step": 7180
    },
    {
        "loss": 0.0536,
        "grad_norm": 0.01710103079676628,
        "learning_rate": 3.6315323294951286e-06,
        "epoch": 6.368467670504872,
        "step": 7190
    },
    {
        "loss": 0.001,
        "grad_norm": 0.03283655643463135,
        "learning_rate": 3.622674933569531e-06,
        "epoch": 6.377325066430469,
        "step": 7200
    },
    {
        "loss": 0.1137,
        "grad_norm": 0.20090562105178833,
        "learning_rate": 3.6138175376439327e-06,
        "epoch": 6.386182462356067,
        "step": 7210
    },
    {
        "loss": 0.0504,
        "grad_norm": 1.2524737119674683,
        "learning_rate": 3.604960141718335e-06,
        "epoch": 6.395039858281665,
        "step": 7220
    },
    {
        "loss": 0.0745,
        "grad_norm": 5.13685941696167,
        "learning_rate": 3.596102745792737e-06,
        "epoch": 6.403897254207263,
        "step": 7230
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.040962103754282,
        "learning_rate": 3.5872453498671396e-06,
        "epoch": 6.412754650132861,
        "step": 7240
    },
    {
        "loss": 0.108,
        "grad_norm": 0.03988618031144142,
        "learning_rate": 3.5783879539415416e-06,
        "epoch": 6.421612046058459,
        "step": 7250
    },
    {
        "loss": 0.0636,
        "grad_norm": 0.22803765535354614,
        "learning_rate": 3.5695305580159433e-06,
        "epoch": 6.430469441984057,
        "step": 7260
    },
    {
        "loss": 0.0424,
        "grad_norm": 0.028887616470456123,
        "learning_rate": 3.5606731620903457e-06,
        "epoch": 6.439326837909655,
        "step": 7270
    },
    {
        "loss": 0.1334,
        "grad_norm": 0.039337027817964554,
        "learning_rate": 3.5518157661647477e-06,
        "epoch": 6.448184233835253,
        "step": 7280
    },
    {
        "loss": 0.0075,
        "grad_norm": 0.03603791445493698,
        "learning_rate": 3.54295837023915e-06,
        "epoch": 6.45704162976085,
        "step": 7290
    },
    {
        "loss": 0.0278,
        "grad_norm": 0.03597978129982948,
        "learning_rate": 3.5341009743135522e-06,
        "epoch": 6.465899025686448,
        "step": 7300
    },
    {
        "loss": 0.0805,
        "grad_norm": 0.024613438174128532,
        "learning_rate": 3.5252435783879543e-06,
        "epoch": 6.474756421612046,
        "step": 7310
    },
    {
        "loss": 0.0482,
        "grad_norm": 193.45713806152344,
        "learning_rate": 3.5163861824623563e-06,
        "epoch": 6.483613817537644,
        "step": 7320
    },
    {
        "loss": 0.0548,
        "grad_norm": 0.023428039625287056,
        "learning_rate": 3.5075287865367587e-06,
        "epoch": 6.492471213463242,
        "step": 7330
    },
    {
        "loss": 0.2015,
        "grad_norm": 84.30101776123047,
        "learning_rate": 3.4986713906111608e-06,
        "epoch": 6.50132860938884,
        "step": 7340
    },
    {
        "loss": 0.0396,
        "grad_norm": 0.1166645735502243,
        "learning_rate": 3.4898139946855624e-06,
        "epoch": 6.510186005314438,
        "step": 7350
    },
    {
        "loss": 0.0967,
        "grad_norm": 0.506722629070282,
        "learning_rate": 3.480956598759965e-06,
        "epoch": 6.519043401240036,
        "step": 7360
    },
    {
        "loss": 0.0547,
        "grad_norm": 154.72361755371094,
        "learning_rate": 3.472099202834367e-06,
        "epoch": 6.527900797165634,
        "step": 7370
    },
    {
        "loss": 0.0461,
        "grad_norm": 53.00182342529297,
        "learning_rate": 3.4632418069087693e-06,
        "epoch": 6.536758193091231,
        "step": 7380
    },
    {
        "loss": 0.0412,
        "grad_norm": 0.03351893648505211,
        "learning_rate": 3.4543844109831714e-06,
        "epoch": 6.545615589016829,
        "step": 7390
    },
    {
        "loss": 0.1037,
        "grad_norm": 0.01341312751173973,
        "learning_rate": 3.445527015057573e-06,
        "epoch": 6.554472984942427,
        "step": 7400
    },
    {
        "loss": 0.0494,
        "grad_norm": 172.7170867919922,
        "learning_rate": 3.4366696191319754e-06,
        "epoch": 6.563330380868025,
        "step": 7410
    },
    {
        "loss": 0.0595,
        "grad_norm": 0.03803260996937752,
        "learning_rate": 3.4278122232063775e-06,
        "epoch": 6.572187776793623,
        "step": 7420
    },
    {
        "loss": 0.0027,
        "grad_norm": 0.016308480873703957,
        "learning_rate": 3.41895482728078e-06,
        "epoch": 6.581045172719221,
        "step": 7430
    },
    {
        "loss": 0.1256,
        "grad_norm": 0.023410074412822723,
        "learning_rate": 3.410097431355182e-06,
        "epoch": 6.589902568644819,
        "step": 7440
    },
    {
        "loss": 0.0122,
        "grad_norm": 64.42591857910156,
        "learning_rate": 3.401240035429584e-06,
        "epoch": 6.598759964570416,
        "step": 7450
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.08098169416189194,
        "learning_rate": 3.392382639503986e-06,
        "epoch": 6.607617360496015,
        "step": 7460
    },
    {
        "loss": 0.0481,
        "grad_norm": 0.05172392725944519,
        "learning_rate": 3.3835252435783885e-06,
        "epoch": 6.616474756421612,
        "step": 7470
    },
    {
        "loss": 0.0275,
        "grad_norm": 0.019142204895615578,
        "learning_rate": 3.3746678476527905e-06,
        "epoch": 6.62533215234721,
        "step": 7480
    },
    {
        "loss": 0.0138,
        "grad_norm": 0.03144734352827072,
        "learning_rate": 3.365810451727192e-06,
        "epoch": 6.634189548272808,
        "step": 7490
    },
    {
        "loss": 0.0222,
        "grad_norm": 0.6081668138504028,
        "learning_rate": 3.3569530558015946e-06,
        "epoch": 6.643046944198406,
        "step": 7500
    },
    {
        "loss": 0.0959,
        "grad_norm": 30.48881721496582,
        "learning_rate": 3.3480956598759966e-06,
        "epoch": 6.651904340124004,
        "step": 7510
    },
    {
        "loss": 0.0701,
        "grad_norm": 229.3272705078125,
        "learning_rate": 3.339238263950399e-06,
        "epoch": 6.660761736049602,
        "step": 7520
    },
    {
        "loss": 0.056,
        "grad_norm": 3.127873420715332,
        "learning_rate": 3.330380868024801e-06,
        "epoch": 6.6696191319752,
        "step": 7530
    },
    {
        "loss": 0.0416,
        "grad_norm": 0.019901005551218987,
        "learning_rate": 3.3215234720992027e-06,
        "epoch": 6.678476527900797,
        "step": 7540
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.3621828258037567,
        "learning_rate": 3.312666076173605e-06,
        "epoch": 6.687333923826395,
        "step": 7550
    },
    {
        "loss": 0.0031,
        "grad_norm": 8.536673545837402,
        "learning_rate": 3.303808680248007e-06,
        "epoch": 6.696191319751993,
        "step": 7560
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.14384591579437256,
        "learning_rate": 3.2949512843224096e-06,
        "epoch": 6.705048715677591,
        "step": 7570
    },
    {
        "loss": 0.0429,
        "grad_norm": 0.01750885508954525,
        "learning_rate": 3.2860938883968117e-06,
        "epoch": 6.713906111603189,
        "step": 7580
    },
    {
        "loss": 0.1102,
        "grad_norm": 115.27112579345703,
        "learning_rate": 3.2772364924712137e-06,
        "epoch": 6.722763507528787,
        "step": 7590
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.21999266743659973,
        "learning_rate": 3.2683790965456157e-06,
        "epoch": 6.731620903454385,
        "step": 7600
    },
    {
        "loss": 0.0761,
        "grad_norm": 157.25514221191406,
        "learning_rate": 3.259521700620018e-06,
        "epoch": 6.7404782993799826,
        "step": 7610
    },
    {
        "loss": 0.0499,
        "grad_norm": 0.039524950087070465,
        "learning_rate": 3.2506643046944202e-06,
        "epoch": 6.7493356953055805,
        "step": 7620
    },
    {
        "loss": 0.0567,
        "grad_norm": 6.221601963043213,
        "learning_rate": 3.241806908768822e-06,
        "epoch": 6.758193091231178,
        "step": 7630
    },
    {
        "loss": 0.0215,
        "grad_norm": 0.019548611715435982,
        "learning_rate": 3.2329495128432243e-06,
        "epoch": 6.767050487156776,
        "step": 7640
    },
    {
        "loss": 0.114,
        "grad_norm": 0.34594962000846863,
        "learning_rate": 3.2240921169176263e-06,
        "epoch": 6.775907883082374,
        "step": 7650
    },
    {
        "loss": 0.0146,
        "grad_norm": 253.2782745361328,
        "learning_rate": 3.2152347209920288e-06,
        "epoch": 6.7847652790079716,
        "step": 7660
    },
    {
        "loss": 0.0652,
        "grad_norm": 0.07234153151512146,
        "learning_rate": 3.206377325066431e-06,
        "epoch": 6.7936226749335695,
        "step": 7670
    },
    {
        "loss": 0.1077,
        "grad_norm": 116.65105438232422,
        "learning_rate": 3.197519929140833e-06,
        "epoch": 6.8024800708591675,
        "step": 7680
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.06681999564170837,
        "learning_rate": 3.188662533215235e-06,
        "epoch": 6.8113374667847655,
        "step": 7690
    },
    {
        "loss": 0.0829,
        "grad_norm": 6.488476276397705,
        "learning_rate": 3.1798051372896373e-06,
        "epoch": 6.8201948627103635,
        "step": 7700
    },
    {
        "loss": 0.0028,
        "grad_norm": 22.312192916870117,
        "learning_rate": 3.1709477413640394e-06,
        "epoch": 6.829052258635961,
        "step": 7710
    },
    {
        "loss": 0.0365,
        "grad_norm": 0.08481470495462418,
        "learning_rate": 3.162090345438442e-06,
        "epoch": 6.8379096545615585,
        "step": 7720
    },
    {
        "loss": 0.0654,
        "grad_norm": 0.03848012909293175,
        "learning_rate": 3.1532329495128434e-06,
        "epoch": 6.8467670504871565,
        "step": 7730
    },
    {
        "loss": 0.0562,
        "grad_norm": 0.06562024354934692,
        "learning_rate": 3.1443755535872455e-06,
        "epoch": 6.8556244464127545,
        "step": 7740
    },
    {
        "loss": 0.0183,
        "grad_norm": 1.14452064037323,
        "learning_rate": 3.135518157661648e-06,
        "epoch": 6.8644818423383525,
        "step": 7750
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.03071533888578415,
        "learning_rate": 3.12666076173605e-06,
        "epoch": 6.87333923826395,
        "step": 7760
    },
    {
        "loss": 0.0151,
        "grad_norm": 0.04301273822784424,
        "learning_rate": 3.1178033658104516e-06,
        "epoch": 6.882196634189548,
        "step": 7770
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.03044561669230461,
        "learning_rate": 3.108945969884854e-06,
        "epoch": 6.891054030115146,
        "step": 7780
    },
    {
        "loss": 0.0207,
        "grad_norm": 148.75485229492188,
        "learning_rate": 3.100088573959256e-06,
        "epoch": 6.899911426040744,
        "step": 7790
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.186687633395195,
        "learning_rate": 3.0912311780336585e-06,
        "epoch": 6.908768821966342,
        "step": 7800
    },
    {
        "loss": 0.0798,
        "grad_norm": 16.304100036621094,
        "learning_rate": 3.0823737821080605e-06,
        "epoch": 6.917626217891939,
        "step": 7810
    },
    {
        "loss": 0.0416,
        "grad_norm": 0.9977138638496399,
        "learning_rate": 3.0735163861824626e-06,
        "epoch": 6.926483613817537,
        "step": 7820
    },
    {
        "loss": 0.0197,
        "grad_norm": 0.014475144445896149,
        "learning_rate": 3.0646589902568646e-06,
        "epoch": 6.935341009743135,
        "step": 7830
    },
    {
        "loss": 0.0744,
        "grad_norm": 0.021477414295077324,
        "learning_rate": 3.055801594331267e-06,
        "epoch": 6.944198405668733,
        "step": 7840
    },
    {
        "loss": 0.0034,
        "grad_norm": 0.01936054602265358,
        "learning_rate": 3.046944198405669e-06,
        "epoch": 6.953055801594331,
        "step": 7850
    },
    {
        "loss": 0.0375,
        "grad_norm": 0.045531440526247025,
        "learning_rate": 3.0380868024800715e-06,
        "epoch": 6.961913197519929,
        "step": 7860
    },
    {
        "loss": 0.0991,
        "grad_norm": 4.8606343269348145,
        "learning_rate": 3.029229406554473e-06,
        "epoch": 6.970770593445527,
        "step": 7870
    },
    {
        "loss": 0.1101,
        "grad_norm": 75.86638641357422,
        "learning_rate": 3.020372010628875e-06,
        "epoch": 6.979627989371125,
        "step": 7880
    },
    {
        "loss": 0.015,
        "grad_norm": 0.14588001370429993,
        "learning_rate": 3.0115146147032776e-06,
        "epoch": 6.988485385296723,
        "step": 7890
    },
    {
        "loss": 0.0312,
        "grad_norm": 0.037304092198610306,
        "learning_rate": 3.0026572187776797e-06,
        "epoch": 6.99734278122232,
        "step": 7900
    },
    {
        "eval_loss": 0.14489899575710297,
        "eval_accuracy": 0.97785,
        "eval_precision": 0.97998,
        "eval_recall": 0.97564,
        "eval_f1": 0.9778,
        "eval_runtime": 149.2929,
        "eval_samples_per_second": 60.492,
        "eval_steps_per_second": 3.785,
        "epoch": 7.0,
        "step": 7903
    },
    {
        "loss": 0.0406,
        "grad_norm": 1.8040306568145752,
        "learning_rate": 2.9937998228520813e-06,
        "epoch": 7.006200177147918,
        "step": 7910
    },
    {
        "loss": 0.0209,
        "grad_norm": 0.018764525651931763,
        "learning_rate": 2.9849424269264837e-06,
        "epoch": 7.015057573073516,
        "step": 7920
    },
    {
        "loss": 0.0543,
        "grad_norm": 0.02086147479712963,
        "learning_rate": 2.9760850310008858e-06,
        "epoch": 7.023914968999114,
        "step": 7930
    },
    {
        "loss": 0.021,
        "grad_norm": 0.03694109246134758,
        "learning_rate": 2.9672276350752882e-06,
        "epoch": 7.032772364924712,
        "step": 7940
    },
    {
        "loss": 0.0151,
        "grad_norm": 0.0148750776425004,
        "learning_rate": 2.9583702391496903e-06,
        "epoch": 7.04162976085031,
        "step": 7950
    },
    {
        "loss": 0.0368,
        "grad_norm": 0.035387374460697174,
        "learning_rate": 2.9495128432240923e-06,
        "epoch": 7.050487156775908,
        "step": 7960
    },
    {
        "loss": 0.0027,
        "grad_norm": 0.017725450918078423,
        "learning_rate": 2.9406554472984943e-06,
        "epoch": 7.059344552701506,
        "step": 7970
    },
    {
        "loss": 0.0008,
        "grad_norm": 7.071762561798096,
        "learning_rate": 2.9317980513728968e-06,
        "epoch": 7.068201948627103,
        "step": 7980
    },
    {
        "loss": 0.0198,
        "grad_norm": 138.8240509033203,
        "learning_rate": 2.922940655447299e-06,
        "epoch": 7.077059344552701,
        "step": 7990
    },
    {
        "loss": 0.0412,
        "grad_norm": 0.011239783838391304,
        "learning_rate": 2.9140832595217013e-06,
        "epoch": 7.085916740478299,
        "step": 8000
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0070974999107420444,
        "learning_rate": 2.905225863596103e-06,
        "epoch": 7.094774136403897,
        "step": 8010
    },
    {
        "loss": 0.0847,
        "grad_norm": 0.0074465577490627766,
        "learning_rate": 2.896368467670505e-06,
        "epoch": 7.103631532329495,
        "step": 8020
    },
    {
        "loss": 0.0391,
        "grad_norm": 0.05599799379706383,
        "learning_rate": 2.8875110717449074e-06,
        "epoch": 7.112488928255093,
        "step": 8030
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.009992895647883415,
        "learning_rate": 2.8786536758193094e-06,
        "epoch": 7.121346324180691,
        "step": 8040
    },
    {
        "loss": 0.0328,
        "grad_norm": 0.02055337093770504,
        "learning_rate": 2.8697962798937114e-06,
        "epoch": 7.130203720106289,
        "step": 8050
    },
    {
        "loss": 0.1064,
        "grad_norm": 0.030777664855122566,
        "learning_rate": 2.8609388839681135e-06,
        "epoch": 7.139061116031886,
        "step": 8060
    },
    {
        "loss": 0.0558,
        "grad_norm": 0.029931342229247093,
        "learning_rate": 2.852081488042516e-06,
        "epoch": 7.147918511957484,
        "step": 8070
    },
    {
        "loss": 0.0801,
        "grad_norm": 0.018536848947405815,
        "learning_rate": 2.843224092116918e-06,
        "epoch": 7.156775907883082,
        "step": 8080
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.014699844643473625,
        "learning_rate": 2.8343666961913204e-06,
        "epoch": 7.16563330380868,
        "step": 8090
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.007550912443548441,
        "learning_rate": 2.825509300265722e-06,
        "epoch": 7.174490699734278,
        "step": 8100
    },
    {
        "loss": 0.0757,
        "grad_norm": 0.020870020613074303,
        "learning_rate": 2.816651904340124e-06,
        "epoch": 7.183348095659876,
        "step": 8110
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.041066162288188934,
        "learning_rate": 2.8077945084145265e-06,
        "epoch": 7.192205491585474,
        "step": 8120
    },
    {
        "loss": 0.0082,
        "grad_norm": 0.029246661812067032,
        "learning_rate": 2.7989371124889285e-06,
        "epoch": 7.201062887511072,
        "step": 8130
    },
    {
        "loss": 0.0444,
        "grad_norm": 0.02203829400241375,
        "learning_rate": 2.790079716563331e-06,
        "epoch": 7.20992028343667,
        "step": 8140
    },
    {
        "loss": 0.1148,
        "grad_norm": 0.02170550264418125,
        "learning_rate": 2.7812223206377326e-06,
        "epoch": 7.218777679362267,
        "step": 8150
    },
    {
        "loss": 0.0012,
        "grad_norm": 0.024110719561576843,
        "learning_rate": 2.7723649247121346e-06,
        "epoch": 7.227635075287865,
        "step": 8160
    },
    {
        "loss": 0.0392,
        "grad_norm": 0.1809074729681015,
        "learning_rate": 2.763507528786537e-06,
        "epoch": 7.236492471213463,
        "step": 8170
    },
    {
        "loss": 0.0171,
        "grad_norm": 0.04702037200331688,
        "learning_rate": 2.754650132860939e-06,
        "epoch": 7.245349867139061,
        "step": 8180
    },
    {
        "loss": 0.0549,
        "grad_norm": 4.715494632720947,
        "learning_rate": 2.745792736935341e-06,
        "epoch": 7.254207263064659,
        "step": 8190
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.08226386457681656,
        "learning_rate": 2.736935341009743e-06,
        "epoch": 7.263064658990257,
        "step": 8200
    },
    {
        "loss": 0.0983,
        "grad_norm": 227.49681091308594,
        "learning_rate": 2.7280779450841456e-06,
        "epoch": 7.271922054915855,
        "step": 8210
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.01882091909646988,
        "learning_rate": 2.7192205491585477e-06,
        "epoch": 7.280779450841453,
        "step": 8220
    },
    {
        "loss": 0.0084,
        "grad_norm": 0.02776218205690384,
        "learning_rate": 2.71036315323295e-06,
        "epoch": 7.289636846767051,
        "step": 8230
    },
    {
        "loss": 0.0049,
        "grad_norm": 0.04556221887469292,
        "learning_rate": 2.7015057573073517e-06,
        "epoch": 7.298494242692648,
        "step": 8240
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.01210194081068039,
        "learning_rate": 2.6926483613817538e-06,
        "epoch": 7.307351638618246,
        "step": 8250
    },
    {
        "loss": 0.027,
        "grad_norm": 0.026038533076643944,
        "learning_rate": 2.6837909654561562e-06,
        "epoch": 7.316209034543844,
        "step": 8260
    },
    {
        "loss": 0.0224,
        "grad_norm": 0.0998622253537178,
        "learning_rate": 2.6749335695305583e-06,
        "epoch": 7.325066430469442,
        "step": 8270
    },
    {
        "loss": 0.0642,
        "grad_norm": 179.40921020507812,
        "learning_rate": 2.6660761736049607e-06,
        "epoch": 7.33392382639504,
        "step": 8280
    },
    {
        "loss": 0.0196,
        "grad_norm": 2.8332531452178955,
        "learning_rate": 2.6572187776793623e-06,
        "epoch": 7.342781222320638,
        "step": 8290
    },
    {
        "loss": 0.0786,
        "grad_norm": 8.41222095489502,
        "learning_rate": 2.6483613817537644e-06,
        "epoch": 7.351638618246236,
        "step": 8300
    },
    {
        "loss": 0.0062,
        "grad_norm": 0.01494618970900774,
        "learning_rate": 2.639503985828167e-06,
        "epoch": 7.360496014171834,
        "step": 8310
    },
    {
        "loss": 0.0597,
        "grad_norm": 2.6485188007354736,
        "learning_rate": 2.630646589902569e-06,
        "epoch": 7.369353410097431,
        "step": 8320
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.09095402806997299,
        "learning_rate": 2.621789193976971e-06,
        "epoch": 7.378210806023029,
        "step": 8330
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.18445974588394165,
        "learning_rate": 2.612931798051373e-06,
        "epoch": 7.387068201948627,
        "step": 8340
    },
    {
        "loss": 0.0339,
        "grad_norm": 0.028396517038345337,
        "learning_rate": 2.6040744021257754e-06,
        "epoch": 7.395925597874225,
        "step": 8350
    },
    {
        "loss": 0.0686,
        "grad_norm": 5.479337215423584,
        "learning_rate": 2.5952170062001774e-06,
        "epoch": 7.404782993799823,
        "step": 8360
    },
    {
        "loss": 0.002,
        "grad_norm": 0.07785772532224655,
        "learning_rate": 2.58635961027458e-06,
        "epoch": 7.413640389725421,
        "step": 8370
    },
    {
        "loss": 0.001,
        "grad_norm": 0.04681845009326935,
        "learning_rate": 2.5775022143489815e-06,
        "epoch": 7.422497785651019,
        "step": 8380
    },
    {
        "loss": 0.1391,
        "grad_norm": 0.009325612336397171,
        "learning_rate": 2.5686448184233835e-06,
        "epoch": 7.431355181576617,
        "step": 8390
    },
    {
        "loss": 0.0047,
        "grad_norm": 0.033349424600601196,
        "learning_rate": 2.559787422497786e-06,
        "epoch": 7.440212577502215,
        "step": 8400
    },
    {
        "loss": 0.0034,
        "grad_norm": 75.91635131835938,
        "learning_rate": 2.550930026572188e-06,
        "epoch": 7.449069973427812,
        "step": 8410
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.02498459629714489,
        "learning_rate": 2.5420726306465904e-06,
        "epoch": 7.45792736935341,
        "step": 8420
    },
    {
        "loss": 0.0885,
        "grad_norm": 92.45964813232422,
        "learning_rate": 2.533215234720992e-06,
        "epoch": 7.466784765279008,
        "step": 8430
    },
    {
        "loss": 0.0895,
        "grad_norm": 207.3819580078125,
        "learning_rate": 2.5243578387953945e-06,
        "epoch": 7.475642161204606,
        "step": 8440
    },
    {
        "loss": 0.0164,
        "grad_norm": 1.5517983436584473,
        "learning_rate": 2.5155004428697965e-06,
        "epoch": 7.484499557130204,
        "step": 8450
    },
    {
        "loss": 0.0442,
        "grad_norm": 0.011429441161453724,
        "learning_rate": 2.506643046944199e-06,
        "epoch": 7.493356953055802,
        "step": 8460
    },
    {
        "loss": 0.0726,
        "grad_norm": 0.13057562708854675,
        "learning_rate": 2.4977856510186006e-06,
        "epoch": 7.5022143489814,
        "step": 8470
    },
    {
        "loss": 0.0395,
        "grad_norm": 0.017155969515442848,
        "learning_rate": 2.4889282550930026e-06,
        "epoch": 7.511071744906998,
        "step": 8480
    },
    {
        "loss": 0.0009,
        "grad_norm": 1.705730676651001,
        "learning_rate": 2.480070859167405e-06,
        "epoch": 7.519929140832595,
        "step": 8490
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.10330763459205627,
        "learning_rate": 2.471213463241807e-06,
        "epoch": 7.528786536758193,
        "step": 8500
    },
    {
        "loss": 0.0276,
        "grad_norm": 0.026361508294939995,
        "learning_rate": 2.462356067316209e-06,
        "epoch": 7.537643932683791,
        "step": 8510
    },
    {
        "loss": 0.0763,
        "grad_norm": 113.60565185546875,
        "learning_rate": 2.4534986713906116e-06,
        "epoch": 7.546501328609389,
        "step": 8520
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.028391554951667786,
        "learning_rate": 2.4446412754650132e-06,
        "epoch": 7.555358724534987,
        "step": 8530
    },
    {
        "loss": 0.0323,
        "grad_norm": 0.2552189528942108,
        "learning_rate": 2.4357838795394157e-06,
        "epoch": 7.564216120460585,
        "step": 8540
    },
    {
        "loss": 0.0237,
        "grad_norm": 0.02811875194311142,
        "learning_rate": 2.4269264836138177e-06,
        "epoch": 7.573073516386183,
        "step": 8550
    },
    {
        "loss": 0.0378,
        "grad_norm": 0.053442977368831635,
        "learning_rate": 2.4180690876882197e-06,
        "epoch": 7.581930912311781,
        "step": 8560
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.009090162813663483,
        "learning_rate": 2.409211691762622e-06,
        "epoch": 7.590788308237379,
        "step": 8570
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.006074503064155579,
        "learning_rate": 2.4003542958370242e-06,
        "epoch": 7.599645704162976,
        "step": 8580
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.011689290404319763,
        "learning_rate": 2.3914968999114263e-06,
        "epoch": 7.608503100088574,
        "step": 8590
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.005900409538298845,
        "learning_rate": 2.3826395039858283e-06,
        "epoch": 7.617360496014172,
        "step": 8600
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.025891240686178207,
        "learning_rate": 2.3737821080602303e-06,
        "epoch": 7.62621789193977,
        "step": 8610
    },
    {
        "loss": 0.1206,
        "grad_norm": 65.89912414550781,
        "learning_rate": 2.3649247121346324e-06,
        "epoch": 7.635075287865368,
        "step": 8620
    },
    {
        "loss": 0.095,
        "grad_norm": 0.02352994866669178,
        "learning_rate": 2.356067316209035e-06,
        "epoch": 7.643932683790966,
        "step": 8630
    },
    {
        "loss": 0.0456,
        "grad_norm": 0.007204934023320675,
        "learning_rate": 2.347209920283437e-06,
        "epoch": 7.6527900797165636,
        "step": 8640
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.006640011444687843,
        "learning_rate": 2.338352524357839e-06,
        "epoch": 7.6616474756421615,
        "step": 8650
    },
    {
        "loss": 0.0225,
        "grad_norm": 0.05814892426133156,
        "learning_rate": 2.3294951284322413e-06,
        "epoch": 7.6705048715677595,
        "step": 8660
    },
    {
        "loss": 0.0124,
        "grad_norm": 0.016395919024944305,
        "learning_rate": 2.320637732506643e-06,
        "epoch": 7.679362267493357,
        "step": 8670
    },
    {
        "loss": 0.0488,
        "grad_norm": 0.007625228259712458,
        "learning_rate": 2.3117803365810454e-06,
        "epoch": 7.688219663418955,
        "step": 8680
    },
    {
        "loss": 0.006,
        "grad_norm": 0.016308989375829697,
        "learning_rate": 2.3029229406554474e-06,
        "epoch": 7.6970770593445526,
        "step": 8690
    },
    {
        "loss": 0.0038,
        "grad_norm": 0.01885802298784256,
        "learning_rate": 2.2940655447298495e-06,
        "epoch": 7.7059344552701505,
        "step": 8700
    },
    {
        "loss": 0.0545,
        "grad_norm": 0.010665998794138432,
        "learning_rate": 2.285208148804252e-06,
        "epoch": 7.7147918511957485,
        "step": 8710
    },
    {
        "loss": 0.007,
        "grad_norm": 0.03696433827280998,
        "learning_rate": 2.276350752878654e-06,
        "epoch": 7.7236492471213465,
        "step": 8720
    },
    {
        "loss": 0.0339,
        "grad_norm": 0.021025976166129112,
        "learning_rate": 2.267493356953056e-06,
        "epoch": 7.7325066430469445,
        "step": 8730
    },
    {
        "loss": 0.0599,
        "grad_norm": 0.011991902254521847,
        "learning_rate": 2.258635961027458e-06,
        "epoch": 7.741364038972542,
        "step": 8740
    },
    {
        "loss": 0.0088,
        "grad_norm": 0.016180986538529396,
        "learning_rate": 2.2497785651018605e-06,
        "epoch": 7.75022143489814,
        "step": 8750
    },
    {
        "loss": 0.0066,
        "grad_norm": 11.046844482421875,
        "learning_rate": 2.240921169176262e-06,
        "epoch": 7.7590788308237375,
        "step": 8760
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.027564112097024918,
        "learning_rate": 2.2320637732506645e-06,
        "epoch": 7.7679362267493355,
        "step": 8770
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.009325201623141766,
        "learning_rate": 2.2232063773250666e-06,
        "epoch": 7.7767936226749335,
        "step": 8780
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.04046140983700752,
        "learning_rate": 2.2143489813994686e-06,
        "epoch": 7.785651018600531,
        "step": 8790
    },
    {
        "loss": 0.0331,
        "grad_norm": 135.13609313964844,
        "learning_rate": 2.205491585473871e-06,
        "epoch": 7.794508414526129,
        "step": 8800
    },
    {
        "loss": 0.043,
        "grad_norm": 0.013556759804487228,
        "learning_rate": 2.196634189548273e-06,
        "epoch": 7.803365810451727,
        "step": 8810
    },
    {
        "loss": 0.0516,
        "grad_norm": 0.45622560381889343,
        "learning_rate": 2.187776793622675e-06,
        "epoch": 7.812223206377325,
        "step": 8820
    },
    {
        "loss": 0.0054,
        "grad_norm": 0.09921654313802719,
        "learning_rate": 2.178919397697077e-06,
        "epoch": 7.8210806023029225,
        "step": 8830
    },
    {
        "loss": 0.0164,
        "grad_norm": 0.1970716118812561,
        "learning_rate": 2.170062001771479e-06,
        "epoch": 7.82993799822852,
        "step": 8840
    },
    {
        "loss": 0.0268,
        "grad_norm": 0.012106411159038544,
        "learning_rate": 2.1612046058458816e-06,
        "epoch": 7.838795394154118,
        "step": 8850
    },
    {
        "loss": 0.0208,
        "grad_norm": 0.030084805563092232,
        "learning_rate": 2.1523472099202837e-06,
        "epoch": 7.847652790079716,
        "step": 8860
    },
    {
        "loss": 0.0535,
        "grad_norm": 0.0912383496761322,
        "learning_rate": 2.1434898139946857e-06,
        "epoch": 7.856510186005314,
        "step": 8870
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.1435600221157074,
        "learning_rate": 2.1346324180690877e-06,
        "epoch": 7.865367581930912,
        "step": 8880
    },
    {
        "loss": 0.0382,
        "grad_norm": 0.36501896381378174,
        "learning_rate": 2.12577502214349e-06,
        "epoch": 7.87422497785651,
        "step": 8890
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0074068764224648476,
        "learning_rate": 2.116917626217892e-06,
        "epoch": 7.883082373782108,
        "step": 8900
    },
    {
        "loss": 0.0291,
        "grad_norm": 0.023493032902479172,
        "learning_rate": 2.1080602302922943e-06,
        "epoch": 7.891939769707706,
        "step": 8910
    },
    {
        "loss": 0.0258,
        "grad_norm": 2.9984130859375,
        "learning_rate": 2.0992028343666963e-06,
        "epoch": 7.900797165633303,
        "step": 8920
    },
    {
        "loss": 0.0225,
        "grad_norm": 0.19906902313232422,
        "learning_rate": 2.0903454384410983e-06,
        "epoch": 7.909654561558901,
        "step": 8930
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.022467859089374542,
        "learning_rate": 2.0814880425155008e-06,
        "epoch": 7.918511957484499,
        "step": 8940
    },
    {
        "loss": 0.0844,
        "grad_norm": 0.018969567492604256,
        "learning_rate": 2.072630646589903e-06,
        "epoch": 7.927369353410097,
        "step": 8950
    },
    {
        "loss": 0.0127,
        "grad_norm": 0.007749895565211773,
        "learning_rate": 2.063773250664305e-06,
        "epoch": 7.936226749335695,
        "step": 8960
    },
    {
        "loss": 0.0051,
        "grad_norm": 0.010781780816614628,
        "learning_rate": 2.054915854738707e-06,
        "epoch": 7.945084145261293,
        "step": 8970
    },
    {
        "loss": 0.0074,
        "grad_norm": 0.013266906142234802,
        "learning_rate": 2.046058458813109e-06,
        "epoch": 7.953941541186891,
        "step": 8980
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.004789508879184723,
        "learning_rate": 2.0372010628875114e-06,
        "epoch": 7.962798937112489,
        "step": 8990
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.005204222165048122,
        "learning_rate": 2.0283436669619134e-06,
        "epoch": 7.971656333038087,
        "step": 9000
    },
    {
        "loss": 0.1193,
        "grad_norm": 67.35662078857422,
        "learning_rate": 2.0194862710363154e-06,
        "epoch": 7.980513728963684,
        "step": 9010
    },
    {
        "loss": 0.0562,
        "grad_norm": 81.87479400634766,
        "learning_rate": 2.0106288751107175e-06,
        "epoch": 7.989371124889282,
        "step": 9020
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.05347680300474167,
        "learning_rate": 2.00177147918512e-06,
        "epoch": 7.99822852081488,
        "step": 9030
    },
    {
        "eval_loss": 0.14597368240356445,
        "eval_accuracy": 0.9814,
        "eval_precision": 0.98375,
        "eval_recall": 0.97896,
        "eval_f1": 0.98135,
        "eval_runtime": 149.3093,
        "eval_samples_per_second": 60.485,
        "eval_steps_per_second": 3.784,
        "epoch": 8.0,
        "step": 9032
    },
    {
        "loss": 0.0616,
        "grad_norm": 0.02264028787612915,
        "learning_rate": 1.9929140832595215e-06,
        "epoch": 8.007085916740479,
        "step": 9040
    },
    {
        "loss": 0.0298,
        "grad_norm": 0.015028156340122223,
        "learning_rate": 1.984056687333924e-06,
        "epoch": 8.015943312666076,
        "step": 9050
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.02007201686501503,
        "learning_rate": 1.975199291408326e-06,
        "epoch": 8.024800708591673,
        "step": 9060
    },
    {
        "loss": 0.045,
        "grad_norm": 0.01677427813410759,
        "learning_rate": 1.966341895482728e-06,
        "epoch": 8.033658104517272,
        "step": 9070
    },
    {
        "loss": 0.0489,
        "grad_norm": 1.1308320760726929,
        "learning_rate": 1.9574844995571305e-06,
        "epoch": 8.04251550044287,
        "step": 9080
    },
    {
        "loss": 0.0267,
        "grad_norm": 0.016211867332458496,
        "learning_rate": 1.9486271036315325e-06,
        "epoch": 8.051372896368468,
        "step": 9090
    },
    {
        "loss": 0.0608,
        "grad_norm": 0.028832383453845978,
        "learning_rate": 1.9397697077059346e-06,
        "epoch": 8.060230292294065,
        "step": 9100
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.008544991724193096,
        "learning_rate": 1.9309123117803366e-06,
        "epoch": 8.069087688219664,
        "step": 9110
    },
    {
        "loss": 0.0392,
        "grad_norm": 15.832642555236816,
        "learning_rate": 1.922054915854739e-06,
        "epoch": 8.077945084145261,
        "step": 9120
    },
    {
        "loss": 0.0222,
        "grad_norm": 0.015049724839627743,
        "learning_rate": 1.913197519929141e-06,
        "epoch": 8.08680248007086,
        "step": 9130
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.014309346675872803,
        "learning_rate": 1.9043401240035431e-06,
        "epoch": 8.095659875996457,
        "step": 9140
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.009002293460071087,
        "learning_rate": 1.8954827280779454e-06,
        "epoch": 8.104517271922054,
        "step": 9150
    },
    {
        "loss": 0.0493,
        "grad_norm": 0.012168657034635544,
        "learning_rate": 1.8866253321523472e-06,
        "epoch": 8.113374667847653,
        "step": 9160
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.02667599730193615,
        "learning_rate": 1.8777679362267494e-06,
        "epoch": 8.12223206377325,
        "step": 9170
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.06962217390537262,
        "learning_rate": 1.8689105403011515e-06,
        "epoch": 8.131089459698849,
        "step": 9180
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0797651931643486,
        "learning_rate": 1.8600531443755537e-06,
        "epoch": 8.139946855624446,
        "step": 9190
    },
    {
        "loss": 0.0227,
        "grad_norm": 0.004991242196410894,
        "learning_rate": 1.851195748449956e-06,
        "epoch": 8.148804251550045,
        "step": 9200
    },
    {
        "loss": 0.0282,
        "grad_norm": 0.010115164332091808,
        "learning_rate": 1.842338352524358e-06,
        "epoch": 8.157661647475642,
        "step": 9210
    },
    {
        "loss": 0.0047,
        "grad_norm": 0.060442835092544556,
        "learning_rate": 1.8334809565987602e-06,
        "epoch": 8.166519043401241,
        "step": 9220
    },
    {
        "loss": 0.0018,
        "grad_norm": 0.07915115356445312,
        "learning_rate": 1.824623560673162e-06,
        "epoch": 8.175376439326838,
        "step": 9230
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.020125234499573708,
        "learning_rate": 1.8157661647475643e-06,
        "epoch": 8.184233835252435,
        "step": 9240
    },
    {
        "loss": 0.039,
        "grad_norm": 0.023697445169091225,
        "learning_rate": 1.8069087688219663e-06,
        "epoch": 8.193091231178034,
        "step": 9250
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.006046309135854244,
        "learning_rate": 1.7980513728963686e-06,
        "epoch": 8.201948627103631,
        "step": 9260
    },
    {
        "loss": 0.0415,
        "grad_norm": 0.016353905200958252,
        "learning_rate": 1.7891939769707708e-06,
        "epoch": 8.21080602302923,
        "step": 9270
    },
    {
        "loss": 0.0024,
        "grad_norm": 0.026875915005803108,
        "learning_rate": 1.7803365810451729e-06,
        "epoch": 8.219663418954827,
        "step": 9280
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.22854088246822357,
        "learning_rate": 1.771479185119575e-06,
        "epoch": 8.228520814880426,
        "step": 9290
    },
    {
        "loss": 0.0577,
        "grad_norm": 0.010778618976473808,
        "learning_rate": 1.7626217891939771e-06,
        "epoch": 8.237378210806023,
        "step": 9300
    },
    {
        "loss": 0.06,
        "grad_norm": 0.015782363712787628,
        "learning_rate": 1.7537643932683794e-06,
        "epoch": 8.24623560673162,
        "step": 9310
    },
    {
        "loss": 0.0055,
        "grad_norm": 2.488149642944336,
        "learning_rate": 1.7449069973427812e-06,
        "epoch": 8.255093002657219,
        "step": 9320
    },
    {
        "loss": 0.0112,
        "grad_norm": 0.38531169295310974,
        "learning_rate": 1.7360496014171834e-06,
        "epoch": 8.263950398582816,
        "step": 9330
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02680744044482708,
        "learning_rate": 1.7271922054915857e-06,
        "epoch": 8.272807794508415,
        "step": 9340
    },
    {
        "loss": 0.0357,
        "grad_norm": 0.3162192404270172,
        "learning_rate": 1.7183348095659877e-06,
        "epoch": 8.281665190434012,
        "step": 9350
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.05958518013358116,
        "learning_rate": 1.70947741364039e-06,
        "epoch": 8.29052258635961,
        "step": 9360
    },
    {
        "loss": 0.0037,
        "grad_norm": 106.00542449951172,
        "learning_rate": 1.700620017714792e-06,
        "epoch": 8.299379982285208,
        "step": 9370
    },
    {
        "loss": 0.0425,
        "grad_norm": 0.01143196877092123,
        "learning_rate": 1.6917626217891942e-06,
        "epoch": 8.308237378210807,
        "step": 9380
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.002840218134224415,
        "learning_rate": 1.682905225863596e-06,
        "epoch": 8.317094774136404,
        "step": 9390
    },
    {
        "loss": 0.0176,
        "grad_norm": 0.012328592129051685,
        "learning_rate": 1.6740478299379983e-06,
        "epoch": 8.325952170062001,
        "step": 9400
    },
    {
        "loss": 0.0389,
        "grad_norm": 0.006035411264747381,
        "learning_rate": 1.6651904340124005e-06,
        "epoch": 8.3348095659876,
        "step": 9410
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.013699298724532127,
        "learning_rate": 1.6563330380868026e-06,
        "epoch": 8.343666961913197,
        "step": 9420
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.030863407999277115,
        "learning_rate": 1.6474756421612048e-06,
        "epoch": 8.352524357838796,
        "step": 9430
    },
    {
        "loss": 0.0146,
        "grad_norm": 1.618455171585083,
        "learning_rate": 1.6386182462356069e-06,
        "epoch": 8.361381753764393,
        "step": 9440
    },
    {
        "loss": 0.0038,
        "grad_norm": 0.03576558828353882,
        "learning_rate": 1.629760850310009e-06,
        "epoch": 8.370239149689992,
        "step": 9450
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.003318847855553031,
        "learning_rate": 1.620903454384411e-06,
        "epoch": 8.379096545615589,
        "step": 9460
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005660391878336668,
        "learning_rate": 1.6120460584588132e-06,
        "epoch": 8.387953941541188,
        "step": 9470
    },
    {
        "loss": 0.0683,
        "grad_norm": 0.0035122819244861603,
        "learning_rate": 1.6031886625332154e-06,
        "epoch": 8.396811337466785,
        "step": 9480
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.009200319647789001,
        "learning_rate": 1.5943312666076174e-06,
        "epoch": 8.405668733392382,
        "step": 9490
    },
    {
        "loss": 0.0495,
        "grad_norm": 64.84783172607422,
        "learning_rate": 1.5854738706820197e-06,
        "epoch": 8.41452612931798,
        "step": 9500
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.010700648650527,
        "learning_rate": 1.5766164747564217e-06,
        "epoch": 8.423383525243578,
        "step": 9510
    },
    {
        "loss": 0.0429,
        "grad_norm": 0.013122031465172768,
        "learning_rate": 1.567759078830824e-06,
        "epoch": 8.432240921169177,
        "step": 9520
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.011704152449965477,
        "learning_rate": 1.5589016829052258e-06,
        "epoch": 8.441098317094774,
        "step": 9530
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007609162013977766,
        "learning_rate": 1.550044286979628e-06,
        "epoch": 8.449955713020373,
        "step": 9540
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004215904977172613,
        "learning_rate": 1.5411868910540303e-06,
        "epoch": 8.45881310894597,
        "step": 9550
    },
    {
        "loss": 0.1345,
        "grad_norm": 49.773033142089844,
        "learning_rate": 1.5323294951284323e-06,
        "epoch": 8.467670504871569,
        "step": 9560
    },
    {
        "loss": 0.0438,
        "grad_norm": 0.005507118068635464,
        "learning_rate": 1.5234720992028345e-06,
        "epoch": 8.476527900797166,
        "step": 9570
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.017825493589043617,
        "learning_rate": 1.5146147032772366e-06,
        "epoch": 8.485385296722763,
        "step": 9580
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.006522131618112326,
        "learning_rate": 1.5057573073516388e-06,
        "epoch": 8.494242692648362,
        "step": 9590
    },
    {
        "loss": 0.0533,
        "grad_norm": 0.03618261590600014,
        "learning_rate": 1.4968999114260406e-06,
        "epoch": 8.503100088573959,
        "step": 9600
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.023233480751514435,
        "learning_rate": 1.4880425155004429e-06,
        "epoch": 8.511957484499558,
        "step": 9610
    },
    {
        "loss": 0.0205,
        "grad_norm": 228.31118774414062,
        "learning_rate": 1.4791851195748451e-06,
        "epoch": 8.520814880425155,
        "step": 9620
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.014217880554497242,
        "learning_rate": 1.4703277236492472e-06,
        "epoch": 8.529672276350754,
        "step": 9630
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.007378678768873215,
        "learning_rate": 1.4614703277236494e-06,
        "epoch": 8.53852967227635,
        "step": 9640
    },
    {
        "loss": 0.0028,
        "grad_norm": 0.0028188899159431458,
        "learning_rate": 1.4526129317980514e-06,
        "epoch": 8.54738706820195,
        "step": 9650
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005162347573786974,
        "learning_rate": 1.4437555358724537e-06,
        "epoch": 8.556244464127547,
        "step": 9660
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.04491870105266571,
        "learning_rate": 1.4348981399468557e-06,
        "epoch": 8.565101860053144,
        "step": 9670
    },
    {
        "loss": 0.0483,
        "grad_norm": 0.03048979677259922,
        "learning_rate": 1.426040744021258e-06,
        "epoch": 8.573959255978743,
        "step": 9680
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007779773324728012,
        "learning_rate": 1.4171833480956602e-06,
        "epoch": 8.58281665190434,
        "step": 9690
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.09135205298662186,
        "learning_rate": 1.408325952170062e-06,
        "epoch": 8.591674047829938,
        "step": 9700
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004307484719902277,
        "learning_rate": 1.3994685562444643e-06,
        "epoch": 8.600531443755536,
        "step": 9710
    },
    {
        "loss": 0.0774,
        "grad_norm": 0.05705445632338524,
        "learning_rate": 1.3906111603188663e-06,
        "epoch": 8.609388839681134,
        "step": 9720
    },
    {
        "loss": 0.0453,
        "grad_norm": 0.0034506614319980145,
        "learning_rate": 1.3817537643932685e-06,
        "epoch": 8.618246235606732,
        "step": 9730
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0042650229297578335,
        "learning_rate": 1.3728963684676706e-06,
        "epoch": 8.627103631532329,
        "step": 9740
    },
    {
        "loss": 0.0172,
        "grad_norm": 194.0003662109375,
        "learning_rate": 1.3640389725420728e-06,
        "epoch": 8.635961027457927,
        "step": 9750
    },
    {
        "loss": 0.0888,
        "grad_norm": 0.02203526720404625,
        "learning_rate": 1.355181576616475e-06,
        "epoch": 8.644818423383525,
        "step": 9760
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005869186483323574,
        "learning_rate": 1.3463241806908769e-06,
        "epoch": 8.653675819309123,
        "step": 9770
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005983020178973675,
        "learning_rate": 1.3374667847652791e-06,
        "epoch": 8.66253321523472,
        "step": 9780
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.08555569499731064,
        "learning_rate": 1.3286093888396812e-06,
        "epoch": 8.67139061116032,
        "step": 9790
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03470529243350029,
        "learning_rate": 1.3197519929140834e-06,
        "epoch": 8.680248007085916,
        "step": 9800
    },
    {
        "loss": 0.0007,
        "grad_norm": 18.523895263671875,
        "learning_rate": 1.3108945969884854e-06,
        "epoch": 8.689105403011515,
        "step": 9810
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.16706615686416626,
        "learning_rate": 1.3020372010628877e-06,
        "epoch": 8.697962798937112,
        "step": 9820
    },
    {
        "loss": 0.0575,
        "grad_norm": 0.0027474388480186462,
        "learning_rate": 1.29317980513729e-06,
        "epoch": 8.706820194862711,
        "step": 9830
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0063910894095897675,
        "learning_rate": 1.2843224092116918e-06,
        "epoch": 8.715677590788308,
        "step": 9840
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004220059607177973,
        "learning_rate": 1.275465013286094e-06,
        "epoch": 8.724534986713905,
        "step": 9850
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03574496880173683,
        "learning_rate": 1.266607617360496e-06,
        "epoch": 8.733392382639504,
        "step": 9860
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.05241865664720535,
        "learning_rate": 1.2577502214348983e-06,
        "epoch": 8.742249778565101,
        "step": 9870
    },
    {
        "loss": 0.0309,
        "grad_norm": 0.004717282485216856,
        "learning_rate": 1.2488928255093003e-06,
        "epoch": 8.7511071744907,
        "step": 9880
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0038255394902080297,
        "learning_rate": 1.2400354295837025e-06,
        "epoch": 8.759964570416297,
        "step": 9890
    },
    {
        "loss": 0.0351,
        "grad_norm": 0.003665827913209796,
        "learning_rate": 1.2311780336581046e-06,
        "epoch": 8.768821966341896,
        "step": 9900
    },
    {
        "loss": 0.0078,
        "grad_norm": 0.011858451180160046,
        "learning_rate": 1.2223206377325066e-06,
        "epoch": 8.777679362267493,
        "step": 9910
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0028986018151044846,
        "learning_rate": 1.2134632418069089e-06,
        "epoch": 8.78653675819309,
        "step": 9920
    },
    {
        "loss": 0.064,
        "grad_norm": 0.08481370657682419,
        "learning_rate": 1.204605845881311e-06,
        "epoch": 8.79539415411869,
        "step": 9930
    },
    {
        "loss": 0.0079,
        "grad_norm": 0.678399384021759,
        "learning_rate": 1.1957484499557131e-06,
        "epoch": 8.804251550044286,
        "step": 9940
    },
    {
        "loss": 0.0028,
        "grad_norm": 14.824946403503418,
        "learning_rate": 1.1868910540301152e-06,
        "epoch": 8.813108945969885,
        "step": 9950
    },
    {
        "loss": 0.0374,
        "grad_norm": 0.0029887708369642496,
        "learning_rate": 1.1780336581045174e-06,
        "epoch": 8.821966341895482,
        "step": 9960
    },
    {
        "loss": 0.0031,
        "grad_norm": 0.0063215564005076885,
        "learning_rate": 1.1691762621789194e-06,
        "epoch": 8.830823737821081,
        "step": 9970
    },
    {
        "loss": 0.0555,
        "grad_norm": 0.005503666587173939,
        "learning_rate": 1.1603188662533215e-06,
        "epoch": 8.839681133746678,
        "step": 9980
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0036085769534111023,
        "learning_rate": 1.1514614703277237e-06,
        "epoch": 8.848538529672277,
        "step": 9990
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00611084746196866,
        "learning_rate": 1.142604074402126e-06,
        "epoch": 8.857395925597874,
        "step": 10000
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.004848782438784838,
        "learning_rate": 1.133746678476528e-06,
        "epoch": 8.866253321523471,
        "step": 10010
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.013250639662146568,
        "learning_rate": 1.1248892825509302e-06,
        "epoch": 8.87511071744907,
        "step": 10020
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.009062230587005615,
        "learning_rate": 1.1160318866253323e-06,
        "epoch": 8.883968113374667,
        "step": 10030
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002791118575260043,
        "learning_rate": 1.1071744906997343e-06,
        "epoch": 8.892825509300266,
        "step": 10040
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.03586122393608093,
        "learning_rate": 1.0983170947741365e-06,
        "epoch": 8.901682905225863,
        "step": 10050
    },
    {
        "loss": 0.0457,
        "grad_norm": 0.004910742864012718,
        "learning_rate": 1.0894596988485386e-06,
        "epoch": 8.910540301151462,
        "step": 10060
    },
    {
        "loss": 0.0022,
        "grad_norm": 102.71076202392578,
        "learning_rate": 1.0806023029229408e-06,
        "epoch": 8.91939769707706,
        "step": 10070
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.003916494082659483,
        "learning_rate": 1.0717449069973429e-06,
        "epoch": 8.928255093002658,
        "step": 10080
    },
    {
        "loss": 0.0538,
        "grad_norm": 0.0034314817748963833,
        "learning_rate": 1.062887511071745e-06,
        "epoch": 8.937112488928255,
        "step": 10090
    },
    {
        "loss": 0.0534,
        "grad_norm": 0.019349386915564537,
        "learning_rate": 1.0540301151461471e-06,
        "epoch": 8.945969884853852,
        "step": 10100
    },
    {
        "loss": 0.0055,
        "grad_norm": 0.010474267415702343,
        "learning_rate": 1.0451727192205492e-06,
        "epoch": 8.954827280779451,
        "step": 10110
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02854795753955841,
        "learning_rate": 1.0363153232949514e-06,
        "epoch": 8.963684676705048,
        "step": 10120
    },
    {
        "loss": 0.0073,
        "grad_norm": 0.005789441056549549,
        "learning_rate": 1.0274579273693534e-06,
        "epoch": 8.972542072630647,
        "step": 10130
    },
    {
        "loss": 0.0518,
        "grad_norm": 5.442429542541504,
        "learning_rate": 1.0186005314437557e-06,
        "epoch": 8.981399468556244,
        "step": 10140
    },
    {
        "loss": 0.0003,
        "grad_norm": 7.0408549308776855,
        "learning_rate": 1.0097431355181577e-06,
        "epoch": 8.990256864481843,
        "step": 10150
    },
    {
        "loss": 0.0099,
        "grad_norm": 0.008568930439651012,
        "learning_rate": 1.00088573959256e-06,
        "epoch": 8.99911426040744,
        "step": 10160
    },
    {
        "eval_loss": 0.14852096140384674,
        "eval_accuracy": 0.98184,
        "eval_precision": 0.98056,
        "eval_recall": 0.98317,
        "eval_f1": 0.98186,
        "eval_runtime": 148.9381,
        "eval_samples_per_second": 60.636,
        "eval_steps_per_second": 3.794,
        "epoch": 9.0,
        "step": 10161
    },
    {
        "loss": 0.0388,
        "grad_norm": 0.002105802297592163,
        "learning_rate": 9.92028343666962e-07,
        "epoch": 9.007971656333037,
        "step": 10170
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.013240735977888107,
        "learning_rate": 9.83170947741364e-07,
        "epoch": 9.016829052258636,
        "step": 10180
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006024904549121857,
        "learning_rate": 9.743135518157663e-07,
        "epoch": 9.025686448184233,
        "step": 10190
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003514389507472515,
        "learning_rate": 9.654561558901683e-07,
        "epoch": 9.034543844109832,
        "step": 10200
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003838179400190711,
        "learning_rate": 9.565987599645705e-07,
        "epoch": 9.043401240035429,
        "step": 10210
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006277074571698904,
        "learning_rate": 9.477413640389727e-07,
        "epoch": 9.052258635961028,
        "step": 10220
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006913589313626289,
        "learning_rate": 9.388839681133747e-07,
        "epoch": 9.061116031886625,
        "step": 10230
    },
    {
        "loss": 0.0523,
        "grad_norm": 0.004139580763876438,
        "learning_rate": 9.300265721877769e-07,
        "epoch": 9.069973427812224,
        "step": 10240
    },
    {
        "loss": 0.0246,
        "grad_norm": 0.006600780412554741,
        "learning_rate": 9.21169176262179e-07,
        "epoch": 9.078830823737821,
        "step": 10250
    },
    {
        "loss": 0.0321,
        "grad_norm": 0.009923901408910751,
        "learning_rate": 9.12311780336581e-07,
        "epoch": 9.087688219663418,
        "step": 10260
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0054943496361374855,
        "learning_rate": 9.034543844109832e-07,
        "epoch": 9.096545615589017,
        "step": 10270
    },
    {
        "loss": 0.0044,
        "grad_norm": 0.007808546535670757,
        "learning_rate": 8.945969884853854e-07,
        "epoch": 9.105403011514614,
        "step": 10280
    },
    {
        "loss": 0.0425,
        "grad_norm": 0.006556476932018995,
        "learning_rate": 8.857395925597875e-07,
        "epoch": 9.114260407440213,
        "step": 10290
    },
    {
        "loss": 0.0665,
        "grad_norm": 0.005416967440396547,
        "learning_rate": 8.768821966341897e-07,
        "epoch": 9.12311780336581,
        "step": 10300
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.007497281301766634,
        "learning_rate": 8.680248007085917e-07,
        "epoch": 9.131975199291409,
        "step": 10310
    },
    {
        "loss": 0.0286,
        "grad_norm": 0.008074712939560413,
        "learning_rate": 8.591674047829939e-07,
        "epoch": 9.140832595217006,
        "step": 10320
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005444150883704424,
        "learning_rate": 8.50310008857396e-07,
        "epoch": 9.149689991142605,
        "step": 10330
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004091526381671429,
        "learning_rate": 8.41452612931798e-07,
        "epoch": 9.158547387068202,
        "step": 10340
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0028215660713613033,
        "learning_rate": 8.325952170062003e-07,
        "epoch": 9.167404782993799,
        "step": 10350
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004969732370227575,
        "learning_rate": 8.237378210806024e-07,
        "epoch": 9.176262178919398,
        "step": 10360
    },
    {
        "loss": 0.0563,
        "grad_norm": 0.013293887488543987,
        "learning_rate": 8.148804251550045e-07,
        "epoch": 9.185119574844995,
        "step": 10370
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006467451807111502,
        "learning_rate": 8.060230292294066e-07,
        "epoch": 9.193976970770594,
        "step": 10380
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.3951326012611389,
        "learning_rate": 7.971656333038087e-07,
        "epoch": 9.202834366696191,
        "step": 10390
    },
    {
        "loss": 0.0838,
        "grad_norm": 0.025112677365541458,
        "learning_rate": 7.883082373782109e-07,
        "epoch": 9.21169176262179,
        "step": 10400
    },
    {
        "loss": 0.0104,
        "grad_norm": 0.0042686560191214085,
        "learning_rate": 7.794508414526129e-07,
        "epoch": 9.220549158547387,
        "step": 10410
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008839031681418419,
        "learning_rate": 7.705934455270151e-07,
        "epoch": 9.229406554472986,
        "step": 10420
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0030669025145471096,
        "learning_rate": 7.617360496014173e-07,
        "epoch": 9.238263950398583,
        "step": 10430
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.015201552771031857,
        "learning_rate": 7.528786536758194e-07,
        "epoch": 9.24712134632418,
        "step": 10440
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019375612027943134,
        "learning_rate": 7.440212577502214e-07,
        "epoch": 9.255978742249779,
        "step": 10450
    },
    {
        "loss": 0.0446,
        "grad_norm": 0.06815365701913834,
        "learning_rate": 7.351638618246236e-07,
        "epoch": 9.264836138175376,
        "step": 10460
    },
    {
        "loss": 0.046,
        "grad_norm": 0.1791725754737854,
        "learning_rate": 7.263064658990257e-07,
        "epoch": 9.273693534100975,
        "step": 10470
    },
    {
        "loss": 0.0628,
        "grad_norm": 0.003809838555753231,
        "learning_rate": 7.174490699734279e-07,
        "epoch": 9.282550930026572,
        "step": 10480
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003919784910976887,
        "learning_rate": 7.085916740478301e-07,
        "epoch": 9.29140832595217,
        "step": 10490
    },
    {
        "loss": 0.0775,
        "grad_norm": 0.012665152549743652,
        "learning_rate": 6.997342781222321e-07,
        "epoch": 9.300265721877768,
        "step": 10500
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0035422835499048233,
        "learning_rate": 6.908768821966343e-07,
        "epoch": 9.309123117803367,
        "step": 10510
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004622208885848522,
        "learning_rate": 6.820194862710364e-07,
        "epoch": 9.317980513728964,
        "step": 10520
    },
    {
        "loss": 0.048,
        "grad_norm": 0.004079402890056372,
        "learning_rate": 6.731620903454384e-07,
        "epoch": 9.32683790965456,
        "step": 10530
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.005064872559159994,
        "learning_rate": 6.643046944198406e-07,
        "epoch": 9.33569530558016,
        "step": 10540
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0026885392144322395,
        "learning_rate": 6.554472984942427e-07,
        "epoch": 9.344552701505757,
        "step": 10550
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.009487410075962543,
        "learning_rate": 6.46589902568645e-07,
        "epoch": 9.353410097431356,
        "step": 10560
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004116796888411045,
        "learning_rate": 6.37732506643047e-07,
        "epoch": 9.362267493356953,
        "step": 10570
    },
    {
        "loss": 0.0006,
        "grad_norm": 20.465105056762695,
        "learning_rate": 6.288751107174491e-07,
        "epoch": 9.371124889282552,
        "step": 10580
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.011733774095773697,
        "learning_rate": 6.200177147918513e-07,
        "epoch": 9.379982285208149,
        "step": 10590
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.043372612446546555,
        "learning_rate": 6.111603188662533e-07,
        "epoch": 9.388839681133746,
        "step": 10600
    },
    {
        "loss": 0.1045,
        "grad_norm": 49.33637619018555,
        "learning_rate": 6.023029229406556e-07,
        "epoch": 9.397697077059345,
        "step": 10610
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.002435504226014018,
        "learning_rate": 5.934455270150576e-07,
        "epoch": 9.406554472984942,
        "step": 10620
    },
    {
        "loss": 0.0224,
        "grad_norm": 0.00658379215747118,
        "learning_rate": 5.845881310894597e-07,
        "epoch": 9.41541186891054,
        "step": 10630
    },
    {
        "loss": 0.0446,
        "grad_norm": 0.019480377435684204,
        "learning_rate": 5.757307351638619e-07,
        "epoch": 9.424269264836138,
        "step": 10640
    },
    {
        "loss": 0.0184,
        "grad_norm": 0.009732258506119251,
        "learning_rate": 5.66873339238264e-07,
        "epoch": 9.433126660761737,
        "step": 10650
    },
    {
        "loss": 0.0245,
        "grad_norm": 0.0019793198443949223,
        "learning_rate": 5.580159433126661e-07,
        "epoch": 9.441984056687334,
        "step": 10660
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002713131019845605,
        "learning_rate": 5.491585473870683e-07,
        "epoch": 9.450841452612933,
        "step": 10670
    },
    {
        "loss": 0.0001,
        "grad_norm": 1.2679178714752197,
        "learning_rate": 5.403011514614704e-07,
        "epoch": 9.45969884853853,
        "step": 10680
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.005105252377688885,
        "learning_rate": 5.314437555358726e-07,
        "epoch": 9.468556244464127,
        "step": 10690
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.005612675100564957,
        "learning_rate": 5.225863596102746e-07,
        "epoch": 9.477413640389726,
        "step": 10700
    },
    {
        "loss": 0.0382,
        "grad_norm": 0.003993539605289698,
        "learning_rate": 5.137289636846767e-07,
        "epoch": 9.486271036315323,
        "step": 10710
    },
    {
        "loss": 0.0001,
        "grad_norm": 1.6334888935089111,
        "learning_rate": 5.048715677590789e-07,
        "epoch": 9.495128432240922,
        "step": 10720
    },
    {
        "loss": 0.0134,
        "grad_norm": 127.58133697509766,
        "learning_rate": 4.96014171833481e-07,
        "epoch": 9.503985828166519,
        "step": 10730
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0043450091034173965,
        "learning_rate": 4.871567759078831e-07,
        "epoch": 9.512843224092117,
        "step": 10740
    },
    {
        "loss": 0.0034,
        "grad_norm": 0.007437828928232193,
        "learning_rate": 4.782993799822853e-07,
        "epoch": 9.521700620017715,
        "step": 10750
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004005101043730974,
        "learning_rate": 4.6944198405668736e-07,
        "epoch": 9.530558015943313,
        "step": 10760
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.0045649828389286995,
        "learning_rate": 4.605845881310895e-07,
        "epoch": 9.53941541186891,
        "step": 10770
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005155628547072411,
        "learning_rate": 4.517271922054916e-07,
        "epoch": 9.548272807794508,
        "step": 10780
    },
    {
        "loss": 0.0699,
        "grad_norm": 197.06765747070312,
        "learning_rate": 4.428697962798938e-07,
        "epoch": 9.557130203720106,
        "step": 10790
    },
    {
        "loss": 0.0111,
        "grad_norm": 0.0022718259133398533,
        "learning_rate": 4.3401240035429586e-07,
        "epoch": 9.565987599645704,
        "step": 10800
    },
    {
        "loss": 0.0152,
        "grad_norm": 0.12283714860677719,
        "learning_rate": 4.25155004428698e-07,
        "epoch": 9.574844995571302,
        "step": 10810
    },
    {
        "loss": 0.0177,
        "grad_norm": 193.6077880859375,
        "learning_rate": 4.1629760850310014e-07,
        "epoch": 9.5837023914969,
        "step": 10820
    },
    {
        "loss": 0.0002,
        "grad_norm": 1.9973275661468506,
        "learning_rate": 4.074402125775023e-07,
        "epoch": 9.592559787422498,
        "step": 10830
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018083404283970594,
        "learning_rate": 3.9858281665190436e-07,
        "epoch": 9.601417183348095,
        "step": 10840
    },
    {
        "loss": 0.0206,
        "grad_norm": 0.0020229166839271784,
        "learning_rate": 3.8972542072630645e-07,
        "epoch": 9.610274579273694,
        "step": 10850
    },
    {
        "loss": 0.0442,
        "grad_norm": 0.012647311203181744,
        "learning_rate": 3.8086802480070864e-07,
        "epoch": 9.619131975199291,
        "step": 10860
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0029191935900598764,
        "learning_rate": 3.720106288751107e-07,
        "epoch": 9.627989371124889,
        "step": 10870
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004173770546913147,
        "learning_rate": 3.6315323294951286e-07,
        "epoch": 9.636846767050487,
        "step": 10880
    },
    {
        "loss": 0.0049,
        "grad_norm": 0.006632171105593443,
        "learning_rate": 3.5429583702391505e-07,
        "epoch": 9.645704162976084,
        "step": 10890
    },
    {
        "loss": 0.025,
        "grad_norm": 0.007557975593954325,
        "learning_rate": 3.4543844109831714e-07,
        "epoch": 9.654561558901683,
        "step": 10900
    },
    {
        "loss": 0.0572,
        "grad_norm": 0.0023486455902457237,
        "learning_rate": 3.365810451727192e-07,
        "epoch": 9.66341895482728,
        "step": 10910
    },
    {
        "loss": 0.0091,
        "grad_norm": 0.027939289808273315,
        "learning_rate": 3.2772364924712136e-07,
        "epoch": 9.67227635075288,
        "step": 10920
    },
    {
        "loss": 0.0354,
        "grad_norm": 0.0066030677407979965,
        "learning_rate": 3.188662533215235e-07,
        "epoch": 9.681133746678476,
        "step": 10930
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0019588894210755825,
        "learning_rate": 3.1000885739592564e-07,
        "epoch": 9.689991142604075,
        "step": 10940
    },
    {
        "loss": 0.0362,
        "grad_norm": 0.005853061098605394,
        "learning_rate": 3.011514614703278e-07,
        "epoch": 9.698848538529672,
        "step": 10950
    },
    {
        "loss": 0.01,
        "grad_norm": 0.0077770669013261795,
        "learning_rate": 2.9229406554472986e-07,
        "epoch": 9.70770593445527,
        "step": 10960
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.02366422489285469,
        "learning_rate": 2.83436669619132e-07,
        "epoch": 9.716563330380868,
        "step": 10970
    },
    {
        "loss": 0.0215,
        "grad_norm": 0.002825841773301363,
        "learning_rate": 2.7457927369353414e-07,
        "epoch": 9.725420726306465,
        "step": 10980
    },
    {
        "loss": 0.0232,
        "grad_norm": 0.017780296504497528,
        "learning_rate": 2.657218777679363e-07,
        "epoch": 9.734278122232064,
        "step": 10990
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.016028141602873802,
        "learning_rate": 2.5686448184233836e-07,
        "epoch": 9.743135518157661,
        "step": 11000
    },
    {
        "loss": 0.043,
        "grad_norm": 0.007647050078958273,
        "learning_rate": 2.480070859167405e-07,
        "epoch": 9.75199291408326,
        "step": 11010
    },
    {
        "loss": 0.0577,
        "grad_norm": 15.537784576416016,
        "learning_rate": 2.3914968999114264e-07,
        "epoch": 9.760850310008857,
        "step": 11020
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.04723522067070007,
        "learning_rate": 2.3029229406554475e-07,
        "epoch": 9.769707705934454,
        "step": 11030
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002781888470053673,
        "learning_rate": 2.214348981399469e-07,
        "epoch": 9.778565101860053,
        "step": 11040
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.004162203520536423,
        "learning_rate": 2.12577502214349e-07,
        "epoch": 9.78742249778565,
        "step": 11050
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005095427855849266,
        "learning_rate": 2.0372010628875114e-07,
        "epoch": 9.79627989371125,
        "step": 11060
    },
    {
        "loss": 0.0063,
        "grad_norm": 0.004791881889104843,
        "learning_rate": 1.9486271036315322e-07,
        "epoch": 9.805137289636846,
        "step": 11070
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.004210523795336485,
        "learning_rate": 1.8600531443755536e-07,
        "epoch": 9.813994685562445,
        "step": 11080
    },
    {
        "loss": 0.0259,
        "grad_norm": 0.005208284594118595,
        "learning_rate": 1.7714791851195753e-07,
        "epoch": 9.822852081488042,
        "step": 11090
    },
    {
        "loss": 0.0051,
        "grad_norm": 0.004498382564634085,
        "learning_rate": 1.682905225863596e-07,
        "epoch": 9.831709477413641,
        "step": 11100
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0034767314791679382,
        "learning_rate": 1.5943312666076175e-07,
        "epoch": 9.840566873339238,
        "step": 11110
    },
    {
        "loss": 0.0388,
        "grad_norm": 0.002154539804905653,
        "learning_rate": 1.505757307351639e-07,
        "epoch": 9.849424269264837,
        "step": 11120
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002371689770370722,
        "learning_rate": 1.41718334809566e-07,
        "epoch": 9.858281665190434,
        "step": 11130
    },
    {
        "loss": 0.002,
        "grad_norm": 0.062008071690797806,
        "learning_rate": 1.3286093888396814e-07,
        "epoch": 9.867139061116031,
        "step": 11140
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006223219912499189,
        "learning_rate": 1.2400354295837025e-07,
        "epoch": 9.87599645704163,
        "step": 11150
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008384786546230316,
        "learning_rate": 1.1514614703277237e-07,
        "epoch": 9.884853852967227,
        "step": 11160
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.02608605846762657,
        "learning_rate": 1.062887511071745e-07,
        "epoch": 9.893711248892826,
        "step": 11170
    },
    {
        "loss": 0.0434,
        "grad_norm": 0.010162516497075558,
        "learning_rate": 9.743135518157661e-08,
        "epoch": 9.902568644818423,
        "step": 11180
    },
    {
        "loss": 0.0,
        "grad_norm": 0.004123030696064234,
        "learning_rate": 8.857395925597876e-08,
        "epoch": 9.911426040744022,
        "step": 11190
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003912962507456541,
        "learning_rate": 7.971656333038087e-08,
        "epoch": 9.920283436669619,
        "step": 11200
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002765806159004569,
        "learning_rate": 7.0859167404783e-08,
        "epoch": 9.929140832595216,
        "step": 11210
    },
    {
        "loss": 0.0652,
        "grad_norm": 302.5634765625,
        "learning_rate": 6.200177147918512e-08,
        "epoch": 9.937998228520815,
        "step": 11220
    },
    {
        "loss": 0.0004,
        "grad_norm": 12.549975395202637,
        "learning_rate": 5.314437555358725e-08,
        "epoch": 9.946855624446412,
        "step": 11230
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.12267209589481354,
        "learning_rate": 4.428697962798938e-08,
        "epoch": 9.955713020372011,
        "step": 11240
    },
    {
        "loss": 0.001,
        "grad_norm": 23.784883499145508,
        "learning_rate": 3.54295837023915e-08,
        "epoch": 9.964570416297608,
        "step": 11250
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.009382042102515697,
        "learning_rate": 2.6572187776793625e-08,
        "epoch": 9.973427812223207,
        "step": 11260
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008911442942917347,
        "learning_rate": 1.771479185119575e-08,
        "epoch": 9.982285208148804,
        "step": 11270
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007229173555970192,
        "learning_rate": 8.857395925597875e-09,
        "epoch": 9.991142604074403,
        "step": 11280
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.001853901776485145,
        "learning_rate": 0.0,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "eval_loss": 0.15074771642684937,
        "eval_accuracy": 0.98239,
        "eval_precision": 0.98101,
        "eval_recall": 0.98383,
        "eval_f1": 0.98242,
        "eval_runtime": 149.1126,
        "eval_samples_per_second": 60.565,
        "eval_steps_per_second": 3.789,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "train_runtime": 10124.3279,
        "train_samples_per_second": 17.842,
        "train_steps_per_second": 1.115,
        "total_flos": 2.37641905201152e+16,
        "train_loss": 0.1563878100635094,
        "epoch": 10.0,
        "step": 11290
    }
]