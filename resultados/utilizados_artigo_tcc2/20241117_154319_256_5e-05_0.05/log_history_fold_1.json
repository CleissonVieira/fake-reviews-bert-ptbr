[
    {
        "loss": 0.6093,
        "grad_norm": 2.9723498821258545,
        "learning_rate": 4.9778761061946906e-05,
        "epoch": 0.04424778761061947,
        "step": 10
    },
    {
        "loss": 0.5641,
        "grad_norm": 3.0275046825408936,
        "learning_rate": 4.955752212389381e-05,
        "epoch": 0.08849557522123894,
        "step": 20
    },
    {
        "loss": 0.5496,
        "grad_norm": 2.683312177658081,
        "learning_rate": 4.9336283185840707e-05,
        "epoch": 0.13274336283185842,
        "step": 30
    },
    {
        "loss": 0.4228,
        "grad_norm": 6.748100280761719,
        "learning_rate": 4.911504424778761e-05,
        "epoch": 0.17699115044247787,
        "step": 40
    },
    {
        "loss": 0.4625,
        "grad_norm": 4.280717372894287,
        "learning_rate": 4.8893805309734514e-05,
        "epoch": 0.22123893805309736,
        "step": 50
    },
    {
        "loss": 0.5731,
        "grad_norm": 2.356167793273926,
        "learning_rate": 4.867256637168142e-05,
        "epoch": 0.26548672566371684,
        "step": 60
    },
    {
        "loss": 0.4731,
        "grad_norm": 5.498449802398682,
        "learning_rate": 4.845132743362832e-05,
        "epoch": 0.30973451327433627,
        "step": 70
    },
    {
        "loss": 0.5251,
        "grad_norm": 4.8790788650512695,
        "learning_rate": 4.823008849557522e-05,
        "epoch": 0.35398230088495575,
        "step": 80
    },
    {
        "loss": 0.4397,
        "grad_norm": 2.8370282649993896,
        "learning_rate": 4.800884955752213e-05,
        "epoch": 0.39823008849557523,
        "step": 90
    },
    {
        "loss": 0.375,
        "grad_norm": 4.9317193031311035,
        "learning_rate": 4.778761061946903e-05,
        "epoch": 0.4424778761061947,
        "step": 100
    },
    {
        "loss": 0.573,
        "grad_norm": 3.3232953548431396,
        "learning_rate": 4.7566371681415936e-05,
        "epoch": 0.48672566371681414,
        "step": 110
    },
    {
        "loss": 0.4646,
        "grad_norm": 2.135104179382324,
        "learning_rate": 4.734513274336283e-05,
        "epoch": 0.5309734513274337,
        "step": 120
    },
    {
        "loss": 0.4337,
        "grad_norm": 1.9596363306045532,
        "learning_rate": 4.7123893805309736e-05,
        "epoch": 0.5752212389380531,
        "step": 130
    },
    {
        "loss": 0.4798,
        "grad_norm": 3.443286418914795,
        "learning_rate": 4.690265486725664e-05,
        "epoch": 0.6194690265486725,
        "step": 140
    },
    {
        "loss": 0.5222,
        "grad_norm": 2.083159923553467,
        "learning_rate": 4.668141592920354e-05,
        "epoch": 0.6637168141592921,
        "step": 150
    },
    {
        "loss": 0.4717,
        "grad_norm": 1.9224129915237427,
        "learning_rate": 4.646017699115045e-05,
        "epoch": 0.7079646017699115,
        "step": 160
    },
    {
        "loss": 0.4708,
        "grad_norm": 2.7193591594696045,
        "learning_rate": 4.6238938053097344e-05,
        "epoch": 0.7522123893805309,
        "step": 170
    },
    {
        "loss": 0.4332,
        "grad_norm": 1.7921274900436401,
        "learning_rate": 4.601769911504425e-05,
        "epoch": 0.7964601769911505,
        "step": 180
    },
    {
        "loss": 0.3996,
        "grad_norm": 2.0502090454101562,
        "learning_rate": 4.579646017699115e-05,
        "epoch": 0.8407079646017699,
        "step": 190
    },
    {
        "loss": 0.4593,
        "grad_norm": 1.5589317083358765,
        "learning_rate": 4.5575221238938055e-05,
        "epoch": 0.8849557522123894,
        "step": 200
    },
    {
        "loss": 0.3911,
        "grad_norm": 2.5894968509674072,
        "learning_rate": 4.535398230088496e-05,
        "epoch": 0.9292035398230089,
        "step": 210
    },
    {
        "loss": 0.5744,
        "grad_norm": 4.577587127685547,
        "learning_rate": 4.5132743362831855e-05,
        "epoch": 0.9734513274336283,
        "step": 220
    },
    {
        "eval_loss": 0.4404553472995758,
        "eval_accuracy": 0.83509,
        "eval_precision": 0.804,
        "eval_recall": 0.88742,
        "eval_f1": 0.84365,
        "eval_runtime": 42.6103,
        "eval_samples_per_second": 42.408,
        "eval_steps_per_second": 2.652,
        "epoch": 1.0,
        "step": 226
    },
    {
        "loss": 0.4588,
        "grad_norm": 4.1927490234375,
        "learning_rate": 4.491150442477876e-05,
        "epoch": 1.0176991150442478,
        "step": 230
    },
    {
        "loss": 0.4862,
        "grad_norm": 3.9018638134002686,
        "learning_rate": 4.469026548672566e-05,
        "epoch": 1.0619469026548674,
        "step": 240
    },
    {
        "loss": 0.4573,
        "grad_norm": 1.8382433652877808,
        "learning_rate": 4.446902654867257e-05,
        "epoch": 1.1061946902654867,
        "step": 250
    },
    {
        "loss": 0.5348,
        "grad_norm": 6.031720161437988,
        "learning_rate": 4.4247787610619477e-05,
        "epoch": 1.1504424778761062,
        "step": 260
    },
    {
        "loss": 0.4101,
        "grad_norm": 2.610712766647339,
        "learning_rate": 4.4026548672566373e-05,
        "epoch": 1.1946902654867257,
        "step": 270
    },
    {
        "loss": 0.489,
        "grad_norm": 16.899015426635742,
        "learning_rate": 4.380530973451328e-05,
        "epoch": 1.238938053097345,
        "step": 280
    },
    {
        "loss": 0.5161,
        "grad_norm": 3.0209975242614746,
        "learning_rate": 4.358407079646018e-05,
        "epoch": 1.2831858407079646,
        "step": 290
    },
    {
        "loss": 0.5474,
        "grad_norm": 3.940997838973999,
        "learning_rate": 4.3362831858407084e-05,
        "epoch": 1.3274336283185841,
        "step": 300
    },
    {
        "loss": 0.4164,
        "grad_norm": 2.0534889698028564,
        "learning_rate": 4.314159292035399e-05,
        "epoch": 1.3716814159292037,
        "step": 310
    },
    {
        "loss": 0.3809,
        "grad_norm": 4.8143792152404785,
        "learning_rate": 4.2920353982300885e-05,
        "epoch": 1.415929203539823,
        "step": 320
    },
    {
        "loss": 0.5051,
        "grad_norm": 2.396944761276245,
        "learning_rate": 4.269911504424779e-05,
        "epoch": 1.4601769911504425,
        "step": 330
    },
    {
        "loss": 0.4848,
        "grad_norm": 1.9307653903961182,
        "learning_rate": 4.247787610619469e-05,
        "epoch": 1.504424778761062,
        "step": 340
    },
    {
        "loss": 0.5062,
        "grad_norm": 1.6652488708496094,
        "learning_rate": 4.2256637168141596e-05,
        "epoch": 1.5486725663716814,
        "step": 350
    },
    {
        "loss": 0.5236,
        "grad_norm": 4.213737964630127,
        "learning_rate": 4.20353982300885e-05,
        "epoch": 1.592920353982301,
        "step": 360
    },
    {
        "loss": 0.4717,
        "grad_norm": 2.141639232635498,
        "learning_rate": 4.1814159292035396e-05,
        "epoch": 1.6371681415929205,
        "step": 370
    },
    {
        "loss": 0.355,
        "grad_norm": 3.2640669345855713,
        "learning_rate": 4.15929203539823e-05,
        "epoch": 1.6814159292035398,
        "step": 380
    },
    {
        "loss": 0.5067,
        "grad_norm": 1.2058759927749634,
        "learning_rate": 4.1371681415929203e-05,
        "epoch": 1.7256637168141593,
        "step": 390
    },
    {
        "loss": 0.5187,
        "grad_norm": 3.5181610584259033,
        "learning_rate": 4.115044247787611e-05,
        "epoch": 1.7699115044247788,
        "step": 400
    },
    {
        "loss": 0.376,
        "grad_norm": 1.723197102546692,
        "learning_rate": 4.092920353982301e-05,
        "epoch": 1.8141592920353982,
        "step": 410
    },
    {
        "loss": 0.3757,
        "grad_norm": 3.9062154293060303,
        "learning_rate": 4.0707964601769914e-05,
        "epoch": 1.8584070796460177,
        "step": 420
    },
    {
        "loss": 0.4992,
        "grad_norm": 2.73638653755188,
        "learning_rate": 4.048672566371682e-05,
        "epoch": 1.9026548672566372,
        "step": 430
    },
    {
        "loss": 0.4865,
        "grad_norm": 1.6474056243896484,
        "learning_rate": 4.026548672566372e-05,
        "epoch": 1.9469026548672566,
        "step": 440
    },
    {
        "loss": 0.5019,
        "grad_norm": 4.178004741668701,
        "learning_rate": 4.0044247787610625e-05,
        "epoch": 1.991150442477876,
        "step": 450
    },
    {
        "eval_loss": 0.4230191111564636,
        "eval_accuracy": 0.82346,
        "eval_precision": 0.76561,
        "eval_recall": 0.93377,
        "eval_f1": 0.84137,
        "eval_runtime": 43.9439,
        "eval_samples_per_second": 41.121,
        "eval_steps_per_second": 2.571,
        "epoch": 2.0,
        "step": 452
    },
    {
        "loss": 0.4378,
        "grad_norm": 2.1315982341766357,
        "learning_rate": 3.982300884955752e-05,
        "epoch": 2.0353982300884956,
        "step": 460
    },
    {
        "loss": 0.5325,
        "grad_norm": 6.808873176574707,
        "learning_rate": 3.9601769911504426e-05,
        "epoch": 2.079646017699115,
        "step": 470
    },
    {
        "loss": 0.4416,
        "grad_norm": 1.601952314376831,
        "learning_rate": 3.938053097345133e-05,
        "epoch": 2.1238938053097347,
        "step": 480
    },
    {
        "loss": 0.4919,
        "grad_norm": 1.0255252122879028,
        "learning_rate": 3.915929203539823e-05,
        "epoch": 2.168141592920354,
        "step": 490
    },
    {
        "loss": 0.5206,
        "grad_norm": 2.3298375606536865,
        "learning_rate": 3.893805309734514e-05,
        "epoch": 2.2123893805309733,
        "step": 500
    },
    {
        "loss": 0.5424,
        "grad_norm": 2.131007432937622,
        "learning_rate": 3.8716814159292034e-05,
        "epoch": 2.256637168141593,
        "step": 510
    },
    {
        "loss": 0.4501,
        "grad_norm": 1.1470897197723389,
        "learning_rate": 3.849557522123894e-05,
        "epoch": 2.3008849557522124,
        "step": 520
    },
    {
        "loss": 0.5129,
        "grad_norm": 5.441868782043457,
        "learning_rate": 3.827433628318584e-05,
        "epoch": 2.3451327433628317,
        "step": 530
    },
    {
        "loss": 0.4755,
        "grad_norm": 1.0184141397476196,
        "learning_rate": 3.8053097345132744e-05,
        "epoch": 2.3893805309734515,
        "step": 540
    },
    {
        "loss": 0.4319,
        "grad_norm": 2.0088088512420654,
        "learning_rate": 3.783185840707965e-05,
        "epoch": 2.433628318584071,
        "step": 550
    },
    {
        "loss": 0.466,
        "grad_norm": 4.051721572875977,
        "learning_rate": 3.7610619469026545e-05,
        "epoch": 2.47787610619469,
        "step": 560
    },
    {
        "loss": 0.392,
        "grad_norm": 4.715438365936279,
        "learning_rate": 3.7389380530973455e-05,
        "epoch": 2.52212389380531,
        "step": 570
    },
    {
        "loss": 0.4381,
        "grad_norm": 3.600957155227661,
        "learning_rate": 3.716814159292036e-05,
        "epoch": 2.566371681415929,
        "step": 580
    },
    {
        "loss": 0.3775,
        "grad_norm": 3.979379653930664,
        "learning_rate": 3.694690265486726e-05,
        "epoch": 2.6106194690265485,
        "step": 590
    },
    {
        "loss": 0.4349,
        "grad_norm": 2.170328140258789,
        "learning_rate": 3.672566371681416e-05,
        "epoch": 2.6548672566371683,
        "step": 600
    },
    {
        "loss": 0.3103,
        "grad_norm": 2.570667266845703,
        "learning_rate": 3.650442477876106e-05,
        "epoch": 2.6991150442477876,
        "step": 610
    },
    {
        "loss": 0.5075,
        "grad_norm": 2.0113885402679443,
        "learning_rate": 3.628318584070797e-05,
        "epoch": 2.7433628318584073,
        "step": 620
    },
    {
        "loss": 0.4258,
        "grad_norm": 6.1853928565979,
        "learning_rate": 3.606194690265487e-05,
        "epoch": 2.7876106194690267,
        "step": 630
    },
    {
        "loss": 0.3506,
        "grad_norm": 3.7601277828216553,
        "learning_rate": 3.5840707964601774e-05,
        "epoch": 2.831858407079646,
        "step": 640
    },
    {
        "loss": 0.3266,
        "grad_norm": 2.8645362854003906,
        "learning_rate": 3.561946902654867e-05,
        "epoch": 2.8761061946902657,
        "step": 650
    },
    {
        "loss": 0.3466,
        "grad_norm": 3.1465253829956055,
        "learning_rate": 3.5398230088495574e-05,
        "epoch": 2.920353982300885,
        "step": 660
    },
    {
        "loss": 0.4903,
        "grad_norm": 3.1451950073242188,
        "learning_rate": 3.517699115044248e-05,
        "epoch": 2.9646017699115044,
        "step": 670
    },
    {
        "eval_loss": 0.4043109118938446,
        "eval_accuracy": 0.84173,
        "eval_precision": 0.81187,
        "eval_recall": 0.89073,
        "eval_f1": 0.84947,
        "eval_runtime": 45.3215,
        "eval_samples_per_second": 39.871,
        "eval_steps_per_second": 2.493,
        "epoch": 3.0,
        "step": 678
    },
    {
        "loss": 0.4277,
        "grad_norm": 1.3808512687683105,
        "learning_rate": 3.495575221238938e-05,
        "epoch": 3.0088495575221237,
        "step": 680
    },
    {
        "loss": 0.456,
        "grad_norm": 1.579475998878479,
        "learning_rate": 3.4734513274336285e-05,
        "epoch": 3.0530973451327434,
        "step": 690
    },
    {
        "loss": 0.4248,
        "grad_norm": 4.4665398597717285,
        "learning_rate": 3.451327433628319e-05,
        "epoch": 3.0973451327433628,
        "step": 700
    },
    {
        "loss": 0.384,
        "grad_norm": 3.4373319149017334,
        "learning_rate": 3.4292035398230086e-05,
        "epoch": 3.1415929203539825,
        "step": 710
    },
    {
        "loss": 0.3593,
        "grad_norm": 1.5852510929107666,
        "learning_rate": 3.407079646017699e-05,
        "epoch": 3.185840707964602,
        "step": 720
    },
    {
        "loss": 0.4768,
        "grad_norm": 2.5874099731445312,
        "learning_rate": 3.38495575221239e-05,
        "epoch": 3.230088495575221,
        "step": 730
    },
    {
        "loss": 0.4276,
        "grad_norm": 1.4900448322296143,
        "learning_rate": 3.3628318584070804e-05,
        "epoch": 3.274336283185841,
        "step": 740
    },
    {
        "loss": 0.5076,
        "grad_norm": 3.8948473930358887,
        "learning_rate": 3.34070796460177e-05,
        "epoch": 3.3185840707964602,
        "step": 750
    },
    {
        "loss": 0.427,
        "grad_norm": 2.4681780338287354,
        "learning_rate": 3.3185840707964604e-05,
        "epoch": 3.3628318584070795,
        "step": 760
    },
    {
        "loss": 0.4134,
        "grad_norm": 3.2767333984375,
        "learning_rate": 3.296460176991151e-05,
        "epoch": 3.4070796460176993,
        "step": 770
    },
    {
        "loss": 0.3996,
        "grad_norm": 4.890903472900391,
        "learning_rate": 3.274336283185841e-05,
        "epoch": 3.4513274336283186,
        "step": 780
    },
    {
        "loss": 0.4233,
        "grad_norm": 1.3297687768936157,
        "learning_rate": 3.2522123893805315e-05,
        "epoch": 3.495575221238938,
        "step": 790
    },
    {
        "loss": 0.4196,
        "grad_norm": 1.5161962509155273,
        "learning_rate": 3.230088495575221e-05,
        "epoch": 3.5398230088495577,
        "step": 800
    },
    {
        "loss": 0.4199,
        "grad_norm": 3.6341354846954346,
        "learning_rate": 3.2079646017699115e-05,
        "epoch": 3.584070796460177,
        "step": 810
    },
    {
        "loss": 0.4636,
        "grad_norm": 0.8656386733055115,
        "learning_rate": 3.185840707964602e-05,
        "epoch": 3.6283185840707963,
        "step": 820
    },
    {
        "loss": 0.4373,
        "grad_norm": 2.790037155151367,
        "learning_rate": 3.163716814159292e-05,
        "epoch": 3.672566371681416,
        "step": 830
    },
    {
        "loss": 0.4377,
        "grad_norm": 9.454636573791504,
        "learning_rate": 3.1415929203539826e-05,
        "epoch": 3.7168141592920354,
        "step": 840
    },
    {
        "loss": 0.4031,
        "grad_norm": 2.9580774307250977,
        "learning_rate": 3.119469026548672e-05,
        "epoch": 3.7610619469026547,
        "step": 850
    },
    {
        "loss": 0.4771,
        "grad_norm": 2.6641478538513184,
        "learning_rate": 3.097345132743363e-05,
        "epoch": 3.8053097345132745,
        "step": 860
    },
    {
        "loss": 0.4737,
        "grad_norm": 1.694413661956787,
        "learning_rate": 3.075221238938053e-05,
        "epoch": 3.849557522123894,
        "step": 870
    },
    {
        "loss": 0.4129,
        "grad_norm": 3.4778711795806885,
        "learning_rate": 3.0530973451327434e-05,
        "epoch": 3.893805309734513,
        "step": 880
    },
    {
        "loss": 0.4226,
        "grad_norm": 4.309176445007324,
        "learning_rate": 3.030973451327434e-05,
        "epoch": 3.938053097345133,
        "step": 890
    },
    {
        "loss": 0.337,
        "grad_norm": 1.819887399673462,
        "learning_rate": 3.008849557522124e-05,
        "epoch": 3.982300884955752,
        "step": 900
    },
    {
        "eval_loss": 0.42523425817489624,
        "eval_accuracy": 0.8373,
        "eval_precision": 0.81161,
        "eval_recall": 0.87969,
        "eval_f1": 0.84428,
        "eval_runtime": 39.9876,
        "eval_samples_per_second": 45.189,
        "eval_steps_per_second": 2.826,
        "epoch": 4.0,
        "step": 904
    },
    {
        "loss": 0.3588,
        "grad_norm": 1.24700927734375,
        "learning_rate": 2.9867256637168145e-05,
        "epoch": 4.0265486725663715,
        "step": 910
    },
    {
        "loss": 0.6021,
        "grad_norm": 2.553483009338379,
        "learning_rate": 2.964601769911505e-05,
        "epoch": 4.070796460176991,
        "step": 920
    },
    {
        "loss": 0.302,
        "grad_norm": 1.2819067239761353,
        "learning_rate": 2.942477876106195e-05,
        "epoch": 4.115044247787611,
        "step": 930
    },
    {
        "loss": 0.4166,
        "grad_norm": 12.846662521362305,
        "learning_rate": 2.9203539823008852e-05,
        "epoch": 4.15929203539823,
        "step": 940
    },
    {
        "loss": 0.3951,
        "grad_norm": 1.4071904420852661,
        "learning_rate": 2.8982300884955753e-05,
        "epoch": 4.20353982300885,
        "step": 950
    },
    {
        "loss": 0.4604,
        "grad_norm": 11.012530326843262,
        "learning_rate": 2.8761061946902656e-05,
        "epoch": 4.247787610619469,
        "step": 960
    },
    {
        "loss": 0.4538,
        "grad_norm": 3.9695088863372803,
        "learning_rate": 2.853982300884956e-05,
        "epoch": 4.292035398230088,
        "step": 970
    },
    {
        "loss": 0.413,
        "grad_norm": 1.4961835145950317,
        "learning_rate": 2.831858407079646e-05,
        "epoch": 4.336283185840708,
        "step": 980
    },
    {
        "loss": 0.3713,
        "grad_norm": 1.3795862197875977,
        "learning_rate": 2.8097345132743364e-05,
        "epoch": 4.380530973451328,
        "step": 990
    },
    {
        "loss": 0.5032,
        "grad_norm": 1.7932230234146118,
        "learning_rate": 2.7876106194690264e-05,
        "epoch": 4.424778761061947,
        "step": 1000
    },
    {
        "loss": 0.4129,
        "grad_norm": 2.8505001068115234,
        "learning_rate": 2.7654867256637168e-05,
        "epoch": 4.469026548672566,
        "step": 1010
    },
    {
        "loss": 0.4472,
        "grad_norm": 2.2657790184020996,
        "learning_rate": 2.743362831858407e-05,
        "epoch": 4.513274336283186,
        "step": 1020
    },
    {
        "loss": 0.3929,
        "grad_norm": 3.6699371337890625,
        "learning_rate": 2.721238938053097e-05,
        "epoch": 4.557522123893805,
        "step": 1030
    },
    {
        "loss": 0.3712,
        "grad_norm": 2.515000343322754,
        "learning_rate": 2.6991150442477875e-05,
        "epoch": 4.601769911504425,
        "step": 1040
    },
    {
        "loss": 0.4991,
        "grad_norm": 1.6044554710388184,
        "learning_rate": 2.6769911504424782e-05,
        "epoch": 4.646017699115045,
        "step": 1050
    },
    {
        "loss": 0.3844,
        "grad_norm": 1.5651262998580933,
        "learning_rate": 2.6548672566371686e-05,
        "epoch": 4.6902654867256635,
        "step": 1060
    },
    {
        "loss": 0.4139,
        "grad_norm": 5.381214141845703,
        "learning_rate": 2.6327433628318586e-05,
        "epoch": 4.734513274336283,
        "step": 1070
    },
    {
        "loss": 0.4223,
        "grad_norm": 3.4322996139526367,
        "learning_rate": 2.610619469026549e-05,
        "epoch": 4.778761061946903,
        "step": 1080
    },
    {
        "loss": 0.4972,
        "grad_norm": 2.733135938644409,
        "learning_rate": 2.5884955752212393e-05,
        "epoch": 4.823008849557522,
        "step": 1090
    },
    {
        "loss": 0.3978,
        "grad_norm": 4.126190185546875,
        "learning_rate": 2.5663716814159294e-05,
        "epoch": 4.867256637168142,
        "step": 1100
    },
    {
        "loss": 0.4093,
        "grad_norm": 3.096313238143921,
        "learning_rate": 2.5442477876106197e-05,
        "epoch": 4.911504424778761,
        "step": 1110
    },
    {
        "loss": 0.3868,
        "grad_norm": 1.8350797891616821,
        "learning_rate": 2.5221238938053098e-05,
        "epoch": 4.95575221238938,
        "step": 1120
    },
    {
        "loss": 0.5473,
        "grad_norm": 46.65195083618164,
        "learning_rate": 2.5e-05,
        "epoch": 5.0,
        "step": 1130
    },
    {
        "eval_loss": 0.4487531781196594,
        "eval_accuracy": 0.83343,
        "eval_precision": 0.81876,
        "eval_recall": 0.85762,
        "eval_f1": 0.83774,
        "eval_runtime": 44.731,
        "eval_samples_per_second": 40.397,
        "eval_steps_per_second": 2.526,
        "epoch": 5.0,
        "step": 1130
    },
    {
        "loss": 0.3877,
        "grad_norm": 1.9946472644805908,
        "learning_rate": 2.4778761061946905e-05,
        "epoch": 5.04424778761062,
        "step": 1140
    },
    {
        "loss": 0.3855,
        "grad_norm": 1.2645814418792725,
        "learning_rate": 2.4557522123893805e-05,
        "epoch": 5.088495575221239,
        "step": 1150
    },
    {
        "loss": 0.4152,
        "grad_norm": 0.7637081742286682,
        "learning_rate": 2.433628318584071e-05,
        "epoch": 5.132743362831858,
        "step": 1160
    },
    {
        "loss": 0.4189,
        "grad_norm": 1.6511814594268799,
        "learning_rate": 2.411504424778761e-05,
        "epoch": 5.176991150442478,
        "step": 1170
    },
    {
        "loss": 0.3587,
        "grad_norm": 1.5008490085601807,
        "learning_rate": 2.3893805309734516e-05,
        "epoch": 5.221238938053097,
        "step": 1180
    },
    {
        "loss": 0.4215,
        "grad_norm": 2.680623769760132,
        "learning_rate": 2.3672566371681416e-05,
        "epoch": 5.265486725663717,
        "step": 1190
    },
    {
        "loss": 0.4958,
        "grad_norm": 0.8563197255134583,
        "learning_rate": 2.345132743362832e-05,
        "epoch": 5.3097345132743365,
        "step": 1200
    },
    {
        "loss": 0.3525,
        "grad_norm": 2.2147738933563232,
        "learning_rate": 2.3230088495575223e-05,
        "epoch": 5.353982300884955,
        "step": 1210
    },
    {
        "loss": 0.43,
        "grad_norm": 4.070655345916748,
        "learning_rate": 2.3008849557522124e-05,
        "epoch": 5.398230088495575,
        "step": 1220
    },
    {
        "loss": 0.5433,
        "grad_norm": 3.5376977920532227,
        "learning_rate": 2.2787610619469027e-05,
        "epoch": 5.442477876106195,
        "step": 1230
    },
    {
        "loss": 0.4501,
        "grad_norm": 3.481447219848633,
        "learning_rate": 2.2566371681415928e-05,
        "epoch": 5.486725663716814,
        "step": 1240
    },
    {
        "loss": 0.4581,
        "grad_norm": 2.3485467433929443,
        "learning_rate": 2.234513274336283e-05,
        "epoch": 5.530973451327434,
        "step": 1250
    },
    {
        "loss": 0.419,
        "grad_norm": 2.093240976333618,
        "learning_rate": 2.2123893805309738e-05,
        "epoch": 5.575221238938053,
        "step": 1260
    },
    {
        "loss": 0.3606,
        "grad_norm": 3.3957273960113525,
        "learning_rate": 2.190265486725664e-05,
        "epoch": 5.619469026548672,
        "step": 1270
    },
    {
        "loss": 0.4835,
        "grad_norm": 1.6988376379013062,
        "learning_rate": 2.1681415929203542e-05,
        "epoch": 5.663716814159292,
        "step": 1280
    },
    {
        "loss": 0.325,
        "grad_norm": 3.3140790462493896,
        "learning_rate": 2.1460176991150442e-05,
        "epoch": 5.707964601769912,
        "step": 1290
    },
    {
        "loss": 0.4646,
        "grad_norm": 2.5568268299102783,
        "learning_rate": 2.1238938053097346e-05,
        "epoch": 5.752212389380531,
        "step": 1300
    },
    {
        "loss": 0.4219,
        "grad_norm": 3.7223284244537354,
        "learning_rate": 2.101769911504425e-05,
        "epoch": 5.79646017699115,
        "step": 1310
    },
    {
        "loss": 0.3963,
        "grad_norm": 5.110591411590576,
        "learning_rate": 2.079646017699115e-05,
        "epoch": 5.84070796460177,
        "step": 1320
    },
    {
        "loss": 0.3766,
        "grad_norm": 1.213668704032898,
        "learning_rate": 2.0575221238938054e-05,
        "epoch": 5.88495575221239,
        "step": 1330
    },
    {
        "loss": 0.4073,
        "grad_norm": 1.9153634309768677,
        "learning_rate": 2.0353982300884957e-05,
        "epoch": 5.929203539823009,
        "step": 1340
    },
    {
        "loss": 0.4737,
        "grad_norm": 3.997650623321533,
        "learning_rate": 2.013274336283186e-05,
        "epoch": 5.9734513274336285,
        "step": 1350
    },
    {
        "eval_loss": 0.4188495874404907,
        "eval_accuracy": 0.82291,
        "eval_precision": 0.82483,
        "eval_recall": 0.82119,
        "eval_f1": 0.82301,
        "eval_runtime": 42.2611,
        "eval_samples_per_second": 42.758,
        "eval_steps_per_second": 2.674,
        "epoch": 6.0,
        "step": 1356
    },
    {
        "loss": 0.3948,
        "grad_norm": 5.644036293029785,
        "learning_rate": 1.991150442477876e-05,
        "epoch": 6.017699115044247,
        "step": 1360
    },
    {
        "loss": 0.4471,
        "grad_norm": 1.2864844799041748,
        "learning_rate": 1.9690265486725665e-05,
        "epoch": 6.061946902654867,
        "step": 1370
    },
    {
        "loss": 0.3394,
        "grad_norm": 1.0542017221450806,
        "learning_rate": 1.946902654867257e-05,
        "epoch": 6.106194690265487,
        "step": 1380
    },
    {
        "loss": 0.4176,
        "grad_norm": 1.5460855960845947,
        "learning_rate": 1.924778761061947e-05,
        "epoch": 6.150442477876107,
        "step": 1390
    },
    {
        "loss": 0.3096,
        "grad_norm": 1.928051233291626,
        "learning_rate": 1.9026548672566372e-05,
        "epoch": 6.1946902654867255,
        "step": 1400
    },
    {
        "loss": 0.3828,
        "grad_norm": 2.529571294784546,
        "learning_rate": 1.8805309734513272e-05,
        "epoch": 6.238938053097345,
        "step": 1410
    },
    {
        "loss": 0.3679,
        "grad_norm": 3.585886240005493,
        "learning_rate": 1.858407079646018e-05,
        "epoch": 6.283185840707965,
        "step": 1420
    },
    {
        "loss": 0.3907,
        "grad_norm": 3.069645881652832,
        "learning_rate": 1.836283185840708e-05,
        "epoch": 6.327433628318584,
        "step": 1430
    },
    {
        "loss": 0.4216,
        "grad_norm": 2.882622718811035,
        "learning_rate": 1.8141592920353983e-05,
        "epoch": 6.371681415929204,
        "step": 1440
    },
    {
        "loss": 0.4154,
        "grad_norm": 1.806242823600769,
        "learning_rate": 1.7920353982300887e-05,
        "epoch": 6.415929203539823,
        "step": 1450
    },
    {
        "loss": 0.4238,
        "grad_norm": 3.936906337738037,
        "learning_rate": 1.7699115044247787e-05,
        "epoch": 6.460176991150442,
        "step": 1460
    },
    {
        "loss": 0.4066,
        "grad_norm": 3.0233728885650635,
        "learning_rate": 1.747787610619469e-05,
        "epoch": 6.504424778761062,
        "step": 1470
    },
    {
        "loss": 0.4791,
        "grad_norm": 5.5325026512146,
        "learning_rate": 1.7256637168141594e-05,
        "epoch": 6.548672566371682,
        "step": 1480
    },
    {
        "loss": 0.3934,
        "grad_norm": 3.8271307945251465,
        "learning_rate": 1.7035398230088495e-05,
        "epoch": 6.592920353982301,
        "step": 1490
    },
    {
        "loss": 0.424,
        "grad_norm": 8.007153511047363,
        "learning_rate": 1.6814159292035402e-05,
        "epoch": 6.6371681415929205,
        "step": 1500
    },
    {
        "loss": 0.4609,
        "grad_norm": 2.307971954345703,
        "learning_rate": 1.6592920353982302e-05,
        "epoch": 6.68141592920354,
        "step": 1510
    },
    {
        "loss": 0.4444,
        "grad_norm": 3.214303731918335,
        "learning_rate": 1.6371681415929206e-05,
        "epoch": 6.725663716814159,
        "step": 1520
    },
    {
        "loss": 0.374,
        "grad_norm": 4.220227241516113,
        "learning_rate": 1.6150442477876106e-05,
        "epoch": 6.769911504424779,
        "step": 1530
    },
    {
        "loss": 0.4168,
        "grad_norm": 3.614154815673828,
        "learning_rate": 1.592920353982301e-05,
        "epoch": 6.814159292035399,
        "step": 1540
    },
    {
        "loss": 0.3388,
        "grad_norm": 2.5695314407348633,
        "learning_rate": 1.5707964601769913e-05,
        "epoch": 6.8584070796460175,
        "step": 1550
    },
    {
        "loss": 0.4486,
        "grad_norm": 1.4972323179244995,
        "learning_rate": 1.5486725663716813e-05,
        "epoch": 6.902654867256637,
        "step": 1560
    },
    {
        "loss": 0.4558,
        "grad_norm": 2.732410430908203,
        "learning_rate": 1.5265486725663717e-05,
        "epoch": 6.946902654867257,
        "step": 1570
    },
    {
        "loss": 0.4033,
        "grad_norm": 1.9331575632095337,
        "learning_rate": 1.504424778761062e-05,
        "epoch": 6.991150442477876,
        "step": 1580
    },
    {
        "eval_loss": 0.42163076996803284,
        "eval_accuracy": 0.84117,
        "eval_precision": 0.81231,
        "eval_recall": 0.88852,
        "eval_f1": 0.84871,
        "eval_runtime": 43.5242,
        "eval_samples_per_second": 41.517,
        "eval_steps_per_second": 2.596,
        "epoch": 7.0,
        "step": 1582
    },
    {
        "train_runtime": 2059.8208,
        "train_samples_per_second": 17.536,
        "train_steps_per_second": 1.097,
        "total_flos": 3326249961861120.0,
        "train_loss": 0.4395140838984744,
        "epoch": 7.0,
        "step": 1582
    }
]