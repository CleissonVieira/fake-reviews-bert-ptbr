[
    {
        "loss": 0.6789,
        "grad_norm": 2.131732940673828,
        "learning_rate": 9.991142604074402e-06,
        "epoch": 0.008857395925597875,
        "step": 10
    },
    {
        "loss": 0.6631,
        "grad_norm": 5.763095855712891,
        "learning_rate": 9.982285208148806e-06,
        "epoch": 0.01771479185119575,
        "step": 20
    },
    {
        "loss": 0.5989,
        "grad_norm": 6.8983001708984375,
        "learning_rate": 9.973427812223207e-06,
        "epoch": 0.026572187776793623,
        "step": 30
    },
    {
        "loss": 0.6349,
        "grad_norm": 2.886880874633789,
        "learning_rate": 9.964570416297609e-06,
        "epoch": 0.0354295837023915,
        "step": 40
    },
    {
        "loss": 0.5753,
        "grad_norm": 4.602179050445557,
        "learning_rate": 9.95571302037201e-06,
        "epoch": 0.04428697962798937,
        "step": 50
    },
    {
        "loss": 0.6017,
        "grad_norm": 6.546477794647217,
        "learning_rate": 9.946855624446414e-06,
        "epoch": 0.053144375553587246,
        "step": 60
    },
    {
        "loss": 0.5842,
        "grad_norm": 9.72498607635498,
        "learning_rate": 9.937998228520815e-06,
        "epoch": 0.06200177147918512,
        "step": 70
    },
    {
        "loss": 0.5756,
        "grad_norm": 3.831347703933716,
        "learning_rate": 9.929140832595217e-06,
        "epoch": 0.070859167404783,
        "step": 80
    },
    {
        "loss": 0.6066,
        "grad_norm": 10.353446960449219,
        "learning_rate": 9.92028343666962e-06,
        "epoch": 0.07971656333038087,
        "step": 90
    },
    {
        "loss": 0.6419,
        "grad_norm": 6.897612571716309,
        "learning_rate": 9.911426040744022e-06,
        "epoch": 0.08857395925597875,
        "step": 100
    },
    {
        "loss": 0.5874,
        "grad_norm": 7.718246936798096,
        "learning_rate": 9.902568644818424e-06,
        "epoch": 0.09743135518157661,
        "step": 110
    },
    {
        "loss": 0.6296,
        "grad_norm": 6.029218673706055,
        "learning_rate": 9.893711248892827e-06,
        "epoch": 0.10628875110717449,
        "step": 120
    },
    {
        "loss": 0.5825,
        "grad_norm": 8.107081413269043,
        "learning_rate": 9.884853852967229e-06,
        "epoch": 0.11514614703277236,
        "step": 130
    },
    {
        "loss": 0.6076,
        "grad_norm": 3.4650564193725586,
        "learning_rate": 9.87599645704163e-06,
        "epoch": 0.12400354295837024,
        "step": 140
    },
    {
        "loss": 0.5976,
        "grad_norm": 10.534632682800293,
        "learning_rate": 9.867139061116032e-06,
        "epoch": 0.1328609388839681,
        "step": 150
    },
    {
        "loss": 0.5302,
        "grad_norm": 4.26618766784668,
        "learning_rate": 9.858281665190435e-06,
        "epoch": 0.141718334809566,
        "step": 160
    },
    {
        "loss": 0.5312,
        "grad_norm": 2.396134853363037,
        "learning_rate": 9.849424269264837e-06,
        "epoch": 0.15057573073516387,
        "step": 170
    },
    {
        "loss": 0.6081,
        "grad_norm": 8.137816429138184,
        "learning_rate": 9.840566873339238e-06,
        "epoch": 0.15943312666076173,
        "step": 180
    },
    {
        "loss": 0.5541,
        "grad_norm": 8.867620468139648,
        "learning_rate": 9.831709477413642e-06,
        "epoch": 0.1682905225863596,
        "step": 190
    },
    {
        "loss": 0.6646,
        "grad_norm": 3.492791175842285,
        "learning_rate": 9.822852081488043e-06,
        "epoch": 0.1771479185119575,
        "step": 200
    },
    {
        "loss": 0.5649,
        "grad_norm": 4.205291748046875,
        "learning_rate": 9.813994685562446e-06,
        "epoch": 0.18600531443755536,
        "step": 210
    },
    {
        "loss": 0.6177,
        "grad_norm": 4.486567497253418,
        "learning_rate": 9.805137289636848e-06,
        "epoch": 0.19486271036315322,
        "step": 220
    },
    {
        "loss": 0.5827,
        "grad_norm": 6.285888195037842,
        "learning_rate": 9.79627989371125e-06,
        "epoch": 0.20372010628875112,
        "step": 230
    },
    {
        "loss": 0.5782,
        "grad_norm": 3.5865559577941895,
        "learning_rate": 9.787422497785651e-06,
        "epoch": 0.21257750221434898,
        "step": 240
    },
    {
        "loss": 0.5996,
        "grad_norm": 2.8640947341918945,
        "learning_rate": 9.778565101860053e-06,
        "epoch": 0.22143489813994685,
        "step": 250
    },
    {
        "loss": 0.5958,
        "grad_norm": 3.4430956840515137,
        "learning_rate": 9.769707705934456e-06,
        "epoch": 0.23029229406554472,
        "step": 260
    },
    {
        "loss": 0.5688,
        "grad_norm": 3.5463385581970215,
        "learning_rate": 9.760850310008858e-06,
        "epoch": 0.2391496899911426,
        "step": 270
    },
    {
        "loss": 0.6045,
        "grad_norm": 7.691771030426025,
        "learning_rate": 9.751992914083261e-06,
        "epoch": 0.24800708591674048,
        "step": 280
    },
    {
        "loss": 0.6532,
        "grad_norm": 3.6400146484375,
        "learning_rate": 9.743135518157663e-06,
        "epoch": 0.25686448184233834,
        "step": 290
    },
    {
        "loss": 0.5922,
        "grad_norm": 2.8589956760406494,
        "learning_rate": 9.734278122232064e-06,
        "epoch": 0.2657218777679362,
        "step": 300
    },
    {
        "loss": 0.564,
        "grad_norm": 5.1815290451049805,
        "learning_rate": 9.725420726306468e-06,
        "epoch": 0.2745792736935341,
        "step": 310
    },
    {
        "loss": 0.6023,
        "grad_norm": 6.492170810699463,
        "learning_rate": 9.71656333038087e-06,
        "epoch": 0.283436669619132,
        "step": 320
    },
    {
        "loss": 0.5373,
        "grad_norm": 4.881801128387451,
        "learning_rate": 9.707705934455271e-06,
        "epoch": 0.29229406554472986,
        "step": 330
    },
    {
        "loss": 0.523,
        "grad_norm": 6.261779308319092,
        "learning_rate": 9.698848538529672e-06,
        "epoch": 0.30115146147032773,
        "step": 340
    },
    {
        "loss": 0.5384,
        "grad_norm": 8.288050651550293,
        "learning_rate": 9.689991142604076e-06,
        "epoch": 0.3100088573959256,
        "step": 350
    },
    {
        "loss": 0.5368,
        "grad_norm": 8.679749488830566,
        "learning_rate": 9.681133746678477e-06,
        "epoch": 0.31886625332152346,
        "step": 360
    },
    {
        "loss": 0.6159,
        "grad_norm": 7.0588555335998535,
        "learning_rate": 9.672276350752879e-06,
        "epoch": 0.32772364924712133,
        "step": 370
    },
    {
        "loss": 0.5433,
        "grad_norm": 4.472865104675293,
        "learning_rate": 9.663418954827282e-06,
        "epoch": 0.3365810451727192,
        "step": 380
    },
    {
        "loss": 0.5844,
        "grad_norm": 9.691142082214355,
        "learning_rate": 9.654561558901684e-06,
        "epoch": 0.3454384410983171,
        "step": 390
    },
    {
        "loss": 0.5926,
        "grad_norm": 4.779804706573486,
        "learning_rate": 9.645704162976086e-06,
        "epoch": 0.354295837023915,
        "step": 400
    },
    {
        "loss": 0.5552,
        "grad_norm": 4.131514072418213,
        "learning_rate": 9.636846767050489e-06,
        "epoch": 0.36315323294951285,
        "step": 410
    },
    {
        "loss": 0.5321,
        "grad_norm": 5.378249645233154,
        "learning_rate": 9.627989371124889e-06,
        "epoch": 0.3720106288751107,
        "step": 420
    },
    {
        "loss": 0.5625,
        "grad_norm": 5.634278297424316,
        "learning_rate": 9.619131975199292e-06,
        "epoch": 0.3808680248007086,
        "step": 430
    },
    {
        "loss": 0.6287,
        "grad_norm": 4.959399223327637,
        "learning_rate": 9.610274579273694e-06,
        "epoch": 0.38972542072630645,
        "step": 440
    },
    {
        "loss": 0.5702,
        "grad_norm": 4.686678409576416,
        "learning_rate": 9.601417183348097e-06,
        "epoch": 0.3985828166519043,
        "step": 450
    },
    {
        "loss": 0.5536,
        "grad_norm": 3.9651193618774414,
        "learning_rate": 9.592559787422499e-06,
        "epoch": 0.40744021257750224,
        "step": 460
    },
    {
        "loss": 0.5532,
        "grad_norm": 6.692692279815674,
        "learning_rate": 9.5837023914969e-06,
        "epoch": 0.4162976085031001,
        "step": 470
    },
    {
        "loss": 0.5788,
        "grad_norm": 8.667091369628906,
        "learning_rate": 9.574844995571303e-06,
        "epoch": 0.42515500442869797,
        "step": 480
    },
    {
        "loss": 0.5165,
        "grad_norm": 13.050721168518066,
        "learning_rate": 9.565987599645705e-06,
        "epoch": 0.43401240035429584,
        "step": 490
    },
    {
        "loss": 0.5553,
        "grad_norm": 5.004499912261963,
        "learning_rate": 9.557130203720107e-06,
        "epoch": 0.4428697962798937,
        "step": 500
    },
    {
        "loss": 0.5026,
        "grad_norm": 6.137173175811768,
        "learning_rate": 9.54827280779451e-06,
        "epoch": 0.45172719220549157,
        "step": 510
    },
    {
        "loss": 0.5521,
        "grad_norm": 15.146425247192383,
        "learning_rate": 9.539415411868912e-06,
        "epoch": 0.46058458813108943,
        "step": 520
    },
    {
        "loss": 0.591,
        "grad_norm": 6.8570876121521,
        "learning_rate": 9.530558015943313e-06,
        "epoch": 0.46944198405668736,
        "step": 530
    },
    {
        "loss": 0.5855,
        "grad_norm": 8.272027015686035,
        "learning_rate": 9.521700620017715e-06,
        "epoch": 0.4782993799822852,
        "step": 540
    },
    {
        "loss": 0.5719,
        "grad_norm": 11.351476669311523,
        "learning_rate": 9.512843224092118e-06,
        "epoch": 0.4871567759078831,
        "step": 550
    },
    {
        "loss": 0.5233,
        "grad_norm": 4.906471252441406,
        "learning_rate": 9.50398582816652e-06,
        "epoch": 0.49601417183348095,
        "step": 560
    },
    {
        "loss": 0.5633,
        "grad_norm": 8.626432418823242,
        "learning_rate": 9.495128432240921e-06,
        "epoch": 0.5048715677590788,
        "step": 570
    },
    {
        "loss": 0.5948,
        "grad_norm": 9.434432029724121,
        "learning_rate": 9.486271036315325e-06,
        "epoch": 0.5137289636846767,
        "step": 580
    },
    {
        "loss": 0.5491,
        "grad_norm": 6.947375774383545,
        "learning_rate": 9.477413640389726e-06,
        "epoch": 0.5225863596102746,
        "step": 590
    },
    {
        "loss": 0.525,
        "grad_norm": 7.037940979003906,
        "learning_rate": 9.46855624446413e-06,
        "epoch": 0.5314437555358724,
        "step": 600
    },
    {
        "loss": 0.5647,
        "grad_norm": 7.246947288513184,
        "learning_rate": 9.45969884853853e-06,
        "epoch": 0.5403011514614703,
        "step": 610
    },
    {
        "loss": 0.439,
        "grad_norm": 6.302206516265869,
        "learning_rate": 9.450841452612933e-06,
        "epoch": 0.5491585473870682,
        "step": 620
    },
    {
        "loss": 0.573,
        "grad_norm": 6.05333948135376,
        "learning_rate": 9.441984056687334e-06,
        "epoch": 0.5580159433126661,
        "step": 630
    },
    {
        "loss": 0.4988,
        "grad_norm": 8.780257225036621,
        "learning_rate": 9.433126660761736e-06,
        "epoch": 0.566873339238264,
        "step": 640
    },
    {
        "loss": 0.5049,
        "grad_norm": 11.775299072265625,
        "learning_rate": 9.42426926483614e-06,
        "epoch": 0.5757307351638619,
        "step": 650
    },
    {
        "loss": 0.5809,
        "grad_norm": 12.441450119018555,
        "learning_rate": 9.415411868910541e-06,
        "epoch": 0.5845881310894597,
        "step": 660
    },
    {
        "loss": 0.5109,
        "grad_norm": 8.38607406616211,
        "learning_rate": 9.406554472984944e-06,
        "epoch": 0.5934455270150576,
        "step": 670
    },
    {
        "loss": 0.4711,
        "grad_norm": 5.794500827789307,
        "learning_rate": 9.397697077059346e-06,
        "epoch": 0.6023029229406555,
        "step": 680
    },
    {
        "loss": 0.6452,
        "grad_norm": 8.484210014343262,
        "learning_rate": 9.388839681133747e-06,
        "epoch": 0.6111603188662533,
        "step": 690
    },
    {
        "loss": 0.5441,
        "grad_norm": 9.24969482421875,
        "learning_rate": 9.379982285208149e-06,
        "epoch": 0.6200177147918512,
        "step": 700
    },
    {
        "loss": 0.6454,
        "grad_norm": 5.118640899658203,
        "learning_rate": 9.37112488928255e-06,
        "epoch": 0.6288751107174491,
        "step": 710
    },
    {
        "loss": 0.512,
        "grad_norm": 6.550199508666992,
        "learning_rate": 9.362267493356954e-06,
        "epoch": 0.6377325066430469,
        "step": 720
    },
    {
        "loss": 0.4876,
        "grad_norm": 3.538566827774048,
        "learning_rate": 9.353410097431356e-06,
        "epoch": 0.6465899025686448,
        "step": 730
    },
    {
        "loss": 0.5295,
        "grad_norm": 5.53999662399292,
        "learning_rate": 9.344552701505759e-06,
        "epoch": 0.6554472984942427,
        "step": 740
    },
    {
        "loss": 0.5796,
        "grad_norm": 15.207036018371582,
        "learning_rate": 9.33569530558016e-06,
        "epoch": 0.6643046944198405,
        "step": 750
    },
    {
        "loss": 0.5138,
        "grad_norm": 11.13650131225586,
        "learning_rate": 9.326837909654562e-06,
        "epoch": 0.6731620903454384,
        "step": 760
    },
    {
        "loss": 0.5553,
        "grad_norm": 4.1182990074157715,
        "learning_rate": 9.317980513728965e-06,
        "epoch": 0.6820194862710364,
        "step": 770
    },
    {
        "loss": 0.4909,
        "grad_norm": 5.240339279174805,
        "learning_rate": 9.309123117803367e-06,
        "epoch": 0.6908768821966342,
        "step": 780
    },
    {
        "loss": 0.4671,
        "grad_norm": 7.954706192016602,
        "learning_rate": 9.300265721877769e-06,
        "epoch": 0.6997342781222321,
        "step": 790
    },
    {
        "loss": 0.4607,
        "grad_norm": 12.116012573242188,
        "learning_rate": 9.29140832595217e-06,
        "epoch": 0.70859167404783,
        "step": 800
    },
    {
        "loss": 0.5563,
        "grad_norm": 8.720306396484375,
        "learning_rate": 9.282550930026572e-06,
        "epoch": 0.7174490699734278,
        "step": 810
    },
    {
        "loss": 0.5359,
        "grad_norm": 7.620436191558838,
        "learning_rate": 9.273693534100975e-06,
        "epoch": 0.7263064658990257,
        "step": 820
    },
    {
        "loss": 0.5016,
        "grad_norm": 24.18531608581543,
        "learning_rate": 9.264836138175377e-06,
        "epoch": 0.7351638618246236,
        "step": 830
    },
    {
        "loss": 0.4847,
        "grad_norm": 13.548759460449219,
        "learning_rate": 9.25597874224978e-06,
        "epoch": 0.7440212577502214,
        "step": 840
    },
    {
        "loss": 0.5343,
        "grad_norm": 11.018075942993164,
        "learning_rate": 9.247121346324182e-06,
        "epoch": 0.7528786536758193,
        "step": 850
    },
    {
        "loss": 0.4871,
        "grad_norm": 15.682148933410645,
        "learning_rate": 9.238263950398583e-06,
        "epoch": 0.7617360496014172,
        "step": 860
    },
    {
        "loss": 0.5338,
        "grad_norm": 14.629230499267578,
        "learning_rate": 9.229406554472987e-06,
        "epoch": 0.770593445527015,
        "step": 870
    },
    {
        "loss": 0.5095,
        "grad_norm": 9.970019340515137,
        "learning_rate": 9.220549158547388e-06,
        "epoch": 0.7794508414526129,
        "step": 880
    },
    {
        "loss": 0.4877,
        "grad_norm": 10.985032081604004,
        "learning_rate": 9.21169176262179e-06,
        "epoch": 0.7883082373782108,
        "step": 890
    },
    {
        "loss": 0.5185,
        "grad_norm": 8.71392822265625,
        "learning_rate": 9.202834366696191e-06,
        "epoch": 0.7971656333038086,
        "step": 900
    },
    {
        "loss": 0.5231,
        "grad_norm": 5.632810592651367,
        "learning_rate": 9.193976970770595e-06,
        "epoch": 0.8060230292294066,
        "step": 910
    },
    {
        "loss": 0.4762,
        "grad_norm": 9.319070816040039,
        "learning_rate": 9.185119574844996e-06,
        "epoch": 0.8148804251550045,
        "step": 920
    },
    {
        "loss": 0.5539,
        "grad_norm": 11.709959983825684,
        "learning_rate": 9.176262178919398e-06,
        "epoch": 0.8237378210806023,
        "step": 930
    },
    {
        "loss": 0.4966,
        "grad_norm": 10.6568021774292,
        "learning_rate": 9.167404782993801e-06,
        "epoch": 0.8325952170062002,
        "step": 940
    },
    {
        "loss": 0.4799,
        "grad_norm": 7.7610039710998535,
        "learning_rate": 9.158547387068203e-06,
        "epoch": 0.8414526129317981,
        "step": 950
    },
    {
        "loss": 0.5224,
        "grad_norm": 7.632605075836182,
        "learning_rate": 9.149689991142604e-06,
        "epoch": 0.8503100088573959,
        "step": 960
    },
    {
        "loss": 0.4762,
        "grad_norm": 5.6536078453063965,
        "learning_rate": 9.140832595217008e-06,
        "epoch": 0.8591674047829938,
        "step": 970
    },
    {
        "loss": 0.4758,
        "grad_norm": 8.851839065551758,
        "learning_rate": 9.13197519929141e-06,
        "epoch": 0.8680248007085917,
        "step": 980
    },
    {
        "loss": 0.4257,
        "grad_norm": 13.315573692321777,
        "learning_rate": 9.123117803365811e-06,
        "epoch": 0.8768821966341895,
        "step": 990
    },
    {
        "loss": 0.496,
        "grad_norm": 16.175952911376953,
        "learning_rate": 9.114260407440213e-06,
        "epoch": 0.8857395925597874,
        "step": 1000
    },
    {
        "loss": 0.4288,
        "grad_norm": 9.475055694580078,
        "learning_rate": 9.105403011514616e-06,
        "epoch": 0.8945969884853853,
        "step": 1010
    },
    {
        "loss": 0.424,
        "grad_norm": 9.931865692138672,
        "learning_rate": 9.096545615589017e-06,
        "epoch": 0.9034543844109831,
        "step": 1020
    },
    {
        "loss": 0.5109,
        "grad_norm": 14.850491523742676,
        "learning_rate": 9.087688219663419e-06,
        "epoch": 0.912311780336581,
        "step": 1030
    },
    {
        "loss": 0.539,
        "grad_norm": 15.246636390686035,
        "learning_rate": 9.078830823737822e-06,
        "epoch": 0.9211691762621789,
        "step": 1040
    },
    {
        "loss": 0.4123,
        "grad_norm": 10.144674301147461,
        "learning_rate": 9.069973427812224e-06,
        "epoch": 0.9300265721877768,
        "step": 1050
    },
    {
        "loss": 0.5548,
        "grad_norm": 18.554235458374023,
        "learning_rate": 9.061116031886627e-06,
        "epoch": 0.9388839681133747,
        "step": 1060
    },
    {
        "loss": 0.4318,
        "grad_norm": 9.390527725219727,
        "learning_rate": 9.052258635961029e-06,
        "epoch": 0.9477413640389726,
        "step": 1070
    },
    {
        "loss": 0.4089,
        "grad_norm": 14.150471687316895,
        "learning_rate": 9.04340124003543e-06,
        "epoch": 0.9565987599645704,
        "step": 1080
    },
    {
        "loss": 0.49,
        "grad_norm": 15.230207443237305,
        "learning_rate": 9.034543844109832e-06,
        "epoch": 0.9654561558901683,
        "step": 1090
    },
    {
        "loss": 0.4438,
        "grad_norm": 13.031488418579102,
        "learning_rate": 9.025686448184234e-06,
        "epoch": 0.9743135518157662,
        "step": 1100
    },
    {
        "loss": 0.4633,
        "grad_norm": 9.30429744720459,
        "learning_rate": 9.016829052258637e-06,
        "epoch": 0.983170947741364,
        "step": 1110
    },
    {
        "loss": 0.4511,
        "grad_norm": 29.417835235595703,
        "learning_rate": 9.007971656333039e-06,
        "epoch": 0.9920283436669619,
        "step": 1120
    },
    {
        "eval_loss": 0.4287741780281067,
        "eval_accuracy": 0.82031,
        "eval_precision": 0.79029,
        "eval_recall": 0.87201,
        "eval_f1": 0.82914,
        "eval_runtime": 216.9891,
        "eval_samples_per_second": 41.624,
        "eval_steps_per_second": 2.604,
        "epoch": 1.0,
        "step": 1129
    },
    {
        "loss": 0.4604,
        "grad_norm": 12.41624927520752,
        "learning_rate": 8.999114260407442e-06,
        "epoch": 1.0008857395925599,
        "step": 1130
    },
    {
        "loss": 0.4371,
        "grad_norm": 16.113645553588867,
        "learning_rate": 8.990256864481844e-06,
        "epoch": 1.0097431355181576,
        "step": 1140
    },
    {
        "loss": 0.3618,
        "grad_norm": 12.63315200805664,
        "learning_rate": 8.981399468556245e-06,
        "epoch": 1.0186005314437556,
        "step": 1150
    },
    {
        "loss": 0.3721,
        "grad_norm": 34.313541412353516,
        "learning_rate": 8.972542072630648e-06,
        "epoch": 1.0274579273693534,
        "step": 1160
    },
    {
        "loss": 0.4812,
        "grad_norm": 12.969732284545898,
        "learning_rate": 8.963684676705048e-06,
        "epoch": 1.0363153232949514,
        "step": 1170
    },
    {
        "loss": 0.3397,
        "grad_norm": 18.000598907470703,
        "learning_rate": 8.954827280779452e-06,
        "epoch": 1.045172719220549,
        "step": 1180
    },
    {
        "loss": 0.4311,
        "grad_norm": 21.111469268798828,
        "learning_rate": 8.945969884853853e-06,
        "epoch": 1.054030115146147,
        "step": 1190
    },
    {
        "loss": 0.3528,
        "grad_norm": 10.680935859680176,
        "learning_rate": 8.937112488928255e-06,
        "epoch": 1.0628875110717448,
        "step": 1200
    },
    {
        "loss": 0.4454,
        "grad_norm": 17.305959701538086,
        "learning_rate": 8.928255093002658e-06,
        "epoch": 1.0717449069973428,
        "step": 1210
    },
    {
        "loss": 0.3271,
        "grad_norm": 14.612080574035645,
        "learning_rate": 8.91939769707706e-06,
        "epoch": 1.0806023029229406,
        "step": 1220
    },
    {
        "loss": 0.3383,
        "grad_norm": 12.646834373474121,
        "learning_rate": 8.910540301151463e-06,
        "epoch": 1.0894596988485385,
        "step": 1230
    },
    {
        "loss": 0.335,
        "grad_norm": 24.482250213623047,
        "learning_rate": 8.901682905225865e-06,
        "epoch": 1.0983170947741363,
        "step": 1240
    },
    {
        "loss": 0.3343,
        "grad_norm": 16.516223907470703,
        "learning_rate": 8.892825509300266e-06,
        "epoch": 1.1071744906997343,
        "step": 1250
    },
    {
        "loss": 0.3432,
        "grad_norm": 21.41741371154785,
        "learning_rate": 8.883968113374668e-06,
        "epoch": 1.1160318866253323,
        "step": 1260
    },
    {
        "loss": 0.4468,
        "grad_norm": 19.145814895629883,
        "learning_rate": 8.87511071744907e-06,
        "epoch": 1.12488928255093,
        "step": 1270
    },
    {
        "loss": 0.3632,
        "grad_norm": 13.174139022827148,
        "learning_rate": 8.866253321523473e-06,
        "epoch": 1.133746678476528,
        "step": 1280
    },
    {
        "loss": 0.4355,
        "grad_norm": 31.82932472229004,
        "learning_rate": 8.857395925597874e-06,
        "epoch": 1.1426040744021257,
        "step": 1290
    },
    {
        "loss": 0.3429,
        "grad_norm": 24.330829620361328,
        "learning_rate": 8.848538529672278e-06,
        "epoch": 1.1514614703277237,
        "step": 1300
    },
    {
        "loss": 0.4186,
        "grad_norm": 20.584253311157227,
        "learning_rate": 8.83968113374668e-06,
        "epoch": 1.1603188662533215,
        "step": 1310
    },
    {
        "loss": 0.3956,
        "grad_norm": 22.489675521850586,
        "learning_rate": 8.830823737821081e-06,
        "epoch": 1.1691762621789195,
        "step": 1320
    },
    {
        "loss": 0.3862,
        "grad_norm": 8.350837707519531,
        "learning_rate": 8.821966341895484e-06,
        "epoch": 1.1780336581045172,
        "step": 1330
    },
    {
        "loss": 0.3766,
        "grad_norm": 19.20330810546875,
        "learning_rate": 8.813108945969886e-06,
        "epoch": 1.1868910540301152,
        "step": 1340
    },
    {
        "loss": 0.4739,
        "grad_norm": 18.515716552734375,
        "learning_rate": 8.804251550044287e-06,
        "epoch": 1.195748449955713,
        "step": 1350
    },
    {
        "loss": 0.3531,
        "grad_norm": 26.446239471435547,
        "learning_rate": 8.795394154118689e-06,
        "epoch": 1.204605845881311,
        "step": 1360
    },
    {
        "loss": 0.3134,
        "grad_norm": 18.777036666870117,
        "learning_rate": 8.786536758193092e-06,
        "epoch": 1.2134632418069087,
        "step": 1370
    },
    {
        "loss": 0.3677,
        "grad_norm": 16.253620147705078,
        "learning_rate": 8.777679362267494e-06,
        "epoch": 1.2223206377325067,
        "step": 1380
    },
    {
        "loss": 0.3976,
        "grad_norm": 17.792627334594727,
        "learning_rate": 8.768821966341896e-06,
        "epoch": 1.2311780336581046,
        "step": 1390
    },
    {
        "loss": 0.4852,
        "grad_norm": 10.409542083740234,
        "learning_rate": 8.759964570416299e-06,
        "epoch": 1.2400354295837024,
        "step": 1400
    },
    {
        "loss": 0.3093,
        "grad_norm": 16.0595645904541,
        "learning_rate": 8.7511071744907e-06,
        "epoch": 1.2488928255093001,
        "step": 1410
    },
    {
        "loss": 0.3893,
        "grad_norm": 13.67750072479248,
        "learning_rate": 8.742249778565102e-06,
        "epoch": 1.2577502214348981,
        "step": 1420
    },
    {
        "loss": 0.3011,
        "grad_norm": 13.156672477722168,
        "learning_rate": 8.733392382639505e-06,
        "epoch": 1.266607617360496,
        "step": 1430
    },
    {
        "loss": 0.3257,
        "grad_norm": 21.279651641845703,
        "learning_rate": 8.724534986713907e-06,
        "epoch": 1.2754650132860939,
        "step": 1440
    },
    {
        "loss": 0.318,
        "grad_norm": 12.645243644714355,
        "learning_rate": 8.715677590788309e-06,
        "epoch": 1.2843224092116918,
        "step": 1450
    },
    {
        "loss": 0.3519,
        "grad_norm": 25.036014556884766,
        "learning_rate": 8.70682019486271e-06,
        "epoch": 1.2931798051372896,
        "step": 1460
    },
    {
        "loss": 0.4213,
        "grad_norm": 21.85283088684082,
        "learning_rate": 8.697962798937114e-06,
        "epoch": 1.3020372010628876,
        "step": 1470
    },
    {
        "loss": 0.3221,
        "grad_norm": 32.46197509765625,
        "learning_rate": 8.689105403011515e-06,
        "epoch": 1.3108945969884853,
        "step": 1480
    },
    {
        "loss": 0.3536,
        "grad_norm": 51.2901725769043,
        "learning_rate": 8.680248007085917e-06,
        "epoch": 1.3197519929140833,
        "step": 1490
    },
    {
        "loss": 0.3573,
        "grad_norm": 13.832901954650879,
        "learning_rate": 8.67139061116032e-06,
        "epoch": 1.328609388839681,
        "step": 1500
    },
    {
        "loss": 0.3009,
        "grad_norm": 12.34682559967041,
        "learning_rate": 8.662533215234722e-06,
        "epoch": 1.337466784765279,
        "step": 1510
    },
    {
        "loss": 0.4645,
        "grad_norm": 18.569801330566406,
        "learning_rate": 8.653675819309125e-06,
        "epoch": 1.346324180690877,
        "step": 1520
    },
    {
        "loss": 0.3453,
        "grad_norm": 25.421478271484375,
        "learning_rate": 8.644818423383527e-06,
        "epoch": 1.3551815766164748,
        "step": 1530
    },
    {
        "loss": 0.3712,
        "grad_norm": 23.721389770507812,
        "learning_rate": 8.635961027457928e-06,
        "epoch": 1.3640389725420725,
        "step": 1540
    },
    {
        "loss": 0.2728,
        "grad_norm": 21.824859619140625,
        "learning_rate": 8.62710363153233e-06,
        "epoch": 1.3728963684676705,
        "step": 1550
    },
    {
        "loss": 0.3329,
        "grad_norm": 31.784564971923828,
        "learning_rate": 8.618246235606731e-06,
        "epoch": 1.3817537643932685,
        "step": 1560
    },
    {
        "loss": 0.229,
        "grad_norm": 27.65476417541504,
        "learning_rate": 8.609388839681135e-06,
        "epoch": 1.3906111603188662,
        "step": 1570
    },
    {
        "loss": 0.2861,
        "grad_norm": 34.94559860229492,
        "learning_rate": 8.600531443755536e-06,
        "epoch": 1.3994685562444642,
        "step": 1580
    },
    {
        "loss": 0.2723,
        "grad_norm": 21.62737274169922,
        "learning_rate": 8.591674047829938e-06,
        "epoch": 1.408325952170062,
        "step": 1590
    },
    {
        "loss": 0.3147,
        "grad_norm": 17.350719451904297,
        "learning_rate": 8.582816651904341e-06,
        "epoch": 1.41718334809566,
        "step": 1600
    },
    {
        "loss": 0.4339,
        "grad_norm": 37.661319732666016,
        "learning_rate": 8.573959255978743e-06,
        "epoch": 1.4260407440212577,
        "step": 1610
    },
    {
        "loss": 0.4469,
        "grad_norm": 4.47210693359375,
        "learning_rate": 8.565101860053146e-06,
        "epoch": 1.4348981399468557,
        "step": 1620
    },
    {
        "loss": 0.4119,
        "grad_norm": 34.91067886352539,
        "learning_rate": 8.556244464127548e-06,
        "epoch": 1.4437555358724534,
        "step": 1630
    },
    {
        "loss": 0.2609,
        "grad_norm": 35.814537048339844,
        "learning_rate": 8.54738706820195e-06,
        "epoch": 1.4526129317980514,
        "step": 1640
    },
    {
        "loss": 0.428,
        "grad_norm": 25.97797966003418,
        "learning_rate": 8.538529672276351e-06,
        "epoch": 1.4614703277236494,
        "step": 1650
    },
    {
        "loss": 0.3504,
        "grad_norm": 8.718656539916992,
        "learning_rate": 8.529672276350753e-06,
        "epoch": 1.4703277236492471,
        "step": 1660
    },
    {
        "loss": 0.3403,
        "grad_norm": 11.938596725463867,
        "learning_rate": 8.520814880425156e-06,
        "epoch": 1.4791851195748449,
        "step": 1670
    },
    {
        "loss": 0.3208,
        "grad_norm": 25.02337646484375,
        "learning_rate": 8.511957484499558e-06,
        "epoch": 1.4880425155004429,
        "step": 1680
    },
    {
        "loss": 0.3014,
        "grad_norm": 13.754439353942871,
        "learning_rate": 8.50310008857396e-06,
        "epoch": 1.4968999114260408,
        "step": 1690
    },
    {
        "loss": 0.3253,
        "grad_norm": 27.69523811340332,
        "learning_rate": 8.494242692648362e-06,
        "epoch": 1.5057573073516386,
        "step": 1700
    },
    {
        "loss": 0.3631,
        "grad_norm": 11.811034202575684,
        "learning_rate": 8.485385296722764e-06,
        "epoch": 1.5146147032772364,
        "step": 1710
    },
    {
        "loss": 0.3163,
        "grad_norm": 6.991868019104004,
        "learning_rate": 8.476527900797167e-06,
        "epoch": 1.5234720992028343,
        "step": 1720
    },
    {
        "loss": 0.2779,
        "grad_norm": 22.777912139892578,
        "learning_rate": 8.467670504871567e-06,
        "epoch": 1.5323294951284323,
        "step": 1730
    },
    {
        "loss": 0.3552,
        "grad_norm": 13.904502868652344,
        "learning_rate": 8.45881310894597e-06,
        "epoch": 1.54118689105403,
        "step": 1740
    },
    {
        "loss": 0.331,
        "grad_norm": 13.96200180053711,
        "learning_rate": 8.449955713020372e-06,
        "epoch": 1.550044286979628,
        "step": 1750
    },
    {
        "loss": 0.3289,
        "grad_norm": 22.558198928833008,
        "learning_rate": 8.441098317094775e-06,
        "epoch": 1.5589016829052258,
        "step": 1760
    },
    {
        "loss": 0.3135,
        "grad_norm": 18.146575927734375,
        "learning_rate": 8.432240921169177e-06,
        "epoch": 1.5677590788308238,
        "step": 1770
    },
    {
        "loss": 0.4212,
        "grad_norm": 16.80817985534668,
        "learning_rate": 8.423383525243579e-06,
        "epoch": 1.5766164747564217,
        "step": 1780
    },
    {
        "loss": 0.2714,
        "grad_norm": 5.826577186584473,
        "learning_rate": 8.414526129317982e-06,
        "epoch": 1.5854738706820195,
        "step": 1790
    },
    {
        "loss": 0.2642,
        "grad_norm": 2.897467613220215,
        "learning_rate": 8.405668733392384e-06,
        "epoch": 1.5943312666076173,
        "step": 1800
    },
    {
        "loss": 0.2219,
        "grad_norm": 22.262304306030273,
        "learning_rate": 8.396811337466785e-06,
        "epoch": 1.6031886625332152,
        "step": 1810
    },
    {
        "loss": 0.3283,
        "grad_norm": 34.212738037109375,
        "learning_rate": 8.387953941541187e-06,
        "epoch": 1.6120460584588132,
        "step": 1820
    },
    {
        "loss": 0.2761,
        "grad_norm": 13.800610542297363,
        "learning_rate": 8.37909654561559e-06,
        "epoch": 1.620903454384411,
        "step": 1830
    },
    {
        "loss": 0.2266,
        "grad_norm": 36.626625061035156,
        "learning_rate": 8.370239149689992e-06,
        "epoch": 1.6297608503100087,
        "step": 1840
    },
    {
        "loss": 0.3844,
        "grad_norm": 19.633934020996094,
        "learning_rate": 8.361381753764393e-06,
        "epoch": 1.6386182462356067,
        "step": 1850
    },
    {
        "loss": 0.3723,
        "grad_norm": 49.333587646484375,
        "learning_rate": 8.352524357838797e-06,
        "epoch": 1.6474756421612047,
        "step": 1860
    },
    {
        "loss": 0.2298,
        "grad_norm": 17.97806739807129,
        "learning_rate": 8.343666961913198e-06,
        "epoch": 1.6563330380868024,
        "step": 1870
    },
    {
        "loss": 0.2677,
        "grad_norm": 24.953283309936523,
        "learning_rate": 8.3348095659876e-06,
        "epoch": 1.6651904340124002,
        "step": 1880
    },
    {
        "loss": 0.3363,
        "grad_norm": 30.42760467529297,
        "learning_rate": 8.325952170062003e-06,
        "epoch": 1.6740478299379982,
        "step": 1890
    },
    {
        "loss": 0.3384,
        "grad_norm": 19.74039649963379,
        "learning_rate": 8.317094774136405e-06,
        "epoch": 1.6829052258635961,
        "step": 1900
    },
    {
        "loss": 0.2527,
        "grad_norm": 12.629709243774414,
        "learning_rate": 8.308237378210808e-06,
        "epoch": 1.6917626217891941,
        "step": 1910
    },
    {
        "loss": 0.3557,
        "grad_norm": 26.65184211730957,
        "learning_rate": 8.299379982285208e-06,
        "epoch": 1.7006200177147919,
        "step": 1920
    },
    {
        "loss": 0.2418,
        "grad_norm": 33.487945556640625,
        "learning_rate": 8.290522586359611e-06,
        "epoch": 1.7094774136403896,
        "step": 1930
    },
    {
        "loss": 0.3241,
        "grad_norm": 25.05392837524414,
        "learning_rate": 8.281665190434013e-06,
        "epoch": 1.7183348095659876,
        "step": 1940
    },
    {
        "loss": 0.2659,
        "grad_norm": 22.68484115600586,
        "learning_rate": 8.272807794508414e-06,
        "epoch": 1.7271922054915856,
        "step": 1950
    },
    {
        "loss": 0.274,
        "grad_norm": 14.010872840881348,
        "learning_rate": 8.263950398582818e-06,
        "epoch": 1.7360496014171833,
        "step": 1960
    },
    {
        "loss": 0.2962,
        "grad_norm": 19.522151947021484,
        "learning_rate": 8.25509300265722e-06,
        "epoch": 1.744906997342781,
        "step": 1970
    },
    {
        "loss": 0.3132,
        "grad_norm": 36.07891845703125,
        "learning_rate": 8.246235606731621e-06,
        "epoch": 1.753764393268379,
        "step": 1980
    },
    {
        "loss": 0.3032,
        "grad_norm": 21.106021881103516,
        "learning_rate": 8.237378210806024e-06,
        "epoch": 1.762621789193977,
        "step": 1990
    },
    {
        "loss": 0.2966,
        "grad_norm": 10.26925277709961,
        "learning_rate": 8.228520814880426e-06,
        "epoch": 1.7714791851195748,
        "step": 2000
    },
    {
        "loss": 0.2683,
        "grad_norm": 17.721242904663086,
        "learning_rate": 8.219663418954828e-06,
        "epoch": 1.7803365810451726,
        "step": 2010
    },
    {
        "loss": 0.2955,
        "grad_norm": 39.612545013427734,
        "learning_rate": 8.210806023029229e-06,
        "epoch": 1.7891939769707705,
        "step": 2020
    },
    {
        "loss": 0.3442,
        "grad_norm": 34.98713302612305,
        "learning_rate": 8.201948627103632e-06,
        "epoch": 1.7980513728963685,
        "step": 2030
    },
    {
        "loss": 0.2687,
        "grad_norm": 7.969947338104248,
        "learning_rate": 8.193091231178034e-06,
        "epoch": 1.8069087688219665,
        "step": 2040
    },
    {
        "loss": 0.3381,
        "grad_norm": 17.846569061279297,
        "learning_rate": 8.184233835252436e-06,
        "epoch": 1.8157661647475642,
        "step": 2050
    },
    {
        "loss": 0.3446,
        "grad_norm": 3.51050066947937,
        "learning_rate": 8.175376439326839e-06,
        "epoch": 1.824623560673162,
        "step": 2060
    },
    {
        "loss": 0.2759,
        "grad_norm": 9.951637268066406,
        "learning_rate": 8.16651904340124e-06,
        "epoch": 1.83348095659876,
        "step": 2070
    },
    {
        "loss": 0.3851,
        "grad_norm": 37.3319091796875,
        "learning_rate": 8.157661647475644e-06,
        "epoch": 1.842338352524358,
        "step": 2080
    },
    {
        "loss": 0.3567,
        "grad_norm": 17.00420570373535,
        "learning_rate": 8.148804251550045e-06,
        "epoch": 1.8511957484499557,
        "step": 2090
    },
    {
        "loss": 0.3628,
        "grad_norm": 31.023847579956055,
        "learning_rate": 8.139946855624447e-06,
        "epoch": 1.8600531443755535,
        "step": 2100
    },
    {
        "loss": 0.3224,
        "grad_norm": 26.03668975830078,
        "learning_rate": 8.131089459698849e-06,
        "epoch": 1.8689105403011514,
        "step": 2110
    },
    {
        "loss": 0.2416,
        "grad_norm": 4.44786262512207,
        "learning_rate": 8.12223206377325e-06,
        "epoch": 1.8777679362267494,
        "step": 2120
    },
    {
        "loss": 0.2727,
        "grad_norm": 15.096532821655273,
        "learning_rate": 8.113374667847654e-06,
        "epoch": 1.8866253321523472,
        "step": 2130
    },
    {
        "loss": 0.2077,
        "grad_norm": 13.849652290344238,
        "learning_rate": 8.104517271922055e-06,
        "epoch": 1.895482728077945,
        "step": 2140
    },
    {
        "loss": 0.334,
        "grad_norm": 40.976139068603516,
        "learning_rate": 8.095659875996459e-06,
        "epoch": 1.904340124003543,
        "step": 2150
    },
    {
        "loss": 0.3226,
        "grad_norm": 21.39752197265625,
        "learning_rate": 8.08680248007086e-06,
        "epoch": 1.9131975199291409,
        "step": 2160
    },
    {
        "loss": 0.2949,
        "grad_norm": 26.152511596679688,
        "learning_rate": 8.077945084145262e-06,
        "epoch": 1.9220549158547389,
        "step": 2170
    },
    {
        "loss": 0.2311,
        "grad_norm": 11.12165641784668,
        "learning_rate": 8.069087688219665e-06,
        "epoch": 1.9309123117803366,
        "step": 2180
    },
    {
        "loss": 0.3378,
        "grad_norm": 26.672943115234375,
        "learning_rate": 8.060230292294067e-06,
        "epoch": 1.9397697077059344,
        "step": 2190
    },
    {
        "loss": 0.2969,
        "grad_norm": 54.49729919433594,
        "learning_rate": 8.051372896368468e-06,
        "epoch": 1.9486271036315324,
        "step": 2200
    },
    {
        "loss": 0.354,
        "grad_norm": 7.984591007232666,
        "learning_rate": 8.04251550044287e-06,
        "epoch": 1.9574844995571303,
        "step": 2210
    },
    {
        "loss": 0.2942,
        "grad_norm": 5.605584144592285,
        "learning_rate": 8.033658104517273e-06,
        "epoch": 1.966341895482728,
        "step": 2220
    },
    {
        "loss": 0.2667,
        "grad_norm": 10.806975364685059,
        "learning_rate": 8.024800708591675e-06,
        "epoch": 1.9751992914083258,
        "step": 2230
    },
    {
        "loss": 0.3748,
        "grad_norm": 26.888916015625,
        "learning_rate": 8.015943312666076e-06,
        "epoch": 1.9840566873339238,
        "step": 2240
    },
    {
        "loss": 0.3811,
        "grad_norm": 35.33046340942383,
        "learning_rate": 8.00708591674048e-06,
        "epoch": 1.9929140832595218,
        "step": 2250
    },
    {
        "eval_loss": 0.35634562373161316,
        "eval_accuracy": 0.86548,
        "eval_precision": 0.80627,
        "eval_recall": 0.96213,
        "eval_f1": 0.87733,
        "eval_runtime": 149.5993,
        "eval_samples_per_second": 60.375,
        "eval_steps_per_second": 3.777,
        "epoch": 2.0,
        "step": 2258
    },
    {
        "loss": 0.2586,
        "grad_norm": 51.69575119018555,
        "learning_rate": 7.998228520814881e-06,
        "epoch": 2.0017714791851198,
        "step": 2260
    },
    {
        "loss": 0.1677,
        "grad_norm": 14.1830415725708,
        "learning_rate": 7.989371124889283e-06,
        "epoch": 2.0106288751107173,
        "step": 2270
    },
    {
        "loss": 0.3315,
        "grad_norm": 21.938886642456055,
        "learning_rate": 7.980513728963686e-06,
        "epoch": 2.0194862710363153,
        "step": 2280
    },
    {
        "loss": 0.1949,
        "grad_norm": 18.612979888916016,
        "learning_rate": 7.971656333038086e-06,
        "epoch": 2.0283436669619133,
        "step": 2290
    },
    {
        "loss": 0.2075,
        "grad_norm": 53.6501579284668,
        "learning_rate": 7.96279893711249e-06,
        "epoch": 2.0372010628875112,
        "step": 2300
    },
    {
        "loss": 0.2573,
        "grad_norm": 16.285024642944336,
        "learning_rate": 7.953941541186891e-06,
        "epoch": 2.0460584588131088,
        "step": 2310
    },
    {
        "loss": 0.1835,
        "grad_norm": 32.63534164428711,
        "learning_rate": 7.945084145261294e-06,
        "epoch": 2.0549158547387067,
        "step": 2320
    },
    {
        "loss": 0.189,
        "grad_norm": 6.456857681274414,
        "learning_rate": 7.936226749335696e-06,
        "epoch": 2.0637732506643047,
        "step": 2330
    },
    {
        "loss": 0.2741,
        "grad_norm": 23.78996467590332,
        "learning_rate": 7.927369353410098e-06,
        "epoch": 2.0726306465899027,
        "step": 2340
    },
    {
        "loss": 0.2465,
        "grad_norm": 49.89091491699219,
        "learning_rate": 7.918511957484501e-06,
        "epoch": 2.0814880425155002,
        "step": 2350
    },
    {
        "loss": 0.1876,
        "grad_norm": 55.44816589355469,
        "learning_rate": 7.909654561558902e-06,
        "epoch": 2.090345438441098,
        "step": 2360
    },
    {
        "loss": 0.2389,
        "grad_norm": 23.169591903686523,
        "learning_rate": 7.900797165633304e-06,
        "epoch": 2.099202834366696,
        "step": 2370
    },
    {
        "loss": 0.2237,
        "grad_norm": 48.610660552978516,
        "learning_rate": 7.891939769707706e-06,
        "epoch": 2.108060230292294,
        "step": 2380
    },
    {
        "loss": 0.2645,
        "grad_norm": 50.56047821044922,
        "learning_rate": 7.883082373782109e-06,
        "epoch": 2.116917626217892,
        "step": 2390
    },
    {
        "loss": 0.2482,
        "grad_norm": 14.02447509765625,
        "learning_rate": 7.87422497785651e-06,
        "epoch": 2.1257750221434897,
        "step": 2400
    },
    {
        "loss": 0.206,
        "grad_norm": 23.952716827392578,
        "learning_rate": 7.865367581930912e-06,
        "epoch": 2.1346324180690877,
        "step": 2410
    },
    {
        "loss": 0.2909,
        "grad_norm": 10.8904447555542,
        "learning_rate": 7.856510186005316e-06,
        "epoch": 2.1434898139946856,
        "step": 2420
    },
    {
        "loss": 0.2009,
        "grad_norm": 37.79105758666992,
        "learning_rate": 7.847652790079717e-06,
        "epoch": 2.1523472099202836,
        "step": 2430
    },
    {
        "loss": 0.1108,
        "grad_norm": 3.291689395904541,
        "learning_rate": 7.838795394154119e-06,
        "epoch": 2.161204605845881,
        "step": 2440
    },
    {
        "loss": 0.2284,
        "grad_norm": 3.8494162559509277,
        "learning_rate": 7.829937998228522e-06,
        "epoch": 2.170062001771479,
        "step": 2450
    },
    {
        "loss": 0.2488,
        "grad_norm": 10.104249954223633,
        "learning_rate": 7.821080602302924e-06,
        "epoch": 2.178919397697077,
        "step": 2460
    },
    {
        "loss": 0.267,
        "grad_norm": 24.93732452392578,
        "learning_rate": 7.812223206377327e-06,
        "epoch": 2.187776793622675,
        "step": 2470
    },
    {
        "loss": 0.3398,
        "grad_norm": 16.55607032775879,
        "learning_rate": 7.803365810451727e-06,
        "epoch": 2.1966341895482726,
        "step": 2480
    },
    {
        "loss": 0.1226,
        "grad_norm": 1.0411059856414795,
        "learning_rate": 7.79450841452613e-06,
        "epoch": 2.2054915854738706,
        "step": 2490
    },
    {
        "loss": 0.0981,
        "grad_norm": 48.63877868652344,
        "learning_rate": 7.785651018600532e-06,
        "epoch": 2.2143489813994686,
        "step": 2500
    },
    {
        "loss": 0.3013,
        "grad_norm": 4.691439628601074,
        "learning_rate": 7.776793622674933e-06,
        "epoch": 2.2232063773250665,
        "step": 2510
    },
    {
        "loss": 0.1885,
        "grad_norm": 4.037015914916992,
        "learning_rate": 7.767936226749337e-06,
        "epoch": 2.2320637732506645,
        "step": 2520
    },
    {
        "loss": 0.2689,
        "grad_norm": 4.110450267791748,
        "learning_rate": 7.759078830823738e-06,
        "epoch": 2.240921169176262,
        "step": 2530
    },
    {
        "loss": 0.1927,
        "grad_norm": 17.255840301513672,
        "learning_rate": 7.750221434898142e-06,
        "epoch": 2.24977856510186,
        "step": 2540
    },
    {
        "loss": 0.1346,
        "grad_norm": 3.53486704826355,
        "learning_rate": 7.741364038972543e-06,
        "epoch": 2.258635961027458,
        "step": 2550
    },
    {
        "loss": 0.2374,
        "grad_norm": 37.30702590942383,
        "learning_rate": 7.732506643046945e-06,
        "epoch": 2.267493356953056,
        "step": 2560
    },
    {
        "loss": 0.2255,
        "grad_norm": 57.61193084716797,
        "learning_rate": 7.723649247121346e-06,
        "epoch": 2.2763507528786535,
        "step": 2570
    },
    {
        "loss": 0.2142,
        "grad_norm": 14.774256706237793,
        "learning_rate": 7.714791851195748e-06,
        "epoch": 2.2852081488042515,
        "step": 2580
    },
    {
        "loss": 0.2194,
        "grad_norm": 18.11249351501465,
        "learning_rate": 7.705934455270151e-06,
        "epoch": 2.2940655447298495,
        "step": 2590
    },
    {
        "loss": 0.3465,
        "grad_norm": 30.873533248901367,
        "learning_rate": 7.697077059344553e-06,
        "epoch": 2.3029229406554474,
        "step": 2600
    },
    {
        "loss": 0.2778,
        "grad_norm": 78.7972412109375,
        "learning_rate": 7.688219663418956e-06,
        "epoch": 2.311780336581045,
        "step": 2610
    },
    {
        "loss": 0.3104,
        "grad_norm": 78.27478790283203,
        "learning_rate": 7.679362267493358e-06,
        "epoch": 2.320637732506643,
        "step": 2620
    },
    {
        "loss": 0.2465,
        "grad_norm": 10.686539649963379,
        "learning_rate": 7.67050487156776e-06,
        "epoch": 2.329495128432241,
        "step": 2630
    },
    {
        "loss": 0.2045,
        "grad_norm": 14.092181205749512,
        "learning_rate": 7.661647475642163e-06,
        "epoch": 2.338352524357839,
        "step": 2640
    },
    {
        "loss": 0.1373,
        "grad_norm": 48.27988052368164,
        "learning_rate": 7.652790079716564e-06,
        "epoch": 2.3472099202834364,
        "step": 2650
    },
    {
        "loss": 0.201,
        "grad_norm": 38.12451934814453,
        "learning_rate": 7.643932683790966e-06,
        "epoch": 2.3560673162090344,
        "step": 2660
    },
    {
        "loss": 0.1928,
        "grad_norm": 23.75607681274414,
        "learning_rate": 7.635075287865368e-06,
        "epoch": 2.3649247121346324,
        "step": 2670
    },
    {
        "loss": 0.1686,
        "grad_norm": 6.447617530822754,
        "learning_rate": 7.62621789193977e-06,
        "epoch": 2.3737821080602304,
        "step": 2680
    },
    {
        "loss": 0.2006,
        "grad_norm": 16.544212341308594,
        "learning_rate": 7.6173604960141725e-06,
        "epoch": 2.3826395039858284,
        "step": 2690
    },
    {
        "loss": 0.2555,
        "grad_norm": 13.231437683105469,
        "learning_rate": 7.608503100088574e-06,
        "epoch": 2.391496899911426,
        "step": 2700
    },
    {
        "loss": 0.2152,
        "grad_norm": 53.989044189453125,
        "learning_rate": 7.599645704162977e-06,
        "epoch": 2.400354295837024,
        "step": 2710
    },
    {
        "loss": 0.2018,
        "grad_norm": 26.75714111328125,
        "learning_rate": 7.590788308237379e-06,
        "epoch": 2.409211691762622,
        "step": 2720
    },
    {
        "loss": 0.1011,
        "grad_norm": 38.10574722290039,
        "learning_rate": 7.5819309123117815e-06,
        "epoch": 2.41806908768822,
        "step": 2730
    },
    {
        "loss": 0.2614,
        "grad_norm": 52.80916213989258,
        "learning_rate": 7.573073516386183e-06,
        "epoch": 2.4269264836138174,
        "step": 2740
    },
    {
        "loss": 0.2452,
        "grad_norm": 6.536996841430664,
        "learning_rate": 7.5642161204605856e-06,
        "epoch": 2.4357838795394153,
        "step": 2750
    },
    {
        "loss": 0.2111,
        "grad_norm": 33.21136474609375,
        "learning_rate": 7.555358724534987e-06,
        "epoch": 2.4446412754650133,
        "step": 2760
    },
    {
        "loss": 0.245,
        "grad_norm": 4.166776657104492,
        "learning_rate": 7.546501328609389e-06,
        "epoch": 2.4534986713906113,
        "step": 2770
    },
    {
        "loss": 0.1953,
        "grad_norm": 7.230647087097168,
        "learning_rate": 7.537643932683791e-06,
        "epoch": 2.4623560673162093,
        "step": 2780
    },
    {
        "loss": 0.1373,
        "grad_norm": 9.931864738464355,
        "learning_rate": 7.528786536758194e-06,
        "epoch": 2.471213463241807,
        "step": 2790
    },
    {
        "loss": 0.1724,
        "grad_norm": 4.65293550491333,
        "learning_rate": 7.519929140832596e-06,
        "epoch": 2.4800708591674048,
        "step": 2800
    },
    {
        "loss": 0.3312,
        "grad_norm": 13.50719928741455,
        "learning_rate": 7.511071744906998e-06,
        "epoch": 2.4889282550930028,
        "step": 2810
    },
    {
        "loss": 0.2417,
        "grad_norm": 3.4378042221069336,
        "learning_rate": 7.5022143489814e-06,
        "epoch": 2.4977856510186003,
        "step": 2820
    },
    {
        "loss": 0.1488,
        "grad_norm": 39.83427810668945,
        "learning_rate": 7.493356953055803e-06,
        "epoch": 2.5066430469441983,
        "step": 2830
    },
    {
        "loss": 0.262,
        "grad_norm": 0.7468695640563965,
        "learning_rate": 7.484499557130205e-06,
        "epoch": 2.5155004428697962,
        "step": 2840
    },
    {
        "loss": 0.1707,
        "grad_norm": 37.52201843261719,
        "learning_rate": 7.475642161204606e-06,
        "epoch": 2.524357838795394,
        "step": 2850
    },
    {
        "loss": 0.2307,
        "grad_norm": 75.41666412353516,
        "learning_rate": 7.466784765279008e-06,
        "epoch": 2.533215234720992,
        "step": 2860
    },
    {
        "loss": 0.2469,
        "grad_norm": 2.1377527713775635,
        "learning_rate": 7.457927369353411e-06,
        "epoch": 2.54207263064659,
        "step": 2870
    },
    {
        "loss": 0.3374,
        "grad_norm": 23.0914249420166,
        "learning_rate": 7.449069973427812e-06,
        "epoch": 2.5509300265721877,
        "step": 2880
    },
    {
        "loss": 0.2804,
        "grad_norm": 18.600467681884766,
        "learning_rate": 7.440212577502215e-06,
        "epoch": 2.5597874224977857,
        "step": 2890
    },
    {
        "loss": 0.2358,
        "grad_norm": 58.368202209472656,
        "learning_rate": 7.431355181576617e-06,
        "epoch": 2.5686448184233837,
        "step": 2900
    },
    {
        "loss": 0.1953,
        "grad_norm": 29.06464958190918,
        "learning_rate": 7.42249778565102e-06,
        "epoch": 2.577502214348981,
        "step": 2910
    },
    {
        "loss": 0.2988,
        "grad_norm": 34.54716873168945,
        "learning_rate": 7.413640389725421e-06,
        "epoch": 2.586359610274579,
        "step": 2920
    },
    {
        "loss": 0.2074,
        "grad_norm": 52.8600959777832,
        "learning_rate": 7.404782993799824e-06,
        "epoch": 2.595217006200177,
        "step": 2930
    },
    {
        "loss": 0.1945,
        "grad_norm": 13.877970695495605,
        "learning_rate": 7.3959255978742254e-06,
        "epoch": 2.604074402125775,
        "step": 2940
    },
    {
        "loss": 0.1152,
        "grad_norm": 46.08885192871094,
        "learning_rate": 7.387068201948627e-06,
        "epoch": 2.612931798051373,
        "step": 2950
    },
    {
        "loss": 0.2028,
        "grad_norm": 16.059579849243164,
        "learning_rate": 7.3782108060230295e-06,
        "epoch": 2.6217891939769706,
        "step": 2960
    },
    {
        "loss": 0.29,
        "grad_norm": 9.097233772277832,
        "learning_rate": 7.369353410097432e-06,
        "epoch": 2.6306465899025686,
        "step": 2970
    },
    {
        "loss": 0.2199,
        "grad_norm": 84.56898498535156,
        "learning_rate": 7.3604960141718344e-06,
        "epoch": 2.6395039858281666,
        "step": 2980
    },
    {
        "loss": 0.214,
        "grad_norm": 6.935011386871338,
        "learning_rate": 7.351638618246236e-06,
        "epoch": 2.648361381753764,
        "step": 2990
    },
    {
        "loss": 0.1323,
        "grad_norm": 29.051992416381836,
        "learning_rate": 7.3427812223206385e-06,
        "epoch": 2.657218777679362,
        "step": 3000
    },
    {
        "loss": 0.196,
        "grad_norm": 7.235388278961182,
        "learning_rate": 7.333923826395041e-06,
        "epoch": 2.66607617360496,
        "step": 3010
    },
    {
        "loss": 0.3585,
        "grad_norm": 75.63216400146484,
        "learning_rate": 7.325066430469443e-06,
        "epoch": 2.674933569530558,
        "step": 3020
    },
    {
        "loss": 0.1174,
        "grad_norm": 38.70362091064453,
        "learning_rate": 7.316209034543845e-06,
        "epoch": 2.683790965456156,
        "step": 3030
    },
    {
        "loss": 0.2706,
        "grad_norm": 3.4429566860198975,
        "learning_rate": 7.307351638618247e-06,
        "epoch": 2.692648361381754,
        "step": 3040
    },
    {
        "loss": 0.3309,
        "grad_norm": 2.1261091232299805,
        "learning_rate": 7.298494242692648e-06,
        "epoch": 2.7015057573073515,
        "step": 3050
    },
    {
        "loss": 0.286,
        "grad_norm": 2.2775185108184814,
        "learning_rate": 7.289636846767051e-06,
        "epoch": 2.7103631532329495,
        "step": 3060
    },
    {
        "loss": 0.1874,
        "grad_norm": 58.0259895324707,
        "learning_rate": 7.280779450841453e-06,
        "epoch": 2.7192205491585475,
        "step": 3070
    },
    {
        "loss": 0.2558,
        "grad_norm": 88.87188720703125,
        "learning_rate": 7.271922054915856e-06,
        "epoch": 2.728077945084145,
        "step": 3080
    },
    {
        "loss": 0.1132,
        "grad_norm": 2.387392044067383,
        "learning_rate": 7.263064658990257e-06,
        "epoch": 2.736935341009743,
        "step": 3090
    },
    {
        "loss": 0.2159,
        "grad_norm": 49.57063674926758,
        "learning_rate": 7.25420726306466e-06,
        "epoch": 2.745792736935341,
        "step": 3100
    },
    {
        "loss": 0.2952,
        "grad_norm": 29.175710678100586,
        "learning_rate": 7.245349867139062e-06,
        "epoch": 2.754650132860939,
        "step": 3110
    },
    {
        "loss": 0.2494,
        "grad_norm": 97.19168853759766,
        "learning_rate": 7.2364924712134646e-06,
        "epoch": 2.763507528786537,
        "step": 3120
    },
    {
        "loss": 0.0957,
        "grad_norm": 2.4392359256744385,
        "learning_rate": 7.227635075287865e-06,
        "epoch": 2.7723649247121345,
        "step": 3130
    },
    {
        "loss": 0.1741,
        "grad_norm": 56.12584686279297,
        "learning_rate": 7.218777679362268e-06,
        "epoch": 2.7812223206377324,
        "step": 3140
    },
    {
        "loss": 0.2702,
        "grad_norm": 63.106300354003906,
        "learning_rate": 7.20992028343667e-06,
        "epoch": 2.7900797165633304,
        "step": 3150
    },
    {
        "loss": 0.1626,
        "grad_norm": 63.06984329223633,
        "learning_rate": 7.201062887511072e-06,
        "epoch": 2.7989371124889284,
        "step": 3160
    },
    {
        "loss": 0.1648,
        "grad_norm": 83.96873474121094,
        "learning_rate": 7.192205491585474e-06,
        "epoch": 2.807794508414526,
        "step": 3170
    },
    {
        "loss": 0.1655,
        "grad_norm": 95.0746841430664,
        "learning_rate": 7.183348095659877e-06,
        "epoch": 2.816651904340124,
        "step": 3180
    },
    {
        "loss": 0.2196,
        "grad_norm": 0.5824891924858093,
        "learning_rate": 7.174490699734279e-06,
        "epoch": 2.825509300265722,
        "step": 3190
    },
    {
        "loss": 0.1797,
        "grad_norm": 30.686445236206055,
        "learning_rate": 7.165633303808681e-06,
        "epoch": 2.83436669619132,
        "step": 3200
    },
    {
        "loss": 0.4374,
        "grad_norm": 36.95708084106445,
        "learning_rate": 7.156775907883083e-06,
        "epoch": 2.843224092116918,
        "step": 3210
    },
    {
        "loss": 0.098,
        "grad_norm": 12.613503456115723,
        "learning_rate": 7.147918511957485e-06,
        "epoch": 2.8520814880425154,
        "step": 3220
    },
    {
        "loss": 0.1887,
        "grad_norm": 144.5872344970703,
        "learning_rate": 7.1390611160318865e-06,
        "epoch": 2.8609388839681134,
        "step": 3230
    },
    {
        "loss": 0.138,
        "grad_norm": 95.7151107788086,
        "learning_rate": 7.130203720106289e-06,
        "epoch": 2.8697962798937113,
        "step": 3240
    },
    {
        "loss": 0.1933,
        "grad_norm": 44.36670684814453,
        "learning_rate": 7.121346324180691e-06,
        "epoch": 2.878653675819309,
        "step": 3250
    },
    {
        "loss": 0.1086,
        "grad_norm": 88.29829406738281,
        "learning_rate": 7.112488928255094e-06,
        "epoch": 2.887511071744907,
        "step": 3260
    },
    {
        "loss": 0.3711,
        "grad_norm": 7.951402187347412,
        "learning_rate": 7.1036315323294955e-06,
        "epoch": 2.896368467670505,
        "step": 3270
    },
    {
        "loss": 0.2573,
        "grad_norm": 63.38267517089844,
        "learning_rate": 7.094774136403898e-06,
        "epoch": 2.905225863596103,
        "step": 3280
    },
    {
        "loss": 0.155,
        "grad_norm": 28.909027099609375,
        "learning_rate": 7.0859167404783e-06,
        "epoch": 2.9140832595217008,
        "step": 3290
    },
    {
        "loss": 0.2091,
        "grad_norm": 1.9546382427215576,
        "learning_rate": 7.077059344552703e-06,
        "epoch": 2.9229406554472988,
        "step": 3300
    },
    {
        "loss": 0.2018,
        "grad_norm": 0.4075814187526703,
        "learning_rate": 7.0682019486271045e-06,
        "epoch": 2.9317980513728963,
        "step": 3310
    },
    {
        "loss": 0.217,
        "grad_norm": 1.9266670942306519,
        "learning_rate": 7.059344552701506e-06,
        "epoch": 2.9406554472984943,
        "step": 3320
    },
    {
        "loss": 0.3223,
        "grad_norm": 2.1727519035339355,
        "learning_rate": 7.0504871567759085e-06,
        "epoch": 2.9495128432240922,
        "step": 3330
    },
    {
        "loss": 0.2127,
        "grad_norm": 2.811142683029175,
        "learning_rate": 7.04162976085031e-06,
        "epoch": 2.9583702391496898,
        "step": 3340
    },
    {
        "loss": 0.1841,
        "grad_norm": 91.80206298828125,
        "learning_rate": 7.032772364924713e-06,
        "epoch": 2.9672276350752878,
        "step": 3350
    },
    {
        "loss": 0.267,
        "grad_norm": 91.96147155761719,
        "learning_rate": 7.023914968999115e-06,
        "epoch": 2.9760850310008857,
        "step": 3360
    },
    {
        "loss": 0.1494,
        "grad_norm": 0.38308387994766235,
        "learning_rate": 7.0150575730735175e-06,
        "epoch": 2.9849424269264837,
        "step": 3370
    },
    {
        "loss": 0.1321,
        "grad_norm": 100.58402252197266,
        "learning_rate": 7.006200177147919e-06,
        "epoch": 2.9937998228520817,
        "step": 3380
    },
    {
        "eval_loss": 0.2245759665966034,
        "eval_accuracy": 0.94442,
        "eval_precision": 0.95387,
        "eval_recall": 0.93401,
        "eval_f1": 0.94384,
        "eval_runtime": 149.92,
        "eval_samples_per_second": 60.245,
        "eval_steps_per_second": 3.769,
        "epoch": 3.0,
        "step": 3387
    },
    {
        "loss": 0.2002,
        "grad_norm": 51.12538528442383,
        "learning_rate": 6.9973427812223216e-06,
        "epoch": 3.002657218777679,
        "step": 3390
    },
    {
        "loss": 0.0848,
        "grad_norm": 40.89641189575195,
        "learning_rate": 6.988485385296724e-06,
        "epoch": 3.011514614703277,
        "step": 3400
    },
    {
        "loss": 0.2168,
        "grad_norm": 3.3562755584716797,
        "learning_rate": 6.979627989371125e-06,
        "epoch": 3.020372010628875,
        "step": 3410
    },
    {
        "loss": 0.1414,
        "grad_norm": 1.3604472875595093,
        "learning_rate": 6.970770593445527e-06,
        "epoch": 3.029229406554473,
        "step": 3420
    },
    {
        "loss": 0.0793,
        "grad_norm": 8.474985122680664,
        "learning_rate": 6.96191319751993e-06,
        "epoch": 3.0380868024800707,
        "step": 3430
    },
    {
        "loss": 0.1479,
        "grad_norm": 35.16762161254883,
        "learning_rate": 6.953055801594331e-06,
        "epoch": 3.0469441984056687,
        "step": 3440
    },
    {
        "loss": 0.3069,
        "grad_norm": 28.816377639770508,
        "learning_rate": 6.944198405668734e-06,
        "epoch": 3.0558015943312666,
        "step": 3450
    },
    {
        "loss": 0.1487,
        "grad_norm": 160.25833129882812,
        "learning_rate": 6.935341009743136e-06,
        "epoch": 3.0646589902568646,
        "step": 3460
    },
    {
        "loss": 0.1121,
        "grad_norm": 82.89625549316406,
        "learning_rate": 6.926483613817539e-06,
        "epoch": 3.073516386182462,
        "step": 3470
    },
    {
        "loss": 0.1434,
        "grad_norm": 4.262258529663086,
        "learning_rate": 6.91762621789194e-06,
        "epoch": 3.08237378210806,
        "step": 3480
    },
    {
        "loss": 0.1506,
        "grad_norm": 120.18563842773438,
        "learning_rate": 6.908768821966343e-06,
        "epoch": 3.091231178033658,
        "step": 3490
    },
    {
        "loss": 0.0992,
        "grad_norm": 84.94893646240234,
        "learning_rate": 6.899911426040744e-06,
        "epoch": 3.100088573959256,
        "step": 3500
    },
    {
        "loss": 0.1452,
        "grad_norm": 1.5014389753341675,
        "learning_rate": 6.891054030115146e-06,
        "epoch": 3.108945969884854,
        "step": 3510
    },
    {
        "loss": 0.223,
        "grad_norm": 0.20683979988098145,
        "learning_rate": 6.882196634189548e-06,
        "epoch": 3.1178033658104516,
        "step": 3520
    },
    {
        "loss": 0.2115,
        "grad_norm": 39.103450775146484,
        "learning_rate": 6.873339238263951e-06,
        "epoch": 3.1266607617360496,
        "step": 3530
    },
    {
        "loss": 0.3238,
        "grad_norm": 13.605277061462402,
        "learning_rate": 6.864481842338353e-06,
        "epoch": 3.1355181576616475,
        "step": 3540
    },
    {
        "loss": 0.0866,
        "grad_norm": 5.787594318389893,
        "learning_rate": 6.855624446412755e-06,
        "epoch": 3.1443755535872455,
        "step": 3550
    },
    {
        "loss": 0.1634,
        "grad_norm": 0.23782096803188324,
        "learning_rate": 6.846767050487157e-06,
        "epoch": 3.153232949512843,
        "step": 3560
    },
    {
        "loss": 0.1112,
        "grad_norm": 94.96890258789062,
        "learning_rate": 6.83790965456156e-06,
        "epoch": 3.162090345438441,
        "step": 3570
    },
    {
        "loss": 0.251,
        "grad_norm": 0.24745428562164307,
        "learning_rate": 6.829052258635962e-06,
        "epoch": 3.170947741364039,
        "step": 3580
    },
    {
        "loss": 0.2015,
        "grad_norm": 0.20577475428581238,
        "learning_rate": 6.820194862710364e-06,
        "epoch": 3.179805137289637,
        "step": 3590
    },
    {
        "loss": 0.0487,
        "grad_norm": 0.5323505997657776,
        "learning_rate": 6.8113374667847655e-06,
        "epoch": 3.1886625332152345,
        "step": 3600
    },
    {
        "loss": 0.1578,
        "grad_norm": 11.255391120910645,
        "learning_rate": 6.802480070859168e-06,
        "epoch": 3.1975199291408325,
        "step": 3610
    },
    {
        "loss": 0.1001,
        "grad_norm": 61.54043197631836,
        "learning_rate": 6.79362267493357e-06,
        "epoch": 3.2063773250664305,
        "step": 3620
    },
    {
        "loss": 0.1266,
        "grad_norm": 42.43164825439453,
        "learning_rate": 6.784765279007972e-06,
        "epoch": 3.2152347209920284,
        "step": 3630
    },
    {
        "loss": 0.3124,
        "grad_norm": 3.0064055919647217,
        "learning_rate": 6.7759078830823745e-06,
        "epoch": 3.2240921169176264,
        "step": 3640
    },
    {
        "loss": 0.1441,
        "grad_norm": 7.884159564971924,
        "learning_rate": 6.767050487156777e-06,
        "epoch": 3.232949512843224,
        "step": 3650
    },
    {
        "loss": 0.1207,
        "grad_norm": 110.69169616699219,
        "learning_rate": 6.7581930912311786e-06,
        "epoch": 3.241806908768822,
        "step": 3660
    },
    {
        "loss": 0.1524,
        "grad_norm": 25.45488929748535,
        "learning_rate": 6.749335695305581e-06,
        "epoch": 3.25066430469442,
        "step": 3670
    },
    {
        "loss": 0.118,
        "grad_norm": 2.6264655590057373,
        "learning_rate": 6.7404782993799835e-06,
        "epoch": 3.259521700620018,
        "step": 3680
    },
    {
        "loss": 0.0487,
        "grad_norm": 0.28648802638053894,
        "learning_rate": 6.731620903454384e-06,
        "epoch": 3.2683790965456154,
        "step": 3690
    },
    {
        "loss": 0.1759,
        "grad_norm": 0.28529900312423706,
        "learning_rate": 6.722763507528787e-06,
        "epoch": 3.2772364924712134,
        "step": 3700
    },
    {
        "loss": 0.1466,
        "grad_norm": 0.25209569931030273,
        "learning_rate": 6.713906111603189e-06,
        "epoch": 3.2860938883968114,
        "step": 3710
    },
    {
        "loss": 0.1153,
        "grad_norm": 118.0688247680664,
        "learning_rate": 6.705048715677592e-06,
        "epoch": 3.2949512843224094,
        "step": 3720
    },
    {
        "loss": 0.2191,
        "grad_norm": 2.3115384578704834,
        "learning_rate": 6.696191319751993e-06,
        "epoch": 3.3038086802480073,
        "step": 3730
    },
    {
        "loss": 0.0378,
        "grad_norm": 35.85234069824219,
        "learning_rate": 6.687333923826396e-06,
        "epoch": 3.312666076173605,
        "step": 3740
    },
    {
        "loss": 0.0962,
        "grad_norm": 1.3259159326553345,
        "learning_rate": 6.678476527900798e-06,
        "epoch": 3.321523472099203,
        "step": 3750
    },
    {
        "loss": 0.2155,
        "grad_norm": 110.14138793945312,
        "learning_rate": 6.6696191319752006e-06,
        "epoch": 3.330380868024801,
        "step": 3760
    },
    {
        "loss": 0.0556,
        "grad_norm": 0.2746155261993408,
        "learning_rate": 6.660761736049602e-06,
        "epoch": 3.3392382639503984,
        "step": 3770
    },
    {
        "loss": 0.0953,
        "grad_norm": 0.23706288635730743,
        "learning_rate": 6.651904340124004e-06,
        "epoch": 3.3480956598759963,
        "step": 3780
    },
    {
        "loss": 0.1246,
        "grad_norm": 44.050262451171875,
        "learning_rate": 6.643046944198405e-06,
        "epoch": 3.3569530558015943,
        "step": 3790
    },
    {
        "loss": 0.2101,
        "grad_norm": 18.332612991333008,
        "learning_rate": 6.634189548272808e-06,
        "epoch": 3.3658104517271923,
        "step": 3800
    },
    {
        "loss": 0.0521,
        "grad_norm": 97.67290496826172,
        "learning_rate": 6.62533215234721e-06,
        "epoch": 3.3746678476527903,
        "step": 3810
    },
    {
        "loss": 0.0838,
        "grad_norm": 79.34185791015625,
        "learning_rate": 6.616474756421613e-06,
        "epoch": 3.383525243578388,
        "step": 3820
    },
    {
        "loss": 0.1236,
        "grad_norm": 12.077733039855957,
        "learning_rate": 6.607617360496014e-06,
        "epoch": 3.3923826395039858,
        "step": 3830
    },
    {
        "loss": 0.1485,
        "grad_norm": 13.302335739135742,
        "learning_rate": 6.598759964570417e-06,
        "epoch": 3.4012400354295838,
        "step": 3840
    },
    {
        "loss": 0.2719,
        "grad_norm": 92.11701965332031,
        "learning_rate": 6.589902568644819e-06,
        "epoch": 3.4100974313551817,
        "step": 3850
    },
    {
        "loss": 0.339,
        "grad_norm": 70.95101928710938,
        "learning_rate": 6.581045172719222e-06,
        "epoch": 3.4189548272807793,
        "step": 3860
    },
    {
        "loss": 0.0796,
        "grad_norm": 19.24017906188965,
        "learning_rate": 6.572187776793623e-06,
        "epoch": 3.4278122232063772,
        "step": 3870
    },
    {
        "loss": 0.2731,
        "grad_norm": 31.83222198486328,
        "learning_rate": 6.563330380868025e-06,
        "epoch": 3.436669619131975,
        "step": 3880
    },
    {
        "loss": 0.1667,
        "grad_norm": 167.08352661132812,
        "learning_rate": 6.554472984942427e-06,
        "epoch": 3.445527015057573,
        "step": 3890
    },
    {
        "loss": 0.074,
        "grad_norm": 3.393099069595337,
        "learning_rate": 6.545615589016829e-06,
        "epoch": 3.454384410983171,
        "step": 3900
    },
    {
        "loss": 0.0843,
        "grad_norm": 6.071408271789551,
        "learning_rate": 6.5367581930912315e-06,
        "epoch": 3.4632418069087687,
        "step": 3910
    },
    {
        "loss": 0.1102,
        "grad_norm": 0.32369565963745117,
        "learning_rate": 6.527900797165634e-06,
        "epoch": 3.4720992028343667,
        "step": 3920
    },
    {
        "loss": 0.1391,
        "grad_norm": 3.1155803203582764,
        "learning_rate": 6.519043401240036e-06,
        "epoch": 3.4809565987599647,
        "step": 3930
    },
    {
        "loss": 0.1195,
        "grad_norm": 61.35051727294922,
        "learning_rate": 6.510186005314438e-06,
        "epoch": 3.4898139946855626,
        "step": 3940
    },
    {
        "loss": 0.193,
        "grad_norm": 13.46629524230957,
        "learning_rate": 6.5013286093888405e-06,
        "epoch": 3.49867139061116,
        "step": 3950
    },
    {
        "loss": 0.2568,
        "grad_norm": 89.40338897705078,
        "learning_rate": 6.492471213463243e-06,
        "epoch": 3.507528786536758,
        "step": 3960
    },
    {
        "loss": 0.214,
        "grad_norm": 38.66071701049805,
        "learning_rate": 6.483613817537644e-06,
        "epoch": 3.516386182462356,
        "step": 3970
    },
    {
        "loss": 0.0642,
        "grad_norm": 3.7167623043060303,
        "learning_rate": 6.474756421612046e-06,
        "epoch": 3.525243578387954,
        "step": 3980
    },
    {
        "loss": 0.1925,
        "grad_norm": 6.953530788421631,
        "learning_rate": 6.465899025686449e-06,
        "epoch": 3.534100974313552,
        "step": 3990
    },
    {
        "loss": 0.2756,
        "grad_norm": 9.389359474182129,
        "learning_rate": 6.457041629760851e-06,
        "epoch": 3.5429583702391496,
        "step": 4000
    },
    {
        "loss": 0.1479,
        "grad_norm": 3.1716651916503906,
        "learning_rate": 6.448184233835253e-06,
        "epoch": 3.5518157661647476,
        "step": 4010
    },
    {
        "loss": 0.1318,
        "grad_norm": 28.86458969116211,
        "learning_rate": 6.439326837909655e-06,
        "epoch": 3.5606731620903456,
        "step": 4020
    },
    {
        "loss": 0.1757,
        "grad_norm": 11.88841724395752,
        "learning_rate": 6.4304694419840576e-06,
        "epoch": 3.569530558015943,
        "step": 4030
    },
    {
        "loss": 0.3102,
        "grad_norm": 5.42709493637085,
        "learning_rate": 6.42161204605846e-06,
        "epoch": 3.578387953941541,
        "step": 4040
    },
    {
        "loss": 0.2184,
        "grad_norm": 2.9120311737060547,
        "learning_rate": 6.412754650132862e-06,
        "epoch": 3.587245349867139,
        "step": 4050
    },
    {
        "loss": 0.1241,
        "grad_norm": 99.3126220703125,
        "learning_rate": 6.403897254207263e-06,
        "epoch": 3.596102745792737,
        "step": 4060
    },
    {
        "loss": 0.1102,
        "grad_norm": 21.13508415222168,
        "learning_rate": 6.395039858281666e-06,
        "epoch": 3.604960141718335,
        "step": 4070
    },
    {
        "loss": 0.185,
        "grad_norm": 0.49180328845977783,
        "learning_rate": 6.386182462356067e-06,
        "epoch": 3.6138175376439325,
        "step": 4080
    },
    {
        "loss": 0.1546,
        "grad_norm": 15.980939865112305,
        "learning_rate": 6.37732506643047e-06,
        "epoch": 3.6226749335695305,
        "step": 4090
    },
    {
        "loss": 0.0833,
        "grad_norm": 7.770605564117432,
        "learning_rate": 6.368467670504872e-06,
        "epoch": 3.6315323294951285,
        "step": 4100
    },
    {
        "loss": 0.1524,
        "grad_norm": 5.5845842361450195,
        "learning_rate": 6.359610274579275e-06,
        "epoch": 3.640389725420726,
        "step": 4110
    },
    {
        "loss": 0.1289,
        "grad_norm": 0.2819482386112213,
        "learning_rate": 6.350752878653676e-06,
        "epoch": 3.649247121346324,
        "step": 4120
    },
    {
        "loss": 0.2996,
        "grad_norm": 3.505735397338867,
        "learning_rate": 6.341895482728079e-06,
        "epoch": 3.658104517271922,
        "step": 4130
    },
    {
        "loss": 0.2264,
        "grad_norm": 0.2605297267436981,
        "learning_rate": 6.333038086802481e-06,
        "epoch": 3.66696191319752,
        "step": 4140
    },
    {
        "loss": 0.1157,
        "grad_norm": 0.2226249873638153,
        "learning_rate": 6.324180690876884e-06,
        "epoch": 3.675819309123118,
        "step": 4150
    },
    {
        "loss": 0.2134,
        "grad_norm": 0.3172450363636017,
        "learning_rate": 6.315323294951284e-06,
        "epoch": 3.684676705048716,
        "step": 4160
    },
    {
        "loss": 0.1264,
        "grad_norm": 1.587231993675232,
        "learning_rate": 6.306465899025687e-06,
        "epoch": 3.6935341009743134,
        "step": 4170
    },
    {
        "loss": 0.1021,
        "grad_norm": 35.06346893310547,
        "learning_rate": 6.2976085031000885e-06,
        "epoch": 3.7023914968999114,
        "step": 4180
    },
    {
        "loss": 0.1106,
        "grad_norm": 0.22811827063560486,
        "learning_rate": 6.288751107174491e-06,
        "epoch": 3.7112488928255094,
        "step": 4190
    },
    {
        "loss": 0.3225,
        "grad_norm": 10.645207405090332,
        "learning_rate": 6.279893711248893e-06,
        "epoch": 3.720106288751107,
        "step": 4200
    },
    {
        "loss": 0.065,
        "grad_norm": 0.4577140510082245,
        "learning_rate": 6.271036315323296e-06,
        "epoch": 3.728963684676705,
        "step": 4210
    },
    {
        "loss": 0.1866,
        "grad_norm": 83.821533203125,
        "learning_rate": 6.2621789193976975e-06,
        "epoch": 3.737821080602303,
        "step": 4220
    },
    {
        "loss": 0.1486,
        "grad_norm": 0.3976655602455139,
        "learning_rate": 6.2533215234721e-06,
        "epoch": 3.746678476527901,
        "step": 4230
    },
    {
        "loss": 0.1985,
        "grad_norm": 4.933508396148682,
        "learning_rate": 6.244464127546502e-06,
        "epoch": 3.755535872453499,
        "step": 4240
    },
    {
        "loss": 0.2353,
        "grad_norm": 48.874881744384766,
        "learning_rate": 6.235606731620903e-06,
        "epoch": 3.7643932683790964,
        "step": 4250
    },
    {
        "loss": 0.1317,
        "grad_norm": 63.748046875,
        "learning_rate": 6.226749335695306e-06,
        "epoch": 3.7732506643046944,
        "step": 4260
    },
    {
        "loss": 0.1531,
        "grad_norm": 87.26464080810547,
        "learning_rate": 6.217891939769708e-06,
        "epoch": 3.7821080602302923,
        "step": 4270
    },
    {
        "loss": 0.1437,
        "grad_norm": 0.27733585238456726,
        "learning_rate": 6.2090345438441105e-06,
        "epoch": 3.7909654561558903,
        "step": 4280
    },
    {
        "loss": 0.1585,
        "grad_norm": 15.556803703308105,
        "learning_rate": 6.200177147918512e-06,
        "epoch": 3.799822852081488,
        "step": 4290
    },
    {
        "loss": 0.0208,
        "grad_norm": 1.5305967330932617,
        "learning_rate": 6.1913197519929146e-06,
        "epoch": 3.808680248007086,
        "step": 4300
    },
    {
        "loss": 0.2016,
        "grad_norm": 3.3679473400115967,
        "learning_rate": 6.182462356067317e-06,
        "epoch": 3.817537643932684,
        "step": 4310
    },
    {
        "loss": 0.036,
        "grad_norm": 0.21064697206020355,
        "learning_rate": 6.1736049601417195e-06,
        "epoch": 3.8263950398582818,
        "step": 4320
    },
    {
        "loss": 0.1485,
        "grad_norm": 33.27278137207031,
        "learning_rate": 6.164747564216121e-06,
        "epoch": 3.8352524357838798,
        "step": 4330
    },
    {
        "loss": 0.1536,
        "grad_norm": 70.38690185546875,
        "learning_rate": 6.155890168290523e-06,
        "epoch": 3.8441098317094773,
        "step": 4340
    },
    {
        "loss": 0.0979,
        "grad_norm": 0.3069396913051605,
        "learning_rate": 6.147032772364925e-06,
        "epoch": 3.8529672276350753,
        "step": 4350
    },
    {
        "loss": 0.1824,
        "grad_norm": 99.63713836669922,
        "learning_rate": 6.138175376439327e-06,
        "epoch": 3.8618246235606732,
        "step": 4360
    },
    {
        "loss": 0.1688,
        "grad_norm": 22.672285079956055,
        "learning_rate": 6.129317980513729e-06,
        "epoch": 3.8706820194862708,
        "step": 4370
    },
    {
        "loss": 0.1371,
        "grad_norm": 0.2651366889476776,
        "learning_rate": 6.120460584588132e-06,
        "epoch": 3.8795394154118688,
        "step": 4380
    },
    {
        "loss": 0.0509,
        "grad_norm": 219.58607482910156,
        "learning_rate": 6.111603188662534e-06,
        "epoch": 3.8883968113374667,
        "step": 4390
    },
    {
        "loss": 0.2915,
        "grad_norm": 3.757261276245117,
        "learning_rate": 6.102745792736936e-06,
        "epoch": 3.8972542072630647,
        "step": 4400
    },
    {
        "loss": 0.1358,
        "grad_norm": 0.373826265335083,
        "learning_rate": 6.093888396811338e-06,
        "epoch": 3.9061116031886627,
        "step": 4410
    },
    {
        "loss": 0.2248,
        "grad_norm": 0.9285464286804199,
        "learning_rate": 6.085031000885741e-06,
        "epoch": 3.9149689991142607,
        "step": 4420
    },
    {
        "loss": 0.1706,
        "grad_norm": 0.21215161681175232,
        "learning_rate": 6.076173604960143e-06,
        "epoch": 3.923826395039858,
        "step": 4430
    },
    {
        "loss": 0.049,
        "grad_norm": 0.21646781265735626,
        "learning_rate": 6.067316209034544e-06,
        "epoch": 3.932683790965456,
        "step": 4440
    },
    {
        "loss": 0.1322,
        "grad_norm": 205.202392578125,
        "learning_rate": 6.058458813108946e-06,
        "epoch": 3.941541186891054,
        "step": 4450
    },
    {
        "loss": 0.1055,
        "grad_norm": 2.698875665664673,
        "learning_rate": 6.049601417183349e-06,
        "epoch": 3.9503985828166517,
        "step": 4460
    },
    {
        "loss": 0.259,
        "grad_norm": 140.43341064453125,
        "learning_rate": 6.04074402125775e-06,
        "epoch": 3.9592559787422497,
        "step": 4470
    },
    {
        "loss": 0.106,
        "grad_norm": 9.814278602600098,
        "learning_rate": 6.031886625332153e-06,
        "epoch": 3.9681133746678476,
        "step": 4480
    },
    {
        "loss": 0.0094,
        "grad_norm": 4.033396244049072,
        "learning_rate": 6.023029229406555e-06,
        "epoch": 3.9769707705934456,
        "step": 4490
    },
    {
        "loss": 0.1458,
        "grad_norm": 53.54623794555664,
        "learning_rate": 6.014171833480958e-06,
        "epoch": 3.9858281665190436,
        "step": 4500
    },
    {
        "loss": 0.1945,
        "grad_norm": 3.0851504802703857,
        "learning_rate": 6.005314437555359e-06,
        "epoch": 3.994685562444641,
        "step": 4510
    },
    {
        "eval_loss": 0.1959836483001709,
        "eval_accuracy": 0.9576,
        "eval_precision": 0.94355,
        "eval_recall": 0.97343,
        "eval_f1": 0.95826,
        "eval_runtime": 149.9228,
        "eval_samples_per_second": 60.244,
        "eval_steps_per_second": 3.769,
        "epoch": 4.0,
        "step": 4516
    },
    {
        "loss": 0.0788,
        "grad_norm": 29.708269119262695,
        "learning_rate": 5.996457041629762e-06,
        "epoch": 4.0035429583702395,
        "step": 4520
    },
    {
        "loss": 0.0696,
        "grad_norm": 0.15209168195724487,
        "learning_rate": 5.9875996457041626e-06,
        "epoch": 4.012400354295837,
        "step": 4530
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.8256669640541077,
        "learning_rate": 5.978742249778565e-06,
        "epoch": 4.021257750221435,
        "step": 4540
    },
    {
        "loss": 0.1356,
        "grad_norm": 15.993602752685547,
        "learning_rate": 5.9698848538529675e-06,
        "epoch": 4.030115146147033,
        "step": 4550
    },
    {
        "loss": 0.0411,
        "grad_norm": 0.3759731948375702,
        "learning_rate": 5.96102745792737e-06,
        "epoch": 4.038972542072631,
        "step": 4560
    },
    {
        "loss": 0.0617,
        "grad_norm": 0.13196273148059845,
        "learning_rate": 5.9521700620017716e-06,
        "epoch": 4.0478299379982285,
        "step": 4570
    },
    {
        "loss": 0.1154,
        "grad_norm": 0.9368904232978821,
        "learning_rate": 5.943312666076174e-06,
        "epoch": 4.0566873339238265,
        "step": 4580
    },
    {
        "loss": 0.1785,
        "grad_norm": 2.256181478500366,
        "learning_rate": 5.9344552701505765e-06,
        "epoch": 4.0655447298494245,
        "step": 4590
    },
    {
        "loss": 0.1234,
        "grad_norm": 2.3954977989196777,
        "learning_rate": 5.925597874224979e-06,
        "epoch": 4.0744021257750225,
        "step": 4600
    },
    {
        "loss": 0.1768,
        "grad_norm": 210.64356994628906,
        "learning_rate": 5.9167404782993805e-06,
        "epoch": 4.0832595217006205,
        "step": 4610
    },
    {
        "loss": 0.1631,
        "grad_norm": 0.26063162088394165,
        "learning_rate": 5.907883082373782e-06,
        "epoch": 4.0921169176262175,
        "step": 4620
    },
    {
        "loss": 0.1828,
        "grad_norm": 3.0142829418182373,
        "learning_rate": 5.899025686448185e-06,
        "epoch": 4.1009743135518155,
        "step": 4630
    },
    {
        "loss": 0.0388,
        "grad_norm": 0.5623618364334106,
        "learning_rate": 5.890168290522586e-06,
        "epoch": 4.1098317094774135,
        "step": 4640
    },
    {
        "loss": 0.1332,
        "grad_norm": 0.15340083837509155,
        "learning_rate": 5.881310894596989e-06,
        "epoch": 4.1186891054030115,
        "step": 4650
    },
    {
        "loss": 0.1243,
        "grad_norm": 52.739891052246094,
        "learning_rate": 5.872453498671391e-06,
        "epoch": 4.1275465013286095,
        "step": 4660
    },
    {
        "loss": 0.0967,
        "grad_norm": 0.4275725483894348,
        "learning_rate": 5.8635961027457936e-06,
        "epoch": 4.136403897254207,
        "step": 4670
    },
    {
        "loss": 0.095,
        "grad_norm": 0.1456776112318039,
        "learning_rate": 5.854738706820195e-06,
        "epoch": 4.145261293179805,
        "step": 4680
    },
    {
        "loss": 0.1112,
        "grad_norm": 15.321423530578613,
        "learning_rate": 5.845881310894598e-06,
        "epoch": 4.154118689105403,
        "step": 4690
    },
    {
        "loss": 0.1934,
        "grad_norm": 8.619664192199707,
        "learning_rate": 5.837023914969e-06,
        "epoch": 4.1629760850310005,
        "step": 4700
    },
    {
        "loss": 0.1368,
        "grad_norm": 55.085121154785156,
        "learning_rate": 5.8281665190434025e-06,
        "epoch": 4.1718334809565985,
        "step": 4710
    },
    {
        "loss": 0.0909,
        "grad_norm": 0.5325379967689514,
        "learning_rate": 5.819309123117803e-06,
        "epoch": 4.180690876882196,
        "step": 4720
    },
    {
        "loss": 0.0682,
        "grad_norm": 0.18156546354293823,
        "learning_rate": 5.810451727192206e-06,
        "epoch": 4.189548272807794,
        "step": 4730
    },
    {
        "loss": 0.0762,
        "grad_norm": 63.01736068725586,
        "learning_rate": 5.801594331266608e-06,
        "epoch": 4.198405668733392,
        "step": 4740
    },
    {
        "loss": 0.0343,
        "grad_norm": 1.421970248222351,
        "learning_rate": 5.79273693534101e-06,
        "epoch": 4.20726306465899,
        "step": 4750
    },
    {
        "loss": 0.0778,
        "grad_norm": 2.603489637374878,
        "learning_rate": 5.783879539415412e-06,
        "epoch": 4.216120460584588,
        "step": 4760
    },
    {
        "loss": 0.1165,
        "grad_norm": 26.84393882751465,
        "learning_rate": 5.775022143489815e-06,
        "epoch": 4.224977856510186,
        "step": 4770
    },
    {
        "loss": 0.1583,
        "grad_norm": 149.27757263183594,
        "learning_rate": 5.766164747564217e-06,
        "epoch": 4.233835252435784,
        "step": 4780
    },
    {
        "loss": 0.1945,
        "grad_norm": 6.416988849639893,
        "learning_rate": 5.757307351638619e-06,
        "epoch": 4.242692648361381,
        "step": 4790
    },
    {
        "loss": 0.0962,
        "grad_norm": 2.443790912628174,
        "learning_rate": 5.748449955713021e-06,
        "epoch": 4.251550044286979,
        "step": 4800
    },
    {
        "loss": 0.0685,
        "grad_norm": 0.1250586360692978,
        "learning_rate": 5.739592559787423e-06,
        "epoch": 4.260407440212577,
        "step": 4810
    },
    {
        "loss": 0.1681,
        "grad_norm": 0.39067527651786804,
        "learning_rate": 5.7307351638618245e-06,
        "epoch": 4.269264836138175,
        "step": 4820
    },
    {
        "loss": 0.1723,
        "grad_norm": 17.792236328125,
        "learning_rate": 5.721877767936227e-06,
        "epoch": 4.278122232063773,
        "step": 4830
    },
    {
        "loss": 0.1511,
        "grad_norm": 111.04285430908203,
        "learning_rate": 5.713020372010629e-06,
        "epoch": 4.286979627989371,
        "step": 4840
    },
    {
        "loss": 0.0772,
        "grad_norm": 9.821378707885742,
        "learning_rate": 5.704162976085032e-06,
        "epoch": 4.295837023914969,
        "step": 4850
    },
    {
        "loss": 0.0361,
        "grad_norm": 0.14377646148204803,
        "learning_rate": 5.6953055801594335e-06,
        "epoch": 4.304694419840567,
        "step": 4860
    },
    {
        "loss": 0.0867,
        "grad_norm": 0.1376478672027588,
        "learning_rate": 5.686448184233836e-06,
        "epoch": 4.313551815766164,
        "step": 4870
    },
    {
        "loss": 0.1187,
        "grad_norm": 4.776771545410156,
        "learning_rate": 5.677590788308238e-06,
        "epoch": 4.322409211691762,
        "step": 4880
    },
    {
        "loss": 0.1216,
        "grad_norm": 64.61083984375,
        "learning_rate": 5.668733392382641e-06,
        "epoch": 4.33126660761736,
        "step": 4890
    },
    {
        "loss": 0.0902,
        "grad_norm": 2.526447296142578,
        "learning_rate": 5.659875996457042e-06,
        "epoch": 4.340124003542958,
        "step": 4900
    },
    {
        "loss": 0.158,
        "grad_norm": 2.9044158458709717,
        "learning_rate": 5.651018600531444e-06,
        "epoch": 4.348981399468556,
        "step": 4910
    },
    {
        "loss": 0.0586,
        "grad_norm": 0.17839136719703674,
        "learning_rate": 5.642161204605846e-06,
        "epoch": 4.357838795394154,
        "step": 4920
    },
    {
        "loss": 0.119,
        "grad_norm": 0.1791914403438568,
        "learning_rate": 5.633303808680248e-06,
        "epoch": 4.366696191319752,
        "step": 4930
    },
    {
        "loss": 0.1248,
        "grad_norm": 0.36267024278640747,
        "learning_rate": 5.6244464127546506e-06,
        "epoch": 4.37555358724535,
        "step": 4940
    },
    {
        "loss": 0.0682,
        "grad_norm": 0.16274622082710266,
        "learning_rate": 5.615589016829053e-06,
        "epoch": 4.384410983170948,
        "step": 4950
    },
    {
        "loss": 0.111,
        "grad_norm": 1.3011242151260376,
        "learning_rate": 5.606731620903455e-06,
        "epoch": 4.393268379096545,
        "step": 4960
    },
    {
        "loss": 0.1708,
        "grad_norm": 44.899662017822266,
        "learning_rate": 5.597874224977857e-06,
        "epoch": 4.402125775022143,
        "step": 4970
    },
    {
        "loss": 0.1717,
        "grad_norm": 0.28100693225860596,
        "learning_rate": 5.5890168290522595e-06,
        "epoch": 4.410983170947741,
        "step": 4980
    },
    {
        "loss": 0.1354,
        "grad_norm": 132.08877563476562,
        "learning_rate": 5.580159433126662e-06,
        "epoch": 4.419840566873339,
        "step": 4990
    },
    {
        "loss": 0.0526,
        "grad_norm": 41.08139419555664,
        "learning_rate": 5.571302037201063e-06,
        "epoch": 4.428697962798937,
        "step": 5000
    },
    {
        "loss": 0.056,
        "grad_norm": 0.2273375540971756,
        "learning_rate": 5.562444641275465e-06,
        "epoch": 4.437555358724535,
        "step": 5010
    },
    {
        "loss": 0.1119,
        "grad_norm": 0.15278898179531097,
        "learning_rate": 5.553587245349868e-06,
        "epoch": 4.446412754650133,
        "step": 5020
    },
    {
        "loss": 0.1154,
        "grad_norm": 0.1345205157995224,
        "learning_rate": 5.544729849424269e-06,
        "epoch": 4.455270150575731,
        "step": 5030
    },
    {
        "loss": 0.0908,
        "grad_norm": 73.80726623535156,
        "learning_rate": 5.535872453498672e-06,
        "epoch": 4.464127546501329,
        "step": 5040
    },
    {
        "loss": 0.2247,
        "grad_norm": 0.3642478585243225,
        "learning_rate": 5.527015057573074e-06,
        "epoch": 4.472984942426926,
        "step": 5050
    },
    {
        "loss": 0.039,
        "grad_norm": 0.3425005376338959,
        "learning_rate": 5.518157661647477e-06,
        "epoch": 4.481842338352524,
        "step": 5060
    },
    {
        "loss": 0.0843,
        "grad_norm": 31.09745216369629,
        "learning_rate": 5.509300265721878e-06,
        "epoch": 4.490699734278122,
        "step": 5070
    },
    {
        "loss": 0.1072,
        "grad_norm": 3.7635326385498047,
        "learning_rate": 5.500442869796281e-06,
        "epoch": 4.49955713020372,
        "step": 5080
    },
    {
        "loss": 0.1766,
        "grad_norm": 2.4746673107147217,
        "learning_rate": 5.491585473870682e-06,
        "epoch": 4.508414526129318,
        "step": 5090
    },
    {
        "loss": 0.052,
        "grad_norm": 0.42442411184310913,
        "learning_rate": 5.482728077945084e-06,
        "epoch": 4.517271922054916,
        "step": 5100
    },
    {
        "loss": 0.1864,
        "grad_norm": 0.19235344231128693,
        "learning_rate": 5.473870682019486e-06,
        "epoch": 4.526129317980514,
        "step": 5110
    },
    {
        "loss": 0.2211,
        "grad_norm": 0.16024716198444366,
        "learning_rate": 5.465013286093889e-06,
        "epoch": 4.534986713906112,
        "step": 5120
    },
    {
        "loss": 0.0888,
        "grad_norm": 0.3104422390460968,
        "learning_rate": 5.456155890168291e-06,
        "epoch": 4.54384410983171,
        "step": 5130
    },
    {
        "loss": 0.1445,
        "grad_norm": 0.7394404411315918,
        "learning_rate": 5.447298494242693e-06,
        "epoch": 4.552701505757307,
        "step": 5140
    },
    {
        "loss": 0.0694,
        "grad_norm": 0.23935414850711823,
        "learning_rate": 5.438441098317095e-06,
        "epoch": 4.561558901682905,
        "step": 5150
    },
    {
        "loss": 0.0927,
        "grad_norm": 209.931884765625,
        "learning_rate": 5.429583702391498e-06,
        "epoch": 4.570416297608503,
        "step": 5160
    },
    {
        "loss": 0.134,
        "grad_norm": 1.9883145093917847,
        "learning_rate": 5.4207263064659e-06,
        "epoch": 4.579273693534101,
        "step": 5170
    },
    {
        "loss": 0.1237,
        "grad_norm": 56.979000091552734,
        "learning_rate": 5.411868910540301e-06,
        "epoch": 4.588131089459699,
        "step": 5180
    },
    {
        "loss": 0.0192,
        "grad_norm": 0.9887338280677795,
        "learning_rate": 5.4030115146147035e-06,
        "epoch": 4.596988485385297,
        "step": 5190
    },
    {
        "loss": 0.0787,
        "grad_norm": 0.14417968690395355,
        "learning_rate": 5.394154118689106e-06,
        "epoch": 4.605845881310895,
        "step": 5200
    },
    {
        "loss": 0.1204,
        "grad_norm": 0.26909399032592773,
        "learning_rate": 5.3852967227635076e-06,
        "epoch": 4.614703277236492,
        "step": 5210
    },
    {
        "loss": 0.0294,
        "grad_norm": 0.08423750102519989,
        "learning_rate": 5.37643932683791e-06,
        "epoch": 4.62356067316209,
        "step": 5220
    },
    {
        "loss": 0.1057,
        "grad_norm": 0.09245956689119339,
        "learning_rate": 5.3675819309123125e-06,
        "epoch": 4.632418069087688,
        "step": 5230
    },
    {
        "loss": 0.0862,
        "grad_norm": 0.107326440513134,
        "learning_rate": 5.358724534986715e-06,
        "epoch": 4.641275465013286,
        "step": 5240
    },
    {
        "loss": 0.1678,
        "grad_norm": 0.11084449291229248,
        "learning_rate": 5.3498671390611165e-06,
        "epoch": 4.650132860938884,
        "step": 5250
    },
    {
        "loss": 0.1948,
        "grad_norm": 2.541490077972412,
        "learning_rate": 5.341009743135519e-06,
        "epoch": 4.658990256864482,
        "step": 5260
    },
    {
        "loss": 0.0065,
        "grad_norm": 0.287063866853714,
        "learning_rate": 5.3321523472099214e-06,
        "epoch": 4.66784765279008,
        "step": 5270
    },
    {
        "loss": 0.0467,
        "grad_norm": 7.177307605743408,
        "learning_rate": 5.323294951284322e-06,
        "epoch": 4.676705048715678,
        "step": 5280
    },
    {
        "loss": 0.14,
        "grad_norm": 4.320406436920166,
        "learning_rate": 5.314437555358725e-06,
        "epoch": 4.685562444641276,
        "step": 5290
    },
    {
        "loss": 0.1141,
        "grad_norm": 0.12236208468675613,
        "learning_rate": 5.305580159433127e-06,
        "epoch": 4.694419840566873,
        "step": 5300
    },
    {
        "loss": 0.147,
        "grad_norm": 0.08214286714792252,
        "learning_rate": 5.296722763507529e-06,
        "epoch": 4.703277236492471,
        "step": 5310
    },
    {
        "loss": 0.0772,
        "grad_norm": 118.4470443725586,
        "learning_rate": 5.287865367581931e-06,
        "epoch": 4.712134632418069,
        "step": 5320
    },
    {
        "loss": 0.1019,
        "grad_norm": 0.19677340984344482,
        "learning_rate": 5.279007971656334e-06,
        "epoch": 4.720992028343667,
        "step": 5330
    },
    {
        "loss": 0.0424,
        "grad_norm": 11.259387969970703,
        "learning_rate": 5.270150575730736e-06,
        "epoch": 4.729849424269265,
        "step": 5340
    },
    {
        "loss": 0.1511,
        "grad_norm": 0.04585643485188484,
        "learning_rate": 5.261293179805138e-06,
        "epoch": 4.738706820194863,
        "step": 5350
    },
    {
        "loss": 0.0391,
        "grad_norm": 0.13640663027763367,
        "learning_rate": 5.25243578387954e-06,
        "epoch": 4.747564216120461,
        "step": 5360
    },
    {
        "loss": 0.1009,
        "grad_norm": 33.39160919189453,
        "learning_rate": 5.243578387953942e-06,
        "epoch": 4.756421612046059,
        "step": 5370
    },
    {
        "loss": 0.073,
        "grad_norm": 0.2570669949054718,
        "learning_rate": 5.234720992028343e-06,
        "epoch": 4.765279007971657,
        "step": 5380
    },
    {
        "loss": 0.0546,
        "grad_norm": 0.12394426017999649,
        "learning_rate": 5.225863596102746e-06,
        "epoch": 4.774136403897254,
        "step": 5390
    },
    {
        "loss": 0.0784,
        "grad_norm": 0.2140645831823349,
        "learning_rate": 5.217006200177148e-06,
        "epoch": 4.782993799822852,
        "step": 5400
    },
    {
        "loss": 0.0468,
        "grad_norm": 0.5066755414009094,
        "learning_rate": 5.208148804251551e-06,
        "epoch": 4.79185119574845,
        "step": 5410
    },
    {
        "loss": 0.0976,
        "grad_norm": 137.1612091064453,
        "learning_rate": 5.199291408325952e-06,
        "epoch": 4.800708591674048,
        "step": 5420
    },
    {
        "loss": 0.0763,
        "grad_norm": 0.25213319063186646,
        "learning_rate": 5.190434012400355e-06,
        "epoch": 4.809565987599646,
        "step": 5430
    },
    {
        "loss": 0.039,
        "grad_norm": 0.6100980639457703,
        "learning_rate": 5.181576616474757e-06,
        "epoch": 4.818423383525244,
        "step": 5440
    },
    {
        "loss": 0.0898,
        "grad_norm": 0.08181946724653244,
        "learning_rate": 5.17271922054916e-06,
        "epoch": 4.827280779450842,
        "step": 5450
    },
    {
        "loss": 0.0894,
        "grad_norm": 0.16231125593185425,
        "learning_rate": 5.1638618246235605e-06,
        "epoch": 4.83613817537644,
        "step": 5460
    },
    {
        "loss": 0.1679,
        "grad_norm": 1.380764126777649,
        "learning_rate": 5.155004428697963e-06,
        "epoch": 4.844995571302038,
        "step": 5470
    },
    {
        "loss": 0.0545,
        "grad_norm": 0.364924818277359,
        "learning_rate": 5.146147032772365e-06,
        "epoch": 4.853852967227635,
        "step": 5480
    },
    {
        "loss": 0.1468,
        "grad_norm": 0.08151175826787949,
        "learning_rate": 5.137289636846767e-06,
        "epoch": 4.862710363153233,
        "step": 5490
    },
    {
        "loss": 0.1163,
        "grad_norm": 0.0776779055595398,
        "learning_rate": 5.1284322409211695e-06,
        "epoch": 4.871567759078831,
        "step": 5500
    },
    {
        "loss": 0.0826,
        "grad_norm": 91.46945190429688,
        "learning_rate": 5.119574844995572e-06,
        "epoch": 4.880425155004429,
        "step": 5510
    },
    {
        "loss": 0.1454,
        "grad_norm": 110.58248901367188,
        "learning_rate": 5.110717449069974e-06,
        "epoch": 4.889282550930027,
        "step": 5520
    },
    {
        "loss": 0.0789,
        "grad_norm": 18.48318862915039,
        "learning_rate": 5.101860053144376e-06,
        "epoch": 4.898139946855625,
        "step": 5530
    },
    {
        "loss": 0.0894,
        "grad_norm": 0.058288559317588806,
        "learning_rate": 5.0930026572187784e-06,
        "epoch": 4.906997342781223,
        "step": 5540
    },
    {
        "loss": 0.0569,
        "grad_norm": 0.08050832152366638,
        "learning_rate": 5.084145261293181e-06,
        "epoch": 4.9158547387068205,
        "step": 5550
    },
    {
        "loss": 0.029,
        "grad_norm": 98.13903045654297,
        "learning_rate": 5.075287865367582e-06,
        "epoch": 4.9247121346324185,
        "step": 5560
    },
    {
        "loss": 0.1471,
        "grad_norm": 0.2332623153924942,
        "learning_rate": 5.066430469441984e-06,
        "epoch": 4.933569530558016,
        "step": 5570
    },
    {
        "loss": 0.122,
        "grad_norm": 27.99287986755371,
        "learning_rate": 5.0575730735163866e-06,
        "epoch": 4.942426926483614,
        "step": 5580
    },
    {
        "loss": 0.0428,
        "grad_norm": 0.06688733398914337,
        "learning_rate": 5.048715677590789e-06,
        "epoch": 4.951284322409212,
        "step": 5590
    },
    {
        "loss": 0.0717,
        "grad_norm": 0.23575496673583984,
        "learning_rate": 5.039858281665191e-06,
        "epoch": 4.9601417183348095,
        "step": 5600
    },
    {
        "loss": 0.0256,
        "grad_norm": 140.0215606689453,
        "learning_rate": 5.031000885739593e-06,
        "epoch": 4.9689991142604075,
        "step": 5610
    },
    {
        "loss": 0.0886,
        "grad_norm": 0.09421158581972122,
        "learning_rate": 5.0221434898139955e-06,
        "epoch": 4.9778565101860055,
        "step": 5620
    },
    {
        "loss": 0.1815,
        "grad_norm": 0.7446475028991699,
        "learning_rate": 5.013286093888398e-06,
        "epoch": 4.9867139061116035,
        "step": 5630
    },
    {
        "loss": 0.1519,
        "grad_norm": 0.10921340435743332,
        "learning_rate": 5.0044286979628e-06,
        "epoch": 4.995571302037201,
        "step": 5640
    },
    {
        "eval_loss": 0.19582131505012512,
        "eval_accuracy": 0.96501,
        "eval_precision": 0.94987,
        "eval_recall": 0.98184,
        "eval_f1": 0.96559,
        "eval_runtime": 149.8826,
        "eval_samples_per_second": 60.26,
        "eval_steps_per_second": 3.77,
        "epoch": 5.0,
        "step": 5645
    },
    {
        "loss": 0.1357,
        "grad_norm": 0.560845673084259,
        "learning_rate": 4.995571302037201e-06,
        "epoch": 5.0044286979627985,
        "step": 5650
    },
    {
        "loss": 0.0428,
        "grad_norm": 2.974536180496216,
        "learning_rate": 4.986713906111604e-06,
        "epoch": 5.0132860938883965,
        "step": 5660
    },
    {
        "loss": 0.1874,
        "grad_norm": 38.35346984863281,
        "learning_rate": 4.977856510186005e-06,
        "epoch": 5.0221434898139945,
        "step": 5670
    },
    {
        "loss": 0.0036,
        "grad_norm": 0.5904988050460815,
        "learning_rate": 4.968999114260408e-06,
        "epoch": 5.0310008857395925,
        "step": 5680
    },
    {
        "loss": 0.005,
        "grad_norm": 0.08989448100328445,
        "learning_rate": 4.96014171833481e-06,
        "epoch": 5.0398582816651905,
        "step": 5690
    },
    {
        "loss": 0.157,
        "grad_norm": 0.6471055150032043,
        "learning_rate": 4.951284322409212e-06,
        "epoch": 5.048715677590788,
        "step": 5700
    },
    {
        "loss": 0.1674,
        "grad_norm": 187.8687744140625,
        "learning_rate": 4.942426926483614e-06,
        "epoch": 5.057573073516386,
        "step": 5710
    },
    {
        "loss": 0.0344,
        "grad_norm": 0.08790552616119385,
        "learning_rate": 4.933569530558016e-06,
        "epoch": 5.066430469441984,
        "step": 5720
    },
    {
        "loss": 0.0531,
        "grad_norm": 0.7310635447502136,
        "learning_rate": 4.924712134632418e-06,
        "epoch": 5.075287865367582,
        "step": 5730
    },
    {
        "loss": 0.0355,
        "grad_norm": 0.07976612448692322,
        "learning_rate": 4.915854738706821e-06,
        "epoch": 5.0841452612931795,
        "step": 5740
    },
    {
        "loss": 0.0978,
        "grad_norm": 0.3634946942329407,
        "learning_rate": 4.906997342781223e-06,
        "epoch": 5.093002657218777,
        "step": 5750
    },
    {
        "loss": 0.095,
        "grad_norm": 53.66997146606445,
        "learning_rate": 4.898139946855625e-06,
        "epoch": 5.101860053144375,
        "step": 5760
    },
    {
        "loss": 0.108,
        "grad_norm": 0.5823618769645691,
        "learning_rate": 4.8892825509300264e-06,
        "epoch": 5.110717449069973,
        "step": 5770
    },
    {
        "loss": 0.2716,
        "grad_norm": 70.36865234375,
        "learning_rate": 4.880425155004429e-06,
        "epoch": 5.119574844995571,
        "step": 5780
    },
    {
        "loss": 0.049,
        "grad_norm": 15.911279678344727,
        "learning_rate": 4.871567759078831e-06,
        "epoch": 5.128432240921169,
        "step": 5790
    },
    {
        "loss": 0.0704,
        "grad_norm": 39.957542419433594,
        "learning_rate": 4.862710363153234e-06,
        "epoch": 5.137289636846767,
        "step": 5800
    },
    {
        "loss": 0.0056,
        "grad_norm": 0.1038571149110794,
        "learning_rate": 4.8538529672276354e-06,
        "epoch": 5.146147032772365,
        "step": 5810
    },
    {
        "loss": 0.16,
        "grad_norm": 0.08769016712903976,
        "learning_rate": 4.844995571302038e-06,
        "epoch": 5.155004428697962,
        "step": 5820
    },
    {
        "loss": 0.0718,
        "grad_norm": 0.116280198097229,
        "learning_rate": 4.8361381753764395e-06,
        "epoch": 5.16386182462356,
        "step": 5830
    },
    {
        "loss": 0.1067,
        "grad_norm": 0.5144360065460205,
        "learning_rate": 4.827280779450842e-06,
        "epoch": 5.172719220549158,
        "step": 5840
    },
    {
        "loss": 0.1337,
        "grad_norm": 89.0077133178711,
        "learning_rate": 4.818423383525244e-06,
        "epoch": 5.181576616474756,
        "step": 5850
    },
    {
        "loss": 0.0209,
        "grad_norm": 0.08094346523284912,
        "learning_rate": 4.809565987599646e-06,
        "epoch": 5.190434012400354,
        "step": 5860
    },
    {
        "loss": 0.0914,
        "grad_norm": 0.10421466827392578,
        "learning_rate": 4.8007085916740485e-06,
        "epoch": 5.199291408325952,
        "step": 5870
    },
    {
        "loss": 0.0696,
        "grad_norm": 0.5794363021850586,
        "learning_rate": 4.79185119574845e-06,
        "epoch": 5.20814880425155,
        "step": 5880
    },
    {
        "loss": 0.029,
        "grad_norm": 85.24849700927734,
        "learning_rate": 4.7829937998228525e-06,
        "epoch": 5.217006200177148,
        "step": 5890
    },
    {
        "loss": 0.0714,
        "grad_norm": 0.0732874646782875,
        "learning_rate": 4.774136403897255e-06,
        "epoch": 5.225863596102746,
        "step": 5900
    },
    {
        "loss": 0.0256,
        "grad_norm": 0.0838693305850029,
        "learning_rate": 4.765279007971657e-06,
        "epoch": 5.234720992028343,
        "step": 5910
    },
    {
        "loss": 0.1273,
        "grad_norm": 0.07358840852975845,
        "learning_rate": 4.756421612046059e-06,
        "epoch": 5.243578387953941,
        "step": 5920
    },
    {
        "loss": 0.0328,
        "grad_norm": 70.01771545410156,
        "learning_rate": 4.747564216120461e-06,
        "epoch": 5.252435783879539,
        "step": 5930
    },
    {
        "loss": 0.0393,
        "grad_norm": 0.04196975380182266,
        "learning_rate": 4.738706820194863e-06,
        "epoch": 5.261293179805137,
        "step": 5940
    },
    {
        "loss": 0.0924,
        "grad_norm": 163.5889129638672,
        "learning_rate": 4.729849424269265e-06,
        "epoch": 5.270150575730735,
        "step": 5950
    },
    {
        "loss": 0.0506,
        "grad_norm": 0.04760656878352165,
        "learning_rate": 4.720992028343667e-06,
        "epoch": 5.279007971656333,
        "step": 5960
    },
    {
        "loss": 0.0614,
        "grad_norm": 0.07963225245475769,
        "learning_rate": 4.71213463241807e-06,
        "epoch": 5.287865367581931,
        "step": 5970
    },
    {
        "loss": 0.0497,
        "grad_norm": 0.05903037264943123,
        "learning_rate": 4.703277236492472e-06,
        "epoch": 5.296722763507529,
        "step": 5980
    },
    {
        "loss": 0.0833,
        "grad_norm": 215.86114501953125,
        "learning_rate": 4.694419840566874e-06,
        "epoch": 5.305580159433127,
        "step": 5990
    },
    {
        "loss": 0.0359,
        "grad_norm": 0.4306057095527649,
        "learning_rate": 4.685562444641275e-06,
        "epoch": 5.314437555358724,
        "step": 6000
    },
    {
        "loss": 0.1783,
        "grad_norm": 0.1916993260383606,
        "learning_rate": 4.676705048715678e-06,
        "epoch": 5.323294951284322,
        "step": 6010
    },
    {
        "loss": 0.1011,
        "grad_norm": 5.484681129455566,
        "learning_rate": 4.66784765279008e-06,
        "epoch": 5.33215234720992,
        "step": 6020
    },
    {
        "loss": 0.0218,
        "grad_norm": 0.2733328640460968,
        "learning_rate": 4.658990256864483e-06,
        "epoch": 5.341009743135518,
        "step": 6030
    },
    {
        "loss": 0.0644,
        "grad_norm": 0.21649883687496185,
        "learning_rate": 4.650132860938884e-06,
        "epoch": 5.349867139061116,
        "step": 6040
    },
    {
        "loss": 0.0207,
        "grad_norm": 0.16854789853096008,
        "learning_rate": 4.641275465013286e-06,
        "epoch": 5.358724534986714,
        "step": 6050
    },
    {
        "loss": 0.0336,
        "grad_norm": 102.15682220458984,
        "learning_rate": 4.632418069087688e-06,
        "epoch": 5.367581930912312,
        "step": 6060
    },
    {
        "loss": 0.0831,
        "grad_norm": 0.08187425136566162,
        "learning_rate": 4.623560673162091e-06,
        "epoch": 5.37643932683791,
        "step": 6070
    },
    {
        "loss": 0.1679,
        "grad_norm": 71.70174407958984,
        "learning_rate": 4.614703277236493e-06,
        "epoch": 5.385296722763507,
        "step": 6080
    },
    {
        "loss": 0.0883,
        "grad_norm": 0.09395727515220642,
        "learning_rate": 4.605845881310895e-06,
        "epoch": 5.394154118689105,
        "step": 6090
    },
    {
        "loss": 0.0848,
        "grad_norm": 1.421226143836975,
        "learning_rate": 4.596988485385297e-06,
        "epoch": 5.403011514614703,
        "step": 6100
    },
    {
        "loss": 0.0856,
        "grad_norm": 105.77642822265625,
        "learning_rate": 4.588131089459699e-06,
        "epoch": 5.411868910540301,
        "step": 6110
    },
    {
        "loss": 0.0156,
        "grad_norm": 134.70159912109375,
        "learning_rate": 4.579273693534101e-06,
        "epoch": 5.420726306465899,
        "step": 6120
    },
    {
        "loss": 0.0352,
        "grad_norm": 0.052949052304029465,
        "learning_rate": 4.570416297608504e-06,
        "epoch": 5.429583702391497,
        "step": 6130
    },
    {
        "loss": 0.0947,
        "grad_norm": 2.822084426879883,
        "learning_rate": 4.5615589016829055e-06,
        "epoch": 5.438441098317095,
        "step": 6140
    },
    {
        "loss": 0.1694,
        "grad_norm": 4.746026039123535,
        "learning_rate": 4.552701505757308e-06,
        "epoch": 5.447298494242693,
        "step": 6150
    },
    {
        "loss": 0.1018,
        "grad_norm": 0.07696906477212906,
        "learning_rate": 4.5438441098317095e-06,
        "epoch": 5.45615589016829,
        "step": 6160
    },
    {
        "loss": 0.1095,
        "grad_norm": 138.839111328125,
        "learning_rate": 4.534986713906112e-06,
        "epoch": 5.465013286093888,
        "step": 6170
    },
    {
        "loss": 0.1458,
        "grad_norm": 2.882951021194458,
        "learning_rate": 4.5261293179805144e-06,
        "epoch": 5.473870682019486,
        "step": 6180
    },
    {
        "loss": 0.0759,
        "grad_norm": 0.07437364757061005,
        "learning_rate": 4.517271922054916e-06,
        "epoch": 5.482728077945084,
        "step": 6190
    },
    {
        "loss": 0.0816,
        "grad_norm": 41.623931884765625,
        "learning_rate": 4.5084145261293185e-06,
        "epoch": 5.491585473870682,
        "step": 6200
    },
    {
        "loss": 0.0761,
        "grad_norm": 0.27680355310440063,
        "learning_rate": 4.499557130203721e-06,
        "epoch": 5.50044286979628,
        "step": 6210
    },
    {
        "loss": 0.0267,
        "grad_norm": 314.9635925292969,
        "learning_rate": 4.4906997342781226e-06,
        "epoch": 5.509300265721878,
        "step": 6220
    },
    {
        "loss": 0.1518,
        "grad_norm": 0.08840780705213547,
        "learning_rate": 4.481842338352524e-06,
        "epoch": 5.518157661647476,
        "step": 6230
    },
    {
        "loss": 0.076,
        "grad_norm": 0.09647900611162186,
        "learning_rate": 4.472984942426927e-06,
        "epoch": 5.527015057573074,
        "step": 6240
    },
    {
        "loss": 0.0649,
        "grad_norm": 0.07357048243284225,
        "learning_rate": 4.464127546501329e-06,
        "epoch": 5.535872453498671,
        "step": 6250
    },
    {
        "loss": 0.0902,
        "grad_norm": 0.07864046841859818,
        "learning_rate": 4.4552701505757315e-06,
        "epoch": 5.544729849424269,
        "step": 6260
    },
    {
        "loss": 0.0301,
        "grad_norm": 1.2533838748931885,
        "learning_rate": 4.446412754650133e-06,
        "epoch": 5.553587245349867,
        "step": 6270
    },
    {
        "loss": 0.0209,
        "grad_norm": 0.08011692762374878,
        "learning_rate": 4.437555358724535e-06,
        "epoch": 5.562444641275465,
        "step": 6280
    },
    {
        "loss": 0.1216,
        "grad_norm": 0.1085023581981659,
        "learning_rate": 4.428697962798937e-06,
        "epoch": 5.571302037201063,
        "step": 6290
    },
    {
        "loss": 0.0941,
        "grad_norm": 0.10110258311033249,
        "learning_rate": 4.41984056687334e-06,
        "epoch": 5.580159433126661,
        "step": 6300
    },
    {
        "loss": 0.0736,
        "grad_norm": 103.28704833984375,
        "learning_rate": 4.410983170947742e-06,
        "epoch": 5.589016829052259,
        "step": 6310
    },
    {
        "loss": 0.0956,
        "grad_norm": 0.24488221108913422,
        "learning_rate": 4.402125775022144e-06,
        "epoch": 5.597874224977857,
        "step": 6320
    },
    {
        "loss": 0.1428,
        "grad_norm": 0.1915421336889267,
        "learning_rate": 4.393268379096546e-06,
        "epoch": 5.606731620903455,
        "step": 6330
    },
    {
        "loss": 0.0027,
        "grad_norm": 0.3418031632900238,
        "learning_rate": 4.384410983170948e-06,
        "epoch": 5.615589016829052,
        "step": 6340
    },
    {
        "loss": 0.1121,
        "grad_norm": 6.086842060089111,
        "learning_rate": 4.37555358724535e-06,
        "epoch": 5.62444641275465,
        "step": 6350
    },
    {
        "loss": 0.1287,
        "grad_norm": 0.04641174525022507,
        "learning_rate": 4.366696191319753e-06,
        "epoch": 5.633303808680248,
        "step": 6360
    },
    {
        "loss": 0.1061,
        "grad_norm": 0.09877293556928635,
        "learning_rate": 4.357838795394154e-06,
        "epoch": 5.642161204605846,
        "step": 6370
    },
    {
        "loss": 0.0724,
        "grad_norm": 0.08933112770318985,
        "learning_rate": 4.348981399468557e-06,
        "epoch": 5.651018600531444,
        "step": 6380
    },
    {
        "loss": 0.0389,
        "grad_norm": 0.1624601185321808,
        "learning_rate": 4.340124003542958e-06,
        "epoch": 5.659875996457042,
        "step": 6390
    },
    {
        "loss": 0.0583,
        "grad_norm": 3.0140676498413086,
        "learning_rate": 4.331266607617361e-06,
        "epoch": 5.66873339238264,
        "step": 6400
    },
    {
        "loss": 0.0256,
        "grad_norm": 0.2856137752532959,
        "learning_rate": 4.322409211691763e-06,
        "epoch": 5.677590788308238,
        "step": 6410
    },
    {
        "loss": 0.0647,
        "grad_norm": 0.11965814977884293,
        "learning_rate": 4.313551815766165e-06,
        "epoch": 5.686448184233836,
        "step": 6420
    },
    {
        "loss": 0.0047,
        "grad_norm": 6.185057640075684,
        "learning_rate": 4.304694419840567e-06,
        "epoch": 5.695305580159433,
        "step": 6430
    },
    {
        "loss": 0.0403,
        "grad_norm": 0.08805423229932785,
        "learning_rate": 4.295837023914969e-06,
        "epoch": 5.704162976085031,
        "step": 6440
    },
    {
        "loss": 0.1044,
        "grad_norm": 196.11395263671875,
        "learning_rate": 4.2869796279893714e-06,
        "epoch": 5.713020372010629,
        "step": 6450
    },
    {
        "loss": 0.0087,
        "grad_norm": 0.1223173514008522,
        "learning_rate": 4.278122232063774e-06,
        "epoch": 5.721877767936227,
        "step": 6460
    },
    {
        "loss": 0.1234,
        "grad_norm": 81.79908752441406,
        "learning_rate": 4.2692648361381755e-06,
        "epoch": 5.730735163861825,
        "step": 6470
    },
    {
        "loss": 0.0866,
        "grad_norm": 1.5644984245300293,
        "learning_rate": 4.260407440212578e-06,
        "epoch": 5.739592559787423,
        "step": 6480
    },
    {
        "loss": 0.0711,
        "grad_norm": 0.0894707664847374,
        "learning_rate": 4.25155004428698e-06,
        "epoch": 5.748449955713021,
        "step": 6490
    },
    {
        "loss": 0.0271,
        "grad_norm": 0.050610337406396866,
        "learning_rate": 4.242692648361382e-06,
        "epoch": 5.757307351638619,
        "step": 6500
    },
    {
        "loss": 0.0371,
        "grad_norm": 0.048270002007484436,
        "learning_rate": 4.233835252435784e-06,
        "epoch": 5.766164747564217,
        "step": 6510
    },
    {
        "loss": 0.0769,
        "grad_norm": 0.06402178853750229,
        "learning_rate": 4.224977856510186e-06,
        "epoch": 5.775022143489814,
        "step": 6520
    },
    {
        "loss": 0.0248,
        "grad_norm": 0.14313343167304993,
        "learning_rate": 4.2161204605845885e-06,
        "epoch": 5.783879539415412,
        "step": 6530
    },
    {
        "loss": 0.0399,
        "grad_norm": 0.8453636169433594,
        "learning_rate": 4.207263064658991e-06,
        "epoch": 5.79273693534101,
        "step": 6540
    },
    {
        "loss": 0.0767,
        "grad_norm": 0.04293717071413994,
        "learning_rate": 4.198405668733393e-06,
        "epoch": 5.801594331266608,
        "step": 6550
    },
    {
        "loss": 0.065,
        "grad_norm": 11.140931129455566,
        "learning_rate": 4.189548272807795e-06,
        "epoch": 5.810451727192206,
        "step": 6560
    },
    {
        "loss": 0.0677,
        "grad_norm": 0.08447239547967911,
        "learning_rate": 4.180690876882197e-06,
        "epoch": 5.819309123117804,
        "step": 6570
    },
    {
        "loss": 0.031,
        "grad_norm": 2.2006938457489014,
        "learning_rate": 4.171833480956599e-06,
        "epoch": 5.8281665190434015,
        "step": 6580
    },
    {
        "loss": 0.0623,
        "grad_norm": 0.7183858752250671,
        "learning_rate": 4.1629760850310016e-06,
        "epoch": 5.837023914968999,
        "step": 6590
    },
    {
        "loss": 0.0821,
        "grad_norm": 0.3451537787914276,
        "learning_rate": 4.154118689105404e-06,
        "epoch": 5.845881310894597,
        "step": 6600
    },
    {
        "loss": 0.03,
        "grad_norm": 1.1816781759262085,
        "learning_rate": 4.145261293179806e-06,
        "epoch": 5.854738706820195,
        "step": 6610
    },
    {
        "loss": 0.0043,
        "grad_norm": 0.043308012187480927,
        "learning_rate": 4.136403897254207e-06,
        "epoch": 5.863596102745793,
        "step": 6620
    },
    {
        "loss": 0.0878,
        "grad_norm": 0.9828515648841858,
        "learning_rate": 4.12754650132861e-06,
        "epoch": 5.8724534986713905,
        "step": 6630
    },
    {
        "loss": 0.0478,
        "grad_norm": 0.03841261938214302,
        "learning_rate": 4.118689105403012e-06,
        "epoch": 5.8813108945969885,
        "step": 6640
    },
    {
        "loss": 0.1585,
        "grad_norm": 0.02404511533677578,
        "learning_rate": 4.109831709477414e-06,
        "epoch": 5.8901682905225865,
        "step": 6650
    },
    {
        "loss": 0.1067,
        "grad_norm": 2.459749698638916,
        "learning_rate": 4.100974313551816e-06,
        "epoch": 5.8990256864481845,
        "step": 6660
    },
    {
        "loss": 0.0709,
        "grad_norm": 11.223946571350098,
        "learning_rate": 4.092116917626218e-06,
        "epoch": 5.9078830823737825,
        "step": 6670
    },
    {
        "loss": 0.0788,
        "grad_norm": 0.03515079617500305,
        "learning_rate": 4.08325952170062e-06,
        "epoch": 5.9167404782993795,
        "step": 6680
    },
    {
        "loss": 0.1424,
        "grad_norm": 0.04069581627845764,
        "learning_rate": 4.074402125775023e-06,
        "epoch": 5.9255978742249775,
        "step": 6690
    },
    {
        "loss": 0.1269,
        "grad_norm": 152.76597595214844,
        "learning_rate": 4.065544729849424e-06,
        "epoch": 5.9344552701505755,
        "step": 6700
    },
    {
        "loss": 0.002,
        "grad_norm": 0.07547993957996368,
        "learning_rate": 4.056687333923827e-06,
        "epoch": 5.9433126660761735,
        "step": 6710
    },
    {
        "loss": 0.0395,
        "grad_norm": 0.0725489929318428,
        "learning_rate": 4.047829937998229e-06,
        "epoch": 5.9521700620017715,
        "step": 6720
    },
    {
        "loss": 0.0651,
        "grad_norm": 0.05078142136335373,
        "learning_rate": 4.038972542072631e-06,
        "epoch": 5.961027457927369,
        "step": 6730
    },
    {
        "loss": 0.0585,
        "grad_norm": 37.271812438964844,
        "learning_rate": 4.030115146147033e-06,
        "epoch": 5.969884853852967,
        "step": 6740
    },
    {
        "loss": 0.0379,
        "grad_norm": 2.9839935302734375,
        "learning_rate": 4.021257750221435e-06,
        "epoch": 5.978742249778565,
        "step": 6750
    },
    {
        "loss": 0.074,
        "grad_norm": 0.06130988150835037,
        "learning_rate": 4.012400354295837e-06,
        "epoch": 5.987599645704163,
        "step": 6760
    },
    {
        "loss": 0.0989,
        "grad_norm": 0.05907745659351349,
        "learning_rate": 4.00354295837024e-06,
        "epoch": 5.9964570416297605,
        "step": 6770
    },
    {
        "eval_loss": 0.1307622343301773,
        "eval_accuracy": 0.97664,
        "eval_precision": 0.98122,
        "eval_recall": 0.97188,
        "eval_f1": 0.97653,
        "eval_runtime": 150.0884,
        "eval_samples_per_second": 60.178,
        "eval_steps_per_second": 3.764,
        "epoch": 6.0,
        "step": 6774
    },
    {
        "loss": 0.0798,
        "grad_norm": 0.0677095279097557,
        "learning_rate": 3.9946855624446415e-06,
        "epoch": 6.005314437555358,
        "step": 6780
    },
    {
        "loss": 0.0016,
        "grad_norm": 1.8129764795303345,
        "learning_rate": 3.985828166519043e-06,
        "epoch": 6.014171833480956,
        "step": 6790
    },
    {
        "loss": 0.0609,
        "grad_norm": 0.058317944407463074,
        "learning_rate": 3.9769707705934455e-06,
        "epoch": 6.023029229406554,
        "step": 6800
    },
    {
        "loss": 0.0012,
        "grad_norm": 0.07909681648015976,
        "learning_rate": 3.968113374667848e-06,
        "epoch": 6.031886625332152,
        "step": 6810
    },
    {
        "loss": 0.1112,
        "grad_norm": 0.13990627229213715,
        "learning_rate": 3.9592559787422504e-06,
        "epoch": 6.04074402125775,
        "step": 6820
    },
    {
        "loss": 0.0023,
        "grad_norm": 3.963585138320923,
        "learning_rate": 3.950398582816652e-06,
        "epoch": 6.049601417183348,
        "step": 6830
    },
    {
        "loss": 0.0354,
        "grad_norm": 0.4509953260421753,
        "learning_rate": 3.9415411868910545e-06,
        "epoch": 6.058458813108946,
        "step": 6840
    },
    {
        "loss": 0.0373,
        "grad_norm": 0.2229941487312317,
        "learning_rate": 3.932683790965456e-06,
        "epoch": 6.067316209034544,
        "step": 6850
    },
    {
        "loss": 0.0012,
        "grad_norm": 11.29837703704834,
        "learning_rate": 3.9238263950398586e-06,
        "epoch": 6.076173604960141,
        "step": 6860
    },
    {
        "loss": 0.0321,
        "grad_norm": 0.03659128397703171,
        "learning_rate": 3.914968999114261e-06,
        "epoch": 6.085031000885739,
        "step": 6870
    },
    {
        "loss": 0.0439,
        "grad_norm": 0.03644147887825966,
        "learning_rate": 3.9061116031886635e-06,
        "epoch": 6.093888396811337,
        "step": 6880
    },
    {
        "loss": 0.2189,
        "grad_norm": 0.026310918852686882,
        "learning_rate": 3.897254207263065e-06,
        "epoch": 6.102745792736935,
        "step": 6890
    },
    {
        "loss": 0.048,
        "grad_norm": 0.04247014969587326,
        "learning_rate": 3.888396811337467e-06,
        "epoch": 6.111603188662533,
        "step": 6900
    },
    {
        "loss": 0.004,
        "grad_norm": 0.023984242230653763,
        "learning_rate": 3.879539415411869e-06,
        "epoch": 6.120460584588131,
        "step": 6910
    },
    {
        "loss": 0.0418,
        "grad_norm": 0.04725638031959534,
        "learning_rate": 3.870682019486272e-06,
        "epoch": 6.129317980513729,
        "step": 6920
    },
    {
        "loss": 0.0261,
        "grad_norm": 0.03319193050265312,
        "learning_rate": 3.861824623560673e-06,
        "epoch": 6.138175376439327,
        "step": 6930
    },
    {
        "loss": 0.2185,
        "grad_norm": 0.05560817942023277,
        "learning_rate": 3.852967227635076e-06,
        "epoch": 6.147032772364924,
        "step": 6940
    },
    {
        "loss": 0.1257,
        "grad_norm": 0.8398032188415527,
        "learning_rate": 3.844109831709478e-06,
        "epoch": 6.155890168290522,
        "step": 6950
    },
    {
        "loss": 0.0346,
        "grad_norm": 0.03045050986111164,
        "learning_rate": 3.83525243578388e-06,
        "epoch": 6.16474756421612,
        "step": 6960
    },
    {
        "loss": 0.0825,
        "grad_norm": 0.027524422854185104,
        "learning_rate": 3.826395039858282e-06,
        "epoch": 6.173604960141718,
        "step": 6970
    },
    {
        "loss": 0.0233,
        "grad_norm": 0.024311954155564308,
        "learning_rate": 3.817537643932684e-06,
        "epoch": 6.182462356067316,
        "step": 6980
    },
    {
        "loss": 0.0378,
        "grad_norm": 0.03013506904244423,
        "learning_rate": 3.8086802480070863e-06,
        "epoch": 6.191319751992914,
        "step": 6990
    },
    {
        "loss": 0.001,
        "grad_norm": 0.3181335926055908,
        "learning_rate": 3.7998228520814883e-06,
        "epoch": 6.200177147918512,
        "step": 7000
    },
    {
        "loss": 0.0225,
        "grad_norm": 195.27333068847656,
        "learning_rate": 3.7909654561558907e-06,
        "epoch": 6.20903454384411,
        "step": 7010
    },
    {
        "loss": 0.0401,
        "grad_norm": 5.0943732261657715,
        "learning_rate": 3.7821080602302928e-06,
        "epoch": 6.217891939769708,
        "step": 7020
    },
    {
        "loss": 0.0415,
        "grad_norm": 0.02461651712656021,
        "learning_rate": 3.7732506643046944e-06,
        "epoch": 6.226749335695305,
        "step": 7030
    },
    {
        "loss": 0.0433,
        "grad_norm": 0.03395438939332962,
        "learning_rate": 3.764393268379097e-06,
        "epoch": 6.235606731620903,
        "step": 7040
    },
    {
        "loss": 0.1356,
        "grad_norm": 0.06843234598636627,
        "learning_rate": 3.755535872453499e-06,
        "epoch": 6.244464127546501,
        "step": 7050
    },
    {
        "loss": 0.0517,
        "grad_norm": 165.9716033935547,
        "learning_rate": 3.7466784765279013e-06,
        "epoch": 6.253321523472099,
        "step": 7060
    },
    {
        "loss": 0.0814,
        "grad_norm": 0.07810737937688828,
        "learning_rate": 3.737821080602303e-06,
        "epoch": 6.262178919397697,
        "step": 7070
    },
    {
        "loss": 0.0555,
        "grad_norm": 0.041856687515974045,
        "learning_rate": 3.7289636846767054e-06,
        "epoch": 6.271036315323295,
        "step": 7080
    },
    {
        "loss": 0.0644,
        "grad_norm": 4.235902309417725,
        "learning_rate": 3.7201062887511074e-06,
        "epoch": 6.279893711248893,
        "step": 7090
    },
    {
        "loss": 0.001,
        "grad_norm": 0.13942857086658478,
        "learning_rate": 3.71124889282551e-06,
        "epoch": 6.288751107174491,
        "step": 7100
    },
    {
        "loss": 0.0363,
        "grad_norm": 0.07144396007061005,
        "learning_rate": 3.702391496899912e-06,
        "epoch": 6.297608503100088,
        "step": 7110
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.059528857469558716,
        "learning_rate": 3.6935341009743135e-06,
        "epoch": 6.306465899025686,
        "step": 7120
    },
    {
        "loss": 0.0882,
        "grad_norm": 0.03697304055094719,
        "learning_rate": 3.684676705048716e-06,
        "epoch": 6.315323294951284,
        "step": 7130
    },
    {
        "loss": 0.0374,
        "grad_norm": 0.2966940999031067,
        "learning_rate": 3.675819309123118e-06,
        "epoch": 6.324180690876882,
        "step": 7140
    },
    {
        "loss": 0.0907,
        "grad_norm": 0.021466489881277084,
        "learning_rate": 3.6669619131975205e-06,
        "epoch": 6.33303808680248,
        "step": 7150
    },
    {
        "loss": 0.0083,
        "grad_norm": 0.10919871926307678,
        "learning_rate": 3.6581045172719225e-06,
        "epoch": 6.341895482728078,
        "step": 7160
    },
    {
        "loss": 0.0857,
        "grad_norm": 0.05524391680955887,
        "learning_rate": 3.649247121346324e-06,
        "epoch": 6.350752878653676,
        "step": 7170
    },
    {
        "loss": 0.0682,
        "grad_norm": 0.029390612617135048,
        "learning_rate": 3.6403897254207266e-06,
        "epoch": 6.359610274579274,
        "step": 7180
    },
    {
        "loss": 0.0646,
        "grad_norm": 0.06468546390533447,
        "learning_rate": 3.6315323294951286e-06,
        "epoch": 6.368467670504872,
        "step": 7190
    },
    {
        "loss": 0.1533,
        "grad_norm": 0.04577770084142685,
        "learning_rate": 3.622674933569531e-06,
        "epoch": 6.377325066430469,
        "step": 7200
    },
    {
        "loss": 0.0055,
        "grad_norm": 21.500141143798828,
        "learning_rate": 3.6138175376439327e-06,
        "epoch": 6.386182462356067,
        "step": 7210
    },
    {
        "loss": 0.1319,
        "grad_norm": 73.96900177001953,
        "learning_rate": 3.604960141718335e-06,
        "epoch": 6.395039858281665,
        "step": 7220
    },
    {
        "loss": 0.068,
        "grad_norm": 0.0510747916996479,
        "learning_rate": 3.596102745792737e-06,
        "epoch": 6.403897254207263,
        "step": 7230
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.07326744496822357,
        "learning_rate": 3.5872453498671396e-06,
        "epoch": 6.412754650132861,
        "step": 7240
    },
    {
        "loss": 0.0079,
        "grad_norm": 0.2373991310596466,
        "learning_rate": 3.5783879539415416e-06,
        "epoch": 6.421612046058459,
        "step": 7250
    },
    {
        "loss": 0.0472,
        "grad_norm": 40.67007827758789,
        "learning_rate": 3.5695305580159433e-06,
        "epoch": 6.430469441984057,
        "step": 7260
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.037353843450546265,
        "learning_rate": 3.5606731620903457e-06,
        "epoch": 6.439326837909655,
        "step": 7270
    },
    {
        "loss": 0.0407,
        "grad_norm": 0.040476977825164795,
        "learning_rate": 3.5518157661647477e-06,
        "epoch": 6.448184233835253,
        "step": 7280
    },
    {
        "loss": 0.0559,
        "grad_norm": 187.86630249023438,
        "learning_rate": 3.54295837023915e-06,
        "epoch": 6.45704162976085,
        "step": 7290
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.27040377259254456,
        "learning_rate": 3.5341009743135522e-06,
        "epoch": 6.465899025686448,
        "step": 7300
    },
    {
        "loss": 0.0412,
        "grad_norm": 0.21577121317386627,
        "learning_rate": 3.5252435783879543e-06,
        "epoch": 6.474756421612046,
        "step": 7310
    },
    {
        "loss": 0.0214,
        "grad_norm": 0.05736130103468895,
        "learning_rate": 3.5163861824623563e-06,
        "epoch": 6.483613817537644,
        "step": 7320
    },
    {
        "loss": 0.0323,
        "grad_norm": 0.570592999458313,
        "learning_rate": 3.5075287865367587e-06,
        "epoch": 6.492471213463242,
        "step": 7330
    },
    {
        "loss": 0.0993,
        "grad_norm": 3.5779988765716553,
        "learning_rate": 3.4986713906111608e-06,
        "epoch": 6.50132860938884,
        "step": 7340
    },
    {
        "loss": 0.0613,
        "grad_norm": 10.613550186157227,
        "learning_rate": 3.4898139946855624e-06,
        "epoch": 6.510186005314438,
        "step": 7350
    },
    {
        "loss": 0.0121,
        "grad_norm": 0.042823854833841324,
        "learning_rate": 3.480956598759965e-06,
        "epoch": 6.519043401240036,
        "step": 7360
    },
    {
        "loss": 0.0355,
        "grad_norm": 0.03069014474749565,
        "learning_rate": 3.472099202834367e-06,
        "epoch": 6.527900797165634,
        "step": 7370
    },
    {
        "loss": 0.034,
        "grad_norm": 0.10512831807136536,
        "learning_rate": 3.4632418069087693e-06,
        "epoch": 6.536758193091231,
        "step": 7380
    },
    {
        "loss": 0.0452,
        "grad_norm": 0.038509391248226166,
        "learning_rate": 3.4543844109831714e-06,
        "epoch": 6.545615589016829,
        "step": 7390
    },
    {
        "loss": 0.0104,
        "grad_norm": 0.08711298555135727,
        "learning_rate": 3.445527015057573e-06,
        "epoch": 6.554472984942427,
        "step": 7400
    },
    {
        "loss": 0.0146,
        "grad_norm": 2.8470871448516846,
        "learning_rate": 3.4366696191319754e-06,
        "epoch": 6.563330380868025,
        "step": 7410
    },
    {
        "loss": 0.0371,
        "grad_norm": 5.66176700592041,
        "learning_rate": 3.4278122232063775e-06,
        "epoch": 6.572187776793623,
        "step": 7420
    },
    {
        "loss": 0.0703,
        "grad_norm": 3.7585976123809814,
        "learning_rate": 3.41895482728078e-06,
        "epoch": 6.581045172719221,
        "step": 7430
    },
    {
        "loss": 0.0326,
        "grad_norm": 0.339643657207489,
        "learning_rate": 3.410097431355182e-06,
        "epoch": 6.589902568644819,
        "step": 7440
    },
    {
        "loss": 0.022,
        "grad_norm": 1.3397526741027832,
        "learning_rate": 3.401240035429584e-06,
        "epoch": 6.598759964570416,
        "step": 7450
    },
    {
        "loss": 0.0443,
        "grad_norm": 0.04854544624686241,
        "learning_rate": 3.392382639503986e-06,
        "epoch": 6.607617360496015,
        "step": 7460
    },
    {
        "loss": 0.0542,
        "grad_norm": 0.03101758286356926,
        "learning_rate": 3.3835252435783885e-06,
        "epoch": 6.616474756421612,
        "step": 7470
    },
    {
        "loss": 0.001,
        "grad_norm": 0.04603378474712372,
        "learning_rate": 3.3746678476527905e-06,
        "epoch": 6.62533215234721,
        "step": 7480
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.012751256115734577,
        "learning_rate": 3.365810451727192e-06,
        "epoch": 6.634189548272808,
        "step": 7490
    },
    {
        "loss": 0.1011,
        "grad_norm": 0.02627871185541153,
        "learning_rate": 3.3569530558015946e-06,
        "epoch": 6.643046944198406,
        "step": 7500
    },
    {
        "loss": 0.0855,
        "grad_norm": 44.62608337402344,
        "learning_rate": 3.3480956598759966e-06,
        "epoch": 6.651904340124004,
        "step": 7510
    },
    {
        "loss": 0.0357,
        "grad_norm": 0.020735666155815125,
        "learning_rate": 3.339238263950399e-06,
        "epoch": 6.660761736049602,
        "step": 7520
    },
    {
        "loss": 0.0396,
        "grad_norm": 35.9205207824707,
        "learning_rate": 3.330380868024801e-06,
        "epoch": 6.6696191319752,
        "step": 7530
    },
    {
        "loss": 0.0806,
        "grad_norm": 26.238506317138672,
        "learning_rate": 3.3215234720992027e-06,
        "epoch": 6.678476527900797,
        "step": 7540
    },
    {
        "loss": 0.0365,
        "grad_norm": 0.03273112699389458,
        "learning_rate": 3.312666076173605e-06,
        "epoch": 6.687333923826395,
        "step": 7550
    },
    {
        "loss": 0.0331,
        "grad_norm": 0.0412757508456707,
        "learning_rate": 3.303808680248007e-06,
        "epoch": 6.696191319751993,
        "step": 7560
    },
    {
        "loss": 0.0283,
        "grad_norm": 0.3120361864566803,
        "learning_rate": 3.2949512843224096e-06,
        "epoch": 6.705048715677591,
        "step": 7570
    },
    {
        "loss": 0.0516,
        "grad_norm": 0.04895918443799019,
        "learning_rate": 3.2860938883968117e-06,
        "epoch": 6.713906111603189,
        "step": 7580
    },
    {
        "loss": 0.0649,
        "grad_norm": 0.03014683537185192,
        "learning_rate": 3.2772364924712137e-06,
        "epoch": 6.722763507528787,
        "step": 7590
    },
    {
        "loss": 0.1525,
        "grad_norm": 19.92843246459961,
        "learning_rate": 3.2683790965456157e-06,
        "epoch": 6.731620903454385,
        "step": 7600
    },
    {
        "loss": 0.0551,
        "grad_norm": 0.020787088200449944,
        "learning_rate": 3.259521700620018e-06,
        "epoch": 6.7404782993799826,
        "step": 7610
    },
    {
        "loss": 0.0493,
        "grad_norm": 0.022594211623072624,
        "learning_rate": 3.2506643046944202e-06,
        "epoch": 6.7493356953055805,
        "step": 7620
    },
    {
        "loss": 0.0361,
        "grad_norm": 0.017302189022302628,
        "learning_rate": 3.241806908768822e-06,
        "epoch": 6.758193091231178,
        "step": 7630
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.12644848227500916,
        "learning_rate": 3.2329495128432243e-06,
        "epoch": 6.767050487156776,
        "step": 7640
    },
    {
        "loss": 0.0397,
        "grad_norm": 0.013588332571089268,
        "learning_rate": 3.2240921169176263e-06,
        "epoch": 6.775907883082374,
        "step": 7650
    },
    {
        "loss": 0.0165,
        "grad_norm": 4.664841651916504,
        "learning_rate": 3.2152347209920288e-06,
        "epoch": 6.7847652790079716,
        "step": 7660
    },
    {
        "loss": 0.0815,
        "grad_norm": 117.96404266357422,
        "learning_rate": 3.206377325066431e-06,
        "epoch": 6.7936226749335695,
        "step": 7670
    },
    {
        "loss": 0.0796,
        "grad_norm": 0.248422309756279,
        "learning_rate": 3.197519929140833e-06,
        "epoch": 6.8024800708591675,
        "step": 7680
    },
    {
        "loss": 0.012,
        "grad_norm": 0.10671436041593552,
        "learning_rate": 3.188662533215235e-06,
        "epoch": 6.8113374667847655,
        "step": 7690
    },
    {
        "loss": 0.0357,
        "grad_norm": 0.015887897461652756,
        "learning_rate": 3.1798051372896373e-06,
        "epoch": 6.8201948627103635,
        "step": 7700
    },
    {
        "loss": 0.0747,
        "grad_norm": 0.020192826166749,
        "learning_rate": 3.1709477413640394e-06,
        "epoch": 6.829052258635961,
        "step": 7710
    },
    {
        "loss": 0.0911,
        "grad_norm": 40.939537048339844,
        "learning_rate": 3.162090345438442e-06,
        "epoch": 6.8379096545615585,
        "step": 7720
    },
    {
        "loss": 0.0339,
        "grad_norm": 0.09365449100732803,
        "learning_rate": 3.1532329495128434e-06,
        "epoch": 6.8467670504871565,
        "step": 7730
    },
    {
        "loss": 0.025,
        "grad_norm": 0.05116855725646019,
        "learning_rate": 3.1443755535872455e-06,
        "epoch": 6.8556244464127545,
        "step": 7740
    },
    {
        "loss": 0.0982,
        "grad_norm": 0.04149186238646507,
        "learning_rate": 3.135518157661648e-06,
        "epoch": 6.8644818423383525,
        "step": 7750
    },
    {
        "loss": 0.096,
        "grad_norm": 0.03911873698234558,
        "learning_rate": 3.12666076173605e-06,
        "epoch": 6.87333923826395,
        "step": 7760
    },
    {
        "loss": 0.0715,
        "grad_norm": 0.09099957346916199,
        "learning_rate": 3.1178033658104516e-06,
        "epoch": 6.882196634189548,
        "step": 7770
    },
    {
        "loss": 0.0974,
        "grad_norm": 0.8038327693939209,
        "learning_rate": 3.108945969884854e-06,
        "epoch": 6.891054030115146,
        "step": 7780
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.07711713761091232,
        "learning_rate": 3.100088573959256e-06,
        "epoch": 6.899911426040744,
        "step": 7790
    },
    {
        "loss": 0.029,
        "grad_norm": 0.023993603885173798,
        "learning_rate": 3.0912311780336585e-06,
        "epoch": 6.908768821966342,
        "step": 7800
    },
    {
        "loss": 0.0405,
        "grad_norm": 0.0101345619186759,
        "learning_rate": 3.0823737821080605e-06,
        "epoch": 6.917626217891939,
        "step": 7810
    },
    {
        "loss": 0.0806,
        "grad_norm": 0.03638797998428345,
        "learning_rate": 3.0735163861824626e-06,
        "epoch": 6.926483613817537,
        "step": 7820
    },
    {
        "loss": 0.0848,
        "grad_norm": 0.020836420357227325,
        "learning_rate": 3.0646589902568646e-06,
        "epoch": 6.935341009743135,
        "step": 7830
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.07456011325120926,
        "learning_rate": 3.055801594331267e-06,
        "epoch": 6.944198405668733,
        "step": 7840
    },
    {
        "loss": 0.0363,
        "grad_norm": 0.027072425931692123,
        "learning_rate": 3.046944198405669e-06,
        "epoch": 6.953055801594331,
        "step": 7850
    },
    {
        "loss": 0.0434,
        "grad_norm": 0.028023438528180122,
        "learning_rate": 3.0380868024800715e-06,
        "epoch": 6.961913197519929,
        "step": 7860
    },
    {
        "loss": 0.0375,
        "grad_norm": 6.501054763793945,
        "learning_rate": 3.029229406554473e-06,
        "epoch": 6.970770593445527,
        "step": 7870
    },
    {
        "loss": 0.0591,
        "grad_norm": 0.013778801076114178,
        "learning_rate": 3.020372010628875e-06,
        "epoch": 6.979627989371125,
        "step": 7880
    },
    {
        "loss": 0.04,
        "grad_norm": 0.10487561672925949,
        "learning_rate": 3.0115146147032776e-06,
        "epoch": 6.988485385296723,
        "step": 7890
    },
    {
        "loss": 0.0414,
        "grad_norm": 0.31974202394485474,
        "learning_rate": 3.0026572187776797e-06,
        "epoch": 6.99734278122232,
        "step": 7900
    },
    {
        "eval_loss": 0.13339108228683472,
        "eval_accuracy": 0.98018,
        "eval_precision": 0.97796,
        "eval_recall": 0.98251,
        "eval_f1": 0.98023,
        "eval_runtime": 149.9093,
        "eval_samples_per_second": 60.25,
        "eval_steps_per_second": 3.769,
        "epoch": 7.0,
        "step": 7903
    },
    {
        "loss": 0.0377,
        "grad_norm": 3.5745327472686768,
        "learning_rate": 2.9937998228520813e-06,
        "epoch": 7.006200177147918,
        "step": 7910
    },
    {
        "loss": 0.0446,
        "grad_norm": 0.05759232118725777,
        "learning_rate": 2.9849424269264837e-06,
        "epoch": 7.015057573073516,
        "step": 7920
    },
    {
        "loss": 0.0548,
        "grad_norm": 0.03902582451701164,
        "learning_rate": 2.9760850310008858e-06,
        "epoch": 7.023914968999114,
        "step": 7930
    },
    {
        "loss": 0.001,
        "grad_norm": 0.03545515239238739,
        "learning_rate": 2.9672276350752882e-06,
        "epoch": 7.032772364924712,
        "step": 7940
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.01606442779302597,
        "learning_rate": 2.9583702391496903e-06,
        "epoch": 7.04162976085031,
        "step": 7950
    },
    {
        "loss": 0.1402,
        "grad_norm": 1.0445317029953003,
        "learning_rate": 2.9495128432240923e-06,
        "epoch": 7.050487156775908,
        "step": 7960
    },
    {
        "loss": 0.0093,
        "grad_norm": 0.01810297928750515,
        "learning_rate": 2.9406554472984943e-06,
        "epoch": 7.059344552701506,
        "step": 7970
    },
    {
        "loss": 0.0129,
        "grad_norm": 0.01757185161113739,
        "learning_rate": 2.9317980513728968e-06,
        "epoch": 7.068201948627103,
        "step": 7980
    },
    {
        "loss": 0.0347,
        "grad_norm": 0.19071702659130096,
        "learning_rate": 2.922940655447299e-06,
        "epoch": 7.077059344552701,
        "step": 7990
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.015160700306296349,
        "learning_rate": 2.9140832595217013e-06,
        "epoch": 7.085916740478299,
        "step": 8000
    },
    {
        "loss": 0.0658,
        "grad_norm": 0.020353270694613457,
        "learning_rate": 2.905225863596103e-06,
        "epoch": 7.094774136403897,
        "step": 8010
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.030050916597247124,
        "learning_rate": 2.896368467670505e-06,
        "epoch": 7.103631532329495,
        "step": 8020
    },
    {
        "loss": 0.0505,
        "grad_norm": 0.03981149196624756,
        "learning_rate": 2.8875110717449074e-06,
        "epoch": 7.112488928255093,
        "step": 8030
    },
    {
        "loss": 0.0873,
        "grad_norm": 0.14975474774837494,
        "learning_rate": 2.8786536758193094e-06,
        "epoch": 7.121346324180691,
        "step": 8040
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.20647284388542175,
        "learning_rate": 2.8697962798937114e-06,
        "epoch": 7.130203720106289,
        "step": 8050
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.08343935757875443,
        "learning_rate": 2.8609388839681135e-06,
        "epoch": 7.139061116031886,
        "step": 8060
    },
    {
        "loss": 0.0579,
        "grad_norm": 0.016502056270837784,
        "learning_rate": 2.852081488042516e-06,
        "epoch": 7.147918511957484,
        "step": 8070
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.016633769497275352,
        "learning_rate": 2.843224092116918e-06,
        "epoch": 7.156775907883082,
        "step": 8080
    },
    {
        "loss": 0.0099,
        "grad_norm": 0.0474485345184803,
        "learning_rate": 2.8343666961913204e-06,
        "epoch": 7.16563330380868,
        "step": 8090
    },
    {
        "loss": 0.0354,
        "grad_norm": 0.05265497416257858,
        "learning_rate": 2.825509300265722e-06,
        "epoch": 7.174490699734278,
        "step": 8100
    },
    {
        "loss": 0.0643,
        "grad_norm": 0.020522980019450188,
        "learning_rate": 2.816651904340124e-06,
        "epoch": 7.183348095659876,
        "step": 8110
    },
    {
        "loss": 0.09,
        "grad_norm": 0.02482829988002777,
        "learning_rate": 2.8077945084145265e-06,
        "epoch": 7.192205491585474,
        "step": 8120
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.023077342659235,
        "learning_rate": 2.7989371124889285e-06,
        "epoch": 7.201062887511072,
        "step": 8130
    },
    {
        "loss": 0.001,
        "grad_norm": 0.07958551496267319,
        "learning_rate": 2.790079716563331e-06,
        "epoch": 7.20992028343667,
        "step": 8140
    },
    {
        "loss": 0.0445,
        "grad_norm": 0.017220787703990936,
        "learning_rate": 2.7812223206377326e-06,
        "epoch": 7.218777679362267,
        "step": 8150
    },
    {
        "loss": 0.0301,
        "grad_norm": 0.01600344106554985,
        "learning_rate": 2.7723649247121346e-06,
        "epoch": 7.227635075287865,
        "step": 8160
    },
    {
        "loss": 0.0058,
        "grad_norm": 0.05105619132518768,
        "learning_rate": 2.763507528786537e-06,
        "epoch": 7.236492471213463,
        "step": 8170
    },
    {
        "loss": 0.0302,
        "grad_norm": 0.021244894713163376,
        "learning_rate": 2.754650132860939e-06,
        "epoch": 7.245349867139061,
        "step": 8180
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.010886149480938911,
        "learning_rate": 2.745792736935341e-06,
        "epoch": 7.254207263064659,
        "step": 8190
    },
    {
        "loss": 0.0759,
        "grad_norm": 0.005962179508060217,
        "learning_rate": 2.736935341009743e-06,
        "epoch": 7.263064658990257,
        "step": 8200
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.1484754979610443,
        "learning_rate": 2.7280779450841456e-06,
        "epoch": 7.271922054915855,
        "step": 8210
    },
    {
        "loss": 0.0466,
        "grad_norm": 0.09806811809539795,
        "learning_rate": 2.7192205491585477e-06,
        "epoch": 7.280779450841453,
        "step": 8220
    },
    {
        "loss": 0.0313,
        "grad_norm": 2.035242795944214,
        "learning_rate": 2.71036315323295e-06,
        "epoch": 7.289636846767051,
        "step": 8230
    },
    {
        "loss": 0.0065,
        "grad_norm": 0.6406707167625427,
        "learning_rate": 2.7015057573073517e-06,
        "epoch": 7.298494242692648,
        "step": 8240
    },
    {
        "loss": 0.035,
        "grad_norm": 230.063232421875,
        "learning_rate": 2.6926483613817538e-06,
        "epoch": 7.307351638618246,
        "step": 8250
    },
    {
        "loss": 0.0029,
        "grad_norm": 0.010266780853271484,
        "learning_rate": 2.6837909654561562e-06,
        "epoch": 7.316209034543844,
        "step": 8260
    },
    {
        "loss": 0.0267,
        "grad_norm": 0.00783906877040863,
        "learning_rate": 2.6749335695305583e-06,
        "epoch": 7.325066430469442,
        "step": 8270
    },
    {
        "loss": 0.0854,
        "grad_norm": 31.08563995361328,
        "learning_rate": 2.6660761736049607e-06,
        "epoch": 7.33392382639504,
        "step": 8280
    },
    {
        "loss": 0.0014,
        "grad_norm": 55.022701263427734,
        "learning_rate": 2.6572187776793623e-06,
        "epoch": 7.342781222320638,
        "step": 8290
    },
    {
        "loss": 0.0534,
        "grad_norm": 89.82132720947266,
        "learning_rate": 2.6483613817537644e-06,
        "epoch": 7.351638618246236,
        "step": 8300
    },
    {
        "loss": 0.0449,
        "grad_norm": 0.018824582919478416,
        "learning_rate": 2.639503985828167e-06,
        "epoch": 7.360496014171834,
        "step": 8310
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.030330268666148186,
        "learning_rate": 2.630646589902569e-06,
        "epoch": 7.369353410097431,
        "step": 8320
    },
    {
        "loss": 0.0142,
        "grad_norm": 218.14796447753906,
        "learning_rate": 2.621789193976971e-06,
        "epoch": 7.378210806023029,
        "step": 8330
    },
    {
        "loss": 0.0433,
        "grad_norm": 0.06562473624944687,
        "learning_rate": 2.612931798051373e-06,
        "epoch": 7.387068201948627,
        "step": 8340
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.009019417688250542,
        "learning_rate": 2.6040744021257754e-06,
        "epoch": 7.395925597874225,
        "step": 8350
    },
    {
        "loss": 0.0135,
        "grad_norm": 0.005956161301583052,
        "learning_rate": 2.5952170062001774e-06,
        "epoch": 7.404782993799823,
        "step": 8360
    },
    {
        "loss": 0.0207,
        "grad_norm": 0.012789139524102211,
        "learning_rate": 2.58635961027458e-06,
        "epoch": 7.413640389725421,
        "step": 8370
    },
    {
        "loss": 0.0438,
        "grad_norm": 0.02491830848157406,
        "learning_rate": 2.5775022143489815e-06,
        "epoch": 7.422497785651019,
        "step": 8380
    },
    {
        "loss": 0.0329,
        "grad_norm": 0.05765409767627716,
        "learning_rate": 2.5686448184233835e-06,
        "epoch": 7.431355181576617,
        "step": 8390
    },
    {
        "loss": 0.0414,
        "grad_norm": 0.021780051290988922,
        "learning_rate": 2.559787422497786e-06,
        "epoch": 7.440212577502215,
        "step": 8400
    },
    {
        "loss": 0.0024,
        "grad_norm": 35.21125030517578,
        "learning_rate": 2.550930026572188e-06,
        "epoch": 7.449069973427812,
        "step": 8410
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.011491245590150356,
        "learning_rate": 2.5420726306465904e-06,
        "epoch": 7.45792736935341,
        "step": 8420
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.021537305787205696,
        "learning_rate": 2.533215234720992e-06,
        "epoch": 7.466784765279008,
        "step": 8430
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.0113608343526721,
        "learning_rate": 2.5243578387953945e-06,
        "epoch": 7.475642161204606,
        "step": 8440
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.016296181827783585,
        "learning_rate": 2.5155004428697965e-06,
        "epoch": 7.484499557130204,
        "step": 8450
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0719776377081871,
        "learning_rate": 2.506643046944199e-06,
        "epoch": 7.493356953055802,
        "step": 8460
    },
    {
        "loss": 0.0038,
        "grad_norm": 0.0331931971013546,
        "learning_rate": 2.4977856510186006e-06,
        "epoch": 7.5022143489814,
        "step": 8470
    },
    {
        "loss": 0.004,
        "grad_norm": 0.01463019847869873,
        "learning_rate": 2.4889282550930026e-06,
        "epoch": 7.511071744906998,
        "step": 8480
    },
    {
        "loss": 0.0324,
        "grad_norm": 0.010215084999799728,
        "learning_rate": 2.480070859167405e-06,
        "epoch": 7.519929140832595,
        "step": 8490
    },
    {
        "loss": 0.0261,
        "grad_norm": 0.03554774448275566,
        "learning_rate": 2.471213463241807e-06,
        "epoch": 7.528786536758193,
        "step": 8500
    },
    {
        "loss": 0.0018,
        "grad_norm": 0.021184764802455902,
        "learning_rate": 2.462356067316209e-06,
        "epoch": 7.537643932683791,
        "step": 8510
    },
    {
        "loss": 0.0169,
        "grad_norm": 0.010239950381219387,
        "learning_rate": 2.4534986713906116e-06,
        "epoch": 7.546501328609389,
        "step": 8520
    },
    {
        "loss": 0.0132,
        "grad_norm": 0.015765145421028137,
        "learning_rate": 2.4446412754650132e-06,
        "epoch": 7.555358724534987,
        "step": 8530
    },
    {
        "loss": 0.002,
        "grad_norm": 0.00834345631301403,
        "learning_rate": 2.4357838795394157e-06,
        "epoch": 7.564216120460585,
        "step": 8540
    },
    {
        "loss": 0.0036,
        "grad_norm": 0.026363655924797058,
        "learning_rate": 2.4269264836138177e-06,
        "epoch": 7.573073516386183,
        "step": 8550
    },
    {
        "loss": 0.0614,
        "grad_norm": 6.812612533569336,
        "learning_rate": 2.4180690876882197e-06,
        "epoch": 7.581930912311781,
        "step": 8560
    },
    {
        "loss": 0.0049,
        "grad_norm": 0.015331994742155075,
        "learning_rate": 2.409211691762622e-06,
        "epoch": 7.590788308237379,
        "step": 8570
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.008923276327550411,
        "learning_rate": 2.4003542958370242e-06,
        "epoch": 7.599645704162976,
        "step": 8580
    },
    {
        "loss": 0.0281,
        "grad_norm": 0.009329982101917267,
        "learning_rate": 2.3914968999114263e-06,
        "epoch": 7.608503100088574,
        "step": 8590
    },
    {
        "loss": 0.0523,
        "grad_norm": 0.041217535734176636,
        "learning_rate": 2.3826395039858283e-06,
        "epoch": 7.617360496014172,
        "step": 8600
    },
    {
        "loss": 0.0571,
        "grad_norm": 0.006787026766687632,
        "learning_rate": 2.3737821080602303e-06,
        "epoch": 7.62621789193977,
        "step": 8610
    },
    {
        "loss": 0.0408,
        "grad_norm": 0.03251073509454727,
        "learning_rate": 2.3649247121346324e-06,
        "epoch": 7.635075287865368,
        "step": 8620
    },
    {
        "loss": 0.0409,
        "grad_norm": 7.938581943511963,
        "learning_rate": 2.356067316209035e-06,
        "epoch": 7.643932683790966,
        "step": 8630
    },
    {
        "loss": 0.0695,
        "grad_norm": 0.09451864659786224,
        "learning_rate": 2.347209920283437e-06,
        "epoch": 7.6527900797165636,
        "step": 8640
    },
    {
        "loss": 0.0896,
        "grad_norm": 37.563175201416016,
        "learning_rate": 2.338352524357839e-06,
        "epoch": 7.6616474756421615,
        "step": 8650
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.024105120450258255,
        "learning_rate": 2.3294951284322413e-06,
        "epoch": 7.6705048715677595,
        "step": 8660
    },
    {
        "loss": 0.0019,
        "grad_norm": 67.82059478759766,
        "learning_rate": 2.320637732506643e-06,
        "epoch": 7.679362267493357,
        "step": 8670
    },
    {
        "loss": 0.0154,
        "grad_norm": 0.10712478309869766,
        "learning_rate": 2.3117803365810454e-06,
        "epoch": 7.688219663418955,
        "step": 8680
    },
    {
        "loss": 0.0401,
        "grad_norm": 0.018794557079672813,
        "learning_rate": 2.3029229406554474e-06,
        "epoch": 7.6970770593445526,
        "step": 8690
    },
    {
        "loss": 0.052,
        "grad_norm": 51.4677619934082,
        "learning_rate": 2.2940655447298495e-06,
        "epoch": 7.7059344552701505,
        "step": 8700
    },
    {
        "loss": 0.0346,
        "grad_norm": 0.08891995251178741,
        "learning_rate": 2.285208148804252e-06,
        "epoch": 7.7147918511957485,
        "step": 8710
    },
    {
        "loss": 0.0728,
        "grad_norm": 0.011027589440345764,
        "learning_rate": 2.276350752878654e-06,
        "epoch": 7.7236492471213465,
        "step": 8720
    },
    {
        "loss": 0.0453,
        "grad_norm": 0.011886926367878914,
        "learning_rate": 2.267493356953056e-06,
        "epoch": 7.7325066430469445,
        "step": 8730
    },
    {
        "loss": 0.0004,
        "grad_norm": 5.105339527130127,
        "learning_rate": 2.258635961027458e-06,
        "epoch": 7.741364038972542,
        "step": 8740
    },
    {
        "loss": 0.0467,
        "grad_norm": 0.031614597886800766,
        "learning_rate": 2.2497785651018605e-06,
        "epoch": 7.75022143489814,
        "step": 8750
    },
    {
        "loss": 0.0051,
        "grad_norm": 0.0036384230479598045,
        "learning_rate": 2.240921169176262e-06,
        "epoch": 7.7590788308237375,
        "step": 8760
    },
    {
        "loss": 0.0871,
        "grad_norm": 12.762035369873047,
        "learning_rate": 2.2320637732506645e-06,
        "epoch": 7.7679362267493355,
        "step": 8770
    },
    {
        "loss": 0.0304,
        "grad_norm": 0.0098780058324337,
        "learning_rate": 2.2232063773250666e-06,
        "epoch": 7.7767936226749335,
        "step": 8780
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.029281137511134148,
        "learning_rate": 2.2143489813994686e-06,
        "epoch": 7.785651018600531,
        "step": 8790
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.018332606181502342,
        "learning_rate": 2.205491585473871e-06,
        "epoch": 7.794508414526129,
        "step": 8800
    },
    {
        "loss": 0.0626,
        "grad_norm": 0.01955449767410755,
        "learning_rate": 2.196634189548273e-06,
        "epoch": 7.803365810451727,
        "step": 8810
    },
    {
        "loss": 0.0227,
        "grad_norm": 0.03675144165754318,
        "learning_rate": 2.187776793622675e-06,
        "epoch": 7.812223206377325,
        "step": 8820
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.07509060204029083,
        "learning_rate": 2.178919397697077e-06,
        "epoch": 7.8210806023029225,
        "step": 8830
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.036226190626621246,
        "learning_rate": 2.170062001771479e-06,
        "epoch": 7.82993799822852,
        "step": 8840
    },
    {
        "loss": 0.0029,
        "grad_norm": 0.017730219289660454,
        "learning_rate": 2.1612046058458816e-06,
        "epoch": 7.838795394154118,
        "step": 8850
    },
    {
        "loss": 0.0722,
        "grad_norm": 0.19588449597358704,
        "learning_rate": 2.1523472099202837e-06,
        "epoch": 7.847652790079716,
        "step": 8860
    },
    {
        "loss": 0.0104,
        "grad_norm": 11.170194625854492,
        "learning_rate": 2.1434898139946857e-06,
        "epoch": 7.856510186005314,
        "step": 8870
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.11144836246967316,
        "learning_rate": 2.1346324180690877e-06,
        "epoch": 7.865367581930912,
        "step": 8880
    },
    {
        "loss": 0.0085,
        "grad_norm": 193.57981872558594,
        "learning_rate": 2.12577502214349e-06,
        "epoch": 7.87422497785651,
        "step": 8890
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.026694511994719505,
        "learning_rate": 2.116917626217892e-06,
        "epoch": 7.883082373782108,
        "step": 8900
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.32496193051338196,
        "learning_rate": 2.1080602302922943e-06,
        "epoch": 7.891939769707706,
        "step": 8910
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.008503304794430733,
        "learning_rate": 2.0992028343666963e-06,
        "epoch": 7.900797165633303,
        "step": 8920
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.007509515155106783,
        "learning_rate": 2.0903454384410983e-06,
        "epoch": 7.909654561558901,
        "step": 8930
    },
    {
        "loss": 0.0387,
        "grad_norm": 0.10213218629360199,
        "learning_rate": 2.0814880425155008e-06,
        "epoch": 7.918511957484499,
        "step": 8940
    },
    {
        "loss": 0.0734,
        "grad_norm": 59.01249694824219,
        "learning_rate": 2.072630646589903e-06,
        "epoch": 7.927369353410097,
        "step": 8950
    },
    {
        "loss": 0.0679,
        "grad_norm": 171.43409729003906,
        "learning_rate": 2.063773250664305e-06,
        "epoch": 7.936226749335695,
        "step": 8960
    },
    {
        "loss": 0.079,
        "grad_norm": 0.008528883568942547,
        "learning_rate": 2.054915854738707e-06,
        "epoch": 7.945084145261293,
        "step": 8970
    },
    {
        "loss": 0.0395,
        "grad_norm": 0.0672336146235466,
        "learning_rate": 2.046058458813109e-06,
        "epoch": 7.953941541186891,
        "step": 8980
    },
    {
        "loss": 0.0271,
        "grad_norm": 200.55894470214844,
        "learning_rate": 2.0372010628875114e-06,
        "epoch": 7.962798937112489,
        "step": 8990
    },
    {
        "loss": 0.0288,
        "grad_norm": 0.008535602129995823,
        "learning_rate": 2.0283436669619134e-06,
        "epoch": 7.971656333038087,
        "step": 9000
    },
    {
        "loss": 0.0301,
        "grad_norm": 58.7869873046875,
        "learning_rate": 2.0194862710363154e-06,
        "epoch": 7.980513728963684,
        "step": 9010
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.09146307408809662,
        "learning_rate": 2.0106288751107175e-06,
        "epoch": 7.989371124889282,
        "step": 9020
    },
    {
        "loss": 0.0205,
        "grad_norm": 164.30096435546875,
        "learning_rate": 2.00177147918512e-06,
        "epoch": 7.99822852081488,
        "step": 9030
    },
    {
        "eval_loss": 0.13068249821662903,
        "eval_accuracy": 0.98251,
        "eval_precision": 0.97681,
        "eval_recall": 0.98849,
        "eval_f1": 0.98261,
        "eval_runtime": 150.0305,
        "eval_samples_per_second": 60.201,
        "eval_steps_per_second": 3.766,
        "epoch": 8.0,
        "step": 9032
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006314862985163927,
        "learning_rate": 1.9929140832595215e-06,
        "epoch": 8.007085916740479,
        "step": 9040
    },
    {
        "loss": 0.0751,
        "grad_norm": 46.2712516784668,
        "learning_rate": 1.984056687333924e-06,
        "epoch": 8.015943312666076,
        "step": 9050
    },
    {
        "loss": 0.0006,
        "grad_norm": 14.261212348937988,
        "learning_rate": 1.975199291408326e-06,
        "epoch": 8.024800708591673,
        "step": 9060
    },
    {
        "loss": 0.0044,
        "grad_norm": 85.29964447021484,
        "learning_rate": 1.966341895482728e-06,
        "epoch": 8.033658104517272,
        "step": 9070
    },
    {
        "loss": 0.0299,
        "grad_norm": 130.13157653808594,
        "learning_rate": 1.9574844995571305e-06,
        "epoch": 8.04251550044287,
        "step": 9080
    },
    {
        "loss": 0.0829,
        "grad_norm": 0.01360909640789032,
        "learning_rate": 1.9486271036315325e-06,
        "epoch": 8.051372896368468,
        "step": 9090
    },
    {
        "loss": 0.0005,
        "grad_norm": 5.9628424644470215,
        "learning_rate": 1.9397697077059346e-06,
        "epoch": 8.060230292294065,
        "step": 9100
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008717120625078678,
        "learning_rate": 1.9309123117803366e-06,
        "epoch": 8.069087688219664,
        "step": 9110
    },
    {
        "loss": 0.0603,
        "grad_norm": 0.09180492907762527,
        "learning_rate": 1.922054915854739e-06,
        "epoch": 8.077945084145261,
        "step": 9120
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.07190032303333282,
        "learning_rate": 1.913197519929141e-06,
        "epoch": 8.08680248007086,
        "step": 9130
    },
    {
        "loss": 0.0218,
        "grad_norm": 0.022244876250624657,
        "learning_rate": 1.9043401240035431e-06,
        "epoch": 8.095659875996457,
        "step": 9140
    },
    {
        "loss": 0.0467,
        "grad_norm": 0.0745241791009903,
        "learning_rate": 1.8954827280779454e-06,
        "epoch": 8.104517271922054,
        "step": 9150
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.10921766608953476,
        "learning_rate": 1.8866253321523472e-06,
        "epoch": 8.113374667847653,
        "step": 9160
    },
    {
        "loss": 0.0146,
        "grad_norm": 0.04810664802789688,
        "learning_rate": 1.8777679362267494e-06,
        "epoch": 8.12223206377325,
        "step": 9170
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.019589897245168686,
        "learning_rate": 1.8689105403011515e-06,
        "epoch": 8.131089459698849,
        "step": 9180
    },
    {
        "loss": 0.0257,
        "grad_norm": 0.02921140193939209,
        "learning_rate": 1.8600531443755537e-06,
        "epoch": 8.139946855624446,
        "step": 9190
    },
    {
        "loss": 0.0589,
        "grad_norm": 7.163451671600342,
        "learning_rate": 1.851195748449956e-06,
        "epoch": 8.148804251550045,
        "step": 9200
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03744357079267502,
        "learning_rate": 1.842338352524358e-06,
        "epoch": 8.157661647475642,
        "step": 9210
    },
    {
        "loss": 0.0425,
        "grad_norm": 0.006026253569871187,
        "learning_rate": 1.8334809565987602e-06,
        "epoch": 8.166519043401241,
        "step": 9220
    },
    {
        "loss": 0.0595,
        "grad_norm": 0.008764849975705147,
        "learning_rate": 1.824623560673162e-06,
        "epoch": 8.175376439326838,
        "step": 9230
    },
    {
        "loss": 0.0529,
        "grad_norm": 0.005527039058506489,
        "learning_rate": 1.8157661647475643e-06,
        "epoch": 8.184233835252435,
        "step": 9240
    },
    {
        "loss": 0.0051,
        "grad_norm": 124.46417999267578,
        "learning_rate": 1.8069087688219663e-06,
        "epoch": 8.193091231178034,
        "step": 9250
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.005537939257919788,
        "learning_rate": 1.7980513728963686e-06,
        "epoch": 8.201948627103631,
        "step": 9260
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.00388384354300797,
        "learning_rate": 1.7891939769707708e-06,
        "epoch": 8.21080602302923,
        "step": 9270
    },
    {
        "loss": 0.0214,
        "grad_norm": 0.004030771553516388,
        "learning_rate": 1.7803365810451729e-06,
        "epoch": 8.219663418954827,
        "step": 9280
    },
    {
        "loss": 0.0253,
        "grad_norm": 0.022414779290556908,
        "learning_rate": 1.771479185119575e-06,
        "epoch": 8.228520814880426,
        "step": 9290
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00431553740054369,
        "learning_rate": 1.7626217891939771e-06,
        "epoch": 8.237378210806023,
        "step": 9300
    },
    {
        "loss": 0.0271,
        "grad_norm": 0.004019463434815407,
        "learning_rate": 1.7537643932683794e-06,
        "epoch": 8.24623560673162,
        "step": 9310
    },
    {
        "loss": 0.0318,
        "grad_norm": 0.012586808763444424,
        "learning_rate": 1.7449069973427812e-06,
        "epoch": 8.255093002657219,
        "step": 9320
    },
    {
        "loss": 0.0577,
        "grad_norm": 3.1207849979400635,
        "learning_rate": 1.7360496014171834e-06,
        "epoch": 8.263950398582816,
        "step": 9330
    },
    {
        "loss": 0.0012,
        "grad_norm": 0.007321062032133341,
        "learning_rate": 1.7271922054915857e-06,
        "epoch": 8.272807794508415,
        "step": 9340
    },
    {
        "loss": 0.0699,
        "grad_norm": 68.6795425415039,
        "learning_rate": 1.7183348095659877e-06,
        "epoch": 8.281665190434012,
        "step": 9350
    },
    {
        "loss": 0.0294,
        "grad_norm": 0.0735364630818367,
        "learning_rate": 1.70947741364039e-06,
        "epoch": 8.29052258635961,
        "step": 9360
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.022861039265990257,
        "learning_rate": 1.700620017714792e-06,
        "epoch": 8.299379982285208,
        "step": 9370
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01466874498873949,
        "learning_rate": 1.6917626217891942e-06,
        "epoch": 8.308237378210807,
        "step": 9380
    },
    {
        "loss": 0.0042,
        "grad_norm": 0.0046934462152421474,
        "learning_rate": 1.682905225863596e-06,
        "epoch": 8.317094774136404,
        "step": 9390
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.010582007467746735,
        "learning_rate": 1.6740478299379983e-06,
        "epoch": 8.325952170062001,
        "step": 9400
    },
    {
        "loss": 0.0012,
        "grad_norm": 0.005272706039249897,
        "learning_rate": 1.6651904340124005e-06,
        "epoch": 8.3348095659876,
        "step": 9410
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.017257584258913994,
        "learning_rate": 1.6563330380868026e-06,
        "epoch": 8.343666961913197,
        "step": 9420
    },
    {
        "loss": 0.0102,
        "grad_norm": 0.0038628161419183016,
        "learning_rate": 1.6474756421612048e-06,
        "epoch": 8.352524357838796,
        "step": 9430
    },
    {
        "loss": 0.0026,
        "grad_norm": 0.002685192506760359,
        "learning_rate": 1.6386182462356069e-06,
        "epoch": 8.361381753764393,
        "step": 9440
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.029329938814044,
        "learning_rate": 1.629760850310009e-06,
        "epoch": 8.370239149689992,
        "step": 9450
    },
    {
        "loss": 0.0819,
        "grad_norm": 0.010654970072209835,
        "learning_rate": 1.620903454384411e-06,
        "epoch": 8.379096545615589,
        "step": 9460
    },
    {
        "loss": 0.0399,
        "grad_norm": 0.06612943112850189,
        "learning_rate": 1.6120460584588132e-06,
        "epoch": 8.387953941541188,
        "step": 9470
    },
    {
        "loss": 0.0117,
        "grad_norm": 0.008701817132532597,
        "learning_rate": 1.6031886625332154e-06,
        "epoch": 8.396811337466785,
        "step": 9480
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004105093888938427,
        "learning_rate": 1.5943312666076174e-06,
        "epoch": 8.405668733392382,
        "step": 9490
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.014204778708517551,
        "learning_rate": 1.5854738706820197e-06,
        "epoch": 8.41452612931798,
        "step": 9500
    },
    {
        "loss": 0.0734,
        "grad_norm": 0.010761392302811146,
        "learning_rate": 1.5766164747564217e-06,
        "epoch": 8.423383525243578,
        "step": 9510
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.025800662115216255,
        "learning_rate": 1.567759078830824e-06,
        "epoch": 8.432240921169177,
        "step": 9520
    },
    {
        "loss": 0.0235,
        "grad_norm": 154.48919677734375,
        "learning_rate": 1.5589016829052258e-06,
        "epoch": 8.441098317094774,
        "step": 9530
    },
    {
        "loss": 0.0113,
        "grad_norm": 0.021103106439113617,
        "learning_rate": 1.550044286979628e-06,
        "epoch": 8.449955713020373,
        "step": 9540
    },
    {
        "loss": 0.0359,
        "grad_norm": 0.09924020618200302,
        "learning_rate": 1.5411868910540303e-06,
        "epoch": 8.45881310894597,
        "step": 9550
    },
    {
        "loss": 0.0008,
        "grad_norm": 20.95516586303711,
        "learning_rate": 1.5323294951284323e-06,
        "epoch": 8.467670504871569,
        "step": 9560
    },
    {
        "loss": 0.0139,
        "grad_norm": 0.07914125174283981,
        "learning_rate": 1.5234720992028345e-06,
        "epoch": 8.476527900797166,
        "step": 9570
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.006176441442221403,
        "learning_rate": 1.5146147032772366e-06,
        "epoch": 8.485385296722763,
        "step": 9580
    },
    {
        "loss": 0.0002,
        "grad_norm": 1.3529051542282104,
        "learning_rate": 1.5057573073516388e-06,
        "epoch": 8.494242692648362,
        "step": 9590
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.011930985376238823,
        "learning_rate": 1.4968999114260406e-06,
        "epoch": 8.503100088573959,
        "step": 9600
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01051434874534607,
        "learning_rate": 1.4880425155004429e-06,
        "epoch": 8.511957484499558,
        "step": 9610
    },
    {
        "loss": 0.0431,
        "grad_norm": 0.0024496912956237793,
        "learning_rate": 1.4791851195748451e-06,
        "epoch": 8.520814880425155,
        "step": 9620
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.05167897045612335,
        "learning_rate": 1.4703277236492472e-06,
        "epoch": 8.529672276350754,
        "step": 9630
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0026001075748354197,
        "learning_rate": 1.4614703277236494e-06,
        "epoch": 8.53852967227635,
        "step": 9640
    },
    {
        "loss": 0.0255,
        "grad_norm": 148.85702514648438,
        "learning_rate": 1.4526129317980514e-06,
        "epoch": 8.54738706820195,
        "step": 9650
    },
    {
        "loss": 0.0794,
        "grad_norm": 0.007909555919468403,
        "learning_rate": 1.4437555358724537e-06,
        "epoch": 8.556244464127547,
        "step": 9660
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.006149916909635067,
        "learning_rate": 1.4348981399468557e-06,
        "epoch": 8.565101860053144,
        "step": 9670
    },
    {
        "loss": 0.0851,
        "grad_norm": 0.09164103120565414,
        "learning_rate": 1.426040744021258e-06,
        "epoch": 8.573959255978743,
        "step": 9680
    },
    {
        "loss": 0.0156,
        "grad_norm": 0.016256019473075867,
        "learning_rate": 1.4171833480956602e-06,
        "epoch": 8.58281665190434,
        "step": 9690
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0029756356962025166,
        "learning_rate": 1.408325952170062e-06,
        "epoch": 8.591674047829938,
        "step": 9700
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.014584982767701149,
        "learning_rate": 1.3994685562444643e-06,
        "epoch": 8.600531443755536,
        "step": 9710
    },
    {
        "loss": 0.0002,
        "grad_norm": 1.807483196258545,
        "learning_rate": 1.3906111603188663e-06,
        "epoch": 8.609388839681134,
        "step": 9720
    },
    {
        "loss": 0.0548,
        "grad_norm": 0.005993627477437258,
        "learning_rate": 1.3817537643932685e-06,
        "epoch": 8.618246235606732,
        "step": 9730
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019649253226816654,
        "learning_rate": 1.3728963684676706e-06,
        "epoch": 8.627103631532329,
        "step": 9740
    },
    {
        "loss": 0.0057,
        "grad_norm": 0.005302788224071264,
        "learning_rate": 1.3640389725420728e-06,
        "epoch": 8.635961027457927,
        "step": 9750
    },
    {
        "loss": 0.0102,
        "grad_norm": 0.012711778283119202,
        "learning_rate": 1.355181576616475e-06,
        "epoch": 8.644818423383525,
        "step": 9760
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.047238368541002274,
        "learning_rate": 1.3463241806908769e-06,
        "epoch": 8.653675819309123,
        "step": 9770
    },
    {
        "loss": 0.0589,
        "grad_norm": 0.005948551930487156,
        "learning_rate": 1.3374667847652791e-06,
        "epoch": 8.66253321523472,
        "step": 9780
    },
    {
        "loss": 0.0423,
        "grad_norm": 0.5554866194725037,
        "learning_rate": 1.3286093888396812e-06,
        "epoch": 8.67139061116032,
        "step": 9790
    },
    {
        "loss": 0.0664,
        "grad_norm": 69.47096252441406,
        "learning_rate": 1.3197519929140834e-06,
        "epoch": 8.680248007085916,
        "step": 9800
    },
    {
        "loss": 0.02,
        "grad_norm": 0.011247004382312298,
        "learning_rate": 1.3108945969884854e-06,
        "epoch": 8.689105403011515,
        "step": 9810
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.022157980129122734,
        "learning_rate": 1.3020372010628877e-06,
        "epoch": 8.697962798937112,
        "step": 9820
    },
    {
        "loss": 0.0062,
        "grad_norm": 0.0031335640233010054,
        "learning_rate": 1.29317980513729e-06,
        "epoch": 8.706820194862711,
        "step": 9830
    },
    {
        "loss": 0.0589,
        "grad_norm": 0.0596984438598156,
        "learning_rate": 1.2843224092116918e-06,
        "epoch": 8.715677590788308,
        "step": 9840
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0028294611256569624,
        "learning_rate": 1.275465013286094e-06,
        "epoch": 8.724534986713905,
        "step": 9850
    },
    {
        "loss": 0.0496,
        "grad_norm": 0.04835325852036476,
        "learning_rate": 1.266607617360496e-06,
        "epoch": 8.733392382639504,
        "step": 9860
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.011495362035930157,
        "learning_rate": 1.2577502214348983e-06,
        "epoch": 8.742249778565101,
        "step": 9870
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.002957394113764167,
        "learning_rate": 1.2488928255093003e-06,
        "epoch": 8.7511071744907,
        "step": 9880
    },
    {
        "loss": 0.0054,
        "grad_norm": 0.0032779257744550705,
        "learning_rate": 1.2400354295837025e-06,
        "epoch": 8.759964570416297,
        "step": 9890
    },
    {
        "loss": 0.0743,
        "grad_norm": 0.002122451551258564,
        "learning_rate": 1.2311780336581046e-06,
        "epoch": 8.768821966341896,
        "step": 9900
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02190098538994789,
        "learning_rate": 1.2223206377325066e-06,
        "epoch": 8.777679362267493,
        "step": 9910
    },
    {
        "loss": 0.0168,
        "grad_norm": 0.0035538289230316877,
        "learning_rate": 1.2134632418069089e-06,
        "epoch": 8.78653675819309,
        "step": 9920
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018394881626591086,
        "learning_rate": 1.204605845881311e-06,
        "epoch": 8.79539415411869,
        "step": 9930
    },
    {
        "loss": 0.0323,
        "grad_norm": 0.009042236022651196,
        "learning_rate": 1.1957484499557131e-06,
        "epoch": 8.804251550044286,
        "step": 9940
    },
    {
        "loss": 0.0263,
        "grad_norm": 0.0031330056954175234,
        "learning_rate": 1.1868910540301152e-06,
        "epoch": 8.813108945969885,
        "step": 9950
    },
    {
        "loss": 0.0449,
        "grad_norm": 0.17108914256095886,
        "learning_rate": 1.1780336581045174e-06,
        "epoch": 8.821966341895482,
        "step": 9960
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.03388730064034462,
        "learning_rate": 1.1691762621789194e-06,
        "epoch": 8.830823737821081,
        "step": 9970
    },
    {
        "loss": 0.0314,
        "grad_norm": 9.053793907165527,
        "learning_rate": 1.1603188662533215e-06,
        "epoch": 8.839681133746678,
        "step": 9980
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0031942136120051146,
        "learning_rate": 1.1514614703277237e-06,
        "epoch": 8.848538529672277,
        "step": 9990
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0038204777520149946,
        "learning_rate": 1.142604074402126e-06,
        "epoch": 8.857395925597874,
        "step": 10000
    },
    {
        "loss": 0.0498,
        "grad_norm": 0.014374306425452232,
        "learning_rate": 1.133746678476528e-06,
        "epoch": 8.866253321523471,
        "step": 10010
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.0031792595982551575,
        "learning_rate": 1.1248892825509302e-06,
        "epoch": 8.87511071744907,
        "step": 10020
    },
    {
        "loss": 0.0057,
        "grad_norm": 0.013301534578204155,
        "learning_rate": 1.1160318866253323e-06,
        "epoch": 8.883968113374667,
        "step": 10030
    },
    {
        "loss": 0.1004,
        "grad_norm": 0.005027160048484802,
        "learning_rate": 1.1071744906997343e-06,
        "epoch": 8.892825509300266,
        "step": 10040
    },
    {
        "loss": 0.007,
        "grad_norm": 0.003853708738461137,
        "learning_rate": 1.0983170947741365e-06,
        "epoch": 8.901682905225863,
        "step": 10050
    },
    {
        "loss": 0.0287,
        "grad_norm": 0.01158223394304514,
        "learning_rate": 1.0894596988485386e-06,
        "epoch": 8.910540301151462,
        "step": 10060
    },
    {
        "loss": 0.0785,
        "grad_norm": 202.1093292236328,
        "learning_rate": 1.0806023029229408e-06,
        "epoch": 8.91939769707706,
        "step": 10070
    },
    {
        "loss": 0.0594,
        "grad_norm": 0.006238448899239302,
        "learning_rate": 1.0717449069973429e-06,
        "epoch": 8.928255093002658,
        "step": 10080
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03511461243033409,
        "learning_rate": 1.062887511071745e-06,
        "epoch": 8.937112488928255,
        "step": 10090
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.010447737760841846,
        "learning_rate": 1.0540301151461471e-06,
        "epoch": 8.945969884853852,
        "step": 10100
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008087165653705597,
        "learning_rate": 1.0451727192205492e-06,
        "epoch": 8.954827280779451,
        "step": 10110
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.060878001153469086,
        "learning_rate": 1.0363153232949514e-06,
        "epoch": 8.963684676705048,
        "step": 10120
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003416543360799551,
        "learning_rate": 1.0274579273693534e-06,
        "epoch": 8.972542072630647,
        "step": 10130
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0025285647716373205,
        "learning_rate": 1.0186005314437557e-06,
        "epoch": 8.981399468556244,
        "step": 10140
    },
    {
        "loss": 0.0455,
        "grad_norm": 0.0027215387672185898,
        "learning_rate": 1.0097431355181577e-06,
        "epoch": 8.990256864481843,
        "step": 10150
    },
    {
        "loss": 0.0544,
        "grad_norm": 0.007930061779916286,
        "learning_rate": 1.00088573959256e-06,
        "epoch": 8.99911426040744,
        "step": 10160
    },
    {
        "eval_loss": 0.13057677447795868,
        "eval_accuracy": 0.98417,
        "eval_precision": 0.9832,
        "eval_recall": 0.98516,
        "eval_f1": 0.98418,
        "eval_runtime": 150.0109,
        "eval_samples_per_second": 60.209,
        "eval_steps_per_second": 3.766,
        "epoch": 9.0,
        "step": 10161
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.013714066706597805,
        "learning_rate": 9.92028343666962e-07,
        "epoch": 9.007971656333037,
        "step": 10170
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003234453499317169,
        "learning_rate": 9.83170947741364e-07,
        "epoch": 9.016829052258636,
        "step": 10180
    },
    {
        "loss": 0.0586,
        "grad_norm": 0.01999969221651554,
        "learning_rate": 9.743135518157663e-07,
        "epoch": 9.025686448184233,
        "step": 10190
    },
    {
        "loss": 0.0324,
        "grad_norm": 0.30013197660446167,
        "learning_rate": 9.654561558901683e-07,
        "epoch": 9.034543844109832,
        "step": 10200
    },
    {
        "loss": 0.0985,
        "grad_norm": 0.37135350704193115,
        "learning_rate": 9.565987599645705e-07,
        "epoch": 9.043401240035429,
        "step": 10210
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.10125842690467834,
        "learning_rate": 9.477413640389727e-07,
        "epoch": 9.052258635961028,
        "step": 10220
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.021369706839323044,
        "learning_rate": 9.388839681133747e-07,
        "epoch": 9.061116031886625,
        "step": 10230
    },
    {
        "loss": 0.0464,
        "grad_norm": 0.0464717373251915,
        "learning_rate": 9.300265721877769e-07,
        "epoch": 9.069973427812224,
        "step": 10240
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.003183134598657489,
        "learning_rate": 9.21169176262179e-07,
        "epoch": 9.078830823737821,
        "step": 10250
    },
    {
        "loss": 0.0098,
        "grad_norm": 0.23290690779685974,
        "learning_rate": 9.12311780336581e-07,
        "epoch": 9.087688219663418,
        "step": 10260
    },
    {
        "loss": 0.0283,
        "grad_norm": 0.15952196717262268,
        "learning_rate": 9.034543844109832e-07,
        "epoch": 9.096545615589017,
        "step": 10270
    },
    {
        "loss": 0.012,
        "grad_norm": 0.004622180946171284,
        "learning_rate": 8.945969884853854e-07,
        "epoch": 9.105403011514614,
        "step": 10280
    },
    {
        "loss": 0.0434,
        "grad_norm": 82.88864135742188,
        "learning_rate": 8.857395925597875e-07,
        "epoch": 9.114260407440213,
        "step": 10290
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03448464348912239,
        "learning_rate": 8.768821966341897e-07,
        "epoch": 9.12311780336581,
        "step": 10300
    },
    {
        "loss": 0.003,
        "grad_norm": 0.0019798786379396915,
        "learning_rate": 8.680248007085917e-07,
        "epoch": 9.131975199291409,
        "step": 10310
    },
    {
        "loss": 0.0247,
        "grad_norm": 263.24755859375,
        "learning_rate": 8.591674047829939e-07,
        "epoch": 9.140832595217006,
        "step": 10320
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03542974963784218,
        "learning_rate": 8.50310008857396e-07,
        "epoch": 9.149689991142605,
        "step": 10330
    },
    {
        "loss": 0.0042,
        "grad_norm": 136.30862426757812,
        "learning_rate": 8.41452612931798e-07,
        "epoch": 9.158547387068202,
        "step": 10340
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008556856773793697,
        "learning_rate": 8.325952170062003e-07,
        "epoch": 9.167404782993799,
        "step": 10350
    },
    {
        "loss": 0.0045,
        "grad_norm": 0.0034255809150636196,
        "learning_rate": 8.237378210806024e-07,
        "epoch": 9.176262178919398,
        "step": 10360
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003995618782937527,
        "learning_rate": 8.148804251550045e-07,
        "epoch": 9.185119574844995,
        "step": 10370
    },
    {
        "loss": 0.1239,
        "grad_norm": 0.008301385678350925,
        "learning_rate": 8.060230292294066e-07,
        "epoch": 9.193976970770594,
        "step": 10380
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0030554011464118958,
        "learning_rate": 7.971656333038087e-07,
        "epoch": 9.202834366696191,
        "step": 10390
    },
    {
        "loss": 0.0062,
        "grad_norm": 0.0032287961803376675,
        "learning_rate": 7.883082373782109e-07,
        "epoch": 9.21169176262179,
        "step": 10400
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.005302312318235636,
        "learning_rate": 7.794508414526129e-07,
        "epoch": 9.220549158547387,
        "step": 10410
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01355069037526846,
        "learning_rate": 7.705934455270151e-07,
        "epoch": 9.229406554472986,
        "step": 10420
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.010592480190098286,
        "learning_rate": 7.617360496014173e-07,
        "epoch": 9.238263950398583,
        "step": 10430
    },
    {
        "loss": 0.0749,
        "grad_norm": 0.0021733965259045362,
        "learning_rate": 7.528786536758194e-07,
        "epoch": 9.24712134632418,
        "step": 10440
    },
    {
        "loss": 0.0186,
        "grad_norm": 0.0029573121573776007,
        "learning_rate": 7.440212577502214e-07,
        "epoch": 9.255978742249779,
        "step": 10450
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019502954091876745,
        "learning_rate": 7.351638618246236e-07,
        "epoch": 9.264836138175376,
        "step": 10460
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007169591262936592,
        "learning_rate": 7.263064658990257e-07,
        "epoch": 9.273693534100975,
        "step": 10470
    },
    {
        "loss": 0.0566,
        "grad_norm": 0.013017766177654266,
        "learning_rate": 7.174490699734279e-07,
        "epoch": 9.282550930026572,
        "step": 10480
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00595476059243083,
        "learning_rate": 7.085916740478301e-07,
        "epoch": 9.29140832595217,
        "step": 10490
    },
    {
        "loss": 0.0091,
        "grad_norm": 0.0018616773886606097,
        "learning_rate": 6.997342781222321e-07,
        "epoch": 9.300265721877768,
        "step": 10500
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.0044929166324436665,
        "learning_rate": 6.908768821966343e-07,
        "epoch": 9.309123117803367,
        "step": 10510
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.06694018095731735,
        "learning_rate": 6.820194862710364e-07,
        "epoch": 9.317980513728964,
        "step": 10520
    },
    {
        "loss": 0.0306,
        "grad_norm": 0.0047393604181706905,
        "learning_rate": 6.731620903454384e-07,
        "epoch": 9.32683790965456,
        "step": 10530
    },
    {
        "loss": 0.0387,
        "grad_norm": 0.008699060417711735,
        "learning_rate": 6.643046944198406e-07,
        "epoch": 9.33569530558016,
        "step": 10540
    },
    {
        "loss": 0.0329,
        "grad_norm": 0.22705748677253723,
        "learning_rate": 6.554472984942427e-07,
        "epoch": 9.344552701505757,
        "step": 10550
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.2013998180627823,
        "learning_rate": 6.46589902568645e-07,
        "epoch": 9.353410097431356,
        "step": 10560
    },
    {
        "loss": 0.0425,
        "grad_norm": 0.0028004609048366547,
        "learning_rate": 6.37732506643047e-07,
        "epoch": 9.362267493356953,
        "step": 10570
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.002706407569348812,
        "learning_rate": 6.288751107174491e-07,
        "epoch": 9.371124889282552,
        "step": 10580
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.0018561870092526078,
        "learning_rate": 6.200177147918513e-07,
        "epoch": 9.379982285208149,
        "step": 10590
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0027684359811246395,
        "learning_rate": 6.111603188662533e-07,
        "epoch": 9.388839681133746,
        "step": 10600
    },
    {
        "loss": 0.0379,
        "grad_norm": 0.01895267702639103,
        "learning_rate": 6.023029229406556e-07,
        "epoch": 9.397697077059345,
        "step": 10610
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0037769696209579706,
        "learning_rate": 5.934455270150576e-07,
        "epoch": 9.406554472984942,
        "step": 10620
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0042953211814165115,
        "learning_rate": 5.845881310894597e-07,
        "epoch": 9.41541186891054,
        "step": 10630
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0116830850020051,
        "learning_rate": 5.757307351638619e-07,
        "epoch": 9.424269264836138,
        "step": 10640
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.08753722906112671,
        "learning_rate": 5.66873339238264e-07,
        "epoch": 9.433126660761737,
        "step": 10650
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.010536039248108864,
        "learning_rate": 5.580159433126661e-07,
        "epoch": 9.441984056687334,
        "step": 10660
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.18397559225559235,
        "learning_rate": 5.491585473870683e-07,
        "epoch": 9.450841452612933,
        "step": 10670
    },
    {
        "loss": 0.0003,
        "grad_norm": 5.57964563369751,
        "learning_rate": 5.403011514614704e-07,
        "epoch": 9.45969884853853,
        "step": 10680
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0028220931999385357,
        "learning_rate": 5.314437555358726e-07,
        "epoch": 9.468556244464127,
        "step": 10690
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006308320909738541,
        "learning_rate": 5.225863596102746e-07,
        "epoch": 9.477413640389726,
        "step": 10700
    },
    {
        "loss": 0.0309,
        "grad_norm": 0.00367009942419827,
        "learning_rate": 5.137289636846767e-07,
        "epoch": 9.486271036315323,
        "step": 10710
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00460086390376091,
        "learning_rate": 5.048715677590789e-07,
        "epoch": 9.495128432240922,
        "step": 10720
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.010308826342225075,
        "learning_rate": 4.96014171833481e-07,
        "epoch": 9.503985828166519,
        "step": 10730
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018761565443128347,
        "learning_rate": 4.871567759078831e-07,
        "epoch": 9.512843224092117,
        "step": 10740
    },
    {
        "loss": 0.0639,
        "grad_norm": 276.0558776855469,
        "learning_rate": 4.782993799822853e-07,
        "epoch": 9.521700620017715,
        "step": 10750
    },
    {
        "loss": 0.0408,
        "grad_norm": 0.0023463889956474304,
        "learning_rate": 4.6944198405668736e-07,
        "epoch": 9.530558015943313,
        "step": 10760
    },
    {
        "loss": 0.0595,
        "grad_norm": 0.03034258633852005,
        "learning_rate": 4.605845881310895e-07,
        "epoch": 9.53941541186891,
        "step": 10770
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.005765384063124657,
        "learning_rate": 4.517271922054916e-07,
        "epoch": 9.548272807794508,
        "step": 10780
    },
    {
        "loss": 0.0363,
        "grad_norm": 0.0187075138092041,
        "learning_rate": 4.428697962798938e-07,
        "epoch": 9.557130203720106,
        "step": 10790
    },
    {
        "loss": 0.0477,
        "grad_norm": 0.021769192069768906,
        "learning_rate": 4.3401240035429586e-07,
        "epoch": 9.565987599645704,
        "step": 10800
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.029913602396845818,
        "learning_rate": 4.25155004428698e-07,
        "epoch": 9.574844995571302,
        "step": 10810
    },
    {
        "loss": 0.0032,
        "grad_norm": 110.89685821533203,
        "learning_rate": 4.1629760850310014e-07,
        "epoch": 9.5837023914969,
        "step": 10820
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006148843094706535,
        "learning_rate": 4.074402125775023e-07,
        "epoch": 9.592559787422498,
        "step": 10830
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.06655789911746979,
        "learning_rate": 3.9858281665190436e-07,
        "epoch": 9.601417183348095,
        "step": 10840
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0027220528572797775,
        "learning_rate": 3.8972542072630645e-07,
        "epoch": 9.610274579273694,
        "step": 10850
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003206853289157152,
        "learning_rate": 3.8086802480070864e-07,
        "epoch": 9.619131975199291,
        "step": 10860
    },
    {
        "loss": 0.082,
        "grad_norm": 30.321895599365234,
        "learning_rate": 3.720106288751107e-07,
        "epoch": 9.627989371124889,
        "step": 10870
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004438807722181082,
        "learning_rate": 3.6315323294951286e-07,
        "epoch": 9.636846767050487,
        "step": 10880
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.01251872070133686,
        "learning_rate": 3.5429583702391505e-07,
        "epoch": 9.645704162976084,
        "step": 10890
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0026998671237379313,
        "learning_rate": 3.4543844109831714e-07,
        "epoch": 9.654561558901683,
        "step": 10900
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00661409692838788,
        "learning_rate": 3.365810451727192e-07,
        "epoch": 9.66341895482728,
        "step": 10910
    },
    {
        "loss": 0.0641,
        "grad_norm": 0.011908267624676228,
        "learning_rate": 3.2772364924712136e-07,
        "epoch": 9.67227635075288,
        "step": 10920
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004348093643784523,
        "learning_rate": 3.188662533215235e-07,
        "epoch": 9.681133746678476,
        "step": 10930
    },
    {
        "loss": 0.0121,
        "grad_norm": 0.0020628818310797215,
        "learning_rate": 3.1000885739592564e-07,
        "epoch": 9.689991142604075,
        "step": 10940
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0017711251275613904,
        "learning_rate": 3.011514614703278e-07,
        "epoch": 9.698848538529672,
        "step": 10950
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01426093839108944,
        "learning_rate": 2.9229406554472986e-07,
        "epoch": 9.70770593445527,
        "step": 10960
    },
    {
        "loss": 0.0263,
        "grad_norm": 0.018586985766887665,
        "learning_rate": 2.83436669619132e-07,
        "epoch": 9.716563330380868,
        "step": 10970
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.007873437367379665,
        "learning_rate": 2.7457927369353414e-07,
        "epoch": 9.725420726306465,
        "step": 10980
    },
    {
        "loss": 0.0461,
        "grad_norm": 0.004959193058311939,
        "learning_rate": 2.657218777679363e-07,
        "epoch": 9.734278122232064,
        "step": 10990
    },
    {
        "loss": 0.0283,
        "grad_norm": 0.002791999140754342,
        "learning_rate": 2.5686448184233836e-07,
        "epoch": 9.743135518157661,
        "step": 11000
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0025337517727166414,
        "learning_rate": 2.480070859167405e-07,
        "epoch": 9.75199291408326,
        "step": 11010
    },
    {
        "loss": 0.0026,
        "grad_norm": 0.056986164301633835,
        "learning_rate": 2.3914968999114264e-07,
        "epoch": 9.760850310008857,
        "step": 11020
    },
    {
        "loss": 0.032,
        "grad_norm": 0.0037529582623392344,
        "learning_rate": 2.3029229406554475e-07,
        "epoch": 9.769707705934454,
        "step": 11030
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0024010390043258667,
        "learning_rate": 2.214348981399469e-07,
        "epoch": 9.778565101860053,
        "step": 11040
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.005589053500443697,
        "learning_rate": 2.12577502214349e-07,
        "epoch": 9.78742249778565,
        "step": 11050
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.0065682618878781796,
        "learning_rate": 2.0372010628875114e-07,
        "epoch": 9.79627989371125,
        "step": 11060
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004294511862099171,
        "learning_rate": 1.9486271036315322e-07,
        "epoch": 9.805137289636846,
        "step": 11070
    },
    {
        "loss": 0.0111,
        "grad_norm": 0.01572936400771141,
        "learning_rate": 1.8600531443755536e-07,
        "epoch": 9.813994685562445,
        "step": 11080
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018902609590440989,
        "learning_rate": 1.7714791851195753e-07,
        "epoch": 9.822852081488042,
        "step": 11090
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.001902758958749473,
        "learning_rate": 1.682905225863596e-07,
        "epoch": 9.831709477413641,
        "step": 11100
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002111357869580388,
        "learning_rate": 1.5943312666076175e-07,
        "epoch": 9.840566873339238,
        "step": 11110
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003969711251556873,
        "learning_rate": 1.505757307351639e-07,
        "epoch": 9.849424269264837,
        "step": 11120
    },
    {
        "loss": 0.0046,
        "grad_norm": 0.007660222705453634,
        "learning_rate": 1.41718334809566e-07,
        "epoch": 9.858281665190434,
        "step": 11130
    },
    {
        "loss": 0.0043,
        "grad_norm": 0.0022036682348698378,
        "learning_rate": 1.3286093888396814e-07,
        "epoch": 9.867139061116031,
        "step": 11140
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006194266956299543,
        "learning_rate": 1.2400354295837025e-07,
        "epoch": 9.87599645704163,
        "step": 11150
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.005496182478964329,
        "learning_rate": 1.1514614703277237e-07,
        "epoch": 9.884853852967227,
        "step": 11160
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02109512872993946,
        "learning_rate": 1.062887511071745e-07,
        "epoch": 9.893711248892826,
        "step": 11170
    },
    {
        "loss": 0.0226,
        "grad_norm": 0.003625820390880108,
        "learning_rate": 9.743135518157661e-08,
        "epoch": 9.902568644818423,
        "step": 11180
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.009729418903589249,
        "learning_rate": 8.857395925597876e-08,
        "epoch": 9.911426040744022,
        "step": 11190
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007651943247765303,
        "learning_rate": 7.971656333038087e-08,
        "epoch": 9.920283436669619,
        "step": 11200
    },
    {
        "loss": 0.1208,
        "grad_norm": 54.136070251464844,
        "learning_rate": 7.0859167404783e-08,
        "epoch": 9.929140832595216,
        "step": 11210
    },
    {
        "loss": 0.0299,
        "grad_norm": 0.002018942730501294,
        "learning_rate": 6.200177147918512e-08,
        "epoch": 9.937998228520815,
        "step": 11220
    },
    {
        "loss": 0.0062,
        "grad_norm": 0.0020752702839672565,
        "learning_rate": 5.314437555358725e-08,
        "epoch": 9.946855624446412,
        "step": 11230
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.003762952983379364,
        "learning_rate": 4.428697962798938e-08,
        "epoch": 9.955713020372011,
        "step": 11240
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007668803445994854,
        "learning_rate": 3.54295837023915e-08,
        "epoch": 9.964570416297608,
        "step": 11250
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.37223976850509644,
        "learning_rate": 2.6572187776793625e-08,
        "epoch": 9.973427812223207,
        "step": 11260
    },
    {
        "loss": 0.0572,
        "grad_norm": 0.6158714294433594,
        "learning_rate": 1.771479185119575e-08,
        "epoch": 9.982285208148804,
        "step": 11270
    },
    {
        "loss": 0.012,
        "grad_norm": 149.34637451171875,
        "learning_rate": 8.857395925597875e-09,
        "epoch": 9.991142604074403,
        "step": 11280
    },
    {
        "loss": 0.0461,
        "grad_norm": 0.0289221853017807,
        "learning_rate": 0.0,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "eval_loss": 0.13507603108882904,
        "eval_accuracy": 0.98384,
        "eval_precision": 0.98001,
        "eval_recall": 0.98782,
        "eval_f1": 0.9839,
        "eval_runtime": 150.034,
        "eval_samples_per_second": 60.2,
        "eval_steps_per_second": 3.766,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "train_runtime": 11468.9206,
        "train_samples_per_second": 15.75,
        "train_steps_per_second": 0.984,
        "total_flos": 2.37628749648384e+16,
        "train_loss": 0.15485560057692616,
        "epoch": 10.0,
        "step": 11290
    }
]