[
    {
        "loss": 0.6931,
        "grad_norm": 3.5063984394073486,
        "learning_rate": 9.991142604074402e-06,
        "epoch": 0.008857395925597875,
        "step": 10
    },
    {
        "loss": 0.6593,
        "grad_norm": 3.4828438758850098,
        "learning_rate": 9.982285208148806e-06,
        "epoch": 0.01771479185119575,
        "step": 20
    },
    {
        "loss": 0.6306,
        "grad_norm": 4.440291881561279,
        "learning_rate": 9.973427812223207e-06,
        "epoch": 0.026572187776793623,
        "step": 30
    },
    {
        "loss": 0.6789,
        "grad_norm": 3.4706332683563232,
        "learning_rate": 9.964570416297609e-06,
        "epoch": 0.0354295837023915,
        "step": 40
    },
    {
        "loss": 0.6018,
        "grad_norm": 3.272338390350342,
        "learning_rate": 9.95571302037201e-06,
        "epoch": 0.04428697962798937,
        "step": 50
    },
    {
        "loss": 0.5829,
        "grad_norm": 4.902161121368408,
        "learning_rate": 9.946855624446414e-06,
        "epoch": 0.053144375553587246,
        "step": 60
    },
    {
        "loss": 0.6313,
        "grad_norm": 4.840915203094482,
        "learning_rate": 9.937998228520815e-06,
        "epoch": 0.06200177147918512,
        "step": 70
    },
    {
        "loss": 0.6403,
        "grad_norm": 7.463415622711182,
        "learning_rate": 9.929140832595217e-06,
        "epoch": 0.070859167404783,
        "step": 80
    },
    {
        "loss": 0.5863,
        "grad_norm": 4.691705226898193,
        "learning_rate": 9.92028343666962e-06,
        "epoch": 0.07971656333038087,
        "step": 90
    },
    {
        "loss": 0.6116,
        "grad_norm": 3.608107805252075,
        "learning_rate": 9.911426040744022e-06,
        "epoch": 0.08857395925597875,
        "step": 100
    },
    {
        "loss": 0.6499,
        "grad_norm": 5.157451152801514,
        "learning_rate": 9.902568644818424e-06,
        "epoch": 0.09743135518157661,
        "step": 110
    },
    {
        "loss": 0.6062,
        "grad_norm": 3.9198124408721924,
        "learning_rate": 9.893711248892827e-06,
        "epoch": 0.10628875110717449,
        "step": 120
    },
    {
        "loss": 0.5874,
        "grad_norm": 4.767683029174805,
        "learning_rate": 9.884853852967229e-06,
        "epoch": 0.11514614703277236,
        "step": 130
    },
    {
        "loss": 0.6094,
        "grad_norm": 2.5936179161071777,
        "learning_rate": 9.87599645704163e-06,
        "epoch": 0.12400354295837024,
        "step": 140
    },
    {
        "loss": 0.6285,
        "grad_norm": 3.410505771636963,
        "learning_rate": 9.867139061116032e-06,
        "epoch": 0.1328609388839681,
        "step": 150
    },
    {
        "loss": 0.5481,
        "grad_norm": 9.17829704284668,
        "learning_rate": 9.858281665190435e-06,
        "epoch": 0.141718334809566,
        "step": 160
    },
    {
        "loss": 0.578,
        "grad_norm": 4.189148902893066,
        "learning_rate": 9.849424269264837e-06,
        "epoch": 0.15057573073516387,
        "step": 170
    },
    {
        "loss": 0.6399,
        "grad_norm": 4.918703079223633,
        "learning_rate": 9.840566873339238e-06,
        "epoch": 0.15943312666076173,
        "step": 180
    },
    {
        "loss": 0.6077,
        "grad_norm": 4.366703033447266,
        "learning_rate": 9.831709477413642e-06,
        "epoch": 0.1682905225863596,
        "step": 190
    },
    {
        "loss": 0.6005,
        "grad_norm": 3.4630162715911865,
        "learning_rate": 9.822852081488043e-06,
        "epoch": 0.1771479185119575,
        "step": 200
    },
    {
        "loss": 0.5614,
        "grad_norm": 5.453832626342773,
        "learning_rate": 9.813994685562446e-06,
        "epoch": 0.18600531443755536,
        "step": 210
    },
    {
        "loss": 0.5364,
        "grad_norm": 3.664137363433838,
        "learning_rate": 9.805137289636848e-06,
        "epoch": 0.19486271036315322,
        "step": 220
    },
    {
        "loss": 0.5341,
        "grad_norm": 5.846314430236816,
        "learning_rate": 9.79627989371125e-06,
        "epoch": 0.20372010628875112,
        "step": 230
    },
    {
        "loss": 0.6671,
        "grad_norm": 6.456735134124756,
        "learning_rate": 9.787422497785651e-06,
        "epoch": 0.21257750221434898,
        "step": 240
    },
    {
        "loss": 0.5923,
        "grad_norm": 5.447303295135498,
        "learning_rate": 9.778565101860053e-06,
        "epoch": 0.22143489813994685,
        "step": 250
    },
    {
        "loss": 0.5809,
        "grad_norm": 6.131535530090332,
        "learning_rate": 9.769707705934456e-06,
        "epoch": 0.23029229406554472,
        "step": 260
    },
    {
        "loss": 0.5762,
        "grad_norm": 4.22085428237915,
        "learning_rate": 9.760850310008858e-06,
        "epoch": 0.2391496899911426,
        "step": 270
    },
    {
        "loss": 0.5659,
        "grad_norm": 5.330777645111084,
        "learning_rate": 9.751992914083261e-06,
        "epoch": 0.24800708591674048,
        "step": 280
    },
    {
        "loss": 0.6376,
        "grad_norm": 6.650249004364014,
        "learning_rate": 9.743135518157663e-06,
        "epoch": 0.25686448184233834,
        "step": 290
    },
    {
        "loss": 0.5911,
        "grad_norm": 6.306488037109375,
        "learning_rate": 9.734278122232064e-06,
        "epoch": 0.2657218777679362,
        "step": 300
    },
    {
        "loss": 0.5701,
        "grad_norm": 4.195838928222656,
        "learning_rate": 9.725420726306468e-06,
        "epoch": 0.2745792736935341,
        "step": 310
    },
    {
        "loss": 0.6272,
        "grad_norm": 4.924046993255615,
        "learning_rate": 9.71656333038087e-06,
        "epoch": 0.283436669619132,
        "step": 320
    },
    {
        "loss": 0.5561,
        "grad_norm": 5.943238258361816,
        "learning_rate": 9.707705934455271e-06,
        "epoch": 0.29229406554472986,
        "step": 330
    },
    {
        "loss": 0.4916,
        "grad_norm": 7.052161693572998,
        "learning_rate": 9.698848538529672e-06,
        "epoch": 0.30115146147032773,
        "step": 340
    },
    {
        "loss": 0.6013,
        "grad_norm": 7.0759124755859375,
        "learning_rate": 9.689991142604076e-06,
        "epoch": 0.3100088573959256,
        "step": 350
    },
    {
        "loss": 0.6487,
        "grad_norm": 10.924983978271484,
        "learning_rate": 9.681133746678477e-06,
        "epoch": 0.31886625332152346,
        "step": 360
    },
    {
        "loss": 0.5157,
        "grad_norm": 4.454391002655029,
        "learning_rate": 9.672276350752879e-06,
        "epoch": 0.32772364924712133,
        "step": 370
    },
    {
        "loss": 0.56,
        "grad_norm": 3.7223098278045654,
        "learning_rate": 9.663418954827282e-06,
        "epoch": 0.3365810451727192,
        "step": 380
    },
    {
        "loss": 0.5653,
        "grad_norm": 4.537693977355957,
        "learning_rate": 9.654561558901684e-06,
        "epoch": 0.3454384410983171,
        "step": 390
    },
    {
        "loss": 0.5391,
        "grad_norm": 5.194148063659668,
        "learning_rate": 9.645704162976086e-06,
        "epoch": 0.354295837023915,
        "step": 400
    },
    {
        "loss": 0.5412,
        "grad_norm": 12.824419021606445,
        "learning_rate": 9.636846767050489e-06,
        "epoch": 0.36315323294951285,
        "step": 410
    },
    {
        "loss": 0.6031,
        "grad_norm": 4.616555213928223,
        "learning_rate": 9.627989371124889e-06,
        "epoch": 0.3720106288751107,
        "step": 420
    },
    {
        "loss": 0.5298,
        "grad_norm": 7.8002190589904785,
        "learning_rate": 9.619131975199292e-06,
        "epoch": 0.3808680248007086,
        "step": 430
    },
    {
        "loss": 0.5956,
        "grad_norm": 6.880026340484619,
        "learning_rate": 9.610274579273694e-06,
        "epoch": 0.38972542072630645,
        "step": 440
    },
    {
        "loss": 0.5138,
        "grad_norm": 7.395564556121826,
        "learning_rate": 9.601417183348097e-06,
        "epoch": 0.3985828166519043,
        "step": 450
    },
    {
        "loss": 0.4906,
        "grad_norm": 6.7167863845825195,
        "learning_rate": 9.592559787422499e-06,
        "epoch": 0.40744021257750224,
        "step": 460
    },
    {
        "loss": 0.5203,
        "grad_norm": 9.872237205505371,
        "learning_rate": 9.5837023914969e-06,
        "epoch": 0.4162976085031001,
        "step": 470
    },
    {
        "loss": 0.5515,
        "grad_norm": 8.602251052856445,
        "learning_rate": 9.574844995571303e-06,
        "epoch": 0.42515500442869797,
        "step": 480
    },
    {
        "loss": 0.58,
        "grad_norm": 13.266870498657227,
        "learning_rate": 9.565987599645705e-06,
        "epoch": 0.43401240035429584,
        "step": 490
    },
    {
        "loss": 0.5289,
        "grad_norm": 10.944671630859375,
        "learning_rate": 9.557130203720107e-06,
        "epoch": 0.4428697962798937,
        "step": 500
    },
    {
        "loss": 0.518,
        "grad_norm": 17.943506240844727,
        "learning_rate": 9.54827280779451e-06,
        "epoch": 0.45172719220549157,
        "step": 510
    },
    {
        "loss": 0.5064,
        "grad_norm": 5.795952320098877,
        "learning_rate": 9.539415411868912e-06,
        "epoch": 0.46058458813108943,
        "step": 520
    },
    {
        "loss": 0.6359,
        "grad_norm": 6.907046794891357,
        "learning_rate": 9.530558015943313e-06,
        "epoch": 0.46944198405668736,
        "step": 530
    },
    {
        "loss": 0.5255,
        "grad_norm": 4.576395511627197,
        "learning_rate": 9.521700620017715e-06,
        "epoch": 0.4782993799822852,
        "step": 540
    },
    {
        "loss": 0.57,
        "grad_norm": 5.661961555480957,
        "learning_rate": 9.512843224092118e-06,
        "epoch": 0.4871567759078831,
        "step": 550
    },
    {
        "loss": 0.5733,
        "grad_norm": 4.453147888183594,
        "learning_rate": 9.50398582816652e-06,
        "epoch": 0.49601417183348095,
        "step": 560
    },
    {
        "loss": 0.5431,
        "grad_norm": 4.588119029998779,
        "learning_rate": 9.495128432240921e-06,
        "epoch": 0.5048715677590788,
        "step": 570
    },
    {
        "loss": 0.5181,
        "grad_norm": 8.271391868591309,
        "learning_rate": 9.486271036315325e-06,
        "epoch": 0.5137289636846767,
        "step": 580
    },
    {
        "loss": 0.5499,
        "grad_norm": 6.233874320983887,
        "learning_rate": 9.477413640389726e-06,
        "epoch": 0.5225863596102746,
        "step": 590
    },
    {
        "loss": 0.4812,
        "grad_norm": 9.298420906066895,
        "learning_rate": 9.46855624446413e-06,
        "epoch": 0.5314437555358724,
        "step": 600
    },
    {
        "loss": 0.4461,
        "grad_norm": 5.112502574920654,
        "learning_rate": 9.45969884853853e-06,
        "epoch": 0.5403011514614703,
        "step": 610
    },
    {
        "loss": 0.4295,
        "grad_norm": 10.977860450744629,
        "learning_rate": 9.450841452612933e-06,
        "epoch": 0.5491585473870682,
        "step": 620
    },
    {
        "loss": 0.4643,
        "grad_norm": 7.120040416717529,
        "learning_rate": 9.441984056687334e-06,
        "epoch": 0.5580159433126661,
        "step": 630
    },
    {
        "loss": 0.5386,
        "grad_norm": 10.668299674987793,
        "learning_rate": 9.433126660761736e-06,
        "epoch": 0.566873339238264,
        "step": 640
    },
    {
        "loss": 0.4991,
        "grad_norm": 7.484799385070801,
        "learning_rate": 9.42426926483614e-06,
        "epoch": 0.5757307351638619,
        "step": 650
    },
    {
        "loss": 0.5814,
        "grad_norm": 8.753294944763184,
        "learning_rate": 9.415411868910541e-06,
        "epoch": 0.5845881310894597,
        "step": 660
    },
    {
        "loss": 0.6394,
        "grad_norm": 9.799630165100098,
        "learning_rate": 9.406554472984944e-06,
        "epoch": 0.5934455270150576,
        "step": 670
    },
    {
        "loss": 0.5911,
        "grad_norm": 6.817066669464111,
        "learning_rate": 9.397697077059346e-06,
        "epoch": 0.6023029229406555,
        "step": 680
    },
    {
        "loss": 0.5269,
        "grad_norm": 7.807209491729736,
        "learning_rate": 9.388839681133747e-06,
        "epoch": 0.6111603188662533,
        "step": 690
    },
    {
        "loss": 0.5324,
        "grad_norm": 6.561089515686035,
        "learning_rate": 9.379982285208149e-06,
        "epoch": 0.6200177147918512,
        "step": 700
    },
    {
        "loss": 0.5511,
        "grad_norm": 4.973282814025879,
        "learning_rate": 9.37112488928255e-06,
        "epoch": 0.6288751107174491,
        "step": 710
    },
    {
        "loss": 0.4983,
        "grad_norm": 7.88413143157959,
        "learning_rate": 9.362267493356954e-06,
        "epoch": 0.6377325066430469,
        "step": 720
    },
    {
        "loss": 0.4713,
        "grad_norm": 7.906178951263428,
        "learning_rate": 9.353410097431356e-06,
        "epoch": 0.6465899025686448,
        "step": 730
    },
    {
        "loss": 0.4718,
        "grad_norm": 6.671188831329346,
        "learning_rate": 9.344552701505759e-06,
        "epoch": 0.6554472984942427,
        "step": 740
    },
    {
        "loss": 0.5386,
        "grad_norm": 7.41001033782959,
        "learning_rate": 9.33569530558016e-06,
        "epoch": 0.6643046944198405,
        "step": 750
    },
    {
        "loss": 0.555,
        "grad_norm": 11.530265808105469,
        "learning_rate": 9.326837909654562e-06,
        "epoch": 0.6731620903454384,
        "step": 760
    },
    {
        "loss": 0.5009,
        "grad_norm": 6.020901203155518,
        "learning_rate": 9.317980513728965e-06,
        "epoch": 0.6820194862710364,
        "step": 770
    },
    {
        "loss": 0.3866,
        "grad_norm": 8.967794418334961,
        "learning_rate": 9.309123117803367e-06,
        "epoch": 0.6908768821966342,
        "step": 780
    },
    {
        "loss": 0.4645,
        "grad_norm": 12.330964088439941,
        "learning_rate": 9.300265721877769e-06,
        "epoch": 0.6997342781222321,
        "step": 790
    },
    {
        "loss": 0.5188,
        "grad_norm": 13.954607963562012,
        "learning_rate": 9.29140832595217e-06,
        "epoch": 0.70859167404783,
        "step": 800
    },
    {
        "loss": 0.6267,
        "grad_norm": 9.475958824157715,
        "learning_rate": 9.282550930026572e-06,
        "epoch": 0.7174490699734278,
        "step": 810
    },
    {
        "loss": 0.4616,
        "grad_norm": 7.7853522300720215,
        "learning_rate": 9.273693534100975e-06,
        "epoch": 0.7263064658990257,
        "step": 820
    },
    {
        "loss": 0.4626,
        "grad_norm": 9.569714546203613,
        "learning_rate": 9.264836138175377e-06,
        "epoch": 0.7351638618246236,
        "step": 830
    },
    {
        "loss": 0.5435,
        "grad_norm": 9.891836166381836,
        "learning_rate": 9.25597874224978e-06,
        "epoch": 0.7440212577502214,
        "step": 840
    },
    {
        "loss": 0.4958,
        "grad_norm": 12.466862678527832,
        "learning_rate": 9.247121346324182e-06,
        "epoch": 0.7528786536758193,
        "step": 850
    },
    {
        "loss": 0.4926,
        "grad_norm": 15.525504112243652,
        "learning_rate": 9.238263950398583e-06,
        "epoch": 0.7617360496014172,
        "step": 860
    },
    {
        "loss": 0.5798,
        "grad_norm": 16.316068649291992,
        "learning_rate": 9.229406554472987e-06,
        "epoch": 0.770593445527015,
        "step": 870
    },
    {
        "loss": 0.4831,
        "grad_norm": 8.438119888305664,
        "learning_rate": 9.220549158547388e-06,
        "epoch": 0.7794508414526129,
        "step": 880
    },
    {
        "loss": 0.566,
        "grad_norm": 9.5382080078125,
        "learning_rate": 9.21169176262179e-06,
        "epoch": 0.7883082373782108,
        "step": 890
    },
    {
        "loss": 0.5375,
        "grad_norm": 10.008082389831543,
        "learning_rate": 9.202834366696191e-06,
        "epoch": 0.7971656333038086,
        "step": 900
    },
    {
        "loss": 0.4428,
        "grad_norm": 8.279999732971191,
        "learning_rate": 9.193976970770595e-06,
        "epoch": 0.8060230292294066,
        "step": 910
    },
    {
        "loss": 0.5099,
        "grad_norm": 17.033967971801758,
        "learning_rate": 9.185119574844996e-06,
        "epoch": 0.8148804251550045,
        "step": 920
    },
    {
        "loss": 0.5482,
        "grad_norm": 5.961972713470459,
        "learning_rate": 9.176262178919398e-06,
        "epoch": 0.8237378210806023,
        "step": 930
    },
    {
        "loss": 0.4694,
        "grad_norm": 12.299093246459961,
        "learning_rate": 9.167404782993801e-06,
        "epoch": 0.8325952170062002,
        "step": 940
    },
    {
        "loss": 0.4989,
        "grad_norm": 11.416754722595215,
        "learning_rate": 9.158547387068203e-06,
        "epoch": 0.8414526129317981,
        "step": 950
    },
    {
        "loss": 0.4688,
        "grad_norm": 10.68675422668457,
        "learning_rate": 9.149689991142604e-06,
        "epoch": 0.8503100088573959,
        "step": 960
    },
    {
        "loss": 0.5373,
        "grad_norm": 19.916927337646484,
        "learning_rate": 9.140832595217008e-06,
        "epoch": 0.8591674047829938,
        "step": 970
    },
    {
        "loss": 0.5245,
        "grad_norm": 10.562273979187012,
        "learning_rate": 9.13197519929141e-06,
        "epoch": 0.8680248007085917,
        "step": 980
    },
    {
        "loss": 0.4772,
        "grad_norm": 6.479689121246338,
        "learning_rate": 9.123117803365811e-06,
        "epoch": 0.8768821966341895,
        "step": 990
    },
    {
        "loss": 0.5412,
        "grad_norm": 7.925320625305176,
        "learning_rate": 9.114260407440213e-06,
        "epoch": 0.8857395925597874,
        "step": 1000
    },
    {
        "loss": 0.4764,
        "grad_norm": 6.995761394500732,
        "learning_rate": 9.105403011514616e-06,
        "epoch": 0.8945969884853853,
        "step": 1010
    },
    {
        "loss": 0.494,
        "grad_norm": 7.355529308319092,
        "learning_rate": 9.096545615589017e-06,
        "epoch": 0.9034543844109831,
        "step": 1020
    },
    {
        "loss": 0.4718,
        "grad_norm": 12.272994041442871,
        "learning_rate": 9.087688219663419e-06,
        "epoch": 0.912311780336581,
        "step": 1030
    },
    {
        "loss": 0.5255,
        "grad_norm": 11.121041297912598,
        "learning_rate": 9.078830823737822e-06,
        "epoch": 0.9211691762621789,
        "step": 1040
    },
    {
        "loss": 0.4264,
        "grad_norm": 9.448700904846191,
        "learning_rate": 9.069973427812224e-06,
        "epoch": 0.9300265721877768,
        "step": 1050
    },
    {
        "loss": 0.4479,
        "grad_norm": 11.20911693572998,
        "learning_rate": 9.061116031886627e-06,
        "epoch": 0.9388839681133747,
        "step": 1060
    },
    {
        "loss": 0.5056,
        "grad_norm": 13.397261619567871,
        "learning_rate": 9.052258635961029e-06,
        "epoch": 0.9477413640389726,
        "step": 1070
    },
    {
        "loss": 0.4833,
        "grad_norm": 14.220564842224121,
        "learning_rate": 9.04340124003543e-06,
        "epoch": 0.9565987599645704,
        "step": 1080
    },
    {
        "loss": 0.3846,
        "grad_norm": 13.920430183410645,
        "learning_rate": 9.034543844109832e-06,
        "epoch": 0.9654561558901683,
        "step": 1090
    },
    {
        "loss": 0.4665,
        "grad_norm": 12.002649307250977,
        "learning_rate": 9.025686448184234e-06,
        "epoch": 0.9743135518157662,
        "step": 1100
    },
    {
        "loss": 0.4921,
        "grad_norm": 15.588223457336426,
        "learning_rate": 9.016829052258637e-06,
        "epoch": 0.983170947741364,
        "step": 1110
    },
    {
        "loss": 0.5271,
        "grad_norm": 10.608026504516602,
        "learning_rate": 9.007971656333039e-06,
        "epoch": 0.9920283436669619,
        "step": 1120
    },
    {
        "eval_loss": 0.44465628266334534,
        "eval_accuracy": 0.80733,
        "eval_precision": 0.75969,
        "eval_recall": 0.899,
        "eval_f1": 0.82349,
        "eval_runtime": 150.1446,
        "eval_samples_per_second": 60.149,
        "eval_steps_per_second": 3.763,
        "epoch": 1.0,
        "step": 1129
    },
    {
        "loss": 0.4664,
        "grad_norm": 20.733657836914062,
        "learning_rate": 8.999114260407442e-06,
        "epoch": 1.0008857395925599,
        "step": 1130
    },
    {
        "loss": 0.4133,
        "grad_norm": 11.50270938873291,
        "learning_rate": 8.990256864481844e-06,
        "epoch": 1.0097431355181576,
        "step": 1140
    },
    {
        "loss": 0.4019,
        "grad_norm": 16.059911727905273,
        "learning_rate": 8.981399468556245e-06,
        "epoch": 1.0186005314437556,
        "step": 1150
    },
    {
        "loss": 0.3214,
        "grad_norm": 16.744619369506836,
        "learning_rate": 8.972542072630648e-06,
        "epoch": 1.0274579273693534,
        "step": 1160
    },
    {
        "loss": 0.5086,
        "grad_norm": 26.853496551513672,
        "learning_rate": 8.963684676705048e-06,
        "epoch": 1.0363153232949514,
        "step": 1170
    },
    {
        "loss": 0.4106,
        "grad_norm": 21.245088577270508,
        "learning_rate": 8.954827280779452e-06,
        "epoch": 1.045172719220549,
        "step": 1180
    },
    {
        "loss": 0.4723,
        "grad_norm": 16.09131622314453,
        "learning_rate": 8.945969884853853e-06,
        "epoch": 1.054030115146147,
        "step": 1190
    },
    {
        "loss": 0.3624,
        "grad_norm": 26.623428344726562,
        "learning_rate": 8.937112488928255e-06,
        "epoch": 1.0628875110717448,
        "step": 1200
    },
    {
        "loss": 0.4405,
        "grad_norm": 8.761970520019531,
        "learning_rate": 8.928255093002658e-06,
        "epoch": 1.0717449069973428,
        "step": 1210
    },
    {
        "loss": 0.4038,
        "grad_norm": 16.693603515625,
        "learning_rate": 8.91939769707706e-06,
        "epoch": 1.0806023029229406,
        "step": 1220
    },
    {
        "loss": 0.3356,
        "grad_norm": 17.24347686767578,
        "learning_rate": 8.910540301151463e-06,
        "epoch": 1.0894596988485385,
        "step": 1230
    },
    {
        "loss": 0.4026,
        "grad_norm": 15.025398254394531,
        "learning_rate": 8.901682905225865e-06,
        "epoch": 1.0983170947741363,
        "step": 1240
    },
    {
        "loss": 0.3634,
        "grad_norm": 30.324817657470703,
        "learning_rate": 8.892825509300266e-06,
        "epoch": 1.1071744906997343,
        "step": 1250
    },
    {
        "loss": 0.3393,
        "grad_norm": 26.31077766418457,
        "learning_rate": 8.883968113374668e-06,
        "epoch": 1.1160318866253323,
        "step": 1260
    },
    {
        "loss": 0.6503,
        "grad_norm": 25.630130767822266,
        "learning_rate": 8.87511071744907e-06,
        "epoch": 1.12488928255093,
        "step": 1270
    },
    {
        "loss": 0.442,
        "grad_norm": 24.43512535095215,
        "learning_rate": 8.866253321523473e-06,
        "epoch": 1.133746678476528,
        "step": 1280
    },
    {
        "loss": 0.3937,
        "grad_norm": 15.339903831481934,
        "learning_rate": 8.857395925597874e-06,
        "epoch": 1.1426040744021257,
        "step": 1290
    },
    {
        "loss": 0.4075,
        "grad_norm": 16.7691593170166,
        "learning_rate": 8.848538529672278e-06,
        "epoch": 1.1514614703277237,
        "step": 1300
    },
    {
        "loss": 0.3585,
        "grad_norm": 21.65750503540039,
        "learning_rate": 8.83968113374668e-06,
        "epoch": 1.1603188662533215,
        "step": 1310
    },
    {
        "loss": 0.3426,
        "grad_norm": 10.399628639221191,
        "learning_rate": 8.830823737821081e-06,
        "epoch": 1.1691762621789195,
        "step": 1320
    },
    {
        "loss": 0.3975,
        "grad_norm": 13.06680679321289,
        "learning_rate": 8.821966341895484e-06,
        "epoch": 1.1780336581045172,
        "step": 1330
    },
    {
        "loss": 0.3102,
        "grad_norm": 26.64228057861328,
        "learning_rate": 8.813108945969886e-06,
        "epoch": 1.1868910540301152,
        "step": 1340
    },
    {
        "loss": 0.3825,
        "grad_norm": 24.47588348388672,
        "learning_rate": 8.804251550044287e-06,
        "epoch": 1.195748449955713,
        "step": 1350
    },
    {
        "loss": 0.4001,
        "grad_norm": 14.064488410949707,
        "learning_rate": 8.795394154118689e-06,
        "epoch": 1.204605845881311,
        "step": 1360
    },
    {
        "loss": 0.3115,
        "grad_norm": 21.495573043823242,
        "learning_rate": 8.786536758193092e-06,
        "epoch": 1.2134632418069087,
        "step": 1370
    },
    {
        "loss": 0.3637,
        "grad_norm": 21.369029998779297,
        "learning_rate": 8.777679362267494e-06,
        "epoch": 1.2223206377325067,
        "step": 1380
    },
    {
        "loss": 0.3409,
        "grad_norm": 26.025815963745117,
        "learning_rate": 8.768821966341896e-06,
        "epoch": 1.2311780336581046,
        "step": 1390
    },
    {
        "loss": 0.3603,
        "grad_norm": 41.52919006347656,
        "learning_rate": 8.759964570416299e-06,
        "epoch": 1.2400354295837024,
        "step": 1400
    },
    {
        "loss": 0.345,
        "grad_norm": 12.926064491271973,
        "learning_rate": 8.7511071744907e-06,
        "epoch": 1.2488928255093001,
        "step": 1410
    },
    {
        "loss": 0.4253,
        "grad_norm": 32.78999710083008,
        "learning_rate": 8.742249778565102e-06,
        "epoch": 1.2577502214348981,
        "step": 1420
    },
    {
        "loss": 0.3124,
        "grad_norm": 14.947915077209473,
        "learning_rate": 8.733392382639505e-06,
        "epoch": 1.266607617360496,
        "step": 1430
    },
    {
        "loss": 0.31,
        "grad_norm": 10.708215713500977,
        "learning_rate": 8.724534986713907e-06,
        "epoch": 1.2754650132860939,
        "step": 1440
    },
    {
        "loss": 0.3414,
        "grad_norm": 30.779895782470703,
        "learning_rate": 8.715677590788309e-06,
        "epoch": 1.2843224092116918,
        "step": 1450
    },
    {
        "loss": 0.3995,
        "grad_norm": 20.06798553466797,
        "learning_rate": 8.70682019486271e-06,
        "epoch": 1.2931798051372896,
        "step": 1460
    },
    {
        "loss": 0.4186,
        "grad_norm": 26.731239318847656,
        "learning_rate": 8.697962798937114e-06,
        "epoch": 1.3020372010628876,
        "step": 1470
    },
    {
        "loss": 0.2824,
        "grad_norm": 20.697168350219727,
        "learning_rate": 8.689105403011515e-06,
        "epoch": 1.3108945969884853,
        "step": 1480
    },
    {
        "loss": 0.3789,
        "grad_norm": 21.347049713134766,
        "learning_rate": 8.680248007085917e-06,
        "epoch": 1.3197519929140833,
        "step": 1490
    },
    {
        "loss": 0.4226,
        "grad_norm": 30.719573974609375,
        "learning_rate": 8.67139061116032e-06,
        "epoch": 1.328609388839681,
        "step": 1500
    },
    {
        "loss": 0.3515,
        "grad_norm": 16.79323387145996,
        "learning_rate": 8.662533215234722e-06,
        "epoch": 1.337466784765279,
        "step": 1510
    },
    {
        "loss": 0.4067,
        "grad_norm": 21.005584716796875,
        "learning_rate": 8.653675819309125e-06,
        "epoch": 1.346324180690877,
        "step": 1520
    },
    {
        "loss": 0.4494,
        "grad_norm": 14.395549774169922,
        "learning_rate": 8.644818423383527e-06,
        "epoch": 1.3551815766164748,
        "step": 1530
    },
    {
        "loss": 0.3928,
        "grad_norm": 23.90926170349121,
        "learning_rate": 8.635961027457928e-06,
        "epoch": 1.3640389725420725,
        "step": 1540
    },
    {
        "loss": 0.3286,
        "grad_norm": 13.823912620544434,
        "learning_rate": 8.62710363153233e-06,
        "epoch": 1.3728963684676705,
        "step": 1550
    },
    {
        "loss": 0.4267,
        "grad_norm": 27.194082260131836,
        "learning_rate": 8.618246235606731e-06,
        "epoch": 1.3817537643932685,
        "step": 1560
    },
    {
        "loss": 0.3682,
        "grad_norm": 17.548110961914062,
        "learning_rate": 8.609388839681135e-06,
        "epoch": 1.3906111603188662,
        "step": 1570
    },
    {
        "loss": 0.386,
        "grad_norm": 18.41130256652832,
        "learning_rate": 8.600531443755536e-06,
        "epoch": 1.3994685562444642,
        "step": 1580
    },
    {
        "loss": 0.3778,
        "grad_norm": 19.931556701660156,
        "learning_rate": 8.591674047829938e-06,
        "epoch": 1.408325952170062,
        "step": 1590
    },
    {
        "loss": 0.3354,
        "grad_norm": 7.586086273193359,
        "learning_rate": 8.582816651904341e-06,
        "epoch": 1.41718334809566,
        "step": 1600
    },
    {
        "loss": 0.2985,
        "grad_norm": 21.887165069580078,
        "learning_rate": 8.573959255978743e-06,
        "epoch": 1.4260407440212577,
        "step": 1610
    },
    {
        "loss": 0.3063,
        "grad_norm": 24.23177719116211,
        "learning_rate": 8.565101860053146e-06,
        "epoch": 1.4348981399468557,
        "step": 1620
    },
    {
        "loss": 0.2624,
        "grad_norm": 3.7924060821533203,
        "learning_rate": 8.556244464127548e-06,
        "epoch": 1.4437555358724534,
        "step": 1630
    },
    {
        "loss": 0.3631,
        "grad_norm": 17.29911231994629,
        "learning_rate": 8.54738706820195e-06,
        "epoch": 1.4526129317980514,
        "step": 1640
    },
    {
        "loss": 0.3536,
        "grad_norm": 28.12080192565918,
        "learning_rate": 8.538529672276351e-06,
        "epoch": 1.4614703277236494,
        "step": 1650
    },
    {
        "loss": 0.326,
        "grad_norm": 23.385242462158203,
        "learning_rate": 8.529672276350753e-06,
        "epoch": 1.4703277236492471,
        "step": 1660
    },
    {
        "loss": 0.3781,
        "grad_norm": 25.774765014648438,
        "learning_rate": 8.520814880425156e-06,
        "epoch": 1.4791851195748449,
        "step": 1670
    },
    {
        "loss": 0.3474,
        "grad_norm": 16.020824432373047,
        "learning_rate": 8.511957484499558e-06,
        "epoch": 1.4880425155004429,
        "step": 1680
    },
    {
        "loss": 0.2782,
        "grad_norm": 9.231138229370117,
        "learning_rate": 8.50310008857396e-06,
        "epoch": 1.4968999114260408,
        "step": 1690
    },
    {
        "loss": 0.3475,
        "grad_norm": 25.99445152282715,
        "learning_rate": 8.494242692648362e-06,
        "epoch": 1.5057573073516386,
        "step": 1700
    },
    {
        "loss": 0.3455,
        "grad_norm": 29.359905242919922,
        "learning_rate": 8.485385296722764e-06,
        "epoch": 1.5146147032772364,
        "step": 1710
    },
    {
        "loss": 0.2944,
        "grad_norm": 23.35110855102539,
        "learning_rate": 8.476527900797167e-06,
        "epoch": 1.5234720992028343,
        "step": 1720
    },
    {
        "loss": 0.4227,
        "grad_norm": 26.5633544921875,
        "learning_rate": 8.467670504871567e-06,
        "epoch": 1.5323294951284323,
        "step": 1730
    },
    {
        "loss": 0.3,
        "grad_norm": 28.52069854736328,
        "learning_rate": 8.45881310894597e-06,
        "epoch": 1.54118689105403,
        "step": 1740
    },
    {
        "loss": 0.37,
        "grad_norm": 17.89406394958496,
        "learning_rate": 8.449955713020372e-06,
        "epoch": 1.550044286979628,
        "step": 1750
    },
    {
        "loss": 0.3602,
        "grad_norm": 12.301291465759277,
        "learning_rate": 8.441098317094775e-06,
        "epoch": 1.5589016829052258,
        "step": 1760
    },
    {
        "loss": 0.2535,
        "grad_norm": 13.678043365478516,
        "learning_rate": 8.432240921169177e-06,
        "epoch": 1.5677590788308238,
        "step": 1770
    },
    {
        "loss": 0.2724,
        "grad_norm": 23.780933380126953,
        "learning_rate": 8.423383525243579e-06,
        "epoch": 1.5766164747564217,
        "step": 1780
    },
    {
        "loss": 0.2928,
        "grad_norm": 23.242921829223633,
        "learning_rate": 8.414526129317982e-06,
        "epoch": 1.5854738706820195,
        "step": 1790
    },
    {
        "loss": 0.4064,
        "grad_norm": 19.44426727294922,
        "learning_rate": 8.405668733392384e-06,
        "epoch": 1.5943312666076173,
        "step": 1800
    },
    {
        "loss": 0.3088,
        "grad_norm": 45.901512145996094,
        "learning_rate": 8.396811337466785e-06,
        "epoch": 1.6031886625332152,
        "step": 1810
    },
    {
        "loss": 0.3764,
        "grad_norm": 63.74799728393555,
        "learning_rate": 8.387953941541187e-06,
        "epoch": 1.6120460584588132,
        "step": 1820
    },
    {
        "loss": 0.338,
        "grad_norm": 28.19668960571289,
        "learning_rate": 8.37909654561559e-06,
        "epoch": 1.620903454384411,
        "step": 1830
    },
    {
        "loss": 0.3111,
        "grad_norm": 9.736859321594238,
        "learning_rate": 8.370239149689992e-06,
        "epoch": 1.6297608503100087,
        "step": 1840
    },
    {
        "loss": 0.3906,
        "grad_norm": 21.256690979003906,
        "learning_rate": 8.361381753764393e-06,
        "epoch": 1.6386182462356067,
        "step": 1850
    },
    {
        "loss": 0.3208,
        "grad_norm": 14.518455505371094,
        "learning_rate": 8.352524357838797e-06,
        "epoch": 1.6474756421612047,
        "step": 1860
    },
    {
        "loss": 0.3474,
        "grad_norm": 16.984899520874023,
        "learning_rate": 8.343666961913198e-06,
        "epoch": 1.6563330380868024,
        "step": 1870
    },
    {
        "loss": 0.2439,
        "grad_norm": 17.125823974609375,
        "learning_rate": 8.3348095659876e-06,
        "epoch": 1.6651904340124002,
        "step": 1880
    },
    {
        "loss": 0.2477,
        "grad_norm": 22.72348403930664,
        "learning_rate": 8.325952170062003e-06,
        "epoch": 1.6740478299379982,
        "step": 1890
    },
    {
        "loss": 0.3298,
        "grad_norm": 7.446277618408203,
        "learning_rate": 8.317094774136405e-06,
        "epoch": 1.6829052258635961,
        "step": 1900
    },
    {
        "loss": 0.3329,
        "grad_norm": 22.69744110107422,
        "learning_rate": 8.308237378210808e-06,
        "epoch": 1.6917626217891941,
        "step": 1910
    },
    {
        "loss": 0.2918,
        "grad_norm": 24.93086814880371,
        "learning_rate": 8.299379982285208e-06,
        "epoch": 1.7006200177147919,
        "step": 1920
    },
    {
        "loss": 0.3175,
        "grad_norm": 11.623211860656738,
        "learning_rate": 8.290522586359611e-06,
        "epoch": 1.7094774136403896,
        "step": 1930
    },
    {
        "loss": 0.2341,
        "grad_norm": 37.46372604370117,
        "learning_rate": 8.281665190434013e-06,
        "epoch": 1.7183348095659876,
        "step": 1940
    },
    {
        "loss": 0.3537,
        "grad_norm": 10.88370132446289,
        "learning_rate": 8.272807794508414e-06,
        "epoch": 1.7271922054915856,
        "step": 1950
    },
    {
        "loss": 0.2785,
        "grad_norm": 16.309650421142578,
        "learning_rate": 8.263950398582818e-06,
        "epoch": 1.7360496014171833,
        "step": 1960
    },
    {
        "loss": 0.3394,
        "grad_norm": 18.77529525756836,
        "learning_rate": 8.25509300265722e-06,
        "epoch": 1.744906997342781,
        "step": 1970
    },
    {
        "loss": 0.297,
        "grad_norm": 20.895153045654297,
        "learning_rate": 8.246235606731621e-06,
        "epoch": 1.753764393268379,
        "step": 1980
    },
    {
        "loss": 0.4114,
        "grad_norm": 43.918758392333984,
        "learning_rate": 8.237378210806024e-06,
        "epoch": 1.762621789193977,
        "step": 1990
    },
    {
        "loss": 0.2564,
        "grad_norm": 32.14649200439453,
        "learning_rate": 8.228520814880426e-06,
        "epoch": 1.7714791851195748,
        "step": 2000
    },
    {
        "loss": 0.2214,
        "grad_norm": 31.99971580505371,
        "learning_rate": 8.219663418954828e-06,
        "epoch": 1.7803365810451726,
        "step": 2010
    },
    {
        "loss": 0.3361,
        "grad_norm": 17.997650146484375,
        "learning_rate": 8.210806023029229e-06,
        "epoch": 1.7891939769707705,
        "step": 2020
    },
    {
        "loss": 0.3226,
        "grad_norm": 6.584772109985352,
        "learning_rate": 8.201948627103632e-06,
        "epoch": 1.7980513728963685,
        "step": 2030
    },
    {
        "loss": 0.1993,
        "grad_norm": 25.596458435058594,
        "learning_rate": 8.193091231178034e-06,
        "epoch": 1.8069087688219665,
        "step": 2040
    },
    {
        "loss": 0.295,
        "grad_norm": 44.850460052490234,
        "learning_rate": 8.184233835252436e-06,
        "epoch": 1.8157661647475642,
        "step": 2050
    },
    {
        "loss": 0.3858,
        "grad_norm": 6.035574436187744,
        "learning_rate": 8.175376439326839e-06,
        "epoch": 1.824623560673162,
        "step": 2060
    },
    {
        "loss": 0.3016,
        "grad_norm": 40.83641052246094,
        "learning_rate": 8.16651904340124e-06,
        "epoch": 1.83348095659876,
        "step": 2070
    },
    {
        "loss": 0.4009,
        "grad_norm": 11.337616920471191,
        "learning_rate": 8.157661647475644e-06,
        "epoch": 1.842338352524358,
        "step": 2080
    },
    {
        "loss": 0.3352,
        "grad_norm": 57.78712463378906,
        "learning_rate": 8.148804251550045e-06,
        "epoch": 1.8511957484499557,
        "step": 2090
    },
    {
        "loss": 0.3014,
        "grad_norm": 38.39476776123047,
        "learning_rate": 8.139946855624447e-06,
        "epoch": 1.8600531443755535,
        "step": 2100
    },
    {
        "loss": 0.2612,
        "grad_norm": 31.708202362060547,
        "learning_rate": 8.131089459698849e-06,
        "epoch": 1.8689105403011514,
        "step": 2110
    },
    {
        "loss": 0.2446,
        "grad_norm": 23.452970504760742,
        "learning_rate": 8.12223206377325e-06,
        "epoch": 1.8777679362267494,
        "step": 2120
    },
    {
        "loss": 0.2566,
        "grad_norm": 9.743371963500977,
        "learning_rate": 8.113374667847654e-06,
        "epoch": 1.8866253321523472,
        "step": 2130
    },
    {
        "loss": 0.2915,
        "grad_norm": 28.655704498291016,
        "learning_rate": 8.104517271922055e-06,
        "epoch": 1.895482728077945,
        "step": 2140
    },
    {
        "loss": 0.3,
        "grad_norm": 38.016807556152344,
        "learning_rate": 8.095659875996459e-06,
        "epoch": 1.904340124003543,
        "step": 2150
    },
    {
        "loss": 0.2888,
        "grad_norm": 13.174437522888184,
        "learning_rate": 8.08680248007086e-06,
        "epoch": 1.9131975199291409,
        "step": 2160
    },
    {
        "loss": 0.2763,
        "grad_norm": 9.388955116271973,
        "learning_rate": 8.077945084145262e-06,
        "epoch": 1.9220549158547389,
        "step": 2170
    },
    {
        "loss": 0.3151,
        "grad_norm": 14.485212326049805,
        "learning_rate": 8.069087688219665e-06,
        "epoch": 1.9309123117803366,
        "step": 2180
    },
    {
        "loss": 0.3652,
        "grad_norm": 32.398841857910156,
        "learning_rate": 8.060230292294067e-06,
        "epoch": 1.9397697077059344,
        "step": 2190
    },
    {
        "loss": 0.3497,
        "grad_norm": 13.497758865356445,
        "learning_rate": 8.051372896368468e-06,
        "epoch": 1.9486271036315324,
        "step": 2200
    },
    {
        "loss": 0.2293,
        "grad_norm": 14.611876487731934,
        "learning_rate": 8.04251550044287e-06,
        "epoch": 1.9574844995571303,
        "step": 2210
    },
    {
        "loss": 0.2884,
        "grad_norm": 59.52164840698242,
        "learning_rate": 8.033658104517273e-06,
        "epoch": 1.966341895482728,
        "step": 2220
    },
    {
        "loss": 0.1954,
        "grad_norm": 5.2899627685546875,
        "learning_rate": 8.024800708591675e-06,
        "epoch": 1.9751992914083258,
        "step": 2230
    },
    {
        "loss": 0.2035,
        "grad_norm": 9.722419738769531,
        "learning_rate": 8.015943312666076e-06,
        "epoch": 1.9840566873339238,
        "step": 2240
    },
    {
        "loss": 0.3663,
        "grad_norm": 8.075071334838867,
        "learning_rate": 8.00708591674048e-06,
        "epoch": 1.9929140832595218,
        "step": 2250
    },
    {
        "eval_loss": 0.26219412684440613,
        "eval_accuracy": 0.91142,
        "eval_precision": 0.91921,
        "eval_recall": 0.9021,
        "eval_f1": 0.91057,
        "eval_runtime": 150.0849,
        "eval_samples_per_second": 60.173,
        "eval_steps_per_second": 3.765,
        "epoch": 2.0,
        "step": 2258
    },
    {
        "loss": 0.3305,
        "grad_norm": 19.83745574951172,
        "learning_rate": 7.998228520814881e-06,
        "epoch": 2.0017714791851198,
        "step": 2260
    },
    {
        "loss": 0.3235,
        "grad_norm": 50.87937545776367,
        "learning_rate": 7.989371124889283e-06,
        "epoch": 2.0106288751107173,
        "step": 2270
    },
    {
        "loss": 0.2638,
        "grad_norm": 8.661174774169922,
        "learning_rate": 7.980513728963686e-06,
        "epoch": 2.0194862710363153,
        "step": 2280
    },
    {
        "loss": 0.2895,
        "grad_norm": 31.442991256713867,
        "learning_rate": 7.971656333038086e-06,
        "epoch": 2.0283436669619133,
        "step": 2290
    },
    {
        "loss": 0.2211,
        "grad_norm": 10.204034805297852,
        "learning_rate": 7.96279893711249e-06,
        "epoch": 2.0372010628875112,
        "step": 2300
    },
    {
        "loss": 0.1996,
        "grad_norm": 38.19313049316406,
        "learning_rate": 7.953941541186891e-06,
        "epoch": 2.0460584588131088,
        "step": 2310
    },
    {
        "loss": 0.1686,
        "grad_norm": 4.675586700439453,
        "learning_rate": 7.945084145261294e-06,
        "epoch": 2.0549158547387067,
        "step": 2320
    },
    {
        "loss": 0.2889,
        "grad_norm": 27.926773071289062,
        "learning_rate": 7.936226749335696e-06,
        "epoch": 2.0637732506643047,
        "step": 2330
    },
    {
        "loss": 0.2905,
        "grad_norm": 27.073331832885742,
        "learning_rate": 7.927369353410098e-06,
        "epoch": 2.0726306465899027,
        "step": 2340
    },
    {
        "loss": 0.2014,
        "grad_norm": 18.738048553466797,
        "learning_rate": 7.918511957484501e-06,
        "epoch": 2.0814880425155002,
        "step": 2350
    },
    {
        "loss": 0.2787,
        "grad_norm": 12.993834495544434,
        "learning_rate": 7.909654561558902e-06,
        "epoch": 2.090345438441098,
        "step": 2360
    },
    {
        "loss": 0.2072,
        "grad_norm": 1.5042318105697632,
        "learning_rate": 7.900797165633304e-06,
        "epoch": 2.099202834366696,
        "step": 2370
    },
    {
        "loss": 0.3559,
        "grad_norm": 29.316242218017578,
        "learning_rate": 7.891939769707706e-06,
        "epoch": 2.108060230292294,
        "step": 2380
    },
    {
        "loss": 0.2603,
        "grad_norm": 25.860937118530273,
        "learning_rate": 7.883082373782109e-06,
        "epoch": 2.116917626217892,
        "step": 2390
    },
    {
        "loss": 0.4525,
        "grad_norm": 67.86168670654297,
        "learning_rate": 7.87422497785651e-06,
        "epoch": 2.1257750221434897,
        "step": 2400
    },
    {
        "loss": 0.2668,
        "grad_norm": 19.03169822692871,
        "learning_rate": 7.865367581930912e-06,
        "epoch": 2.1346324180690877,
        "step": 2410
    },
    {
        "loss": 0.186,
        "grad_norm": 10.696999549865723,
        "learning_rate": 7.856510186005316e-06,
        "epoch": 2.1434898139946856,
        "step": 2420
    },
    {
        "loss": 0.2065,
        "grad_norm": 43.92713165283203,
        "learning_rate": 7.847652790079717e-06,
        "epoch": 2.1523472099202836,
        "step": 2430
    },
    {
        "loss": 0.1737,
        "grad_norm": 1.893345594406128,
        "learning_rate": 7.838795394154119e-06,
        "epoch": 2.161204605845881,
        "step": 2440
    },
    {
        "loss": 0.2777,
        "grad_norm": 69.21954345703125,
        "learning_rate": 7.829937998228522e-06,
        "epoch": 2.170062001771479,
        "step": 2450
    },
    {
        "loss": 0.2478,
        "grad_norm": 24.402450561523438,
        "learning_rate": 7.821080602302924e-06,
        "epoch": 2.178919397697077,
        "step": 2460
    },
    {
        "loss": 0.1982,
        "grad_norm": 38.282718658447266,
        "learning_rate": 7.812223206377327e-06,
        "epoch": 2.187776793622675,
        "step": 2470
    },
    {
        "loss": 0.2357,
        "grad_norm": 44.9727897644043,
        "learning_rate": 7.803365810451727e-06,
        "epoch": 2.1966341895482726,
        "step": 2480
    },
    {
        "loss": 0.2076,
        "grad_norm": 38.762794494628906,
        "learning_rate": 7.79450841452613e-06,
        "epoch": 2.2054915854738706,
        "step": 2490
    },
    {
        "loss": 0.3365,
        "grad_norm": 58.669673919677734,
        "learning_rate": 7.785651018600532e-06,
        "epoch": 2.2143489813994686,
        "step": 2500
    },
    {
        "loss": 0.1962,
        "grad_norm": 40.350311279296875,
        "learning_rate": 7.776793622674933e-06,
        "epoch": 2.2232063773250665,
        "step": 2510
    },
    {
        "loss": 0.2029,
        "grad_norm": 3.3345909118652344,
        "learning_rate": 7.767936226749337e-06,
        "epoch": 2.2320637732506645,
        "step": 2520
    },
    {
        "loss": 0.1572,
        "grad_norm": 48.824771881103516,
        "learning_rate": 7.759078830823738e-06,
        "epoch": 2.240921169176262,
        "step": 2530
    },
    {
        "loss": 0.1834,
        "grad_norm": 71.85078430175781,
        "learning_rate": 7.750221434898142e-06,
        "epoch": 2.24977856510186,
        "step": 2540
    },
    {
        "loss": 0.2739,
        "grad_norm": 6.859999656677246,
        "learning_rate": 7.741364038972543e-06,
        "epoch": 2.258635961027458,
        "step": 2550
    },
    {
        "loss": 0.2721,
        "grad_norm": 34.26105880737305,
        "learning_rate": 7.732506643046945e-06,
        "epoch": 2.267493356953056,
        "step": 2560
    },
    {
        "loss": 0.1898,
        "grad_norm": 0.967062771320343,
        "learning_rate": 7.723649247121346e-06,
        "epoch": 2.2763507528786535,
        "step": 2570
    },
    {
        "loss": 0.1715,
        "grad_norm": 3.1182429790496826,
        "learning_rate": 7.714791851195748e-06,
        "epoch": 2.2852081488042515,
        "step": 2580
    },
    {
        "loss": 0.2564,
        "grad_norm": 55.38456726074219,
        "learning_rate": 7.705934455270151e-06,
        "epoch": 2.2940655447298495,
        "step": 2590
    },
    {
        "loss": 0.2082,
        "grad_norm": 53.2066764831543,
        "learning_rate": 7.697077059344553e-06,
        "epoch": 2.3029229406554474,
        "step": 2600
    },
    {
        "loss": 0.197,
        "grad_norm": 81.34741973876953,
        "learning_rate": 7.688219663418956e-06,
        "epoch": 2.311780336581045,
        "step": 2610
    },
    {
        "loss": 0.3286,
        "grad_norm": 68.83944702148438,
        "learning_rate": 7.679362267493358e-06,
        "epoch": 2.320637732506643,
        "step": 2620
    },
    {
        "loss": 0.2575,
        "grad_norm": 1.5185099840164185,
        "learning_rate": 7.67050487156776e-06,
        "epoch": 2.329495128432241,
        "step": 2630
    },
    {
        "loss": 0.1104,
        "grad_norm": 6.958985328674316,
        "learning_rate": 7.661647475642163e-06,
        "epoch": 2.338352524357839,
        "step": 2640
    },
    {
        "loss": 0.1919,
        "grad_norm": 0.43875202536582947,
        "learning_rate": 7.652790079716564e-06,
        "epoch": 2.3472099202834364,
        "step": 2650
    },
    {
        "loss": 0.3938,
        "grad_norm": 24.601093292236328,
        "learning_rate": 7.643932683790966e-06,
        "epoch": 2.3560673162090344,
        "step": 2660
    },
    {
        "loss": 0.0728,
        "grad_norm": 3.5396084785461426,
        "learning_rate": 7.635075287865368e-06,
        "epoch": 2.3649247121346324,
        "step": 2670
    },
    {
        "loss": 0.3955,
        "grad_norm": 2.48598051071167,
        "learning_rate": 7.62621789193977e-06,
        "epoch": 2.3737821080602304,
        "step": 2680
    },
    {
        "loss": 0.1222,
        "grad_norm": 55.82883071899414,
        "learning_rate": 7.6173604960141725e-06,
        "epoch": 2.3826395039858284,
        "step": 2690
    },
    {
        "loss": 0.2109,
        "grad_norm": 8.01640796661377,
        "learning_rate": 7.608503100088574e-06,
        "epoch": 2.391496899911426,
        "step": 2700
    },
    {
        "loss": 0.115,
        "grad_norm": 73.9697036743164,
        "learning_rate": 7.599645704162977e-06,
        "epoch": 2.400354295837024,
        "step": 2710
    },
    {
        "loss": 0.3332,
        "grad_norm": 79.0153579711914,
        "learning_rate": 7.590788308237379e-06,
        "epoch": 2.409211691762622,
        "step": 2720
    },
    {
        "loss": 0.2144,
        "grad_norm": 17.584117889404297,
        "learning_rate": 7.5819309123117815e-06,
        "epoch": 2.41806908768822,
        "step": 2730
    },
    {
        "loss": 0.1446,
        "grad_norm": 17.66411781311035,
        "learning_rate": 7.573073516386183e-06,
        "epoch": 2.4269264836138174,
        "step": 2740
    },
    {
        "loss": 0.2651,
        "grad_norm": 57.64051818847656,
        "learning_rate": 7.5642161204605856e-06,
        "epoch": 2.4357838795394153,
        "step": 2750
    },
    {
        "loss": 0.2431,
        "grad_norm": 0.48485350608825684,
        "learning_rate": 7.555358724534987e-06,
        "epoch": 2.4446412754650133,
        "step": 2760
    },
    {
        "loss": 0.2203,
        "grad_norm": 47.446136474609375,
        "learning_rate": 7.546501328609389e-06,
        "epoch": 2.4534986713906113,
        "step": 2770
    },
    {
        "loss": 0.2175,
        "grad_norm": 50.67032241821289,
        "learning_rate": 7.537643932683791e-06,
        "epoch": 2.4623560673162093,
        "step": 2780
    },
    {
        "loss": 0.2424,
        "grad_norm": 39.52892303466797,
        "learning_rate": 7.528786536758194e-06,
        "epoch": 2.471213463241807,
        "step": 2790
    },
    {
        "loss": 0.2369,
        "grad_norm": 103.75068664550781,
        "learning_rate": 7.519929140832596e-06,
        "epoch": 2.4800708591674048,
        "step": 2800
    },
    {
        "loss": 0.2676,
        "grad_norm": 62.04242706298828,
        "learning_rate": 7.511071744906998e-06,
        "epoch": 2.4889282550930028,
        "step": 2810
    },
    {
        "loss": 0.1302,
        "grad_norm": 0.2996789515018463,
        "learning_rate": 7.5022143489814e-06,
        "epoch": 2.4977856510186003,
        "step": 2820
    },
    {
        "loss": 0.2468,
        "grad_norm": 6.923162460327148,
        "learning_rate": 7.493356953055803e-06,
        "epoch": 2.5066430469441983,
        "step": 2830
    },
    {
        "loss": 0.3592,
        "grad_norm": 1.0183565616607666,
        "learning_rate": 7.484499557130205e-06,
        "epoch": 2.5155004428697962,
        "step": 2840
    },
    {
        "loss": 0.3621,
        "grad_norm": 71.85150909423828,
        "learning_rate": 7.475642161204606e-06,
        "epoch": 2.524357838795394,
        "step": 2850
    },
    {
        "loss": 0.2127,
        "grad_norm": 38.460777282714844,
        "learning_rate": 7.466784765279008e-06,
        "epoch": 2.533215234720992,
        "step": 2860
    },
    {
        "loss": 0.2766,
        "grad_norm": 1.459634780883789,
        "learning_rate": 7.457927369353411e-06,
        "epoch": 2.54207263064659,
        "step": 2870
    },
    {
        "loss": 0.2558,
        "grad_norm": 1.6984716653823853,
        "learning_rate": 7.449069973427812e-06,
        "epoch": 2.5509300265721877,
        "step": 2880
    },
    {
        "loss": 0.2453,
        "grad_norm": 0.4727250635623932,
        "learning_rate": 7.440212577502215e-06,
        "epoch": 2.5597874224977857,
        "step": 2890
    },
    {
        "loss": 0.2395,
        "grad_norm": 5.768871784210205,
        "learning_rate": 7.431355181576617e-06,
        "epoch": 2.5686448184233837,
        "step": 2900
    },
    {
        "loss": 0.297,
        "grad_norm": 0.7176893949508667,
        "learning_rate": 7.42249778565102e-06,
        "epoch": 2.577502214348981,
        "step": 2910
    },
    {
        "loss": 0.3297,
        "grad_norm": 48.050621032714844,
        "learning_rate": 7.413640389725421e-06,
        "epoch": 2.586359610274579,
        "step": 2920
    },
    {
        "loss": 0.1936,
        "grad_norm": 50.20148468017578,
        "learning_rate": 7.404782993799824e-06,
        "epoch": 2.595217006200177,
        "step": 2930
    },
    {
        "loss": 0.135,
        "grad_norm": 35.323951721191406,
        "learning_rate": 7.3959255978742254e-06,
        "epoch": 2.604074402125775,
        "step": 2940
    },
    {
        "loss": 0.2434,
        "grad_norm": 5.1221113204956055,
        "learning_rate": 7.387068201948627e-06,
        "epoch": 2.612931798051373,
        "step": 2950
    },
    {
        "loss": 0.2191,
        "grad_norm": 2.5443637371063232,
        "learning_rate": 7.3782108060230295e-06,
        "epoch": 2.6217891939769706,
        "step": 2960
    },
    {
        "loss": 0.1756,
        "grad_norm": 39.08746337890625,
        "learning_rate": 7.369353410097432e-06,
        "epoch": 2.6306465899025686,
        "step": 2970
    },
    {
        "loss": 0.3889,
        "grad_norm": 25.541107177734375,
        "learning_rate": 7.3604960141718344e-06,
        "epoch": 2.6395039858281666,
        "step": 2980
    },
    {
        "loss": 0.2628,
        "grad_norm": 75.45612335205078,
        "learning_rate": 7.351638618246236e-06,
        "epoch": 2.648361381753764,
        "step": 2990
    },
    {
        "loss": 0.179,
        "grad_norm": 21.611501693725586,
        "learning_rate": 7.3427812223206385e-06,
        "epoch": 2.657218777679362,
        "step": 3000
    },
    {
        "loss": 0.24,
        "grad_norm": 47.03607177734375,
        "learning_rate": 7.333923826395041e-06,
        "epoch": 2.66607617360496,
        "step": 3010
    },
    {
        "loss": 0.1297,
        "grad_norm": 0.7292273044586182,
        "learning_rate": 7.325066430469443e-06,
        "epoch": 2.674933569530558,
        "step": 3020
    },
    {
        "loss": 0.2003,
        "grad_norm": 3.7938215732574463,
        "learning_rate": 7.316209034543845e-06,
        "epoch": 2.683790965456156,
        "step": 3030
    },
    {
        "loss": 0.2521,
        "grad_norm": 3.785832643508911,
        "learning_rate": 7.307351638618247e-06,
        "epoch": 2.692648361381754,
        "step": 3040
    },
    {
        "loss": 0.1321,
        "grad_norm": 4.0495758056640625,
        "learning_rate": 7.298494242692648e-06,
        "epoch": 2.7015057573073515,
        "step": 3050
    },
    {
        "loss": 0.2177,
        "grad_norm": 36.193477630615234,
        "learning_rate": 7.289636846767051e-06,
        "epoch": 2.7103631532329495,
        "step": 3060
    },
    {
        "loss": 0.2294,
        "grad_norm": 5.31496000289917,
        "learning_rate": 7.280779450841453e-06,
        "epoch": 2.7192205491585475,
        "step": 3070
    },
    {
        "loss": 0.3106,
        "grad_norm": 22.26607894897461,
        "learning_rate": 7.271922054915856e-06,
        "epoch": 2.728077945084145,
        "step": 3080
    },
    {
        "loss": 0.3021,
        "grad_norm": 24.07988739013672,
        "learning_rate": 7.263064658990257e-06,
        "epoch": 2.736935341009743,
        "step": 3090
    },
    {
        "loss": 0.2335,
        "grad_norm": 67.84408569335938,
        "learning_rate": 7.25420726306466e-06,
        "epoch": 2.745792736935341,
        "step": 3100
    },
    {
        "loss": 0.2008,
        "grad_norm": 30.434097290039062,
        "learning_rate": 7.245349867139062e-06,
        "epoch": 2.754650132860939,
        "step": 3110
    },
    {
        "loss": 0.1836,
        "grad_norm": 4.565478324890137,
        "learning_rate": 7.2364924712134646e-06,
        "epoch": 2.763507528786537,
        "step": 3120
    },
    {
        "loss": 0.1661,
        "grad_norm": 14.76399040222168,
        "learning_rate": 7.227635075287865e-06,
        "epoch": 2.7723649247121345,
        "step": 3130
    },
    {
        "loss": 0.2656,
        "grad_norm": 48.81344985961914,
        "learning_rate": 7.218777679362268e-06,
        "epoch": 2.7812223206377324,
        "step": 3140
    },
    {
        "loss": 0.1975,
        "grad_norm": 27.19898223876953,
        "learning_rate": 7.20992028343667e-06,
        "epoch": 2.7900797165633304,
        "step": 3150
    },
    {
        "loss": 0.2399,
        "grad_norm": 24.756113052368164,
        "learning_rate": 7.201062887511072e-06,
        "epoch": 2.7989371124889284,
        "step": 3160
    },
    {
        "loss": 0.1377,
        "grad_norm": 2.2715044021606445,
        "learning_rate": 7.192205491585474e-06,
        "epoch": 2.807794508414526,
        "step": 3170
    },
    {
        "loss": 0.1169,
        "grad_norm": 23.267127990722656,
        "learning_rate": 7.183348095659877e-06,
        "epoch": 2.816651904340124,
        "step": 3180
    },
    {
        "loss": 0.1563,
        "grad_norm": 41.634193420410156,
        "learning_rate": 7.174490699734279e-06,
        "epoch": 2.825509300265722,
        "step": 3190
    },
    {
        "loss": 0.1982,
        "grad_norm": 8.955123901367188,
        "learning_rate": 7.165633303808681e-06,
        "epoch": 2.83436669619132,
        "step": 3200
    },
    {
        "loss": 0.2362,
        "grad_norm": 56.701446533203125,
        "learning_rate": 7.156775907883083e-06,
        "epoch": 2.843224092116918,
        "step": 3210
    },
    {
        "loss": 0.1326,
        "grad_norm": 0.6367221474647522,
        "learning_rate": 7.147918511957485e-06,
        "epoch": 2.8520814880425154,
        "step": 3220
    },
    {
        "loss": 0.2405,
        "grad_norm": 24.231700897216797,
        "learning_rate": 7.1390611160318865e-06,
        "epoch": 2.8609388839681134,
        "step": 3230
    },
    {
        "loss": 0.2475,
        "grad_norm": 62.74552536010742,
        "learning_rate": 7.130203720106289e-06,
        "epoch": 2.8697962798937113,
        "step": 3240
    },
    {
        "loss": 0.121,
        "grad_norm": 111.32415771484375,
        "learning_rate": 7.121346324180691e-06,
        "epoch": 2.878653675819309,
        "step": 3250
    },
    {
        "loss": 0.2459,
        "grad_norm": 62.71006393432617,
        "learning_rate": 7.112488928255094e-06,
        "epoch": 2.887511071744907,
        "step": 3260
    },
    {
        "loss": 0.3086,
        "grad_norm": 109.99711608886719,
        "learning_rate": 7.1036315323294955e-06,
        "epoch": 2.896368467670505,
        "step": 3270
    },
    {
        "loss": 0.1528,
        "grad_norm": 11.37956428527832,
        "learning_rate": 7.094774136403898e-06,
        "epoch": 2.905225863596103,
        "step": 3280
    },
    {
        "loss": 0.2128,
        "grad_norm": 56.91134262084961,
        "learning_rate": 7.0859167404783e-06,
        "epoch": 2.9140832595217008,
        "step": 3290
    },
    {
        "loss": 0.1734,
        "grad_norm": 14.34688663482666,
        "learning_rate": 7.077059344552703e-06,
        "epoch": 2.9229406554472988,
        "step": 3300
    },
    {
        "loss": 0.1827,
        "grad_norm": 20.55921173095703,
        "learning_rate": 7.0682019486271045e-06,
        "epoch": 2.9317980513728963,
        "step": 3310
    },
    {
        "loss": 0.1445,
        "grad_norm": 53.03473663330078,
        "learning_rate": 7.059344552701506e-06,
        "epoch": 2.9406554472984943,
        "step": 3320
    },
    {
        "loss": 0.2626,
        "grad_norm": 26.197092056274414,
        "learning_rate": 7.0504871567759085e-06,
        "epoch": 2.9495128432240922,
        "step": 3330
    },
    {
        "loss": 0.2178,
        "grad_norm": 64.20206451416016,
        "learning_rate": 7.04162976085031e-06,
        "epoch": 2.9583702391496898,
        "step": 3340
    },
    {
        "loss": 0.1542,
        "grad_norm": 45.904544830322266,
        "learning_rate": 7.032772364924713e-06,
        "epoch": 2.9672276350752878,
        "step": 3350
    },
    {
        "loss": 0.1905,
        "grad_norm": 59.12601852416992,
        "learning_rate": 7.023914968999115e-06,
        "epoch": 2.9760850310008857,
        "step": 3360
    },
    {
        "loss": 0.3488,
        "grad_norm": 27.734378814697266,
        "learning_rate": 7.0150575730735175e-06,
        "epoch": 2.9849424269264837,
        "step": 3370
    },
    {
        "loss": 0.1474,
        "grad_norm": 30.054061889648438,
        "learning_rate": 7.006200177147919e-06,
        "epoch": 2.9937998228520817,
        "step": 3380
    },
    {
        "eval_loss": 0.20854642987251282,
        "eval_accuracy": 0.94696,
        "eval_precision": 0.96031,
        "eval_recall": 0.93245,
        "eval_f1": 0.94617,
        "eval_runtime": 149.8793,
        "eval_samples_per_second": 60.255,
        "eval_steps_per_second": 3.77,
        "epoch": 3.0,
        "step": 3387
    },
    {
        "loss": 0.2008,
        "grad_norm": 52.789024353027344,
        "learning_rate": 6.9973427812223216e-06,
        "epoch": 3.002657218777679,
        "step": 3390
    },
    {
        "loss": 0.2192,
        "grad_norm": 7.438864231109619,
        "learning_rate": 6.988485385296724e-06,
        "epoch": 3.011514614703277,
        "step": 3400
    },
    {
        "loss": 0.1725,
        "grad_norm": 108.51326751708984,
        "learning_rate": 6.979627989371125e-06,
        "epoch": 3.020372010628875,
        "step": 3410
    },
    {
        "loss": 0.2003,
        "grad_norm": 100.07703399658203,
        "learning_rate": 6.970770593445527e-06,
        "epoch": 3.029229406554473,
        "step": 3420
    },
    {
        "loss": 0.1297,
        "grad_norm": 0.3911769986152649,
        "learning_rate": 6.96191319751993e-06,
        "epoch": 3.0380868024800707,
        "step": 3430
    },
    {
        "loss": 0.1596,
        "grad_norm": 43.88953399658203,
        "learning_rate": 6.953055801594331e-06,
        "epoch": 3.0469441984056687,
        "step": 3440
    },
    {
        "loss": 0.0785,
        "grad_norm": 55.84791564941406,
        "learning_rate": 6.944198405668734e-06,
        "epoch": 3.0558015943312666,
        "step": 3450
    },
    {
        "loss": 0.1237,
        "grad_norm": 17.656356811523438,
        "learning_rate": 6.935341009743136e-06,
        "epoch": 3.0646589902568646,
        "step": 3460
    },
    {
        "loss": 0.1551,
        "grad_norm": 107.36418914794922,
        "learning_rate": 6.926483613817539e-06,
        "epoch": 3.073516386182462,
        "step": 3470
    },
    {
        "loss": 0.1335,
        "grad_norm": 31.126928329467773,
        "learning_rate": 6.91762621789194e-06,
        "epoch": 3.08237378210806,
        "step": 3480
    },
    {
        "loss": 0.143,
        "grad_norm": 0.45400306582450867,
        "learning_rate": 6.908768821966343e-06,
        "epoch": 3.091231178033658,
        "step": 3490
    },
    {
        "loss": 0.16,
        "grad_norm": 133.34927368164062,
        "learning_rate": 6.899911426040744e-06,
        "epoch": 3.100088573959256,
        "step": 3500
    },
    {
        "loss": 0.099,
        "grad_norm": 1.050777554512024,
        "learning_rate": 6.891054030115146e-06,
        "epoch": 3.108945969884854,
        "step": 3510
    },
    {
        "loss": 0.1666,
        "grad_norm": 91.53321838378906,
        "learning_rate": 6.882196634189548e-06,
        "epoch": 3.1178033658104516,
        "step": 3520
    },
    {
        "loss": 0.101,
        "grad_norm": 1.095077633857727,
        "learning_rate": 6.873339238263951e-06,
        "epoch": 3.1266607617360496,
        "step": 3530
    },
    {
        "loss": 0.1376,
        "grad_norm": 25.4495906829834,
        "learning_rate": 6.864481842338353e-06,
        "epoch": 3.1355181576616475,
        "step": 3540
    },
    {
        "loss": 0.021,
        "grad_norm": 0.39384162425994873,
        "learning_rate": 6.855624446412755e-06,
        "epoch": 3.1443755535872455,
        "step": 3550
    },
    {
        "loss": 0.3488,
        "grad_norm": 108.96360778808594,
        "learning_rate": 6.846767050487157e-06,
        "epoch": 3.153232949512843,
        "step": 3560
    },
    {
        "loss": 0.1511,
        "grad_norm": 0.5782315731048584,
        "learning_rate": 6.83790965456156e-06,
        "epoch": 3.162090345438441,
        "step": 3570
    },
    {
        "loss": 0.0982,
        "grad_norm": 18.69277572631836,
        "learning_rate": 6.829052258635962e-06,
        "epoch": 3.170947741364039,
        "step": 3580
    },
    {
        "loss": 0.1093,
        "grad_norm": 48.807212829589844,
        "learning_rate": 6.820194862710364e-06,
        "epoch": 3.179805137289637,
        "step": 3590
    },
    {
        "loss": 0.2127,
        "grad_norm": 0.7852912545204163,
        "learning_rate": 6.8113374667847655e-06,
        "epoch": 3.1886625332152345,
        "step": 3600
    },
    {
        "loss": 0.2176,
        "grad_norm": 77.4134292602539,
        "learning_rate": 6.802480070859168e-06,
        "epoch": 3.1975199291408325,
        "step": 3610
    },
    {
        "loss": 0.1825,
        "grad_norm": 95.5717544555664,
        "learning_rate": 6.79362267493357e-06,
        "epoch": 3.2063773250664305,
        "step": 3620
    },
    {
        "loss": 0.177,
        "grad_norm": 100.21321868896484,
        "learning_rate": 6.784765279007972e-06,
        "epoch": 3.2152347209920284,
        "step": 3630
    },
    {
        "loss": 0.1682,
        "grad_norm": 8.051782608032227,
        "learning_rate": 6.7759078830823745e-06,
        "epoch": 3.2240921169176264,
        "step": 3640
    },
    {
        "loss": 0.0241,
        "grad_norm": 0.6497520208358765,
        "learning_rate": 6.767050487156777e-06,
        "epoch": 3.232949512843224,
        "step": 3650
    },
    {
        "loss": 0.1964,
        "grad_norm": 1.3808410167694092,
        "learning_rate": 6.7581930912311786e-06,
        "epoch": 3.241806908768822,
        "step": 3660
    },
    {
        "loss": 0.1112,
        "grad_norm": 6.081044673919678,
        "learning_rate": 6.749335695305581e-06,
        "epoch": 3.25066430469442,
        "step": 3670
    },
    {
        "loss": 0.1928,
        "grad_norm": 101.50547790527344,
        "learning_rate": 6.7404782993799835e-06,
        "epoch": 3.259521700620018,
        "step": 3680
    },
    {
        "loss": 0.2959,
        "grad_norm": 17.490991592407227,
        "learning_rate": 6.731620903454384e-06,
        "epoch": 3.2683790965456154,
        "step": 3690
    },
    {
        "loss": 0.1768,
        "grad_norm": 3.955589532852173,
        "learning_rate": 6.722763507528787e-06,
        "epoch": 3.2772364924712134,
        "step": 3700
    },
    {
        "loss": 0.1424,
        "grad_norm": 6.167608737945557,
        "learning_rate": 6.713906111603189e-06,
        "epoch": 3.2860938883968114,
        "step": 3710
    },
    {
        "loss": 0.1674,
        "grad_norm": 0.3918702006340027,
        "learning_rate": 6.705048715677592e-06,
        "epoch": 3.2949512843224094,
        "step": 3720
    },
    {
        "loss": 0.1386,
        "grad_norm": 103.53119659423828,
        "learning_rate": 6.696191319751993e-06,
        "epoch": 3.3038086802480073,
        "step": 3730
    },
    {
        "loss": 0.1415,
        "grad_norm": 2.383028984069824,
        "learning_rate": 6.687333923826396e-06,
        "epoch": 3.312666076173605,
        "step": 3740
    },
    {
        "loss": 0.1226,
        "grad_norm": 51.243438720703125,
        "learning_rate": 6.678476527900798e-06,
        "epoch": 3.321523472099203,
        "step": 3750
    },
    {
        "loss": 0.2221,
        "grad_norm": 1.2759454250335693,
        "learning_rate": 6.6696191319752006e-06,
        "epoch": 3.330380868024801,
        "step": 3760
    },
    {
        "loss": 0.0585,
        "grad_norm": 44.599830627441406,
        "learning_rate": 6.660761736049602e-06,
        "epoch": 3.3392382639503984,
        "step": 3770
    },
    {
        "loss": 0.1878,
        "grad_norm": 17.611501693725586,
        "learning_rate": 6.651904340124004e-06,
        "epoch": 3.3480956598759963,
        "step": 3780
    },
    {
        "loss": 0.1328,
        "grad_norm": 13.497628211975098,
        "learning_rate": 6.643046944198405e-06,
        "epoch": 3.3569530558015943,
        "step": 3790
    },
    {
        "loss": 0.2136,
        "grad_norm": 2.4837334156036377,
        "learning_rate": 6.634189548272808e-06,
        "epoch": 3.3658104517271923,
        "step": 3800
    },
    {
        "loss": 0.1153,
        "grad_norm": 27.012958526611328,
        "learning_rate": 6.62533215234721e-06,
        "epoch": 3.3746678476527903,
        "step": 3810
    },
    {
        "loss": 0.1867,
        "grad_norm": 130.80496215820312,
        "learning_rate": 6.616474756421613e-06,
        "epoch": 3.383525243578388,
        "step": 3820
    },
    {
        "loss": 0.055,
        "grad_norm": 27.727449417114258,
        "learning_rate": 6.607617360496014e-06,
        "epoch": 3.3923826395039858,
        "step": 3830
    },
    {
        "loss": 0.1957,
        "grad_norm": 0.47320836782455444,
        "learning_rate": 6.598759964570417e-06,
        "epoch": 3.4012400354295838,
        "step": 3840
    },
    {
        "loss": 0.1955,
        "grad_norm": 5.072383403778076,
        "learning_rate": 6.589902568644819e-06,
        "epoch": 3.4100974313551817,
        "step": 3850
    },
    {
        "loss": 0.201,
        "grad_norm": 4.594649314880371,
        "learning_rate": 6.581045172719222e-06,
        "epoch": 3.4189548272807793,
        "step": 3860
    },
    {
        "loss": 0.0768,
        "grad_norm": 46.83216094970703,
        "learning_rate": 6.572187776793623e-06,
        "epoch": 3.4278122232063772,
        "step": 3870
    },
    {
        "loss": 0.2433,
        "grad_norm": 104.3322525024414,
        "learning_rate": 6.563330380868025e-06,
        "epoch": 3.436669619131975,
        "step": 3880
    },
    {
        "loss": 0.2606,
        "grad_norm": 156.15179443359375,
        "learning_rate": 6.554472984942427e-06,
        "epoch": 3.445527015057573,
        "step": 3890
    },
    {
        "loss": 0.149,
        "grad_norm": 0.154861718416214,
        "learning_rate": 6.545615589016829e-06,
        "epoch": 3.454384410983171,
        "step": 3900
    },
    {
        "loss": 0.1329,
        "grad_norm": 83.1611328125,
        "learning_rate": 6.5367581930912315e-06,
        "epoch": 3.4632418069087687,
        "step": 3910
    },
    {
        "loss": 0.1499,
        "grad_norm": 0.17472828924655914,
        "learning_rate": 6.527900797165634e-06,
        "epoch": 3.4720992028343667,
        "step": 3920
    },
    {
        "loss": 0.142,
        "grad_norm": 1.415666937828064,
        "learning_rate": 6.519043401240036e-06,
        "epoch": 3.4809565987599647,
        "step": 3930
    },
    {
        "loss": 0.0824,
        "grad_norm": 0.2939881384372711,
        "learning_rate": 6.510186005314438e-06,
        "epoch": 3.4898139946855626,
        "step": 3940
    },
    {
        "loss": 0.0561,
        "grad_norm": 16.17378807067871,
        "learning_rate": 6.5013286093888405e-06,
        "epoch": 3.49867139061116,
        "step": 3950
    },
    {
        "loss": 0.1152,
        "grad_norm": 0.1327831745147705,
        "learning_rate": 6.492471213463243e-06,
        "epoch": 3.507528786536758,
        "step": 3960
    },
    {
        "loss": 0.2528,
        "grad_norm": 83.23462677001953,
        "learning_rate": 6.483613817537644e-06,
        "epoch": 3.516386182462356,
        "step": 3970
    },
    {
        "loss": 0.2503,
        "grad_norm": 93.39876556396484,
        "learning_rate": 6.474756421612046e-06,
        "epoch": 3.525243578387954,
        "step": 3980
    },
    {
        "loss": 0.2561,
        "grad_norm": 29.47353172302246,
        "learning_rate": 6.465899025686449e-06,
        "epoch": 3.534100974313552,
        "step": 3990
    },
    {
        "loss": 0.1711,
        "grad_norm": 0.35634028911590576,
        "learning_rate": 6.457041629760851e-06,
        "epoch": 3.5429583702391496,
        "step": 4000
    },
    {
        "loss": 0.2529,
        "grad_norm": 0.1880086213350296,
        "learning_rate": 6.448184233835253e-06,
        "epoch": 3.5518157661647476,
        "step": 4010
    },
    {
        "loss": 0.1653,
        "grad_norm": 176.5060272216797,
        "learning_rate": 6.439326837909655e-06,
        "epoch": 3.5606731620903456,
        "step": 4020
    },
    {
        "loss": 0.0884,
        "grad_norm": 0.19973833858966827,
        "learning_rate": 6.4304694419840576e-06,
        "epoch": 3.569530558015943,
        "step": 4030
    },
    {
        "loss": 0.1611,
        "grad_norm": 65.24954223632812,
        "learning_rate": 6.42161204605846e-06,
        "epoch": 3.578387953941541,
        "step": 4040
    },
    {
        "loss": 0.1694,
        "grad_norm": 85.17407989501953,
        "learning_rate": 6.412754650132862e-06,
        "epoch": 3.587245349867139,
        "step": 4050
    },
    {
        "loss": 0.241,
        "grad_norm": 71.80357360839844,
        "learning_rate": 6.403897254207263e-06,
        "epoch": 3.596102745792737,
        "step": 4060
    },
    {
        "loss": 0.1139,
        "grad_norm": 69.41377258300781,
        "learning_rate": 6.395039858281666e-06,
        "epoch": 3.604960141718335,
        "step": 4070
    },
    {
        "loss": 0.1934,
        "grad_norm": 2.3707776069641113,
        "learning_rate": 6.386182462356067e-06,
        "epoch": 3.6138175376439325,
        "step": 4080
    },
    {
        "loss": 0.0458,
        "grad_norm": 9.101408958435059,
        "learning_rate": 6.37732506643047e-06,
        "epoch": 3.6226749335695305,
        "step": 4090
    },
    {
        "loss": 0.0837,
        "grad_norm": 9.559112548828125,
        "learning_rate": 6.368467670504872e-06,
        "epoch": 3.6315323294951285,
        "step": 4100
    },
    {
        "loss": 0.2057,
        "grad_norm": 0.19669726490974426,
        "learning_rate": 6.359610274579275e-06,
        "epoch": 3.640389725420726,
        "step": 4110
    },
    {
        "loss": 0.1004,
        "grad_norm": 0.7785244584083557,
        "learning_rate": 6.350752878653676e-06,
        "epoch": 3.649247121346324,
        "step": 4120
    },
    {
        "loss": 0.1178,
        "grad_norm": 0.17910799384117126,
        "learning_rate": 6.341895482728079e-06,
        "epoch": 3.658104517271922,
        "step": 4130
    },
    {
        "loss": 0.1012,
        "grad_norm": 24.485219955444336,
        "learning_rate": 6.333038086802481e-06,
        "epoch": 3.66696191319752,
        "step": 4140
    },
    {
        "loss": 0.114,
        "grad_norm": 0.1824139952659607,
        "learning_rate": 6.324180690876884e-06,
        "epoch": 3.675819309123118,
        "step": 4150
    },
    {
        "loss": 0.1276,
        "grad_norm": 21.597505569458008,
        "learning_rate": 6.315323294951284e-06,
        "epoch": 3.684676705048716,
        "step": 4160
    },
    {
        "loss": 0.1296,
        "grad_norm": 11.92389965057373,
        "learning_rate": 6.306465899025687e-06,
        "epoch": 3.6935341009743134,
        "step": 4170
    },
    {
        "loss": 0.4061,
        "grad_norm": 64.28104400634766,
        "learning_rate": 6.2976085031000885e-06,
        "epoch": 3.7023914968999114,
        "step": 4180
    },
    {
        "loss": 0.3716,
        "grad_norm": 87.77888488769531,
        "learning_rate": 6.288751107174491e-06,
        "epoch": 3.7112488928255094,
        "step": 4190
    },
    {
        "loss": 0.1181,
        "grad_norm": 0.15179385244846344,
        "learning_rate": 6.279893711248893e-06,
        "epoch": 3.720106288751107,
        "step": 4200
    },
    {
        "loss": 0.0784,
        "grad_norm": 0.2531307339668274,
        "learning_rate": 6.271036315323296e-06,
        "epoch": 3.728963684676705,
        "step": 4210
    },
    {
        "loss": 0.1785,
        "grad_norm": 0.12839274108409882,
        "learning_rate": 6.2621789193976975e-06,
        "epoch": 3.737821080602303,
        "step": 4220
    },
    {
        "loss": 0.13,
        "grad_norm": 98.5491943359375,
        "learning_rate": 6.2533215234721e-06,
        "epoch": 3.746678476527901,
        "step": 4230
    },
    {
        "loss": 0.155,
        "grad_norm": 3.3150506019592285,
        "learning_rate": 6.244464127546502e-06,
        "epoch": 3.755535872453499,
        "step": 4240
    },
    {
        "loss": 0.1509,
        "grad_norm": 13.716327667236328,
        "learning_rate": 6.235606731620903e-06,
        "epoch": 3.7643932683790964,
        "step": 4250
    },
    {
        "loss": 0.113,
        "grad_norm": 0.6665719747543335,
        "learning_rate": 6.226749335695306e-06,
        "epoch": 3.7732506643046944,
        "step": 4260
    },
    {
        "loss": 0.1304,
        "grad_norm": 0.8874181509017944,
        "learning_rate": 6.217891939769708e-06,
        "epoch": 3.7821080602302923,
        "step": 4270
    },
    {
        "loss": 0.142,
        "grad_norm": 0.21505723893642426,
        "learning_rate": 6.2090345438441105e-06,
        "epoch": 3.7909654561558903,
        "step": 4280
    },
    {
        "loss": 0.1075,
        "grad_norm": 1.4003825187683105,
        "learning_rate": 6.200177147918512e-06,
        "epoch": 3.799822852081488,
        "step": 4290
    },
    {
        "loss": 0.1188,
        "grad_norm": 0.7443421483039856,
        "learning_rate": 6.1913197519929146e-06,
        "epoch": 3.808680248007086,
        "step": 4300
    },
    {
        "loss": 0.2261,
        "grad_norm": 14.568143844604492,
        "learning_rate": 6.182462356067317e-06,
        "epoch": 3.817537643932684,
        "step": 4310
    },
    {
        "loss": 0.0881,
        "grad_norm": 95.4306869506836,
        "learning_rate": 6.1736049601417195e-06,
        "epoch": 3.8263950398582818,
        "step": 4320
    },
    {
        "loss": 0.0546,
        "grad_norm": 89.50367736816406,
        "learning_rate": 6.164747564216121e-06,
        "epoch": 3.8352524357838798,
        "step": 4330
    },
    {
        "loss": 0.1161,
        "grad_norm": 14.480128288269043,
        "learning_rate": 6.155890168290523e-06,
        "epoch": 3.8441098317094773,
        "step": 4340
    },
    {
        "loss": 0.2022,
        "grad_norm": 93.66508483886719,
        "learning_rate": 6.147032772364925e-06,
        "epoch": 3.8529672276350753,
        "step": 4350
    },
    {
        "loss": 0.1241,
        "grad_norm": 146.97647094726562,
        "learning_rate": 6.138175376439327e-06,
        "epoch": 3.8618246235606732,
        "step": 4360
    },
    {
        "loss": 0.1808,
        "grad_norm": 176.4888916015625,
        "learning_rate": 6.129317980513729e-06,
        "epoch": 3.8706820194862708,
        "step": 4370
    },
    {
        "loss": 0.0981,
        "grad_norm": 45.90718078613281,
        "learning_rate": 6.120460584588132e-06,
        "epoch": 3.8795394154118688,
        "step": 4380
    },
    {
        "loss": 0.1997,
        "grad_norm": 2.041741371154785,
        "learning_rate": 6.111603188662534e-06,
        "epoch": 3.8883968113374667,
        "step": 4390
    },
    {
        "loss": 0.1149,
        "grad_norm": 10.653563499450684,
        "learning_rate": 6.102745792736936e-06,
        "epoch": 3.8972542072630647,
        "step": 4400
    },
    {
        "loss": 0.2168,
        "grad_norm": 6.360729694366455,
        "learning_rate": 6.093888396811338e-06,
        "epoch": 3.9061116031886627,
        "step": 4410
    },
    {
        "loss": 0.0894,
        "grad_norm": 0.2965129613876343,
        "learning_rate": 6.085031000885741e-06,
        "epoch": 3.9149689991142607,
        "step": 4420
    },
    {
        "loss": 0.1136,
        "grad_norm": 120.42840576171875,
        "learning_rate": 6.076173604960143e-06,
        "epoch": 3.923826395039858,
        "step": 4430
    },
    {
        "loss": 0.0116,
        "grad_norm": 0.16072583198547363,
        "learning_rate": 6.067316209034544e-06,
        "epoch": 3.932683790965456,
        "step": 4440
    },
    {
        "loss": 0.1826,
        "grad_norm": 96.10276794433594,
        "learning_rate": 6.058458813108946e-06,
        "epoch": 3.941541186891054,
        "step": 4450
    },
    {
        "loss": 0.1322,
        "grad_norm": 1.9231338500976562,
        "learning_rate": 6.049601417183349e-06,
        "epoch": 3.9503985828166517,
        "step": 4460
    },
    {
        "loss": 0.1699,
        "grad_norm": 158.55455017089844,
        "learning_rate": 6.04074402125775e-06,
        "epoch": 3.9592559787422497,
        "step": 4470
    },
    {
        "loss": 0.1548,
        "grad_norm": 0.4698030650615692,
        "learning_rate": 6.031886625332153e-06,
        "epoch": 3.9681133746678476,
        "step": 4480
    },
    {
        "loss": 0.2729,
        "grad_norm": 114.72364044189453,
        "learning_rate": 6.023029229406555e-06,
        "epoch": 3.9769707705934456,
        "step": 4490
    },
    {
        "loss": 0.137,
        "grad_norm": 0.10225147753953934,
        "learning_rate": 6.014171833480958e-06,
        "epoch": 3.9858281665190436,
        "step": 4500
    },
    {
        "loss": 0.1049,
        "grad_norm": 1.3932150602340698,
        "learning_rate": 6.005314437555359e-06,
        "epoch": 3.994685562444641,
        "step": 4510
    },
    {
        "eval_loss": 0.1879734992980957,
        "eval_accuracy": 0.96113,
        "eval_precision": 0.96452,
        "eval_recall": 0.95748,
        "eval_f1": 0.96099,
        "eval_runtime": 150.0887,
        "eval_samples_per_second": 60.171,
        "eval_steps_per_second": 3.764,
        "epoch": 4.0,
        "step": 4516
    },
    {
        "loss": 0.0851,
        "grad_norm": 61.749881744384766,
        "learning_rate": 5.996457041629762e-06,
        "epoch": 4.0035429583702395,
        "step": 4520
    },
    {
        "loss": 0.1556,
        "grad_norm": 2.9051334857940674,
        "learning_rate": 5.9875996457041626e-06,
        "epoch": 4.012400354295837,
        "step": 4530
    },
    {
        "loss": 0.0783,
        "grad_norm": 0.7579514384269714,
        "learning_rate": 5.978742249778565e-06,
        "epoch": 4.021257750221435,
        "step": 4540
    },
    {
        "loss": 0.1009,
        "grad_norm": 0.17949925363063812,
        "learning_rate": 5.9698848538529675e-06,
        "epoch": 4.030115146147033,
        "step": 4550
    },
    {
        "loss": 0.1087,
        "grad_norm": 0.16731272637844086,
        "learning_rate": 5.96102745792737e-06,
        "epoch": 4.038972542072631,
        "step": 4560
    },
    {
        "loss": 0.0631,
        "grad_norm": 0.10471925884485245,
        "learning_rate": 5.9521700620017716e-06,
        "epoch": 4.0478299379982285,
        "step": 4570
    },
    {
        "loss": 0.0209,
        "grad_norm": 0.15459834039211273,
        "learning_rate": 5.943312666076174e-06,
        "epoch": 4.0566873339238265,
        "step": 4580
    },
    {
        "loss": 0.0411,
        "grad_norm": 0.5348668098449707,
        "learning_rate": 5.9344552701505765e-06,
        "epoch": 4.0655447298494245,
        "step": 4590
    },
    {
        "loss": 0.1573,
        "grad_norm": 1.1080249547958374,
        "learning_rate": 5.925597874224979e-06,
        "epoch": 4.0744021257750225,
        "step": 4600
    },
    {
        "loss": 0.1623,
        "grad_norm": 5.1388936042785645,
        "learning_rate": 5.9167404782993805e-06,
        "epoch": 4.0832595217006205,
        "step": 4610
    },
    {
        "loss": 0.0399,
        "grad_norm": 0.15825413167476654,
        "learning_rate": 5.907883082373782e-06,
        "epoch": 4.0921169176262175,
        "step": 4620
    },
    {
        "loss": 0.0606,
        "grad_norm": 0.1281878501176834,
        "learning_rate": 5.899025686448185e-06,
        "epoch": 4.1009743135518155,
        "step": 4630
    },
    {
        "loss": 0.1855,
        "grad_norm": 0.5040372610092163,
        "learning_rate": 5.890168290522586e-06,
        "epoch": 4.1098317094774135,
        "step": 4640
    },
    {
        "loss": 0.0723,
        "grad_norm": 1.9604259729385376,
        "learning_rate": 5.881310894596989e-06,
        "epoch": 4.1186891054030115,
        "step": 4650
    },
    {
        "loss": 0.0436,
        "grad_norm": 0.15502861142158508,
        "learning_rate": 5.872453498671391e-06,
        "epoch": 4.1275465013286095,
        "step": 4660
    },
    {
        "loss": 0.084,
        "grad_norm": 50.668235778808594,
        "learning_rate": 5.8635961027457936e-06,
        "epoch": 4.136403897254207,
        "step": 4670
    },
    {
        "loss": 0.1218,
        "grad_norm": 46.451541900634766,
        "learning_rate": 5.854738706820195e-06,
        "epoch": 4.145261293179805,
        "step": 4680
    },
    {
        "loss": 0.1622,
        "grad_norm": 0.10304214805364609,
        "learning_rate": 5.845881310894598e-06,
        "epoch": 4.154118689105403,
        "step": 4690
    },
    {
        "loss": 0.05,
        "grad_norm": 1.58721125125885,
        "learning_rate": 5.837023914969e-06,
        "epoch": 4.1629760850310005,
        "step": 4700
    },
    {
        "loss": 0.0701,
        "grad_norm": 122.81932067871094,
        "learning_rate": 5.8281665190434025e-06,
        "epoch": 4.1718334809565985,
        "step": 4710
    },
    {
        "loss": 0.1148,
        "grad_norm": 0.11389099061489105,
        "learning_rate": 5.819309123117803e-06,
        "epoch": 4.180690876882196,
        "step": 4720
    },
    {
        "loss": 0.095,
        "grad_norm": 11.163119316101074,
        "learning_rate": 5.810451727192206e-06,
        "epoch": 4.189548272807794,
        "step": 4730
    },
    {
        "loss": 0.0566,
        "grad_norm": 2.0150270462036133,
        "learning_rate": 5.801594331266608e-06,
        "epoch": 4.198405668733392,
        "step": 4740
    },
    {
        "loss": 0.1559,
        "grad_norm": 140.02041625976562,
        "learning_rate": 5.79273693534101e-06,
        "epoch": 4.20726306465899,
        "step": 4750
    },
    {
        "loss": 0.071,
        "grad_norm": 51.587432861328125,
        "learning_rate": 5.783879539415412e-06,
        "epoch": 4.216120460584588,
        "step": 4760
    },
    {
        "loss": 0.1099,
        "grad_norm": 0.1475040763616562,
        "learning_rate": 5.775022143489815e-06,
        "epoch": 4.224977856510186,
        "step": 4770
    },
    {
        "loss": 0.0725,
        "grad_norm": 0.14165495336055756,
        "learning_rate": 5.766164747564217e-06,
        "epoch": 4.233835252435784,
        "step": 4780
    },
    {
        "loss": 0.1632,
        "grad_norm": 0.10863960534334183,
        "learning_rate": 5.757307351638619e-06,
        "epoch": 4.242692648361381,
        "step": 4790
    },
    {
        "loss": 0.1616,
        "grad_norm": 51.5909423828125,
        "learning_rate": 5.748449955713021e-06,
        "epoch": 4.251550044286979,
        "step": 4800
    },
    {
        "loss": 0.0816,
        "grad_norm": 0.5258281826972961,
        "learning_rate": 5.739592559787423e-06,
        "epoch": 4.260407440212577,
        "step": 4810
    },
    {
        "loss": 0.1276,
        "grad_norm": 126.76579284667969,
        "learning_rate": 5.7307351638618245e-06,
        "epoch": 4.269264836138175,
        "step": 4820
    },
    {
        "loss": 0.0728,
        "grad_norm": 0.3735392689704895,
        "learning_rate": 5.721877767936227e-06,
        "epoch": 4.278122232063773,
        "step": 4830
    },
    {
        "loss": 0.0473,
        "grad_norm": 119.34902954101562,
        "learning_rate": 5.713020372010629e-06,
        "epoch": 4.286979627989371,
        "step": 4840
    },
    {
        "loss": 0.0702,
        "grad_norm": 0.13718470931053162,
        "learning_rate": 5.704162976085032e-06,
        "epoch": 4.295837023914969,
        "step": 4850
    },
    {
        "loss": 0.1183,
        "grad_norm": 3.4518723487854004,
        "learning_rate": 5.6953055801594335e-06,
        "epoch": 4.304694419840567,
        "step": 4860
    },
    {
        "loss": 0.1127,
        "grad_norm": 0.6300734877586365,
        "learning_rate": 5.686448184233836e-06,
        "epoch": 4.313551815766164,
        "step": 4870
    },
    {
        "loss": 0.0665,
        "grad_norm": 0.15853343904018402,
        "learning_rate": 5.677590788308238e-06,
        "epoch": 4.322409211691762,
        "step": 4880
    },
    {
        "loss": 0.0767,
        "grad_norm": 0.31258076429367065,
        "learning_rate": 5.668733392382641e-06,
        "epoch": 4.33126660761736,
        "step": 4890
    },
    {
        "loss": 0.0878,
        "grad_norm": 0.15263427793979645,
        "learning_rate": 5.659875996457042e-06,
        "epoch": 4.340124003542958,
        "step": 4900
    },
    {
        "loss": 0.2001,
        "grad_norm": 0.15061798691749573,
        "learning_rate": 5.651018600531444e-06,
        "epoch": 4.348981399468556,
        "step": 4910
    },
    {
        "loss": 0.1071,
        "grad_norm": 0.5125303268432617,
        "learning_rate": 5.642161204605846e-06,
        "epoch": 4.357838795394154,
        "step": 4920
    },
    {
        "loss": 0.1199,
        "grad_norm": 110.23607635498047,
        "learning_rate": 5.633303808680248e-06,
        "epoch": 4.366696191319752,
        "step": 4930
    },
    {
        "loss": 0.1722,
        "grad_norm": 3.760758638381958,
        "learning_rate": 5.6244464127546506e-06,
        "epoch": 4.37555358724535,
        "step": 4940
    },
    {
        "loss": 0.0939,
        "grad_norm": 0.7979565262794495,
        "learning_rate": 5.615589016829053e-06,
        "epoch": 4.384410983170948,
        "step": 4950
    },
    {
        "loss": 0.0394,
        "grad_norm": 104.40253448486328,
        "learning_rate": 5.606731620903455e-06,
        "epoch": 4.393268379096545,
        "step": 4960
    },
    {
        "loss": 0.0731,
        "grad_norm": 261.2263488769531,
        "learning_rate": 5.597874224977857e-06,
        "epoch": 4.402125775022143,
        "step": 4970
    },
    {
        "loss": 0.063,
        "grad_norm": 0.08976497501134872,
        "learning_rate": 5.5890168290522595e-06,
        "epoch": 4.410983170947741,
        "step": 4980
    },
    {
        "loss": 0.1348,
        "grad_norm": 65.02389526367188,
        "learning_rate": 5.580159433126662e-06,
        "epoch": 4.419840566873339,
        "step": 4990
    },
    {
        "loss": 0.0988,
        "grad_norm": 54.178863525390625,
        "learning_rate": 5.571302037201063e-06,
        "epoch": 4.428697962798937,
        "step": 5000
    },
    {
        "loss": 0.1207,
        "grad_norm": 0.11969707161188126,
        "learning_rate": 5.562444641275465e-06,
        "epoch": 4.437555358724535,
        "step": 5010
    },
    {
        "loss": 0.0081,
        "grad_norm": 0.23030902445316315,
        "learning_rate": 5.553587245349868e-06,
        "epoch": 4.446412754650133,
        "step": 5020
    },
    {
        "loss": 0.0893,
        "grad_norm": 34.12007522583008,
        "learning_rate": 5.544729849424269e-06,
        "epoch": 4.455270150575731,
        "step": 5030
    },
    {
        "loss": 0.0659,
        "grad_norm": 0.11967584490776062,
        "learning_rate": 5.535872453498672e-06,
        "epoch": 4.464127546501329,
        "step": 5040
    },
    {
        "loss": 0.0752,
        "grad_norm": 13.95203971862793,
        "learning_rate": 5.527015057573074e-06,
        "epoch": 4.472984942426926,
        "step": 5050
    },
    {
        "loss": 0.072,
        "grad_norm": 80.08551788330078,
        "learning_rate": 5.518157661647477e-06,
        "epoch": 4.481842338352524,
        "step": 5060
    },
    {
        "loss": 0.0728,
        "grad_norm": 0.3898667097091675,
        "learning_rate": 5.509300265721878e-06,
        "epoch": 4.490699734278122,
        "step": 5070
    },
    {
        "loss": 0.2818,
        "grad_norm": 252.0382843017578,
        "learning_rate": 5.500442869796281e-06,
        "epoch": 4.49955713020372,
        "step": 5080
    },
    {
        "loss": 0.0527,
        "grad_norm": 147.86419677734375,
        "learning_rate": 5.491585473870682e-06,
        "epoch": 4.508414526129318,
        "step": 5090
    },
    {
        "loss": 0.0624,
        "grad_norm": 2.598461151123047,
        "learning_rate": 5.482728077945084e-06,
        "epoch": 4.517271922054916,
        "step": 5100
    },
    {
        "loss": 0.1047,
        "grad_norm": 0.4106508791446686,
        "learning_rate": 5.473870682019486e-06,
        "epoch": 4.526129317980514,
        "step": 5110
    },
    {
        "loss": 0.1415,
        "grad_norm": 2.5922133922576904,
        "learning_rate": 5.465013286093889e-06,
        "epoch": 4.534986713906112,
        "step": 5120
    },
    {
        "loss": 0.1266,
        "grad_norm": 0.09374444931745529,
        "learning_rate": 5.456155890168291e-06,
        "epoch": 4.54384410983171,
        "step": 5130
    },
    {
        "loss": 0.1153,
        "grad_norm": 49.405792236328125,
        "learning_rate": 5.447298494242693e-06,
        "epoch": 4.552701505757307,
        "step": 5140
    },
    {
        "loss": 0.0339,
        "grad_norm": 67.84147644042969,
        "learning_rate": 5.438441098317095e-06,
        "epoch": 4.561558901682905,
        "step": 5150
    },
    {
        "loss": 0.1954,
        "grad_norm": 0.09749623388051987,
        "learning_rate": 5.429583702391498e-06,
        "epoch": 4.570416297608503,
        "step": 5160
    },
    {
        "loss": 0.0287,
        "grad_norm": 0.10291076451539993,
        "learning_rate": 5.4207263064659e-06,
        "epoch": 4.579273693534101,
        "step": 5170
    },
    {
        "loss": 0.0912,
        "grad_norm": 21.232868194580078,
        "learning_rate": 5.411868910540301e-06,
        "epoch": 4.588131089459699,
        "step": 5180
    },
    {
        "loss": 0.1019,
        "grad_norm": 44.08971405029297,
        "learning_rate": 5.4030115146147035e-06,
        "epoch": 4.596988485385297,
        "step": 5190
    },
    {
        "loss": 0.1317,
        "grad_norm": 43.34023666381836,
        "learning_rate": 5.394154118689106e-06,
        "epoch": 4.605845881310895,
        "step": 5200
    },
    {
        "loss": 0.0943,
        "grad_norm": 0.08782890439033508,
        "learning_rate": 5.3852967227635076e-06,
        "epoch": 4.614703277236492,
        "step": 5210
    },
    {
        "loss": 0.0858,
        "grad_norm": 117.54219818115234,
        "learning_rate": 5.37643932683791e-06,
        "epoch": 4.62356067316209,
        "step": 5220
    },
    {
        "loss": 0.0942,
        "grad_norm": 0.07199160754680634,
        "learning_rate": 5.3675819309123125e-06,
        "epoch": 4.632418069087688,
        "step": 5230
    },
    {
        "loss": 0.0159,
        "grad_norm": 1.8903322219848633,
        "learning_rate": 5.358724534986715e-06,
        "epoch": 4.641275465013286,
        "step": 5240
    },
    {
        "loss": 0.1175,
        "grad_norm": 0.15520136058330536,
        "learning_rate": 5.3498671390611165e-06,
        "epoch": 4.650132860938884,
        "step": 5250
    },
    {
        "loss": 0.0422,
        "grad_norm": 0.15694645047187805,
        "learning_rate": 5.341009743135519e-06,
        "epoch": 4.658990256864482,
        "step": 5260
    },
    {
        "loss": 0.0218,
        "grad_norm": 0.09995272010564804,
        "learning_rate": 5.3321523472099214e-06,
        "epoch": 4.66784765279008,
        "step": 5270
    },
    {
        "loss": 0.0395,
        "grad_norm": 0.8648533821105957,
        "learning_rate": 5.323294951284322e-06,
        "epoch": 4.676705048715678,
        "step": 5280
    },
    {
        "loss": 0.0897,
        "grad_norm": 0.06631257385015488,
        "learning_rate": 5.314437555358725e-06,
        "epoch": 4.685562444641276,
        "step": 5290
    },
    {
        "loss": 0.1176,
        "grad_norm": 0.28600582480430603,
        "learning_rate": 5.305580159433127e-06,
        "epoch": 4.694419840566873,
        "step": 5300
    },
    {
        "loss": 0.0878,
        "grad_norm": 6.311934947967529,
        "learning_rate": 5.296722763507529e-06,
        "epoch": 4.703277236492471,
        "step": 5310
    },
    {
        "loss": 0.1317,
        "grad_norm": 7.2423882484436035,
        "learning_rate": 5.287865367581931e-06,
        "epoch": 4.712134632418069,
        "step": 5320
    },
    {
        "loss": 0.1779,
        "grad_norm": 0.08469478040933609,
        "learning_rate": 5.279007971656334e-06,
        "epoch": 4.720992028343667,
        "step": 5330
    },
    {
        "loss": 0.0442,
        "grad_norm": 2.7452707290649414,
        "learning_rate": 5.270150575730736e-06,
        "epoch": 4.729849424269265,
        "step": 5340
    },
    {
        "loss": 0.2036,
        "grad_norm": 55.535770416259766,
        "learning_rate": 5.261293179805138e-06,
        "epoch": 4.738706820194863,
        "step": 5350
    },
    {
        "loss": 0.1449,
        "grad_norm": 0.14245066046714783,
        "learning_rate": 5.25243578387954e-06,
        "epoch": 4.747564216120461,
        "step": 5360
    },
    {
        "loss": 0.0253,
        "grad_norm": 0.19173236191272736,
        "learning_rate": 5.243578387953942e-06,
        "epoch": 4.756421612046059,
        "step": 5370
    },
    {
        "loss": 0.1693,
        "grad_norm": 0.10381633043289185,
        "learning_rate": 5.234720992028343e-06,
        "epoch": 4.765279007971657,
        "step": 5380
    },
    {
        "loss": 0.0405,
        "grad_norm": 3.314427614212036,
        "learning_rate": 5.225863596102746e-06,
        "epoch": 4.774136403897254,
        "step": 5390
    },
    {
        "loss": 0.0414,
        "grad_norm": 0.06871019303798676,
        "learning_rate": 5.217006200177148e-06,
        "epoch": 4.782993799822852,
        "step": 5400
    },
    {
        "loss": 0.1605,
        "grad_norm": 0.5759869813919067,
        "learning_rate": 5.208148804251551e-06,
        "epoch": 4.79185119574845,
        "step": 5410
    },
    {
        "loss": 0.1,
        "grad_norm": 50.35334777832031,
        "learning_rate": 5.199291408325952e-06,
        "epoch": 4.800708591674048,
        "step": 5420
    },
    {
        "loss": 0.1481,
        "grad_norm": 0.06953806430101395,
        "learning_rate": 5.190434012400355e-06,
        "epoch": 4.809565987599646,
        "step": 5430
    },
    {
        "loss": 0.0833,
        "grad_norm": 120.25167846679688,
        "learning_rate": 5.181576616474757e-06,
        "epoch": 4.818423383525244,
        "step": 5440
    },
    {
        "loss": 0.0776,
        "grad_norm": 0.6967997550964355,
        "learning_rate": 5.17271922054916e-06,
        "epoch": 4.827280779450842,
        "step": 5450
    },
    {
        "loss": 0.0263,
        "grad_norm": 12.888989448547363,
        "learning_rate": 5.1638618246235605e-06,
        "epoch": 4.83613817537644,
        "step": 5460
    },
    {
        "loss": 0.1441,
        "grad_norm": 141.670654296875,
        "learning_rate": 5.155004428697963e-06,
        "epoch": 4.844995571302038,
        "step": 5470
    },
    {
        "loss": 0.0581,
        "grad_norm": 0.2469334453344345,
        "learning_rate": 5.146147032772365e-06,
        "epoch": 4.853852967227635,
        "step": 5480
    },
    {
        "loss": 0.0969,
        "grad_norm": 0.41010016202926636,
        "learning_rate": 5.137289636846767e-06,
        "epoch": 4.862710363153233,
        "step": 5490
    },
    {
        "loss": 0.106,
        "grad_norm": 0.10518839955329895,
        "learning_rate": 5.1284322409211695e-06,
        "epoch": 4.871567759078831,
        "step": 5500
    },
    {
        "loss": 0.2631,
        "grad_norm": 0.0967891737818718,
        "learning_rate": 5.119574844995572e-06,
        "epoch": 4.880425155004429,
        "step": 5510
    },
    {
        "loss": 0.1647,
        "grad_norm": 0.07884415239095688,
        "learning_rate": 5.110717449069974e-06,
        "epoch": 4.889282550930027,
        "step": 5520
    },
    {
        "loss": 0.1012,
        "grad_norm": 0.6183837652206421,
        "learning_rate": 5.101860053144376e-06,
        "epoch": 4.898139946855625,
        "step": 5530
    },
    {
        "loss": 0.0828,
        "grad_norm": 0.10800045728683472,
        "learning_rate": 5.0930026572187784e-06,
        "epoch": 4.906997342781223,
        "step": 5540
    },
    {
        "loss": 0.0303,
        "grad_norm": 44.9383544921875,
        "learning_rate": 5.084145261293181e-06,
        "epoch": 4.9158547387068205,
        "step": 5550
    },
    {
        "loss": 0.1012,
        "grad_norm": 57.709678649902344,
        "learning_rate": 5.075287865367582e-06,
        "epoch": 4.9247121346324185,
        "step": 5560
    },
    {
        "loss": 0.0964,
        "grad_norm": 0.7594762444496155,
        "learning_rate": 5.066430469441984e-06,
        "epoch": 4.933569530558016,
        "step": 5570
    },
    {
        "loss": 0.1168,
        "grad_norm": 12.996216773986816,
        "learning_rate": 5.0575730735163866e-06,
        "epoch": 4.942426926483614,
        "step": 5580
    },
    {
        "loss": 0.1647,
        "grad_norm": 74.49772644042969,
        "learning_rate": 5.048715677590789e-06,
        "epoch": 4.951284322409212,
        "step": 5590
    },
    {
        "loss": 0.0199,
        "grad_norm": 0.12009954452514648,
        "learning_rate": 5.039858281665191e-06,
        "epoch": 4.9601417183348095,
        "step": 5600
    },
    {
        "loss": 0.1212,
        "grad_norm": 74.95893859863281,
        "learning_rate": 5.031000885739593e-06,
        "epoch": 4.9689991142604075,
        "step": 5610
    },
    {
        "loss": 0.1599,
        "grad_norm": 34.71544647216797,
        "learning_rate": 5.0221434898139955e-06,
        "epoch": 4.9778565101860055,
        "step": 5620
    },
    {
        "loss": 0.1236,
        "grad_norm": 0.43326422572135925,
        "learning_rate": 5.013286093888398e-06,
        "epoch": 4.9867139061116035,
        "step": 5630
    },
    {
        "loss": 0.085,
        "grad_norm": 0.07129109650850296,
        "learning_rate": 5.0044286979628e-06,
        "epoch": 4.995571302037201,
        "step": 5640
    },
    {
        "eval_loss": 0.16326819360256195,
        "eval_accuracy": 0.97099,
        "eval_precision": 0.97161,
        "eval_recall": 0.97032,
        "eval_f1": 0.97097,
        "eval_runtime": 150.1048,
        "eval_samples_per_second": 60.165,
        "eval_steps_per_second": 3.764,
        "epoch": 5.0,
        "step": 5645
    },
    {
        "loss": 0.1146,
        "grad_norm": 0.07518176734447479,
        "learning_rate": 4.995571302037201e-06,
        "epoch": 5.0044286979627985,
        "step": 5650
    },
    {
        "loss": 0.0932,
        "grad_norm": 0.28894904255867004,
        "learning_rate": 4.986713906111604e-06,
        "epoch": 5.0132860938883965,
        "step": 5660
    },
    {
        "loss": 0.1814,
        "grad_norm": 122.03028106689453,
        "learning_rate": 4.977856510186005e-06,
        "epoch": 5.0221434898139945,
        "step": 5670
    },
    {
        "loss": 0.1067,
        "grad_norm": 0.08781798928976059,
        "learning_rate": 4.968999114260408e-06,
        "epoch": 5.0310008857395925,
        "step": 5680
    },
    {
        "loss": 0.0036,
        "grad_norm": 0.0607290081679821,
        "learning_rate": 4.96014171833481e-06,
        "epoch": 5.0398582816651905,
        "step": 5690
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.13745661079883575,
        "learning_rate": 4.951284322409212e-06,
        "epoch": 5.048715677590788,
        "step": 5700
    },
    {
        "loss": 0.0669,
        "grad_norm": 2.73866868019104,
        "learning_rate": 4.942426926483614e-06,
        "epoch": 5.057573073516386,
        "step": 5710
    },
    {
        "loss": 0.1398,
        "grad_norm": 0.1082836166024208,
        "learning_rate": 4.933569530558016e-06,
        "epoch": 5.066430469441984,
        "step": 5720
    },
    {
        "loss": 0.0665,
        "grad_norm": 0.054329823702573776,
        "learning_rate": 4.924712134632418e-06,
        "epoch": 5.075287865367582,
        "step": 5730
    },
    {
        "loss": 0.1047,
        "grad_norm": 0.1488438993692398,
        "learning_rate": 4.915854738706821e-06,
        "epoch": 5.0841452612931795,
        "step": 5740
    },
    {
        "loss": 0.0643,
        "grad_norm": 49.537200927734375,
        "learning_rate": 4.906997342781223e-06,
        "epoch": 5.093002657218777,
        "step": 5750
    },
    {
        "loss": 0.0455,
        "grad_norm": 148.73956298828125,
        "learning_rate": 4.898139946855625e-06,
        "epoch": 5.101860053144375,
        "step": 5760
    },
    {
        "loss": 0.0166,
        "grad_norm": 0.07284277677536011,
        "learning_rate": 4.8892825509300264e-06,
        "epoch": 5.110717449069973,
        "step": 5770
    },
    {
        "loss": 0.2001,
        "grad_norm": 0.082914799451828,
        "learning_rate": 4.880425155004429e-06,
        "epoch": 5.119574844995571,
        "step": 5780
    },
    {
        "loss": 0.1509,
        "grad_norm": 2.9501092433929443,
        "learning_rate": 4.871567759078831e-06,
        "epoch": 5.128432240921169,
        "step": 5790
    },
    {
        "loss": 0.0157,
        "grad_norm": 0.09567715227603912,
        "learning_rate": 4.862710363153234e-06,
        "epoch": 5.137289636846767,
        "step": 5800
    },
    {
        "loss": 0.1345,
        "grad_norm": 138.0227508544922,
        "learning_rate": 4.8538529672276354e-06,
        "epoch": 5.146147032772365,
        "step": 5810
    },
    {
        "loss": 0.0565,
        "grad_norm": 0.1188403069972992,
        "learning_rate": 4.844995571302038e-06,
        "epoch": 5.155004428697962,
        "step": 5820
    },
    {
        "loss": 0.119,
        "grad_norm": 35.753116607666016,
        "learning_rate": 4.8361381753764395e-06,
        "epoch": 5.16386182462356,
        "step": 5830
    },
    {
        "loss": 0.0457,
        "grad_norm": 1.5558863878250122,
        "learning_rate": 4.827280779450842e-06,
        "epoch": 5.172719220549158,
        "step": 5840
    },
    {
        "loss": 0.1211,
        "grad_norm": 0.12331641465425491,
        "learning_rate": 4.818423383525244e-06,
        "epoch": 5.181576616474756,
        "step": 5850
    },
    {
        "loss": 0.0564,
        "grad_norm": 0.11410755664110184,
        "learning_rate": 4.809565987599646e-06,
        "epoch": 5.190434012400354,
        "step": 5860
    },
    {
        "loss": 0.0821,
        "grad_norm": 0.08991162478923798,
        "learning_rate": 4.8007085916740485e-06,
        "epoch": 5.199291408325952,
        "step": 5870
    },
    {
        "loss": 0.1179,
        "grad_norm": 2.883524179458618,
        "learning_rate": 4.79185119574845e-06,
        "epoch": 5.20814880425155,
        "step": 5880
    },
    {
        "loss": 0.0898,
        "grad_norm": 15.399092674255371,
        "learning_rate": 4.7829937998228525e-06,
        "epoch": 5.217006200177148,
        "step": 5890
    },
    {
        "loss": 0.0366,
        "grad_norm": 0.08457353711128235,
        "learning_rate": 4.774136403897255e-06,
        "epoch": 5.225863596102746,
        "step": 5900
    },
    {
        "loss": 0.08,
        "grad_norm": 0.51216059923172,
        "learning_rate": 4.765279007971657e-06,
        "epoch": 5.234720992028343,
        "step": 5910
    },
    {
        "loss": 0.1054,
        "grad_norm": 158.7257080078125,
        "learning_rate": 4.756421612046059e-06,
        "epoch": 5.243578387953941,
        "step": 5920
    },
    {
        "loss": 0.0104,
        "grad_norm": 0.10830134898424149,
        "learning_rate": 4.747564216120461e-06,
        "epoch": 5.252435783879539,
        "step": 5930
    },
    {
        "loss": 0.002,
        "grad_norm": 0.061725687235593796,
        "learning_rate": 4.738706820194863e-06,
        "epoch": 5.261293179805137,
        "step": 5940
    },
    {
        "loss": 0.0742,
        "grad_norm": 3.862663984298706,
        "learning_rate": 4.729849424269265e-06,
        "epoch": 5.270150575730735,
        "step": 5950
    },
    {
        "loss": 0.0571,
        "grad_norm": 164.20510864257812,
        "learning_rate": 4.720992028343667e-06,
        "epoch": 5.279007971656333,
        "step": 5960
    },
    {
        "loss": 0.035,
        "grad_norm": 0.03827187046408653,
        "learning_rate": 4.71213463241807e-06,
        "epoch": 5.287865367581931,
        "step": 5970
    },
    {
        "loss": 0.0991,
        "grad_norm": 0.12613098323345184,
        "learning_rate": 4.703277236492472e-06,
        "epoch": 5.296722763507529,
        "step": 5980
    },
    {
        "loss": 0.1182,
        "grad_norm": 0.04960412532091141,
        "learning_rate": 4.694419840566874e-06,
        "epoch": 5.305580159433127,
        "step": 5990
    },
    {
        "loss": 0.027,
        "grad_norm": 110.75603485107422,
        "learning_rate": 4.685562444641275e-06,
        "epoch": 5.314437555358724,
        "step": 6000
    },
    {
        "loss": 0.0839,
        "grad_norm": 0.180263489484787,
        "learning_rate": 4.676705048715678e-06,
        "epoch": 5.323294951284322,
        "step": 6010
    },
    {
        "loss": 0.1426,
        "grad_norm": 1.0707073211669922,
        "learning_rate": 4.66784765279008e-06,
        "epoch": 5.33215234720992,
        "step": 6020
    },
    {
        "loss": 0.0464,
        "grad_norm": 2.649235486984253,
        "learning_rate": 4.658990256864483e-06,
        "epoch": 5.341009743135518,
        "step": 6030
    },
    {
        "loss": 0.0446,
        "grad_norm": 43.831031799316406,
        "learning_rate": 4.650132860938884e-06,
        "epoch": 5.349867139061116,
        "step": 6040
    },
    {
        "loss": 0.0362,
        "grad_norm": 0.0549992099404335,
        "learning_rate": 4.641275465013286e-06,
        "epoch": 5.358724534986714,
        "step": 6050
    },
    {
        "loss": 0.0597,
        "grad_norm": 61.448238372802734,
        "learning_rate": 4.632418069087688e-06,
        "epoch": 5.367581930912312,
        "step": 6060
    },
    {
        "loss": 0.1262,
        "grad_norm": 84.46305847167969,
        "learning_rate": 4.623560673162091e-06,
        "epoch": 5.37643932683791,
        "step": 6070
    },
    {
        "loss": 0.0509,
        "grad_norm": 0.10224805772304535,
        "learning_rate": 4.614703277236493e-06,
        "epoch": 5.385296722763507,
        "step": 6080
    },
    {
        "loss": 0.0974,
        "grad_norm": 0.07646039873361588,
        "learning_rate": 4.605845881310895e-06,
        "epoch": 5.394154118689105,
        "step": 6090
    },
    {
        "loss": 0.1083,
        "grad_norm": 131.981201171875,
        "learning_rate": 4.596988485385297e-06,
        "epoch": 5.403011514614703,
        "step": 6100
    },
    {
        "loss": 0.0922,
        "grad_norm": 0.11771876364946365,
        "learning_rate": 4.588131089459699e-06,
        "epoch": 5.411868910540301,
        "step": 6110
    },
    {
        "loss": 0.0265,
        "grad_norm": 0.06684520840644836,
        "learning_rate": 4.579273693534101e-06,
        "epoch": 5.420726306465899,
        "step": 6120
    },
    {
        "loss": 0.0097,
        "grad_norm": 0.08912424743175507,
        "learning_rate": 4.570416297608504e-06,
        "epoch": 5.429583702391497,
        "step": 6130
    },
    {
        "loss": 0.0932,
        "grad_norm": 23.356908798217773,
        "learning_rate": 4.5615589016829055e-06,
        "epoch": 5.438441098317095,
        "step": 6140
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.04812800511717796,
        "learning_rate": 4.552701505757308e-06,
        "epoch": 5.447298494242693,
        "step": 6150
    },
    {
        "loss": 0.0518,
        "grad_norm": 0.6573323011398315,
        "learning_rate": 4.5438441098317095e-06,
        "epoch": 5.45615589016829,
        "step": 6160
    },
    {
        "loss": 0.0235,
        "grad_norm": 145.80921936035156,
        "learning_rate": 4.534986713906112e-06,
        "epoch": 5.465013286093888,
        "step": 6170
    },
    {
        "loss": 0.0561,
        "grad_norm": 0.03635896369814873,
        "learning_rate": 4.5261293179805144e-06,
        "epoch": 5.473870682019486,
        "step": 6180
    },
    {
        "loss": 0.0317,
        "grad_norm": 0.061536844819784164,
        "learning_rate": 4.517271922054916e-06,
        "epoch": 5.482728077945084,
        "step": 6190
    },
    {
        "loss": 0.1304,
        "grad_norm": 0.04981251806020737,
        "learning_rate": 4.5084145261293185e-06,
        "epoch": 5.491585473870682,
        "step": 6200
    },
    {
        "loss": 0.1358,
        "grad_norm": 140.7860565185547,
        "learning_rate": 4.499557130203721e-06,
        "epoch": 5.50044286979628,
        "step": 6210
    },
    {
        "loss": 0.0424,
        "grad_norm": 127.5897445678711,
        "learning_rate": 4.4906997342781226e-06,
        "epoch": 5.509300265721878,
        "step": 6220
    },
    {
        "loss": 0.1334,
        "grad_norm": 116.31021118164062,
        "learning_rate": 4.481842338352524e-06,
        "epoch": 5.518157661647476,
        "step": 6230
    },
    {
        "loss": 0.0076,
        "grad_norm": 0.24134907126426697,
        "learning_rate": 4.472984942426927e-06,
        "epoch": 5.527015057573074,
        "step": 6240
    },
    {
        "loss": 0.086,
        "grad_norm": 0.09357314556837082,
        "learning_rate": 4.464127546501329e-06,
        "epoch": 5.535872453498671,
        "step": 6250
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.059385303407907486,
        "learning_rate": 4.4552701505757315e-06,
        "epoch": 5.544729849424269,
        "step": 6260
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.0596415214240551,
        "learning_rate": 4.446412754650133e-06,
        "epoch": 5.553587245349867,
        "step": 6270
    },
    {
        "loss": 0.0469,
        "grad_norm": 25.322158813476562,
        "learning_rate": 4.437555358724535e-06,
        "epoch": 5.562444641275465,
        "step": 6280
    },
    {
        "loss": 0.0784,
        "grad_norm": 17.01251983642578,
        "learning_rate": 4.428697962798937e-06,
        "epoch": 5.571302037201063,
        "step": 6290
    },
    {
        "loss": 0.1278,
        "grad_norm": 0.5329475402832031,
        "learning_rate": 4.41984056687334e-06,
        "epoch": 5.580159433126661,
        "step": 6300
    },
    {
        "loss": 0.044,
        "grad_norm": 0.045072104781866074,
        "learning_rate": 4.410983170947742e-06,
        "epoch": 5.589016829052259,
        "step": 6310
    },
    {
        "loss": 0.1286,
        "grad_norm": 0.04118598625063896,
        "learning_rate": 4.402125775022144e-06,
        "epoch": 5.597874224977857,
        "step": 6320
    },
    {
        "loss": 0.0366,
        "grad_norm": 0.03449518606066704,
        "learning_rate": 4.393268379096546e-06,
        "epoch": 5.606731620903455,
        "step": 6330
    },
    {
        "loss": 0.0491,
        "grad_norm": 0.06893112510442734,
        "learning_rate": 4.384410983170948e-06,
        "epoch": 5.615589016829052,
        "step": 6340
    },
    {
        "loss": 0.1111,
        "grad_norm": 0.0366937629878521,
        "learning_rate": 4.37555358724535e-06,
        "epoch": 5.62444641275465,
        "step": 6350
    },
    {
        "loss": 0.1205,
        "grad_norm": 88.63916778564453,
        "learning_rate": 4.366696191319753e-06,
        "epoch": 5.633303808680248,
        "step": 6360
    },
    {
        "loss": 0.0805,
        "grad_norm": 0.07857286930084229,
        "learning_rate": 4.357838795394154e-06,
        "epoch": 5.642161204605846,
        "step": 6370
    },
    {
        "loss": 0.0703,
        "grad_norm": 5.723936557769775,
        "learning_rate": 4.348981399468557e-06,
        "epoch": 5.651018600531444,
        "step": 6380
    },
    {
        "loss": 0.0785,
        "grad_norm": 0.05219241604208946,
        "learning_rate": 4.340124003542958e-06,
        "epoch": 5.659875996457042,
        "step": 6390
    },
    {
        "loss": 0.0022,
        "grad_norm": 0.09465158730745316,
        "learning_rate": 4.331266607617361e-06,
        "epoch": 5.66873339238264,
        "step": 6400
    },
    {
        "loss": 0.177,
        "grad_norm": 32.47216033935547,
        "learning_rate": 4.322409211691763e-06,
        "epoch": 5.677590788308238,
        "step": 6410
    },
    {
        "loss": 0.067,
        "grad_norm": 87.94173431396484,
        "learning_rate": 4.313551815766165e-06,
        "epoch": 5.686448184233836,
        "step": 6420
    },
    {
        "loss": 0.0902,
        "grad_norm": 0.4878392517566681,
        "learning_rate": 4.304694419840567e-06,
        "epoch": 5.695305580159433,
        "step": 6430
    },
    {
        "loss": 0.0882,
        "grad_norm": 0.047230370342731476,
        "learning_rate": 4.295837023914969e-06,
        "epoch": 5.704162976085031,
        "step": 6440
    },
    {
        "loss": 0.0286,
        "grad_norm": 0.07433320581912994,
        "learning_rate": 4.2869796279893714e-06,
        "epoch": 5.713020372010629,
        "step": 6450
    },
    {
        "loss": 0.042,
        "grad_norm": 0.0371188148856163,
        "learning_rate": 4.278122232063774e-06,
        "epoch": 5.721877767936227,
        "step": 6460
    },
    {
        "loss": 0.0324,
        "grad_norm": 0.0829462856054306,
        "learning_rate": 4.2692648361381755e-06,
        "epoch": 5.730735163861825,
        "step": 6470
    },
    {
        "loss": 0.0531,
        "grad_norm": 0.04740562289953232,
        "learning_rate": 4.260407440212578e-06,
        "epoch": 5.739592559787423,
        "step": 6480
    },
    {
        "loss": 0.0187,
        "grad_norm": 0.03012165240943432,
        "learning_rate": 4.25155004428698e-06,
        "epoch": 5.748449955713021,
        "step": 6490
    },
    {
        "loss": 0.0169,
        "grad_norm": 0.05107036978006363,
        "learning_rate": 4.242692648361382e-06,
        "epoch": 5.757307351638619,
        "step": 6500
    },
    {
        "loss": 0.084,
        "grad_norm": 189.6749725341797,
        "learning_rate": 4.233835252435784e-06,
        "epoch": 5.766164747564217,
        "step": 6510
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.5928244590759277,
        "learning_rate": 4.224977856510186e-06,
        "epoch": 5.775022143489814,
        "step": 6520
    },
    {
        "loss": 0.0887,
        "grad_norm": 76.86597442626953,
        "learning_rate": 4.2161204605845885e-06,
        "epoch": 5.783879539415412,
        "step": 6530
    },
    {
        "loss": 0.096,
        "grad_norm": 0.0450691357254982,
        "learning_rate": 4.207263064658991e-06,
        "epoch": 5.79273693534101,
        "step": 6540
    },
    {
        "loss": 0.1121,
        "grad_norm": 102.72261810302734,
        "learning_rate": 4.198405668733393e-06,
        "epoch": 5.801594331266608,
        "step": 6550
    },
    {
        "loss": 0.0949,
        "grad_norm": 0.056640759110450745,
        "learning_rate": 4.189548272807795e-06,
        "epoch": 5.810451727192206,
        "step": 6560
    },
    {
        "loss": 0.0024,
        "grad_norm": 0.060014281421899796,
        "learning_rate": 4.180690876882197e-06,
        "epoch": 5.819309123117804,
        "step": 6570
    },
    {
        "loss": 0.0501,
        "grad_norm": 0.01809031330049038,
        "learning_rate": 4.171833480956599e-06,
        "epoch": 5.8281665190434015,
        "step": 6580
    },
    {
        "loss": 0.0554,
        "grad_norm": 0.11581949889659882,
        "learning_rate": 4.1629760850310016e-06,
        "epoch": 5.837023914968999,
        "step": 6590
    },
    {
        "loss": 0.0834,
        "grad_norm": 21.480854034423828,
        "learning_rate": 4.154118689105404e-06,
        "epoch": 5.845881310894597,
        "step": 6600
    },
    {
        "loss": 0.0589,
        "grad_norm": 84.65708923339844,
        "learning_rate": 4.145261293179806e-06,
        "epoch": 5.854738706820195,
        "step": 6610
    },
    {
        "loss": 0.0869,
        "grad_norm": 5.285351753234863,
        "learning_rate": 4.136403897254207e-06,
        "epoch": 5.863596102745793,
        "step": 6620
    },
    {
        "loss": 0.015,
        "grad_norm": 0.13516943156719208,
        "learning_rate": 4.12754650132861e-06,
        "epoch": 5.8724534986713905,
        "step": 6630
    },
    {
        "loss": 0.0431,
        "grad_norm": 0.2581881582736969,
        "learning_rate": 4.118689105403012e-06,
        "epoch": 5.8813108945969885,
        "step": 6640
    },
    {
        "loss": 0.0465,
        "grad_norm": 35.612491607666016,
        "learning_rate": 4.109831709477414e-06,
        "epoch": 5.8901682905225865,
        "step": 6650
    },
    {
        "loss": 0.086,
        "grad_norm": 0.03640736639499664,
        "learning_rate": 4.100974313551816e-06,
        "epoch": 5.8990256864481845,
        "step": 6660
    },
    {
        "loss": 0.1148,
        "grad_norm": 0.031345184892416,
        "learning_rate": 4.092116917626218e-06,
        "epoch": 5.9078830823737825,
        "step": 6670
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.11939239501953125,
        "learning_rate": 4.08325952170062e-06,
        "epoch": 5.9167404782993795,
        "step": 6680
    },
    {
        "loss": 0.0021,
        "grad_norm": 5.870989799499512,
        "learning_rate": 4.074402125775023e-06,
        "epoch": 5.9255978742249775,
        "step": 6690
    },
    {
        "loss": 0.1161,
        "grad_norm": 48.84564208984375,
        "learning_rate": 4.065544729849424e-06,
        "epoch": 5.9344552701505755,
        "step": 6700
    },
    {
        "loss": 0.0389,
        "grad_norm": 0.0349050909280777,
        "learning_rate": 4.056687333923827e-06,
        "epoch": 5.9433126660761735,
        "step": 6710
    },
    {
        "loss": 0.0734,
        "grad_norm": 3.475029468536377,
        "learning_rate": 4.047829937998229e-06,
        "epoch": 5.9521700620017715,
        "step": 6720
    },
    {
        "loss": 0.049,
        "grad_norm": 0.06236005574464798,
        "learning_rate": 4.038972542072631e-06,
        "epoch": 5.961027457927369,
        "step": 6730
    },
    {
        "loss": 0.0455,
        "grad_norm": 0.08164322376251221,
        "learning_rate": 4.030115146147033e-06,
        "epoch": 5.969884853852967,
        "step": 6740
    },
    {
        "loss": 0.1221,
        "grad_norm": 0.05187001824378967,
        "learning_rate": 4.021257750221435e-06,
        "epoch": 5.978742249778565,
        "step": 6750
    },
    {
        "loss": 0.1132,
        "grad_norm": 0.7567829489707947,
        "learning_rate": 4.012400354295837e-06,
        "epoch": 5.987599645704163,
        "step": 6760
    },
    {
        "loss": 0.0774,
        "grad_norm": 0.03907499834895134,
        "learning_rate": 4.00354295837024e-06,
        "epoch": 5.9964570416297605,
        "step": 6770
    },
    {
        "eval_loss": 0.1555883288383484,
        "eval_accuracy": 0.9752,
        "eval_precision": 0.97625,
        "eval_recall": 0.97409,
        "eval_f1": 0.97517,
        "eval_runtime": 150.1403,
        "eval_samples_per_second": 60.15,
        "eval_steps_per_second": 3.763,
        "epoch": 6.0,
        "step": 6774
    },
    {
        "loss": 0.0846,
        "grad_norm": 0.07016365975141525,
        "learning_rate": 3.9946855624446415e-06,
        "epoch": 6.005314437555358,
        "step": 6780
    },
    {
        "loss": 0.0636,
        "grad_norm": 24.07868194580078,
        "learning_rate": 3.985828166519043e-06,
        "epoch": 6.014171833480956,
        "step": 6790
    },
    {
        "loss": 0.0268,
        "grad_norm": 69.6318359375,
        "learning_rate": 3.9769707705934455e-06,
        "epoch": 6.023029229406554,
        "step": 6800
    },
    {
        "loss": 0.0172,
        "grad_norm": 0.07157383859157562,
        "learning_rate": 3.968113374667848e-06,
        "epoch": 6.031886625332152,
        "step": 6810
    },
    {
        "loss": 0.0229,
        "grad_norm": 0.12995927035808563,
        "learning_rate": 3.9592559787422504e-06,
        "epoch": 6.04074402125775,
        "step": 6820
    },
    {
        "loss": 0.0657,
        "grad_norm": 0.051391735672950745,
        "learning_rate": 3.950398582816652e-06,
        "epoch": 6.049601417183348,
        "step": 6830
    },
    {
        "loss": 0.0937,
        "grad_norm": 0.054663628339767456,
        "learning_rate": 3.9415411868910545e-06,
        "epoch": 6.058458813108946,
        "step": 6840
    },
    {
        "loss": 0.0603,
        "grad_norm": 0.06721413135528564,
        "learning_rate": 3.932683790965456e-06,
        "epoch": 6.067316209034544,
        "step": 6850
    },
    {
        "loss": 0.001,
        "grad_norm": 0.09438153356313705,
        "learning_rate": 3.9238263950398586e-06,
        "epoch": 6.076173604960141,
        "step": 6860
    },
    {
        "loss": 0.0042,
        "grad_norm": 0.048938922584056854,
        "learning_rate": 3.914968999114261e-06,
        "epoch": 6.085031000885739,
        "step": 6870
    },
    {
        "loss": 0.0847,
        "grad_norm": 0.19781547784805298,
        "learning_rate": 3.9061116031886635e-06,
        "epoch": 6.093888396811337,
        "step": 6880
    },
    {
        "loss": 0.0399,
        "grad_norm": 0.04883338138461113,
        "learning_rate": 3.897254207263065e-06,
        "epoch": 6.102745792736935,
        "step": 6890
    },
    {
        "loss": 0.0099,
        "grad_norm": 0.045564714819192886,
        "learning_rate": 3.888396811337467e-06,
        "epoch": 6.111603188662533,
        "step": 6900
    },
    {
        "loss": 0.1433,
        "grad_norm": 0.03215953707695007,
        "learning_rate": 3.879539415411869e-06,
        "epoch": 6.120460584588131,
        "step": 6910
    },
    {
        "loss": 0.0388,
        "grad_norm": 0.07981475442647934,
        "learning_rate": 3.870682019486272e-06,
        "epoch": 6.129317980513729,
        "step": 6920
    },
    {
        "loss": 0.001,
        "grad_norm": 0.061808764934539795,
        "learning_rate": 3.861824623560673e-06,
        "epoch": 6.138175376439327,
        "step": 6930
    },
    {
        "loss": 0.1235,
        "grad_norm": 0.04249163717031479,
        "learning_rate": 3.852967227635076e-06,
        "epoch": 6.147032772364924,
        "step": 6940
    },
    {
        "loss": 0.0534,
        "grad_norm": 17.544178009033203,
        "learning_rate": 3.844109831709478e-06,
        "epoch": 6.155890168290522,
        "step": 6950
    },
    {
        "loss": 0.0552,
        "grad_norm": 118.08052062988281,
        "learning_rate": 3.83525243578388e-06,
        "epoch": 6.16474756421612,
        "step": 6960
    },
    {
        "loss": 0.0522,
        "grad_norm": 164.11805725097656,
        "learning_rate": 3.826395039858282e-06,
        "epoch": 6.173604960141718,
        "step": 6970
    },
    {
        "loss": 0.0432,
        "grad_norm": 0.27300921082496643,
        "learning_rate": 3.817537643932684e-06,
        "epoch": 6.182462356067316,
        "step": 6980
    },
    {
        "loss": 0.0922,
        "grad_norm": 44.619544982910156,
        "learning_rate": 3.8086802480070863e-06,
        "epoch": 6.191319751992914,
        "step": 6990
    },
    {
        "loss": 0.0646,
        "grad_norm": 0.0355331152677536,
        "learning_rate": 3.7998228520814883e-06,
        "epoch": 6.200177147918512,
        "step": 7000
    },
    {
        "loss": 0.0598,
        "grad_norm": 4.42365026473999,
        "learning_rate": 3.7909654561558907e-06,
        "epoch": 6.20903454384411,
        "step": 7010
    },
    {
        "loss": 0.0367,
        "grad_norm": 0.04997925087809563,
        "learning_rate": 3.7821080602302928e-06,
        "epoch": 6.217891939769708,
        "step": 7020
    },
    {
        "loss": 0.0837,
        "grad_norm": 16.288515090942383,
        "learning_rate": 3.7732506643046944e-06,
        "epoch": 6.226749335695305,
        "step": 7030
    },
    {
        "loss": 0.0498,
        "grad_norm": 111.09879302978516,
        "learning_rate": 3.764393268379097e-06,
        "epoch": 6.235606731620903,
        "step": 7040
    },
    {
        "loss": 0.0518,
        "grad_norm": 0.04771648347377777,
        "learning_rate": 3.755535872453499e-06,
        "epoch": 6.244464127546501,
        "step": 7050
    },
    {
        "loss": 0.008,
        "grad_norm": 0.02026214823126793,
        "learning_rate": 3.7466784765279013e-06,
        "epoch": 6.253321523472099,
        "step": 7060
    },
    {
        "loss": 0.0162,
        "grad_norm": 0.02841024659574032,
        "learning_rate": 3.737821080602303e-06,
        "epoch": 6.262178919397697,
        "step": 7070
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.025297803804278374,
        "learning_rate": 3.7289636846767054e-06,
        "epoch": 6.271036315323295,
        "step": 7080
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.050815336406230927,
        "learning_rate": 3.7201062887511074e-06,
        "epoch": 6.279893711248893,
        "step": 7090
    },
    {
        "loss": 0.041,
        "grad_norm": 38.60904312133789,
        "learning_rate": 3.71124889282551e-06,
        "epoch": 6.288751107174491,
        "step": 7100
    },
    {
        "loss": 0.0331,
        "grad_norm": 14.100274085998535,
        "learning_rate": 3.702391496899912e-06,
        "epoch": 6.297608503100088,
        "step": 7110
    },
    {
        "loss": 0.0964,
        "grad_norm": 31.692346572875977,
        "learning_rate": 3.6935341009743135e-06,
        "epoch": 6.306465899025686,
        "step": 7120
    },
    {
        "loss": 0.0363,
        "grad_norm": 63.54181671142578,
        "learning_rate": 3.684676705048716e-06,
        "epoch": 6.315323294951284,
        "step": 7130
    },
    {
        "loss": 0.001,
        "grad_norm": 0.046854496002197266,
        "learning_rate": 3.675819309123118e-06,
        "epoch": 6.324180690876882,
        "step": 7140
    },
    {
        "loss": 0.0676,
        "grad_norm": 24.54328727722168,
        "learning_rate": 3.6669619131975205e-06,
        "epoch": 6.33303808680248,
        "step": 7150
    },
    {
        "loss": 0.078,
        "grad_norm": 0.5256655216217041,
        "learning_rate": 3.6581045172719225e-06,
        "epoch": 6.341895482728078,
        "step": 7160
    },
    {
        "loss": 0.0407,
        "grad_norm": 0.1319580227136612,
        "learning_rate": 3.649247121346324e-06,
        "epoch": 6.350752878653676,
        "step": 7170
    },
    {
        "loss": 0.0793,
        "grad_norm": 265.89202880859375,
        "learning_rate": 3.6403897254207266e-06,
        "epoch": 6.359610274579274,
        "step": 7180
    },
    {
        "loss": 0.0806,
        "grad_norm": 32.87297821044922,
        "learning_rate": 3.6315323294951286e-06,
        "epoch": 6.368467670504872,
        "step": 7190
    },
    {
        "loss": 0.034,
        "grad_norm": 0.0485653281211853,
        "learning_rate": 3.622674933569531e-06,
        "epoch": 6.377325066430469,
        "step": 7200
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.04593044891953468,
        "learning_rate": 3.6138175376439327e-06,
        "epoch": 6.386182462356067,
        "step": 7210
    },
    {
        "loss": 0.0151,
        "grad_norm": 0.11354944109916687,
        "learning_rate": 3.604960141718335e-06,
        "epoch": 6.395039858281665,
        "step": 7220
    },
    {
        "loss": 0.0476,
        "grad_norm": 42.73421859741211,
        "learning_rate": 3.596102745792737e-06,
        "epoch": 6.403897254207263,
        "step": 7230
    },
    {
        "loss": 0.0251,
        "grad_norm": 1.4059853553771973,
        "learning_rate": 3.5872453498671396e-06,
        "epoch": 6.412754650132861,
        "step": 7240
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.03798140957951546,
        "learning_rate": 3.5783879539415416e-06,
        "epoch": 6.421612046058459,
        "step": 7250
    },
    {
        "loss": 0.039,
        "grad_norm": 0.06567586213350296,
        "learning_rate": 3.5695305580159433e-06,
        "epoch": 6.430469441984057,
        "step": 7260
    },
    {
        "loss": 0.0227,
        "grad_norm": 3.98142147064209,
        "learning_rate": 3.5606731620903457e-06,
        "epoch": 6.439326837909655,
        "step": 7270
    },
    {
        "loss": 0.1155,
        "grad_norm": 34.032840728759766,
        "learning_rate": 3.5518157661647477e-06,
        "epoch": 6.448184233835253,
        "step": 7280
    },
    {
        "loss": 0.0073,
        "grad_norm": 0.01900707557797432,
        "learning_rate": 3.54295837023915e-06,
        "epoch": 6.45704162976085,
        "step": 7290
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.02882951684296131,
        "learning_rate": 3.5341009743135522e-06,
        "epoch": 6.465899025686448,
        "step": 7300
    },
    {
        "loss": 0.0835,
        "grad_norm": 0.03291637450456619,
        "learning_rate": 3.5252435783879543e-06,
        "epoch": 6.474756421612046,
        "step": 7310
    },
    {
        "loss": 0.0759,
        "grad_norm": 0.05419468879699707,
        "learning_rate": 3.5163861824623563e-06,
        "epoch": 6.483613817537644,
        "step": 7320
    },
    {
        "loss": 0.1148,
        "grad_norm": 0.01280729565769434,
        "learning_rate": 3.5075287865367587e-06,
        "epoch": 6.492471213463242,
        "step": 7330
    },
    {
        "loss": 0.0854,
        "grad_norm": 0.017970848828554153,
        "learning_rate": 3.4986713906111608e-06,
        "epoch": 6.50132860938884,
        "step": 7340
    },
    {
        "loss": 0.0864,
        "grad_norm": 48.408447265625,
        "learning_rate": 3.4898139946855624e-06,
        "epoch": 6.510186005314438,
        "step": 7350
    },
    {
        "loss": 0.047,
        "grad_norm": 0.04291778802871704,
        "learning_rate": 3.480956598759965e-06,
        "epoch": 6.519043401240036,
        "step": 7360
    },
    {
        "loss": 0.0444,
        "grad_norm": 0.026221709325909615,
        "learning_rate": 3.472099202834367e-06,
        "epoch": 6.527900797165634,
        "step": 7370
    },
    {
        "loss": 0.001,
        "grad_norm": 0.04343234747648239,
        "learning_rate": 3.4632418069087693e-06,
        "epoch": 6.536758193091231,
        "step": 7380
    },
    {
        "loss": 0.0406,
        "grad_norm": 0.03479015454649925,
        "learning_rate": 3.4543844109831714e-06,
        "epoch": 6.545615589016829,
        "step": 7390
    },
    {
        "loss": 0.0325,
        "grad_norm": 0.022406432777643204,
        "learning_rate": 3.445527015057573e-06,
        "epoch": 6.554472984942427,
        "step": 7400
    },
    {
        "loss": 0.0084,
        "grad_norm": 0.894972562789917,
        "learning_rate": 3.4366696191319754e-06,
        "epoch": 6.563330380868025,
        "step": 7410
    },
    {
        "loss": 0.0036,
        "grad_norm": 0.7037526369094849,
        "learning_rate": 3.4278122232063775e-06,
        "epoch": 6.572187776793623,
        "step": 7420
    },
    {
        "loss": 0.0488,
        "grad_norm": 0.2296018749475479,
        "learning_rate": 3.41895482728078e-06,
        "epoch": 6.581045172719221,
        "step": 7430
    },
    {
        "loss": 0.0863,
        "grad_norm": 0.032158441841602325,
        "learning_rate": 3.410097431355182e-06,
        "epoch": 6.589902568644819,
        "step": 7440
    },
    {
        "loss": 0.0567,
        "grad_norm": 0.044903840869665146,
        "learning_rate": 3.401240035429584e-06,
        "epoch": 6.598759964570416,
        "step": 7450
    },
    {
        "loss": 0.0132,
        "grad_norm": 1.597344160079956,
        "learning_rate": 3.392382639503986e-06,
        "epoch": 6.607617360496015,
        "step": 7460
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.02963555045425892,
        "learning_rate": 3.3835252435783885e-06,
        "epoch": 6.616474756421612,
        "step": 7470
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.029991894960403442,
        "learning_rate": 3.3746678476527905e-06,
        "epoch": 6.62533215234721,
        "step": 7480
    },
    {
        "loss": 0.0408,
        "grad_norm": 0.010745851323008537,
        "learning_rate": 3.365810451727192e-06,
        "epoch": 6.634189548272808,
        "step": 7490
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.018701789900660515,
        "learning_rate": 3.3569530558015946e-06,
        "epoch": 6.643046944198406,
        "step": 7500
    },
    {
        "loss": 0.0822,
        "grad_norm": 0.014242306351661682,
        "learning_rate": 3.3480956598759966e-06,
        "epoch": 6.651904340124004,
        "step": 7510
    },
    {
        "loss": 0.0848,
        "grad_norm": 0.02548026666045189,
        "learning_rate": 3.339238263950399e-06,
        "epoch": 6.660761736049602,
        "step": 7520
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.11441393196582794,
        "learning_rate": 3.330380868024801e-06,
        "epoch": 6.6696191319752,
        "step": 7530
    },
    {
        "loss": 0.011,
        "grad_norm": 0.030091894790530205,
        "learning_rate": 3.3215234720992027e-06,
        "epoch": 6.678476527900797,
        "step": 7540
    },
    {
        "loss": 0.001,
        "grad_norm": 0.013363751582801342,
        "learning_rate": 3.312666076173605e-06,
        "epoch": 6.687333923826395,
        "step": 7550
    },
    {
        "loss": 0.0844,
        "grad_norm": 0.02790059894323349,
        "learning_rate": 3.303808680248007e-06,
        "epoch": 6.696191319751993,
        "step": 7560
    },
    {
        "loss": 0.0196,
        "grad_norm": 264.4253845214844,
        "learning_rate": 3.2949512843224096e-06,
        "epoch": 6.705048715677591,
        "step": 7570
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.019868208095431328,
        "learning_rate": 3.2860938883968117e-06,
        "epoch": 6.713906111603189,
        "step": 7580
    },
    {
        "loss": 0.0203,
        "grad_norm": 4.763735294342041,
        "learning_rate": 3.2772364924712137e-06,
        "epoch": 6.722763507528787,
        "step": 7590
    },
    {
        "loss": 0.0465,
        "grad_norm": 0.26778239011764526,
        "learning_rate": 3.2683790965456157e-06,
        "epoch": 6.731620903454385,
        "step": 7600
    },
    {
        "loss": 0.0415,
        "grad_norm": 0.044264357537031174,
        "learning_rate": 3.259521700620018e-06,
        "epoch": 6.7404782993799826,
        "step": 7610
    },
    {
        "loss": 0.0897,
        "grad_norm": 0.017900552600622177,
        "learning_rate": 3.2506643046944202e-06,
        "epoch": 6.7493356953055805,
        "step": 7620
    },
    {
        "loss": 0.0386,
        "grad_norm": 3.6055057048797607,
        "learning_rate": 3.241806908768822e-06,
        "epoch": 6.758193091231178,
        "step": 7630
    },
    {
        "loss": 0.0602,
        "grad_norm": 0.03354591876268387,
        "learning_rate": 3.2329495128432243e-06,
        "epoch": 6.767050487156776,
        "step": 7640
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.0679883062839508,
        "learning_rate": 3.2240921169176263e-06,
        "epoch": 6.775907883082374,
        "step": 7650
    },
    {
        "loss": 0.013,
        "grad_norm": 0.2282877117395401,
        "learning_rate": 3.2152347209920288e-06,
        "epoch": 6.7847652790079716,
        "step": 7660
    },
    {
        "loss": 0.0414,
        "grad_norm": 0.03422883152961731,
        "learning_rate": 3.206377325066431e-06,
        "epoch": 6.7936226749335695,
        "step": 7670
    },
    {
        "loss": 0.0387,
        "grad_norm": 53.8209342956543,
        "learning_rate": 3.197519929140833e-06,
        "epoch": 6.8024800708591675,
        "step": 7680
    },
    {
        "loss": 0.0393,
        "grad_norm": 0.03718575835227966,
        "learning_rate": 3.188662533215235e-06,
        "epoch": 6.8113374667847655,
        "step": 7690
    },
    {
        "loss": 0.0521,
        "grad_norm": 0.015325815416872501,
        "learning_rate": 3.1798051372896373e-06,
        "epoch": 6.8201948627103635,
        "step": 7700
    },
    {
        "loss": 0.0421,
        "grad_norm": 5.37584924697876,
        "learning_rate": 3.1709477413640394e-06,
        "epoch": 6.829052258635961,
        "step": 7710
    },
    {
        "loss": 0.0488,
        "grad_norm": 0.046127885580062866,
        "learning_rate": 3.162090345438442e-06,
        "epoch": 6.8379096545615585,
        "step": 7720
    },
    {
        "loss": 0.0933,
        "grad_norm": 0.04332161322236061,
        "learning_rate": 3.1532329495128434e-06,
        "epoch": 6.8467670504871565,
        "step": 7730
    },
    {
        "loss": 0.0396,
        "grad_norm": 0.04318317770957947,
        "learning_rate": 3.1443755535872455e-06,
        "epoch": 6.8556244464127545,
        "step": 7740
    },
    {
        "loss": 0.0745,
        "grad_norm": 0.04527191072702408,
        "learning_rate": 3.135518157661648e-06,
        "epoch": 6.8644818423383525,
        "step": 7750
    },
    {
        "loss": 0.0163,
        "grad_norm": 0.10331392288208008,
        "learning_rate": 3.12666076173605e-06,
        "epoch": 6.87333923826395,
        "step": 7760
    },
    {
        "loss": 0.0852,
        "grad_norm": 159.7010955810547,
        "learning_rate": 3.1178033658104516e-06,
        "epoch": 6.882196634189548,
        "step": 7770
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.027265867218375206,
        "learning_rate": 3.108945969884854e-06,
        "epoch": 6.891054030115146,
        "step": 7780
    },
    {
        "loss": 0.0497,
        "grad_norm": 0.0259840227663517,
        "learning_rate": 3.100088573959256e-06,
        "epoch": 6.899911426040744,
        "step": 7790
    },
    {
        "loss": 0.0937,
        "grad_norm": 346.1205139160156,
        "learning_rate": 3.0912311780336585e-06,
        "epoch": 6.908768821966342,
        "step": 7800
    },
    {
        "loss": 0.1343,
        "grad_norm": 16.142433166503906,
        "learning_rate": 3.0823737821080605e-06,
        "epoch": 6.917626217891939,
        "step": 7810
    },
    {
        "loss": 0.1184,
        "grad_norm": 0.015489600598812103,
        "learning_rate": 3.0735163861824626e-06,
        "epoch": 6.926483613817537,
        "step": 7820
    },
    {
        "loss": 0.0731,
        "grad_norm": 0.02846648544073105,
        "learning_rate": 3.0646589902568646e-06,
        "epoch": 6.935341009743135,
        "step": 7830
    },
    {
        "loss": 0.1214,
        "grad_norm": 191.0819549560547,
        "learning_rate": 3.055801594331267e-06,
        "epoch": 6.944198405668733,
        "step": 7840
    },
    {
        "loss": 0.0044,
        "grad_norm": 3.133701801300049,
        "learning_rate": 3.046944198405669e-06,
        "epoch": 6.953055801594331,
        "step": 7850
    },
    {
        "loss": 0.0482,
        "grad_norm": 5.177959442138672,
        "learning_rate": 3.0380868024800715e-06,
        "epoch": 6.961913197519929,
        "step": 7860
    },
    {
        "loss": 0.0425,
        "grad_norm": 4.088061332702637,
        "learning_rate": 3.029229406554473e-06,
        "epoch": 6.970770593445527,
        "step": 7870
    },
    {
        "loss": 0.0635,
        "grad_norm": 0.0798429474234581,
        "learning_rate": 3.020372010628875e-06,
        "epoch": 6.979627989371125,
        "step": 7880
    },
    {
        "loss": 0.0544,
        "grad_norm": 4.722679138183594,
        "learning_rate": 3.0115146147032776e-06,
        "epoch": 6.988485385296723,
        "step": 7890
    },
    {
        "loss": 0.0625,
        "grad_norm": 14.256326675415039,
        "learning_rate": 3.0026572187776797e-06,
        "epoch": 6.99734278122232,
        "step": 7900
    },
    {
        "eval_loss": 0.1561637967824936,
        "eval_accuracy": 0.97387,
        "eval_precision": 0.98526,
        "eval_recall": 0.96213,
        "eval_f1": 0.97355,
        "eval_runtime": 150.1297,
        "eval_samples_per_second": 60.155,
        "eval_steps_per_second": 3.763,
        "epoch": 7.0,
        "step": 7903
    },
    {
        "loss": 0.0629,
        "grad_norm": 0.038653820753097534,
        "learning_rate": 2.9937998228520813e-06,
        "epoch": 7.006200177147918,
        "step": 7910
    },
    {
        "loss": 0.0815,
        "grad_norm": 0.6352139711380005,
        "learning_rate": 2.9849424269264837e-06,
        "epoch": 7.015057573073516,
        "step": 7920
    },
    {
        "loss": 0.0524,
        "grad_norm": 0.02915966883301735,
        "learning_rate": 2.9760850310008858e-06,
        "epoch": 7.023914968999114,
        "step": 7930
    },
    {
        "loss": 0.0077,
        "grad_norm": 0.020822620019316673,
        "learning_rate": 2.9672276350752882e-06,
        "epoch": 7.032772364924712,
        "step": 7940
    },
    {
        "loss": 0.0355,
        "grad_norm": 0.02442692033946514,
        "learning_rate": 2.9583702391496903e-06,
        "epoch": 7.04162976085031,
        "step": 7950
    },
    {
        "loss": 0.1337,
        "grad_norm": 0.03610258549451828,
        "learning_rate": 2.9495128432240923e-06,
        "epoch": 7.050487156775908,
        "step": 7960
    },
    {
        "loss": 0.001,
        "grad_norm": 0.020357728004455566,
        "learning_rate": 2.9406554472984943e-06,
        "epoch": 7.059344552701506,
        "step": 7970
    },
    {
        "loss": 0.0381,
        "grad_norm": 0.03915733844041824,
        "learning_rate": 2.9317980513728968e-06,
        "epoch": 7.068201948627103,
        "step": 7980
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.03686806187033653,
        "learning_rate": 2.922940655447299e-06,
        "epoch": 7.077059344552701,
        "step": 7990
    },
    {
        "loss": 0.0223,
        "grad_norm": 193.44464111328125,
        "learning_rate": 2.9140832595217013e-06,
        "epoch": 7.085916740478299,
        "step": 8000
    },
    {
        "loss": 0.0254,
        "grad_norm": 0.019323062151670456,
        "learning_rate": 2.905225863596103e-06,
        "epoch": 7.094774136403897,
        "step": 8010
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.062126610428094864,
        "learning_rate": 2.896368467670505e-06,
        "epoch": 7.103631532329495,
        "step": 8020
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.01830674521625042,
        "learning_rate": 2.8875110717449074e-06,
        "epoch": 7.112488928255093,
        "step": 8030
    },
    {
        "loss": 0.0163,
        "grad_norm": 152.50791931152344,
        "learning_rate": 2.8786536758193094e-06,
        "epoch": 7.121346324180691,
        "step": 8040
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.01845664717257023,
        "learning_rate": 2.8697962798937114e-06,
        "epoch": 7.130203720106289,
        "step": 8050
    },
    {
        "loss": 0.0386,
        "grad_norm": 62.96970748901367,
        "learning_rate": 2.8609388839681135e-06,
        "epoch": 7.139061116031886,
        "step": 8060
    },
    {
        "loss": 0.0739,
        "grad_norm": 0.019780656322836876,
        "learning_rate": 2.852081488042516e-06,
        "epoch": 7.147918511957484,
        "step": 8070
    },
    {
        "loss": 0.0348,
        "grad_norm": 1.8421393632888794,
        "learning_rate": 2.843224092116918e-06,
        "epoch": 7.156775907883082,
        "step": 8080
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.02344544604420662,
        "learning_rate": 2.8343666961913204e-06,
        "epoch": 7.16563330380868,
        "step": 8090
    },
    {
        "loss": 0.044,
        "grad_norm": 0.017260026186704636,
        "learning_rate": 2.825509300265722e-06,
        "epoch": 7.174490699734278,
        "step": 8100
    },
    {
        "loss": 0.1015,
        "grad_norm": 0.4636271893978119,
        "learning_rate": 2.816651904340124e-06,
        "epoch": 7.183348095659876,
        "step": 8110
    },
    {
        "loss": 0.0523,
        "grad_norm": 5.361510753631592,
        "learning_rate": 2.8077945084145265e-06,
        "epoch": 7.192205491585474,
        "step": 8120
    },
    {
        "loss": 0.0577,
        "grad_norm": 0.029554683715105057,
        "learning_rate": 2.7989371124889285e-06,
        "epoch": 7.201062887511072,
        "step": 8130
    },
    {
        "loss": 0.1645,
        "grad_norm": 0.05081408843398094,
        "learning_rate": 2.790079716563331e-06,
        "epoch": 7.20992028343667,
        "step": 8140
    },
    {
        "loss": 0.0026,
        "grad_norm": 0.022714652121067047,
        "learning_rate": 2.7812223206377326e-06,
        "epoch": 7.218777679362267,
        "step": 8150
    },
    {
        "loss": 0.0074,
        "grad_norm": 0.019129913300275803,
        "learning_rate": 2.7723649247121346e-06,
        "epoch": 7.227635075287865,
        "step": 8160
    },
    {
        "loss": 0.1767,
        "grad_norm": 42.3958625793457,
        "learning_rate": 2.763507528786537e-06,
        "epoch": 7.236492471213463,
        "step": 8170
    },
    {
        "loss": 0.0545,
        "grad_norm": 0.02225068025290966,
        "learning_rate": 2.754650132860939e-06,
        "epoch": 7.245349867139061,
        "step": 8180
    },
    {
        "loss": 0.0811,
        "grad_norm": 5.823775768280029,
        "learning_rate": 2.745792736935341e-06,
        "epoch": 7.254207263064659,
        "step": 8190
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.01033310778439045,
        "learning_rate": 2.736935341009743e-06,
        "epoch": 7.263064658990257,
        "step": 8200
    },
    {
        "loss": 0.0418,
        "grad_norm": 0.02345716953277588,
        "learning_rate": 2.7280779450841456e-06,
        "epoch": 7.271922054915855,
        "step": 8210
    },
    {
        "loss": 0.084,
        "grad_norm": 0.015811527147889137,
        "learning_rate": 2.7192205491585477e-06,
        "epoch": 7.280779450841453,
        "step": 8220
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.016723893582820892,
        "learning_rate": 2.71036315323295e-06,
        "epoch": 7.289636846767051,
        "step": 8230
    },
    {
        "loss": 0.0406,
        "grad_norm": 0.07665029168128967,
        "learning_rate": 2.7015057573073517e-06,
        "epoch": 7.298494242692648,
        "step": 8240
    },
    {
        "loss": 0.0768,
        "grad_norm": 0.07367123663425446,
        "learning_rate": 2.6926483613817538e-06,
        "epoch": 7.307351638618246,
        "step": 8250
    },
    {
        "loss": 0.0061,
        "grad_norm": 0.015508372336626053,
        "learning_rate": 2.6837909654561562e-06,
        "epoch": 7.316209034543844,
        "step": 8260
    },
    {
        "loss": 0.0035,
        "grad_norm": 0.0931299477815628,
        "learning_rate": 2.6749335695305583e-06,
        "epoch": 7.325066430469442,
        "step": 8270
    },
    {
        "loss": 0.0785,
        "grad_norm": 0.012272709980607033,
        "learning_rate": 2.6660761736049607e-06,
        "epoch": 7.33392382639504,
        "step": 8280
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.03749619424343109,
        "learning_rate": 2.6572187776793623e-06,
        "epoch": 7.342781222320638,
        "step": 8290
    },
    {
        "loss": 0.09,
        "grad_norm": 462.3894348144531,
        "learning_rate": 2.6483613817537644e-06,
        "epoch": 7.351638618246236,
        "step": 8300
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.01343893725425005,
        "learning_rate": 2.639503985828167e-06,
        "epoch": 7.360496014171834,
        "step": 8310
    },
    {
        "loss": 0.0008,
        "grad_norm": 5.424544811248779,
        "learning_rate": 2.630646589902569e-06,
        "epoch": 7.369353410097431,
        "step": 8320
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.013416866771876812,
        "learning_rate": 2.621789193976971e-06,
        "epoch": 7.378210806023029,
        "step": 8330
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.022766442969441414,
        "learning_rate": 2.612931798051373e-06,
        "epoch": 7.387068201948627,
        "step": 8340
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.04325350373983383,
        "learning_rate": 2.6040744021257754e-06,
        "epoch": 7.395925597874225,
        "step": 8350
    },
    {
        "loss": 0.0632,
        "grad_norm": 0.028963249176740646,
        "learning_rate": 2.5952170062001774e-06,
        "epoch": 7.404782993799823,
        "step": 8360
    },
    {
        "loss": 0.0562,
        "grad_norm": 0.019488733261823654,
        "learning_rate": 2.58635961027458e-06,
        "epoch": 7.413640389725421,
        "step": 8370
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.038158513605594635,
        "learning_rate": 2.5775022143489815e-06,
        "epoch": 7.422497785651019,
        "step": 8380
    },
    {
        "loss": 0.1445,
        "grad_norm": 0.013427987694740295,
        "learning_rate": 2.5686448184233835e-06,
        "epoch": 7.431355181576617,
        "step": 8390
    },
    {
        "loss": 0.0474,
        "grad_norm": 0.43638551235198975,
        "learning_rate": 2.559787422497786e-06,
        "epoch": 7.440212577502215,
        "step": 8400
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.09747099131345749,
        "learning_rate": 2.550930026572188e-06,
        "epoch": 7.449069973427812,
        "step": 8410
    },
    {
        "loss": 0.0208,
        "grad_norm": 92.55564880371094,
        "learning_rate": 2.5420726306465904e-06,
        "epoch": 7.45792736935341,
        "step": 8420
    },
    {
        "loss": 0.0584,
        "grad_norm": 179.61973571777344,
        "learning_rate": 2.533215234720992e-06,
        "epoch": 7.466784765279008,
        "step": 8430
    },
    {
        "loss": 0.0883,
        "grad_norm": 0.03373359888792038,
        "learning_rate": 2.5243578387953945e-06,
        "epoch": 7.475642161204606,
        "step": 8440
    },
    {
        "loss": 0.0527,
        "grad_norm": 0.014285288751125336,
        "learning_rate": 2.5155004428697965e-06,
        "epoch": 7.484499557130204,
        "step": 8450
    },
    {
        "loss": 0.0419,
        "grad_norm": 0.017187733203172684,
        "learning_rate": 2.506643046944199e-06,
        "epoch": 7.493356953055802,
        "step": 8460
    },
    {
        "loss": 0.0348,
        "grad_norm": 0.029203375801444054,
        "learning_rate": 2.4977856510186006e-06,
        "epoch": 7.5022143489814,
        "step": 8470
    },
    {
        "loss": 0.0642,
        "grad_norm": 0.04649782553315163,
        "learning_rate": 2.4889282550930026e-06,
        "epoch": 7.511071744906998,
        "step": 8480
    },
    {
        "loss": 0.0016,
        "grad_norm": 38.65314483642578,
        "learning_rate": 2.480070859167405e-06,
        "epoch": 7.519929140832595,
        "step": 8490
    },
    {
        "loss": 0.0183,
        "grad_norm": 58.35579299926758,
        "learning_rate": 2.471213463241807e-06,
        "epoch": 7.528786536758193,
        "step": 8500
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.04624200612306595,
        "learning_rate": 2.462356067316209e-06,
        "epoch": 7.537643932683791,
        "step": 8510
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.01592841185629368,
        "learning_rate": 2.4534986713906116e-06,
        "epoch": 7.546501328609389,
        "step": 8520
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.014269588515162468,
        "learning_rate": 2.4446412754650132e-06,
        "epoch": 7.555358724534987,
        "step": 8530
    },
    {
        "loss": 0.0695,
        "grad_norm": 0.023470524698495865,
        "learning_rate": 2.4357838795394157e-06,
        "epoch": 7.564216120460585,
        "step": 8540
    },
    {
        "loss": 0.0036,
        "grad_norm": 0.07770050317049026,
        "learning_rate": 2.4269264836138177e-06,
        "epoch": 7.573073516386183,
        "step": 8550
    },
    {
        "loss": 0.02,
        "grad_norm": 0.01287211012095213,
        "learning_rate": 2.4180690876882197e-06,
        "epoch": 7.581930912311781,
        "step": 8560
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.116356261074543,
        "learning_rate": 2.409211691762622e-06,
        "epoch": 7.590788308237379,
        "step": 8570
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.019811322912573814,
        "learning_rate": 2.4003542958370242e-06,
        "epoch": 7.599645704162976,
        "step": 8580
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.12980516254901886,
        "learning_rate": 2.3914968999114263e-06,
        "epoch": 7.608503100088574,
        "step": 8590
    },
    {
        "loss": 0.053,
        "grad_norm": 0.02701232209801674,
        "learning_rate": 2.3826395039858283e-06,
        "epoch": 7.617360496014172,
        "step": 8600
    },
    {
        "loss": 0.0077,
        "grad_norm": 0.034722957760095596,
        "learning_rate": 2.3737821080602303e-06,
        "epoch": 7.62621789193977,
        "step": 8610
    },
    {
        "loss": 0.0055,
        "grad_norm": 0.022904934361577034,
        "learning_rate": 2.3649247121346324e-06,
        "epoch": 7.635075287865368,
        "step": 8620
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.02324022352695465,
        "learning_rate": 2.356067316209035e-06,
        "epoch": 7.643932683790966,
        "step": 8630
    },
    {
        "loss": 0.0421,
        "grad_norm": 0.01692000776529312,
        "learning_rate": 2.347209920283437e-06,
        "epoch": 7.6527900797165636,
        "step": 8640
    },
    {
        "loss": 0.0501,
        "grad_norm": 0.010096034035086632,
        "learning_rate": 2.338352524357839e-06,
        "epoch": 7.6616474756421615,
        "step": 8650
    },
    {
        "loss": 0.0277,
        "grad_norm": 0.017530735582113266,
        "learning_rate": 2.3294951284322413e-06,
        "epoch": 7.6705048715677595,
        "step": 8660
    },
    {
        "loss": 0.0743,
        "grad_norm": 0.0082143135368824,
        "learning_rate": 2.320637732506643e-06,
        "epoch": 7.679362267493357,
        "step": 8670
    },
    {
        "loss": 0.0457,
        "grad_norm": 0.020109176635742188,
        "learning_rate": 2.3117803365810454e-06,
        "epoch": 7.688219663418955,
        "step": 8680
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.5598817467689514,
        "learning_rate": 2.3029229406554474e-06,
        "epoch": 7.6970770593445526,
        "step": 8690
    },
    {
        "loss": 0.0291,
        "grad_norm": 0.07302992790937424,
        "learning_rate": 2.2940655447298495e-06,
        "epoch": 7.7059344552701505,
        "step": 8700
    },
    {
        "loss": 0.0118,
        "grad_norm": 0.04034654423594475,
        "learning_rate": 2.285208148804252e-06,
        "epoch": 7.7147918511957485,
        "step": 8710
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.015475543215870857,
        "learning_rate": 2.276350752878654e-06,
        "epoch": 7.7236492471213465,
        "step": 8720
    },
    {
        "loss": 0.0365,
        "grad_norm": 0.02898479253053665,
        "learning_rate": 2.267493356953056e-06,
        "epoch": 7.7325066430469445,
        "step": 8730
    },
    {
        "loss": 0.045,
        "grad_norm": 121.98942565917969,
        "learning_rate": 2.258635961027458e-06,
        "epoch": 7.741364038972542,
        "step": 8740
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.014356065541505814,
        "learning_rate": 2.2497785651018605e-06,
        "epoch": 7.75022143489814,
        "step": 8750
    },
    {
        "loss": 0.156,
        "grad_norm": 0.014095542952418327,
        "learning_rate": 2.240921169176262e-06,
        "epoch": 7.7590788308237375,
        "step": 8760
    },
    {
        "loss": 0.0706,
        "grad_norm": 0.026440519839525223,
        "learning_rate": 2.2320637732506645e-06,
        "epoch": 7.7679362267493355,
        "step": 8770
    },
    {
        "loss": 0.0424,
        "grad_norm": 0.04053911566734314,
        "learning_rate": 2.2232063773250666e-06,
        "epoch": 7.7767936226749335,
        "step": 8780
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.04464433714747429,
        "learning_rate": 2.2143489813994686e-06,
        "epoch": 7.785651018600531,
        "step": 8790
    },
    {
        "loss": 0.0544,
        "grad_norm": 0.016338303685188293,
        "learning_rate": 2.205491585473871e-06,
        "epoch": 7.794508414526129,
        "step": 8800
    },
    {
        "loss": 0.0397,
        "grad_norm": 0.011806633323431015,
        "learning_rate": 2.196634189548273e-06,
        "epoch": 7.803365810451727,
        "step": 8810
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.027783963829278946,
        "learning_rate": 2.187776793622675e-06,
        "epoch": 7.812223206377325,
        "step": 8820
    },
    {
        "loss": 0.0113,
        "grad_norm": 0.029542118310928345,
        "learning_rate": 2.178919397697077e-06,
        "epoch": 7.8210806023029225,
        "step": 8830
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.03824653476476669,
        "learning_rate": 2.170062001771479e-06,
        "epoch": 7.82993799822852,
        "step": 8840
    },
    {
        "loss": 0.0282,
        "grad_norm": 0.009735774248838425,
        "learning_rate": 2.1612046058458816e-06,
        "epoch": 7.838795394154118,
        "step": 8850
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.016423366963863373,
        "learning_rate": 2.1523472099202837e-06,
        "epoch": 7.847652790079716,
        "step": 8860
    },
    {
        "loss": 0.0747,
        "grad_norm": 231.79380798339844,
        "learning_rate": 2.1434898139946857e-06,
        "epoch": 7.856510186005314,
        "step": 8870
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.027331598103046417,
        "learning_rate": 2.1346324180690877e-06,
        "epoch": 7.865367581930912,
        "step": 8880
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.022828657180070877,
        "learning_rate": 2.12577502214349e-06,
        "epoch": 7.87422497785651,
        "step": 8890
    },
    {
        "loss": 0.0163,
        "grad_norm": 0.023689724504947662,
        "learning_rate": 2.116917626217892e-06,
        "epoch": 7.883082373782108,
        "step": 8900
    },
    {
        "loss": 0.068,
        "grad_norm": 0.05120307579636574,
        "learning_rate": 2.1080602302922943e-06,
        "epoch": 7.891939769707706,
        "step": 8910
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.017995204776525497,
        "learning_rate": 2.0992028343666963e-06,
        "epoch": 7.900797165633303,
        "step": 8920
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.05257677286863327,
        "learning_rate": 2.0903454384410983e-06,
        "epoch": 7.909654561558901,
        "step": 8930
    },
    {
        "loss": 0.042,
        "grad_norm": 0.020005935803055763,
        "learning_rate": 2.0814880425155008e-06,
        "epoch": 7.918511957484499,
        "step": 8940
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.011607612483203411,
        "learning_rate": 2.072630646589903e-06,
        "epoch": 7.927369353410097,
        "step": 8950
    },
    {
        "loss": 0.0391,
        "grad_norm": 81.14246368408203,
        "learning_rate": 2.063773250664305e-06,
        "epoch": 7.936226749335695,
        "step": 8960
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.014115077443420887,
        "learning_rate": 2.054915854738707e-06,
        "epoch": 7.945084145261293,
        "step": 8970
    },
    {
        "loss": 0.0771,
        "grad_norm": 232.1785430908203,
        "learning_rate": 2.046058458813109e-06,
        "epoch": 7.953941541186891,
        "step": 8980
    },
    {
        "loss": 0.083,
        "grad_norm": 0.022647486999630928,
        "learning_rate": 2.0372010628875114e-06,
        "epoch": 7.962798937112489,
        "step": 8990
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.007120019756257534,
        "learning_rate": 2.0283436669619134e-06,
        "epoch": 7.971656333038087,
        "step": 9000
    },
    {
        "loss": 0.1308,
        "grad_norm": 13.371310234069824,
        "learning_rate": 2.0194862710363154e-06,
        "epoch": 7.980513728963684,
        "step": 9010
    },
    {
        "loss": 0.0126,
        "grad_norm": 0.0132353650406003,
        "learning_rate": 2.0106288751107175e-06,
        "epoch": 7.989371124889282,
        "step": 9020
    },
    {
        "loss": 0.0424,
        "grad_norm": 0.01781407929956913,
        "learning_rate": 2.00177147918512e-06,
        "epoch": 7.99822852081488,
        "step": 9030
    },
    {
        "eval_loss": 0.1453954428434372,
        "eval_accuracy": 0.97985,
        "eval_precision": 0.98006,
        "eval_recall": 0.97962,
        "eval_f1": 0.97984,
        "eval_runtime": 150.1652,
        "eval_samples_per_second": 60.14,
        "eval_steps_per_second": 3.763,
        "epoch": 8.0,
        "step": 9032
    },
    {
        "loss": 0.0404,
        "grad_norm": 0.11155244708061218,
        "learning_rate": 1.9929140832595215e-06,
        "epoch": 8.007085916740479,
        "step": 9040
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.02175639569759369,
        "learning_rate": 1.984056687333924e-06,
        "epoch": 8.015943312666076,
        "step": 9050
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.019223935902118683,
        "learning_rate": 1.975199291408326e-06,
        "epoch": 8.024800708591673,
        "step": 9060
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.007198133040219545,
        "learning_rate": 1.966341895482728e-06,
        "epoch": 8.033658104517272,
        "step": 9070
    },
    {
        "loss": 0.1097,
        "grad_norm": 0.03959427773952484,
        "learning_rate": 1.9574844995571305e-06,
        "epoch": 8.04251550044287,
        "step": 9080
    },
    {
        "loss": 0.0664,
        "grad_norm": 0.018899187445640564,
        "learning_rate": 1.9486271036315325e-06,
        "epoch": 8.051372896368468,
        "step": 9090
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.012847000733017921,
        "learning_rate": 1.9397697077059346e-06,
        "epoch": 8.060230292294065,
        "step": 9100
    },
    {
        "loss": 0.0343,
        "grad_norm": 0.027110397815704346,
        "learning_rate": 1.9309123117803366e-06,
        "epoch": 8.069087688219664,
        "step": 9110
    },
    {
        "loss": 0.014,
        "grad_norm": 0.006940848659723997,
        "learning_rate": 1.922054915854739e-06,
        "epoch": 8.077945084145261,
        "step": 9120
    },
    {
        "loss": 0.006,
        "grad_norm": 125.4185791015625,
        "learning_rate": 1.913197519929141e-06,
        "epoch": 8.08680248007086,
        "step": 9130
    },
    {
        "loss": 0.0325,
        "grad_norm": 0.01202666386961937,
        "learning_rate": 1.9043401240035431e-06,
        "epoch": 8.095659875996457,
        "step": 9140
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.6101059317588806,
        "learning_rate": 1.8954827280779454e-06,
        "epoch": 8.104517271922054,
        "step": 9150
    },
    {
        "loss": 0.0011,
        "grad_norm": 22.184490203857422,
        "learning_rate": 1.8866253321523472e-06,
        "epoch": 8.113374667847653,
        "step": 9160
    },
    {
        "loss": 0.1007,
        "grad_norm": 0.06640757620334625,
        "learning_rate": 1.8777679362267494e-06,
        "epoch": 8.12223206377325,
        "step": 9170
    },
    {
        "loss": 0.0026,
        "grad_norm": 63.4493522644043,
        "learning_rate": 1.8689105403011515e-06,
        "epoch": 8.131089459698849,
        "step": 9180
    },
    {
        "loss": 0.0399,
        "grad_norm": 0.4200931191444397,
        "learning_rate": 1.8600531443755537e-06,
        "epoch": 8.139946855624446,
        "step": 9190
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.013609436340630054,
        "learning_rate": 1.851195748449956e-06,
        "epoch": 8.148804251550045,
        "step": 9200
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.030767912045121193,
        "learning_rate": 1.842338352524358e-06,
        "epoch": 8.157661647475642,
        "step": 9210
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.157211035490036,
        "learning_rate": 1.8334809565987602e-06,
        "epoch": 8.166519043401241,
        "step": 9220
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.013180680572986603,
        "learning_rate": 1.824623560673162e-06,
        "epoch": 8.175376439326838,
        "step": 9230
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.01511470228433609,
        "learning_rate": 1.8157661647475643e-06,
        "epoch": 8.184233835252435,
        "step": 9240
    },
    {
        "loss": 0.0502,
        "grad_norm": 0.005038809031248093,
        "learning_rate": 1.8069087688219663e-06,
        "epoch": 8.193091231178034,
        "step": 9250
    },
    {
        "loss": 0.0692,
        "grad_norm": 0.008257868699729443,
        "learning_rate": 1.7980513728963686e-06,
        "epoch": 8.201948627103631,
        "step": 9260
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.01396779716014862,
        "learning_rate": 1.7891939769707708e-06,
        "epoch": 8.21080602302923,
        "step": 9270
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.03771008551120758,
        "learning_rate": 1.7803365810451729e-06,
        "epoch": 8.219663418954827,
        "step": 9280
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.015193399973213673,
        "learning_rate": 1.771479185119575e-06,
        "epoch": 8.228520814880426,
        "step": 9290
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.007069417275488377,
        "learning_rate": 1.7626217891939771e-06,
        "epoch": 8.237378210806023,
        "step": 9300
    },
    {
        "loss": 0.0633,
        "grad_norm": 0.02107294276356697,
        "learning_rate": 1.7537643932683794e-06,
        "epoch": 8.24623560673162,
        "step": 9310
    },
    {
        "loss": 0.0364,
        "grad_norm": 0.018258843570947647,
        "learning_rate": 1.7449069973427812e-06,
        "epoch": 8.255093002657219,
        "step": 9320
    },
    {
        "loss": 0.0438,
        "grad_norm": 0.0636492371559143,
        "learning_rate": 1.7360496014171834e-06,
        "epoch": 8.263950398582816,
        "step": 9330
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.017576277256011963,
        "learning_rate": 1.7271922054915857e-06,
        "epoch": 8.272807794508415,
        "step": 9340
    },
    {
        "loss": 0.0252,
        "grad_norm": 0.021037111058831215,
        "learning_rate": 1.7183348095659877e-06,
        "epoch": 8.281665190434012,
        "step": 9350
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.2502491772174835,
        "learning_rate": 1.70947741364039e-06,
        "epoch": 8.29052258635961,
        "step": 9360
    },
    {
        "loss": 0.0046,
        "grad_norm": 0.04382717236876488,
        "learning_rate": 1.700620017714792e-06,
        "epoch": 8.299379982285208,
        "step": 9370
    },
    {
        "loss": 0.1084,
        "grad_norm": 74.70109558105469,
        "learning_rate": 1.6917626217891942e-06,
        "epoch": 8.308237378210807,
        "step": 9380
    },
    {
        "loss": 0.0925,
        "grad_norm": 0.006667802110314369,
        "learning_rate": 1.682905225863596e-06,
        "epoch": 8.317094774136404,
        "step": 9390
    },
    {
        "loss": 0.0506,
        "grad_norm": 0.003936316817998886,
        "learning_rate": 1.6740478299379983e-06,
        "epoch": 8.325952170062001,
        "step": 9400
    },
    {
        "loss": 0.0389,
        "grad_norm": 0.011471216566860676,
        "learning_rate": 1.6651904340124005e-06,
        "epoch": 8.3348095659876,
        "step": 9410
    },
    {
        "loss": 0.0241,
        "grad_norm": 0.012746901251375675,
        "learning_rate": 1.6563330380868026e-06,
        "epoch": 8.343666961913197,
        "step": 9420
    },
    {
        "loss": 0.0349,
        "grad_norm": 0.041514039039611816,
        "learning_rate": 1.6474756421612048e-06,
        "epoch": 8.352524357838796,
        "step": 9430
    },
    {
        "loss": 0.0173,
        "grad_norm": 0.03746592625975609,
        "learning_rate": 1.6386182462356069e-06,
        "epoch": 8.361381753764393,
        "step": 9440
    },
    {
        "loss": 0.063,
        "grad_norm": 0.038786228746175766,
        "learning_rate": 1.629760850310009e-06,
        "epoch": 8.370239149689992,
        "step": 9450
    },
    {
        "loss": 0.0619,
        "grad_norm": 0.007764331065118313,
        "learning_rate": 1.620903454384411e-06,
        "epoch": 8.379096545615589,
        "step": 9460
    },
    {
        "loss": 0.0395,
        "grad_norm": 0.010025604628026485,
        "learning_rate": 1.6120460584588132e-06,
        "epoch": 8.387953941541188,
        "step": 9470
    },
    {
        "loss": 0.0721,
        "grad_norm": 0.01078272145241499,
        "learning_rate": 1.6031886625332154e-06,
        "epoch": 8.396811337466785,
        "step": 9480
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.040181443095207214,
        "learning_rate": 1.5943312666076174e-06,
        "epoch": 8.405668733392382,
        "step": 9490
    },
    {
        "loss": 0.0702,
        "grad_norm": 0.016719087958335876,
        "learning_rate": 1.5854738706820197e-06,
        "epoch": 8.41452612931798,
        "step": 9500
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.0088455555960536,
        "learning_rate": 1.5766164747564217e-06,
        "epoch": 8.423383525243578,
        "step": 9510
    },
    {
        "loss": 0.0303,
        "grad_norm": 0.00853784754872322,
        "learning_rate": 1.567759078830824e-06,
        "epoch": 8.432240921169177,
        "step": 9520
    },
    {
        "loss": 0.0066,
        "grad_norm": 0.2534281313419342,
        "learning_rate": 1.5589016829052258e-06,
        "epoch": 8.441098317094774,
        "step": 9530
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.009399489499628544,
        "learning_rate": 1.550044286979628e-06,
        "epoch": 8.449955713020373,
        "step": 9540
    },
    {
        "loss": 0.0911,
        "grad_norm": 0.01297987625002861,
        "learning_rate": 1.5411868910540303e-06,
        "epoch": 8.45881310894597,
        "step": 9550
    },
    {
        "loss": 0.0434,
        "grad_norm": 20.656286239624023,
        "learning_rate": 1.5323294951284323e-06,
        "epoch": 8.467670504871569,
        "step": 9560
    },
    {
        "loss": 0.0329,
        "grad_norm": 0.049697380512952805,
        "learning_rate": 1.5234720992028345e-06,
        "epoch": 8.476527900797166,
        "step": 9570
    },
    {
        "loss": 0.0789,
        "grad_norm": 0.010919438675045967,
        "learning_rate": 1.5146147032772366e-06,
        "epoch": 8.485385296722763,
        "step": 9580
    },
    {
        "loss": 0.0385,
        "grad_norm": 0.01623857393860817,
        "learning_rate": 1.5057573073516388e-06,
        "epoch": 8.494242692648362,
        "step": 9590
    },
    {
        "loss": 0.0025,
        "grad_norm": 0.023062746971845627,
        "learning_rate": 1.4968999114260406e-06,
        "epoch": 8.503100088573959,
        "step": 9600
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.015840305015444756,
        "learning_rate": 1.4880425155004429e-06,
        "epoch": 8.511957484499558,
        "step": 9610
    },
    {
        "loss": 0.0082,
        "grad_norm": 1.6233896017074585,
        "learning_rate": 1.4791851195748451e-06,
        "epoch": 8.520814880425155,
        "step": 9620
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.026852816343307495,
        "learning_rate": 1.4703277236492472e-06,
        "epoch": 8.529672276350754,
        "step": 9630
    },
    {
        "loss": 0.0152,
        "grad_norm": 0.0156184621155262,
        "learning_rate": 1.4614703277236494e-06,
        "epoch": 8.53852967227635,
        "step": 9640
    },
    {
        "loss": 0.0029,
        "grad_norm": 0.010561294853687286,
        "learning_rate": 1.4526129317980514e-06,
        "epoch": 8.54738706820195,
        "step": 9650
    },
    {
        "loss": 0.0553,
        "grad_norm": 0.0660509318113327,
        "learning_rate": 1.4437555358724537e-06,
        "epoch": 8.556244464127547,
        "step": 9660
    },
    {
        "loss": 0.0092,
        "grad_norm": 0.9013622999191284,
        "learning_rate": 1.4348981399468557e-06,
        "epoch": 8.565101860053144,
        "step": 9670
    },
    {
        "loss": 0.0391,
        "grad_norm": 189.19976806640625,
        "learning_rate": 1.426040744021258e-06,
        "epoch": 8.573959255978743,
        "step": 9680
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.04420541599392891,
        "learning_rate": 1.4171833480956602e-06,
        "epoch": 8.58281665190434,
        "step": 9690
    },
    {
        "loss": 0.0048,
        "grad_norm": 0.05690569803118706,
        "learning_rate": 1.408325952170062e-06,
        "epoch": 8.591674047829938,
        "step": 9700
    },
    {
        "loss": 0.0133,
        "grad_norm": 0.007161220535635948,
        "learning_rate": 1.3994685562444643e-06,
        "epoch": 8.600531443755536,
        "step": 9710
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.007770758122205734,
        "learning_rate": 1.3906111603188663e-06,
        "epoch": 8.609388839681134,
        "step": 9720
    },
    {
        "loss": 0.0115,
        "grad_norm": 0.006711394991725683,
        "learning_rate": 1.3817537643932685e-06,
        "epoch": 8.618246235606732,
        "step": 9730
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.018856659531593323,
        "learning_rate": 1.3728963684676706e-06,
        "epoch": 8.627103631532329,
        "step": 9740
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.0439787432551384,
        "learning_rate": 1.3640389725420728e-06,
        "epoch": 8.635961027457927,
        "step": 9750
    },
    {
        "loss": 0.0893,
        "grad_norm": 0.17575277388095856,
        "learning_rate": 1.355181576616475e-06,
        "epoch": 8.644818423383525,
        "step": 9760
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.00978882983326912,
        "learning_rate": 1.3463241806908769e-06,
        "epoch": 8.653675819309123,
        "step": 9770
    },
    {
        "loss": 0.0618,
        "grad_norm": 0.4179835915565491,
        "learning_rate": 1.3374667847652791e-06,
        "epoch": 8.66253321523472,
        "step": 9780
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.24903614819049835,
        "learning_rate": 1.3286093888396812e-06,
        "epoch": 8.67139061116032,
        "step": 9790
    },
    {
        "loss": 0.0267,
        "grad_norm": 0.01107051596045494,
        "learning_rate": 1.3197519929140834e-06,
        "epoch": 8.680248007085916,
        "step": 9800
    },
    {
        "loss": 0.0129,
        "grad_norm": 0.005365787539631128,
        "learning_rate": 1.3108945969884854e-06,
        "epoch": 8.689105403011515,
        "step": 9810
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.01726766861975193,
        "learning_rate": 1.3020372010628877e-06,
        "epoch": 8.697962798937112,
        "step": 9820
    },
    {
        "loss": 0.015,
        "grad_norm": 0.008383896201848984,
        "learning_rate": 1.29317980513729e-06,
        "epoch": 8.706820194862711,
        "step": 9830
    },
    {
        "loss": 0.0224,
        "grad_norm": 0.021701456978917122,
        "learning_rate": 1.2843224092116918e-06,
        "epoch": 8.715677590788308,
        "step": 9840
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.019421279430389404,
        "learning_rate": 1.275465013286094e-06,
        "epoch": 8.724534986713905,
        "step": 9850
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.023148363456130028,
        "learning_rate": 1.266607617360496e-06,
        "epoch": 8.733392382639504,
        "step": 9860
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.019846351817250252,
        "learning_rate": 1.2577502214348983e-06,
        "epoch": 8.742249778565101,
        "step": 9870
    },
    {
        "loss": 0.0275,
        "grad_norm": 0.004940786864608526,
        "learning_rate": 1.2488928255093003e-06,
        "epoch": 8.7511071744907,
        "step": 9880
    },
    {
        "loss": 0.064,
        "grad_norm": 148.74481201171875,
        "learning_rate": 1.2400354295837025e-06,
        "epoch": 8.759964570416297,
        "step": 9890
    },
    {
        "loss": 0.0039,
        "grad_norm": 0.03673233464360237,
        "learning_rate": 1.2311780336581046e-06,
        "epoch": 8.768821966341896,
        "step": 9900
    },
    {
        "loss": 0.037,
        "grad_norm": 0.007412167731672525,
        "learning_rate": 1.2223206377325066e-06,
        "epoch": 8.777679362267493,
        "step": 9910
    },
    {
        "loss": 0.0316,
        "grad_norm": 0.004512591753154993,
        "learning_rate": 1.2134632418069089e-06,
        "epoch": 8.78653675819309,
        "step": 9920
    },
    {
        "loss": 0.0364,
        "grad_norm": 0.010069284588098526,
        "learning_rate": 1.204605845881311e-06,
        "epoch": 8.79539415411869,
        "step": 9930
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.07502368837594986,
        "learning_rate": 1.1957484499557131e-06,
        "epoch": 8.804251550044286,
        "step": 9940
    },
    {
        "loss": 0.0059,
        "grad_norm": 176.40658569335938,
        "learning_rate": 1.1868910540301152e-06,
        "epoch": 8.813108945969885,
        "step": 9950
    },
    {
        "loss": 0.0065,
        "grad_norm": 0.2409595251083374,
        "learning_rate": 1.1780336581045174e-06,
        "epoch": 8.821966341895482,
        "step": 9960
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.004797365050762892,
        "learning_rate": 1.1691762621789194e-06,
        "epoch": 8.830823737821081,
        "step": 9970
    },
    {
        "loss": 0.07,
        "grad_norm": 0.007692499551922083,
        "learning_rate": 1.1603188662533215e-06,
        "epoch": 8.839681133746678,
        "step": 9980
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.006075542885810137,
        "learning_rate": 1.1514614703277237e-06,
        "epoch": 8.848538529672277,
        "step": 9990
    },
    {
        "loss": 0.0766,
        "grad_norm": 0.029509173706173897,
        "learning_rate": 1.142604074402126e-06,
        "epoch": 8.857395925597874,
        "step": 10000
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.07785899937152863,
        "learning_rate": 1.133746678476528e-06,
        "epoch": 8.866253321523471,
        "step": 10010
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.008015863597393036,
        "learning_rate": 1.1248892825509302e-06,
        "epoch": 8.87511071744907,
        "step": 10020
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.053262535482645035,
        "learning_rate": 1.1160318866253323e-06,
        "epoch": 8.883968113374667,
        "step": 10030
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02967091090977192,
        "learning_rate": 1.1071744906997343e-06,
        "epoch": 8.892825509300266,
        "step": 10040
    },
    {
        "loss": 0.0568,
        "grad_norm": 40.76229476928711,
        "learning_rate": 1.0983170947741365e-06,
        "epoch": 8.901682905225863,
        "step": 10050
    },
    {
        "loss": 0.0824,
        "grad_norm": 0.005429205019026995,
        "learning_rate": 1.0894596988485386e-06,
        "epoch": 8.910540301151462,
        "step": 10060
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.004424664191901684,
        "learning_rate": 1.0806023029229408e-06,
        "epoch": 8.91939769707706,
        "step": 10070
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005564478226006031,
        "learning_rate": 1.0717449069973429e-06,
        "epoch": 8.928255093002658,
        "step": 10080
    },
    {
        "loss": 0.0421,
        "grad_norm": 0.007093123625963926,
        "learning_rate": 1.062887511071745e-06,
        "epoch": 8.937112488928255,
        "step": 10090
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.05469127371907234,
        "learning_rate": 1.0540301151461471e-06,
        "epoch": 8.945969884853852,
        "step": 10100
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.013836233876645565,
        "learning_rate": 1.0451727192205492e-06,
        "epoch": 8.954827280779451,
        "step": 10110
    },
    {
        "loss": 0.0018,
        "grad_norm": 0.7611817121505737,
        "learning_rate": 1.0363153232949514e-06,
        "epoch": 8.963684676705048,
        "step": 10120
    },
    {
        "loss": 0.0024,
        "grad_norm": 0.05803708732128143,
        "learning_rate": 1.0274579273693534e-06,
        "epoch": 8.972542072630647,
        "step": 10130
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01417392585426569,
        "learning_rate": 1.0186005314437557e-06,
        "epoch": 8.981399468556244,
        "step": 10140
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.012044393457472324,
        "learning_rate": 1.0097431355181577e-06,
        "epoch": 8.990256864481843,
        "step": 10150
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.012289020232856274,
        "learning_rate": 1.00088573959256e-06,
        "epoch": 8.99911426040744,
        "step": 10160
    },
    {
        "eval_loss": 0.14516915380954742,
        "eval_accuracy": 0.98162,
        "eval_precision": 0.98055,
        "eval_recall": 0.98272,
        "eval_f1": 0.98164,
        "eval_runtime": 150.1532,
        "eval_samples_per_second": 60.145,
        "eval_steps_per_second": 3.763,
        "epoch": 9.0,
        "step": 10161
    },
    {
        "loss": 0.0119,
        "grad_norm": 0.0020092660561203957,
        "learning_rate": 9.92028343666962e-07,
        "epoch": 9.007971656333037,
        "step": 10170
    },
    {
        "loss": 0.0475,
        "grad_norm": 0.004234826657921076,
        "learning_rate": 9.83170947741364e-07,
        "epoch": 9.016829052258636,
        "step": 10180
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.018331747502088547,
        "learning_rate": 9.743135518157663e-07,
        "epoch": 9.025686448184233,
        "step": 10190
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.014796284027397633,
        "learning_rate": 9.654561558901683e-07,
        "epoch": 9.034543844109832,
        "step": 10200
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.004444198217242956,
        "learning_rate": 9.565987599645705e-07,
        "epoch": 9.043401240035429,
        "step": 10210
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.019626669585704803,
        "learning_rate": 9.477413640389727e-07,
        "epoch": 9.052258635961028,
        "step": 10220
    },
    {
        "loss": 0.0008,
        "grad_norm": 31.76262664794922,
        "learning_rate": 9.388839681133747e-07,
        "epoch": 9.061116031886625,
        "step": 10230
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.007691757287830114,
        "learning_rate": 9.300265721877769e-07,
        "epoch": 9.069973427812224,
        "step": 10240
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.004030793439596891,
        "learning_rate": 9.21169176262179e-07,
        "epoch": 9.078830823737821,
        "step": 10250
    },
    {
        "loss": 0.085,
        "grad_norm": 0.0174481850117445,
        "learning_rate": 9.12311780336581e-07,
        "epoch": 9.087688219663418,
        "step": 10260
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.004400100093334913,
        "learning_rate": 9.034543844109832e-07,
        "epoch": 9.096545615589017,
        "step": 10270
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005328401457518339,
        "learning_rate": 8.945969884853854e-07,
        "epoch": 9.105403011514614,
        "step": 10280
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.00830342061817646,
        "learning_rate": 8.857395925597875e-07,
        "epoch": 9.114260407440213,
        "step": 10290
    },
    {
        "loss": 0.1253,
        "grad_norm": 0.011041427962481976,
        "learning_rate": 8.768821966341897e-07,
        "epoch": 9.12311780336581,
        "step": 10300
    },
    {
        "loss": 0.0079,
        "grad_norm": 0.3705238699913025,
        "learning_rate": 8.680248007085917e-07,
        "epoch": 9.131975199291409,
        "step": 10310
    },
    {
        "loss": 0.061,
        "grad_norm": 0.01127812173217535,
        "learning_rate": 8.591674047829939e-07,
        "epoch": 9.140832595217006,
        "step": 10320
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.8963224291801453,
        "learning_rate": 8.50310008857396e-07,
        "epoch": 9.149689991142605,
        "step": 10330
    },
    {
        "loss": 0.0287,
        "grad_norm": 0.008934547193348408,
        "learning_rate": 8.41452612931798e-07,
        "epoch": 9.158547387068202,
        "step": 10340
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.03153422474861145,
        "learning_rate": 8.325952170062003e-07,
        "epoch": 9.167404782993799,
        "step": 10350
    },
    {
        "loss": 0.0175,
        "grad_norm": 0.004115861840546131,
        "learning_rate": 8.237378210806024e-07,
        "epoch": 9.176262178919398,
        "step": 10360
    },
    {
        "loss": 0.0058,
        "grad_norm": 0.020569274201989174,
        "learning_rate": 8.148804251550045e-07,
        "epoch": 9.185119574844995,
        "step": 10370
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00453938078135252,
        "learning_rate": 8.060230292294066e-07,
        "epoch": 9.193976970770594,
        "step": 10380
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.04348422586917877,
        "learning_rate": 7.971656333038087e-07,
        "epoch": 9.202834366696191,
        "step": 10390
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03192655369639397,
        "learning_rate": 7.883082373782109e-07,
        "epoch": 9.21169176262179,
        "step": 10400
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.018278593197464943,
        "learning_rate": 7.794508414526129e-07,
        "epoch": 9.220549158547387,
        "step": 10410
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007201761938631535,
        "learning_rate": 7.705934455270151e-07,
        "epoch": 9.229406554472986,
        "step": 10420
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.009746504947543144,
        "learning_rate": 7.617360496014173e-07,
        "epoch": 9.238263950398583,
        "step": 10430
    },
    {
        "loss": 0.0004,
        "grad_norm": 1.003210425376892,
        "learning_rate": 7.528786536758194e-07,
        "epoch": 9.24712134632418,
        "step": 10440
    },
    {
        "loss": 0.0085,
        "grad_norm": 0.0021270844154059887,
        "learning_rate": 7.440212577502214e-07,
        "epoch": 9.255978742249779,
        "step": 10450
    },
    {
        "loss": 0.0362,
        "grad_norm": 0.0077623967081308365,
        "learning_rate": 7.351638618246236e-07,
        "epoch": 9.264836138175376,
        "step": 10460
    },
    {
        "loss": 0.0609,
        "grad_norm": 25.226449966430664,
        "learning_rate": 7.263064658990257e-07,
        "epoch": 9.273693534100975,
        "step": 10470
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.012868660502135754,
        "learning_rate": 7.174490699734279e-07,
        "epoch": 9.282550930026572,
        "step": 10480
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.019239338114857674,
        "learning_rate": 7.085916740478301e-07,
        "epoch": 9.29140832595217,
        "step": 10490
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.011391088366508484,
        "learning_rate": 6.997342781222321e-07,
        "epoch": 9.300265721877768,
        "step": 10500
    },
    {
        "loss": 0.0097,
        "grad_norm": 0.006256393156945705,
        "learning_rate": 6.908768821966343e-07,
        "epoch": 9.309123117803367,
        "step": 10510
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02098274603486061,
        "learning_rate": 6.820194862710364e-07,
        "epoch": 9.317980513728964,
        "step": 10520
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.0067465524189174175,
        "learning_rate": 6.731620903454384e-07,
        "epoch": 9.32683790965456,
        "step": 10530
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00918908417224884,
        "learning_rate": 6.643046944198406e-07,
        "epoch": 9.33569530558016,
        "step": 10540
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.006454737391322851,
        "learning_rate": 6.554472984942427e-07,
        "epoch": 9.344552701505757,
        "step": 10550
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.004764700308442116,
        "learning_rate": 6.46589902568645e-07,
        "epoch": 9.353410097431356,
        "step": 10560
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.013301590457558632,
        "learning_rate": 6.37732506643047e-07,
        "epoch": 9.362267493356953,
        "step": 10570
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.010812745429575443,
        "learning_rate": 6.288751107174491e-07,
        "epoch": 9.371124889282552,
        "step": 10580
    },
    {
        "loss": 0.0107,
        "grad_norm": 0.015759063884615898,
        "learning_rate": 6.200177147918513e-07,
        "epoch": 9.379982285208149,
        "step": 10590
    },
    {
        "loss": 0.0081,
        "grad_norm": 0.0034099589101970196,
        "learning_rate": 6.111603188662533e-07,
        "epoch": 9.388839681133746,
        "step": 10600
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.008405624888837337,
        "learning_rate": 6.023029229406556e-07,
        "epoch": 9.397697077059345,
        "step": 10610
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0027542319148778915,
        "learning_rate": 5.934455270150576e-07,
        "epoch": 9.406554472984942,
        "step": 10620
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.015564948320388794,
        "learning_rate": 5.845881310894597e-07,
        "epoch": 9.41541186891054,
        "step": 10630
    },
    {
        "loss": 0.046,
        "grad_norm": 0.3588576018810272,
        "learning_rate": 5.757307351638619e-07,
        "epoch": 9.424269264836138,
        "step": 10640
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.023621531203389168,
        "learning_rate": 5.66873339238264e-07,
        "epoch": 9.433126660761737,
        "step": 10650
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0032090269960463047,
        "learning_rate": 5.580159433126661e-07,
        "epoch": 9.441984056687334,
        "step": 10660
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002463732613250613,
        "learning_rate": 5.491585473870683e-07,
        "epoch": 9.450841452612933,
        "step": 10670
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.016431977972388268,
        "learning_rate": 5.403011514614704e-07,
        "epoch": 9.45969884853853,
        "step": 10680
    },
    {
        "loss": 0.0498,
        "grad_norm": 0.008573124185204506,
        "learning_rate": 5.314437555358726e-07,
        "epoch": 9.468556244464127,
        "step": 10690
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.003689767559990287,
        "learning_rate": 5.225863596102746e-07,
        "epoch": 9.477413640389726,
        "step": 10700
    },
    {
        "loss": 0.0448,
        "grad_norm": 0.0036449956241995096,
        "learning_rate": 5.137289636846767e-07,
        "epoch": 9.486271036315323,
        "step": 10710
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005593970417976379,
        "learning_rate": 5.048715677590789e-07,
        "epoch": 9.495128432240922,
        "step": 10720
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.002550982404500246,
        "learning_rate": 4.96014171833481e-07,
        "epoch": 9.503985828166519,
        "step": 10730
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.0031892871484160423,
        "learning_rate": 4.871567759078831e-07,
        "epoch": 9.512843224092117,
        "step": 10740
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0038267243653535843,
        "learning_rate": 4.782993799822853e-07,
        "epoch": 9.521700620017715,
        "step": 10750
    },
    {
        "loss": 0.0237,
        "grad_norm": 0.013297307305037975,
        "learning_rate": 4.6944198405668736e-07,
        "epoch": 9.530558015943313,
        "step": 10760
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005894714500755072,
        "learning_rate": 4.605845881310895e-07,
        "epoch": 9.53941541186891,
        "step": 10770
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.004990981426090002,
        "learning_rate": 4.517271922054916e-07,
        "epoch": 9.548272807794508,
        "step": 10780
    },
    {
        "loss": 0.0002,
        "grad_norm": 1.439568281173706,
        "learning_rate": 4.428697962798938e-07,
        "epoch": 9.557130203720106,
        "step": 10790
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0038034424651414156,
        "learning_rate": 4.3401240035429586e-07,
        "epoch": 9.565987599645704,
        "step": 10800
    },
    {
        "loss": 0.0018,
        "grad_norm": 0.011275817640125751,
        "learning_rate": 4.25155004428698e-07,
        "epoch": 9.574844995571302,
        "step": 10810
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0022666200529783964,
        "learning_rate": 4.1629760850310014e-07,
        "epoch": 9.5837023914969,
        "step": 10820
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.013528633862733841,
        "learning_rate": 4.074402125775023e-07,
        "epoch": 9.592559787422498,
        "step": 10830
    },
    {
        "loss": 0.0105,
        "grad_norm": 0.009546970017254353,
        "learning_rate": 3.9858281665190436e-07,
        "epoch": 9.601417183348095,
        "step": 10840
    },
    {
        "loss": 0.048,
        "grad_norm": 0.004455887246876955,
        "learning_rate": 3.8972542072630645e-07,
        "epoch": 9.610274579273694,
        "step": 10850
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.00474053667858243,
        "learning_rate": 3.8086802480070864e-07,
        "epoch": 9.619131975199291,
        "step": 10860
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004533383063971996,
        "learning_rate": 3.720106288751107e-07,
        "epoch": 9.627989371124889,
        "step": 10870
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.2787260413169861,
        "learning_rate": 3.6315323294951286e-07,
        "epoch": 9.636846767050487,
        "step": 10880
    },
    {
        "loss": 0.0596,
        "grad_norm": 0.00852238666266203,
        "learning_rate": 3.5429583702391505e-07,
        "epoch": 9.645704162976084,
        "step": 10890
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.003942831885069609,
        "learning_rate": 3.4543844109831714e-07,
        "epoch": 9.654561558901683,
        "step": 10900
    },
    {
        "loss": 0.0534,
        "grad_norm": 0.0033696014434099197,
        "learning_rate": 3.365810451727192e-07,
        "epoch": 9.66341895482728,
        "step": 10910
    },
    {
        "loss": 0.0417,
        "grad_norm": 0.04403281956911087,
        "learning_rate": 3.2772364924712136e-07,
        "epoch": 9.67227635075288,
        "step": 10920
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0077388714998960495,
        "learning_rate": 3.188662533215235e-07,
        "epoch": 9.681133746678476,
        "step": 10930
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.004899770021438599,
        "learning_rate": 3.1000885739592564e-07,
        "epoch": 9.689991142604075,
        "step": 10940
    },
    {
        "loss": 0.0478,
        "grad_norm": 0.003709717420861125,
        "learning_rate": 3.011514614703278e-07,
        "epoch": 9.698848538529672,
        "step": 10950
    },
    {
        "loss": 0.0079,
        "grad_norm": 0.011722085066139698,
        "learning_rate": 2.9229406554472986e-07,
        "epoch": 9.70770593445527,
        "step": 10960
    },
    {
        "loss": 0.0044,
        "grad_norm": 0.2708875834941864,
        "learning_rate": 2.83436669619132e-07,
        "epoch": 9.716563330380868,
        "step": 10970
    },
    {
        "loss": 0.0528,
        "grad_norm": 0.006588372401893139,
        "learning_rate": 2.7457927369353414e-07,
        "epoch": 9.725420726306465,
        "step": 10980
    },
    {
        "loss": 0.025,
        "grad_norm": 0.012852204963564873,
        "learning_rate": 2.657218777679363e-07,
        "epoch": 9.734278122232064,
        "step": 10990
    },
    {
        "loss": 0.0615,
        "grad_norm": 0.005865580402314663,
        "learning_rate": 2.5686448184233836e-07,
        "epoch": 9.743135518157661,
        "step": 11000
    },
    {
        "loss": 0.0507,
        "grad_norm": 0.02518491819500923,
        "learning_rate": 2.480070859167405e-07,
        "epoch": 9.75199291408326,
        "step": 11010
    },
    {
        "loss": 0.0401,
        "grad_norm": 122.332275390625,
        "learning_rate": 2.3914968999114264e-07,
        "epoch": 9.760850310008857,
        "step": 11020
    },
    {
        "loss": 0.0386,
        "grad_norm": 0.00878214556723833,
        "learning_rate": 2.3029229406554475e-07,
        "epoch": 9.769707705934454,
        "step": 11030
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.01314435712993145,
        "learning_rate": 2.214348981399469e-07,
        "epoch": 9.778565101860053,
        "step": 11040
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005481785163283348,
        "learning_rate": 2.12577502214349e-07,
        "epoch": 9.78742249778565,
        "step": 11050
    },
    {
        "loss": 0.0414,
        "grad_norm": 12.968591690063477,
        "learning_rate": 2.0372010628875114e-07,
        "epoch": 9.79627989371125,
        "step": 11060
    },
    {
        "loss": 0.0386,
        "grad_norm": 0.0035548009909689426,
        "learning_rate": 1.9486271036315322e-07,
        "epoch": 9.805137289636846,
        "step": 11070
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.015013649128377438,
        "learning_rate": 1.8600531443755536e-07,
        "epoch": 9.813994685562445,
        "step": 11080
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006485700141638517,
        "learning_rate": 1.7714791851195753e-07,
        "epoch": 9.822852081488042,
        "step": 11090
    },
    {
        "loss": 0.0209,
        "grad_norm": 0.003213890828192234,
        "learning_rate": 1.682905225863596e-07,
        "epoch": 9.831709477413641,
        "step": 11100
    },
    {
        "loss": 0.0053,
        "grad_norm": 0.002748416271060705,
        "learning_rate": 1.5943312666076175e-07,
        "epoch": 9.840566873339238,
        "step": 11110
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005474067758768797,
        "learning_rate": 1.505757307351639e-07,
        "epoch": 9.849424269264837,
        "step": 11120
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.0037039639428257942,
        "learning_rate": 1.41718334809566e-07,
        "epoch": 9.858281665190434,
        "step": 11130
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0060861436650156975,
        "learning_rate": 1.3286093888396814e-07,
        "epoch": 9.867139061116031,
        "step": 11140
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.4821110665798187,
        "learning_rate": 1.2400354295837025e-07,
        "epoch": 9.87599645704163,
        "step": 11150
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0173431858420372,
        "learning_rate": 1.1514614703277237e-07,
        "epoch": 9.884853852967227,
        "step": 11160
    },
    {
        "loss": 0.0316,
        "grad_norm": 0.005640738643705845,
        "learning_rate": 1.062887511071745e-07,
        "epoch": 9.893711248892826,
        "step": 11170
    },
    {
        "loss": 0.0623,
        "grad_norm": 0.05154001712799072,
        "learning_rate": 9.743135518157661e-08,
        "epoch": 9.902568644818423,
        "step": 11180
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.022145111113786697,
        "learning_rate": 8.857395925597876e-08,
        "epoch": 9.911426040744022,
        "step": 11190
    },
    {
        "loss": 0.0464,
        "grad_norm": 0.09659496694803238,
        "learning_rate": 7.971656333038087e-08,
        "epoch": 9.920283436669619,
        "step": 11200
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004677908960729837,
        "learning_rate": 7.0859167404783e-08,
        "epoch": 9.929140832595216,
        "step": 11210
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0042304485104978085,
        "learning_rate": 6.200177147918512e-08,
        "epoch": 9.937998228520815,
        "step": 11220
    },
    {
        "loss": 0.0217,
        "grad_norm": 222.6343994140625,
        "learning_rate": 5.314437555358725e-08,
        "epoch": 9.946855624446412,
        "step": 11230
    },
    {
        "loss": 0.1004,
        "grad_norm": 0.21712824702262878,
        "learning_rate": 4.428697962798938e-08,
        "epoch": 9.955713020372011,
        "step": 11240
    },
    {
        "loss": 0.0471,
        "grad_norm": 0.0042448490858078,
        "learning_rate": 3.54295837023915e-08,
        "epoch": 9.964570416297608,
        "step": 11250
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004608790390193462,
        "learning_rate": 2.6572187776793625e-08,
        "epoch": 9.973427812223207,
        "step": 11260
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004118247423321009,
        "learning_rate": 1.771479185119575e-08,
        "epoch": 9.982285208148804,
        "step": 11270
    },
    {
        "loss": 0.0044,
        "grad_norm": 0.007716652005910873,
        "learning_rate": 8.857395925597875e-09,
        "epoch": 9.991142604074403,
        "step": 11280
    },
    {
        "loss": 0.0338,
        "grad_norm": 0.006661913823336363,
        "learning_rate": 0.0,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "eval_loss": 0.1545817255973816,
        "eval_accuracy": 0.98129,
        "eval_precision": 0.97885,
        "eval_recall": 0.98383,
        "eval_f1": 0.98133,
        "eval_runtime": 149.9088,
        "eval_samples_per_second": 60.243,
        "eval_steps_per_second": 3.769,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "train_runtime": 11964.4777,
        "train_samples_per_second": 15.098,
        "train_steps_per_second": 0.944,
        "total_flos": 2.37641905201152e+16,
        "train_loss": 0.15610904382186858,
        "epoch": 10.0,
        "step": 11290
    }
]