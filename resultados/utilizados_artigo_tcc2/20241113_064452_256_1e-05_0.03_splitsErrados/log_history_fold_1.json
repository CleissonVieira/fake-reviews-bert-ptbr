[
    {
        "loss": 0.6885,
        "grad_norm": 0.9244028925895691,
        "learning_rate": 9.991142604074402e-06,
        "epoch": 0.008857395925597875,
        "step": 10
    },
    {
        "loss": 0.6754,
        "grad_norm": 1.4450064897537231,
        "learning_rate": 9.982285208148806e-06,
        "epoch": 0.01771479185119575,
        "step": 20
    },
    {
        "loss": 0.6545,
        "grad_norm": 1.928724765777588,
        "learning_rate": 9.973427812223207e-06,
        "epoch": 0.026572187776793623,
        "step": 30
    },
    {
        "loss": 0.64,
        "grad_norm": 2.712883710861206,
        "learning_rate": 9.964570416297609e-06,
        "epoch": 0.0354295837023915,
        "step": 40
    },
    {
        "loss": 0.6024,
        "grad_norm": 10.86821174621582,
        "learning_rate": 9.95571302037201e-06,
        "epoch": 0.04428697962798937,
        "step": 50
    },
    {
        "loss": 0.6505,
        "grad_norm": 6.672933101654053,
        "learning_rate": 9.946855624446414e-06,
        "epoch": 0.053144375553587246,
        "step": 60
    },
    {
        "loss": 0.6132,
        "grad_norm": 4.534265041351318,
        "learning_rate": 9.937998228520815e-06,
        "epoch": 0.06200177147918512,
        "step": 70
    },
    {
        "loss": 0.5973,
        "grad_norm": 3.0613672733306885,
        "learning_rate": 9.929140832595217e-06,
        "epoch": 0.070859167404783,
        "step": 80
    },
    {
        "loss": 0.5719,
        "grad_norm": 5.771178245544434,
        "learning_rate": 9.92028343666962e-06,
        "epoch": 0.07971656333038087,
        "step": 90
    },
    {
        "loss": 0.6349,
        "grad_norm": 4.081672191619873,
        "learning_rate": 9.911426040744022e-06,
        "epoch": 0.08857395925597875,
        "step": 100
    },
    {
        "loss": 0.5704,
        "grad_norm": 4.391259670257568,
        "learning_rate": 9.902568644818424e-06,
        "epoch": 0.09743135518157661,
        "step": 110
    },
    {
        "loss": 0.5892,
        "grad_norm": 6.393207550048828,
        "learning_rate": 9.893711248892827e-06,
        "epoch": 0.10628875110717449,
        "step": 120
    },
    {
        "loss": 0.5256,
        "grad_norm": 3.809086799621582,
        "learning_rate": 9.884853852967229e-06,
        "epoch": 0.11514614703277236,
        "step": 130
    },
    {
        "loss": 0.7012,
        "grad_norm": 6.419222831726074,
        "learning_rate": 9.87599645704163e-06,
        "epoch": 0.12400354295837024,
        "step": 140
    },
    {
        "loss": 0.5711,
        "grad_norm": 3.3876864910125732,
        "learning_rate": 9.867139061116032e-06,
        "epoch": 0.1328609388839681,
        "step": 150
    },
    {
        "loss": 0.6273,
        "grad_norm": 8.820401191711426,
        "learning_rate": 9.858281665190435e-06,
        "epoch": 0.141718334809566,
        "step": 160
    },
    {
        "loss": 0.5568,
        "grad_norm": 3.2072787284851074,
        "learning_rate": 9.849424269264837e-06,
        "epoch": 0.15057573073516387,
        "step": 170
    },
    {
        "loss": 0.577,
        "grad_norm": 5.057685852050781,
        "learning_rate": 9.840566873339238e-06,
        "epoch": 0.15943312666076173,
        "step": 180
    },
    {
        "loss": 0.5645,
        "grad_norm": 6.988160133361816,
        "learning_rate": 9.831709477413642e-06,
        "epoch": 0.1682905225863596,
        "step": 190
    },
    {
        "loss": 0.604,
        "grad_norm": 5.200307369232178,
        "learning_rate": 9.822852081488043e-06,
        "epoch": 0.1771479185119575,
        "step": 200
    },
    {
        "loss": 0.4949,
        "grad_norm": 5.988243579864502,
        "learning_rate": 9.813994685562446e-06,
        "epoch": 0.18600531443755536,
        "step": 210
    },
    {
        "loss": 0.571,
        "grad_norm": 4.469237327575684,
        "learning_rate": 9.805137289636848e-06,
        "epoch": 0.19486271036315322,
        "step": 220
    },
    {
        "loss": 0.5505,
        "grad_norm": 6.475681304931641,
        "learning_rate": 9.79627989371125e-06,
        "epoch": 0.20372010628875112,
        "step": 230
    },
    {
        "loss": 0.5954,
        "grad_norm": 3.460334539413452,
        "learning_rate": 9.787422497785651e-06,
        "epoch": 0.21257750221434898,
        "step": 240
    },
    {
        "loss": 0.6118,
        "grad_norm": 5.692878723144531,
        "learning_rate": 9.778565101860053e-06,
        "epoch": 0.22143489813994685,
        "step": 250
    },
    {
        "loss": 0.6313,
        "grad_norm": 3.6341145038604736,
        "learning_rate": 9.769707705934456e-06,
        "epoch": 0.23029229406554472,
        "step": 260
    },
    {
        "loss": 0.5809,
        "grad_norm": 3.9664037227630615,
        "learning_rate": 9.760850310008858e-06,
        "epoch": 0.2391496899911426,
        "step": 270
    },
    {
        "loss": 0.522,
        "grad_norm": 3.087644100189209,
        "learning_rate": 9.751992914083261e-06,
        "epoch": 0.24800708591674048,
        "step": 280
    },
    {
        "loss": 0.5175,
        "grad_norm": 5.697565078735352,
        "learning_rate": 9.743135518157663e-06,
        "epoch": 0.25686448184233834,
        "step": 290
    },
    {
        "loss": 0.7221,
        "grad_norm": 9.042569160461426,
        "learning_rate": 9.734278122232064e-06,
        "epoch": 0.2657218777679362,
        "step": 300
    },
    {
        "loss": 0.6215,
        "grad_norm": 5.187030792236328,
        "learning_rate": 9.725420726306468e-06,
        "epoch": 0.2745792736935341,
        "step": 310
    },
    {
        "loss": 0.5616,
        "grad_norm": 4.0667877197265625,
        "learning_rate": 9.71656333038087e-06,
        "epoch": 0.283436669619132,
        "step": 320
    },
    {
        "loss": 0.5879,
        "grad_norm": 2.5624706745147705,
        "learning_rate": 9.707705934455271e-06,
        "epoch": 0.29229406554472986,
        "step": 330
    },
    {
        "loss": 0.5431,
        "grad_norm": 2.8599143028259277,
        "learning_rate": 9.698848538529672e-06,
        "epoch": 0.30115146147032773,
        "step": 340
    },
    {
        "loss": 0.5794,
        "grad_norm": 3.981297016143799,
        "learning_rate": 9.689991142604076e-06,
        "epoch": 0.3100088573959256,
        "step": 350
    },
    {
        "loss": 0.5661,
        "grad_norm": 5.699369430541992,
        "learning_rate": 9.681133746678477e-06,
        "epoch": 0.31886625332152346,
        "step": 360
    },
    {
        "loss": 0.5531,
        "grad_norm": 3.5419514179229736,
        "learning_rate": 9.672276350752879e-06,
        "epoch": 0.32772364924712133,
        "step": 370
    },
    {
        "loss": 0.5767,
        "grad_norm": 4.759144306182861,
        "learning_rate": 9.663418954827282e-06,
        "epoch": 0.3365810451727192,
        "step": 380
    },
    {
        "loss": 0.5872,
        "grad_norm": 4.708831787109375,
        "learning_rate": 9.654561558901684e-06,
        "epoch": 0.3454384410983171,
        "step": 390
    },
    {
        "loss": 0.5271,
        "grad_norm": 4.818172454833984,
        "learning_rate": 9.645704162976086e-06,
        "epoch": 0.354295837023915,
        "step": 400
    },
    {
        "loss": 0.5318,
        "grad_norm": 4.423202037811279,
        "learning_rate": 9.636846767050489e-06,
        "epoch": 0.36315323294951285,
        "step": 410
    },
    {
        "loss": 0.5559,
        "grad_norm": 9.002031326293945,
        "learning_rate": 9.627989371124889e-06,
        "epoch": 0.3720106288751107,
        "step": 420
    },
    {
        "loss": 0.5746,
        "grad_norm": 5.260331153869629,
        "learning_rate": 9.619131975199292e-06,
        "epoch": 0.3808680248007086,
        "step": 430
    },
    {
        "loss": 0.524,
        "grad_norm": 6.466829776763916,
        "learning_rate": 9.610274579273694e-06,
        "epoch": 0.38972542072630645,
        "step": 440
    },
    {
        "loss": 0.5878,
        "grad_norm": 7.3091936111450195,
        "learning_rate": 9.601417183348097e-06,
        "epoch": 0.3985828166519043,
        "step": 450
    },
    {
        "loss": 0.5926,
        "grad_norm": 3.9081532955169678,
        "learning_rate": 9.592559787422499e-06,
        "epoch": 0.40744021257750224,
        "step": 460
    },
    {
        "loss": 0.5783,
        "grad_norm": 5.043695449829102,
        "learning_rate": 9.5837023914969e-06,
        "epoch": 0.4162976085031001,
        "step": 470
    },
    {
        "loss": 0.556,
        "grad_norm": 5.765947341918945,
        "learning_rate": 9.574844995571303e-06,
        "epoch": 0.42515500442869797,
        "step": 480
    },
    {
        "loss": 0.5774,
        "grad_norm": 8.67348575592041,
        "learning_rate": 9.565987599645705e-06,
        "epoch": 0.43401240035429584,
        "step": 490
    },
    {
        "loss": 0.456,
        "grad_norm": 6.806321620941162,
        "learning_rate": 9.557130203720107e-06,
        "epoch": 0.4428697962798937,
        "step": 500
    },
    {
        "loss": 0.5471,
        "grad_norm": 7.123927116394043,
        "learning_rate": 9.54827280779451e-06,
        "epoch": 0.45172719220549157,
        "step": 510
    },
    {
        "loss": 0.5789,
        "grad_norm": 6.255744457244873,
        "learning_rate": 9.539415411868912e-06,
        "epoch": 0.46058458813108943,
        "step": 520
    },
    {
        "loss": 0.528,
        "grad_norm": 3.960789918899536,
        "learning_rate": 9.530558015943313e-06,
        "epoch": 0.46944198405668736,
        "step": 530
    },
    {
        "loss": 0.5381,
        "grad_norm": 7.998471736907959,
        "learning_rate": 9.521700620017715e-06,
        "epoch": 0.4782993799822852,
        "step": 540
    },
    {
        "loss": 0.5845,
        "grad_norm": 5.997004508972168,
        "learning_rate": 9.512843224092118e-06,
        "epoch": 0.4871567759078831,
        "step": 550
    },
    {
        "loss": 0.5061,
        "grad_norm": 7.776415824890137,
        "learning_rate": 9.50398582816652e-06,
        "epoch": 0.49601417183348095,
        "step": 560
    },
    {
        "loss": 0.6032,
        "grad_norm": 5.924100875854492,
        "learning_rate": 9.495128432240921e-06,
        "epoch": 0.5048715677590788,
        "step": 570
    },
    {
        "loss": 0.5191,
        "grad_norm": 6.197171211242676,
        "learning_rate": 9.486271036315325e-06,
        "epoch": 0.5137289636846767,
        "step": 580
    },
    {
        "loss": 0.5045,
        "grad_norm": 10.645755767822266,
        "learning_rate": 9.477413640389726e-06,
        "epoch": 0.5225863596102746,
        "step": 590
    },
    {
        "loss": 0.505,
        "grad_norm": 7.593591690063477,
        "learning_rate": 9.46855624446413e-06,
        "epoch": 0.5314437555358724,
        "step": 600
    },
    {
        "loss": 0.5595,
        "grad_norm": 8.073838233947754,
        "learning_rate": 9.45969884853853e-06,
        "epoch": 0.5403011514614703,
        "step": 610
    },
    {
        "loss": 0.5719,
        "grad_norm": 6.256491184234619,
        "learning_rate": 9.450841452612933e-06,
        "epoch": 0.5491585473870682,
        "step": 620
    },
    {
        "loss": 0.5527,
        "grad_norm": 5.324495792388916,
        "learning_rate": 9.441984056687334e-06,
        "epoch": 0.5580159433126661,
        "step": 630
    },
    {
        "loss": 0.6116,
        "grad_norm": 6.9797210693359375,
        "learning_rate": 9.433126660761736e-06,
        "epoch": 0.566873339238264,
        "step": 640
    },
    {
        "loss": 0.5948,
        "grad_norm": 5.242048740386963,
        "learning_rate": 9.42426926483614e-06,
        "epoch": 0.5757307351638619,
        "step": 650
    },
    {
        "loss": 0.5575,
        "grad_norm": 5.0311737060546875,
        "learning_rate": 9.415411868910541e-06,
        "epoch": 0.5845881310894597,
        "step": 660
    },
    {
        "loss": 0.5148,
        "grad_norm": 6.812474727630615,
        "learning_rate": 9.406554472984944e-06,
        "epoch": 0.5934455270150576,
        "step": 670
    },
    {
        "loss": 0.5417,
        "grad_norm": 11.47169303894043,
        "learning_rate": 9.397697077059346e-06,
        "epoch": 0.6023029229406555,
        "step": 680
    },
    {
        "loss": 0.4666,
        "grad_norm": 7.488059043884277,
        "learning_rate": 9.388839681133747e-06,
        "epoch": 0.6111603188662533,
        "step": 690
    },
    {
        "loss": 0.4655,
        "grad_norm": 7.565762519836426,
        "learning_rate": 9.379982285208149e-06,
        "epoch": 0.6200177147918512,
        "step": 700
    },
    {
        "loss": 0.5111,
        "grad_norm": 5.9335479736328125,
        "learning_rate": 9.37112488928255e-06,
        "epoch": 0.6288751107174491,
        "step": 710
    },
    {
        "loss": 0.5347,
        "grad_norm": 11.40123462677002,
        "learning_rate": 9.362267493356954e-06,
        "epoch": 0.6377325066430469,
        "step": 720
    },
    {
        "loss": 0.5417,
        "grad_norm": 7.039013385772705,
        "learning_rate": 9.353410097431356e-06,
        "epoch": 0.6465899025686448,
        "step": 730
    },
    {
        "loss": 0.5053,
        "grad_norm": 6.813379764556885,
        "learning_rate": 9.344552701505759e-06,
        "epoch": 0.6554472984942427,
        "step": 740
    },
    {
        "loss": 0.5408,
        "grad_norm": 10.176315307617188,
        "learning_rate": 9.33569530558016e-06,
        "epoch": 0.6643046944198405,
        "step": 750
    },
    {
        "loss": 0.4604,
        "grad_norm": 8.393214225769043,
        "learning_rate": 9.326837909654562e-06,
        "epoch": 0.6731620903454384,
        "step": 760
    },
    {
        "loss": 0.4808,
        "grad_norm": 6.21117639541626,
        "learning_rate": 9.317980513728965e-06,
        "epoch": 0.6820194862710364,
        "step": 770
    },
    {
        "loss": 0.5011,
        "grad_norm": 9.388884544372559,
        "learning_rate": 9.309123117803367e-06,
        "epoch": 0.6908768821966342,
        "step": 780
    },
    {
        "loss": 0.4577,
        "grad_norm": 8.251786231994629,
        "learning_rate": 9.300265721877769e-06,
        "epoch": 0.6997342781222321,
        "step": 790
    },
    {
        "loss": 0.4787,
        "grad_norm": 7.46010160446167,
        "learning_rate": 9.29140832595217e-06,
        "epoch": 0.70859167404783,
        "step": 800
    },
    {
        "loss": 0.4499,
        "grad_norm": 9.212647438049316,
        "learning_rate": 9.282550930026572e-06,
        "epoch": 0.7174490699734278,
        "step": 810
    },
    {
        "loss": 0.4823,
        "grad_norm": 7.75726842880249,
        "learning_rate": 9.273693534100975e-06,
        "epoch": 0.7263064658990257,
        "step": 820
    },
    {
        "loss": 0.4745,
        "grad_norm": 6.501785755157471,
        "learning_rate": 9.264836138175377e-06,
        "epoch": 0.7351638618246236,
        "step": 830
    },
    {
        "loss": 0.466,
        "grad_norm": 8.257828712463379,
        "learning_rate": 9.25597874224978e-06,
        "epoch": 0.7440212577502214,
        "step": 840
    },
    {
        "loss": 0.5271,
        "grad_norm": 12.643779754638672,
        "learning_rate": 9.247121346324182e-06,
        "epoch": 0.7528786536758193,
        "step": 850
    },
    {
        "loss": 0.5265,
        "grad_norm": 7.708468914031982,
        "learning_rate": 9.238263950398583e-06,
        "epoch": 0.7617360496014172,
        "step": 860
    },
    {
        "loss": 0.4946,
        "grad_norm": 14.631093978881836,
        "learning_rate": 9.229406554472987e-06,
        "epoch": 0.770593445527015,
        "step": 870
    },
    {
        "loss": 0.4651,
        "grad_norm": 8.226408958435059,
        "learning_rate": 9.220549158547388e-06,
        "epoch": 0.7794508414526129,
        "step": 880
    },
    {
        "loss": 0.4728,
        "grad_norm": 5.899658203125,
        "learning_rate": 9.21169176262179e-06,
        "epoch": 0.7883082373782108,
        "step": 890
    },
    {
        "loss": 0.513,
        "grad_norm": 7.193161487579346,
        "learning_rate": 9.202834366696191e-06,
        "epoch": 0.7971656333038086,
        "step": 900
    },
    {
        "loss": 0.5215,
        "grad_norm": 7.4538984298706055,
        "learning_rate": 9.193976970770595e-06,
        "epoch": 0.8060230292294066,
        "step": 910
    },
    {
        "loss": 0.4295,
        "grad_norm": 9.992740631103516,
        "learning_rate": 9.185119574844996e-06,
        "epoch": 0.8148804251550045,
        "step": 920
    },
    {
        "loss": 0.5585,
        "grad_norm": 16.849613189697266,
        "learning_rate": 9.176262178919398e-06,
        "epoch": 0.8237378210806023,
        "step": 930
    },
    {
        "loss": 0.4373,
        "grad_norm": 9.38866901397705,
        "learning_rate": 9.167404782993801e-06,
        "epoch": 0.8325952170062002,
        "step": 940
    },
    {
        "loss": 0.547,
        "grad_norm": 9.506311416625977,
        "learning_rate": 9.158547387068203e-06,
        "epoch": 0.8414526129317981,
        "step": 950
    },
    {
        "loss": 0.4562,
        "grad_norm": 6.856567859649658,
        "learning_rate": 9.149689991142604e-06,
        "epoch": 0.8503100088573959,
        "step": 960
    },
    {
        "loss": 0.4881,
        "grad_norm": 10.826138496398926,
        "learning_rate": 9.140832595217008e-06,
        "epoch": 0.8591674047829938,
        "step": 970
    },
    {
        "loss": 0.4464,
        "grad_norm": 14.764484405517578,
        "learning_rate": 9.13197519929141e-06,
        "epoch": 0.8680248007085917,
        "step": 980
    },
    {
        "loss": 0.55,
        "grad_norm": 10.20794677734375,
        "learning_rate": 9.123117803365811e-06,
        "epoch": 0.8768821966341895,
        "step": 990
    },
    {
        "loss": 0.4761,
        "grad_norm": 10.260964393615723,
        "learning_rate": 9.114260407440213e-06,
        "epoch": 0.8857395925597874,
        "step": 1000
    },
    {
        "loss": 0.4654,
        "grad_norm": 15.357306480407715,
        "learning_rate": 9.105403011514616e-06,
        "epoch": 0.8945969884853853,
        "step": 1010
    },
    {
        "loss": 0.4413,
        "grad_norm": 13.678326606750488,
        "learning_rate": 9.096545615589017e-06,
        "epoch": 0.9034543844109831,
        "step": 1020
    },
    {
        "loss": 0.4825,
        "grad_norm": 11.325357437133789,
        "learning_rate": 9.087688219663419e-06,
        "epoch": 0.912311780336581,
        "step": 1030
    },
    {
        "loss": 0.4028,
        "grad_norm": 14.366002082824707,
        "learning_rate": 9.078830823737822e-06,
        "epoch": 0.9211691762621789,
        "step": 1040
    },
    {
        "loss": 0.4096,
        "grad_norm": 7.984833717346191,
        "learning_rate": 9.069973427812224e-06,
        "epoch": 0.9300265721877768,
        "step": 1050
    },
    {
        "loss": 0.4823,
        "grad_norm": 13.699256896972656,
        "learning_rate": 9.061116031886627e-06,
        "epoch": 0.9388839681133747,
        "step": 1060
    },
    {
        "loss": 0.4585,
        "grad_norm": 16.817333221435547,
        "learning_rate": 9.052258635961029e-06,
        "epoch": 0.9477413640389726,
        "step": 1070
    },
    {
        "loss": 0.4874,
        "grad_norm": 13.181870460510254,
        "learning_rate": 9.04340124003543e-06,
        "epoch": 0.9565987599645704,
        "step": 1080
    },
    {
        "loss": 0.4874,
        "grad_norm": 9.822175025939941,
        "learning_rate": 9.034543844109832e-06,
        "epoch": 0.9654561558901683,
        "step": 1090
    },
    {
        "loss": 0.3835,
        "grad_norm": 10.199759483337402,
        "learning_rate": 9.025686448184234e-06,
        "epoch": 0.9743135518157662,
        "step": 1100
    },
    {
        "loss": 0.4262,
        "grad_norm": 9.211343765258789,
        "learning_rate": 9.016829052258637e-06,
        "epoch": 0.983170947741364,
        "step": 1110
    },
    {
        "loss": 0.4602,
        "grad_norm": 14.301056861877441,
        "learning_rate": 9.007971656333039e-06,
        "epoch": 0.9920283436669619,
        "step": 1120
    },
    {
        "eval_loss": 0.436585009098053,
        "eval_accuracy": 0.80547,
        "eval_precision": 0.86915,
        "eval_recall": 0.71922,
        "eval_f1": 0.78711,
        "eval_runtime": 148.9807,
        "eval_samples_per_second": 60.625,
        "eval_steps_per_second": 3.792,
        "epoch": 1.0,
        "step": 1129
    },
    {
        "loss": 0.4787,
        "grad_norm": 13.003019332885742,
        "learning_rate": 8.999114260407442e-06,
        "epoch": 1.0008857395925599,
        "step": 1130
    },
    {
        "loss": 0.4475,
        "grad_norm": 6.5779900550842285,
        "learning_rate": 8.990256864481844e-06,
        "epoch": 1.0097431355181576,
        "step": 1140
    },
    {
        "loss": 0.3333,
        "grad_norm": 12.393670082092285,
        "learning_rate": 8.981399468556245e-06,
        "epoch": 1.0186005314437556,
        "step": 1150
    },
    {
        "loss": 0.3443,
        "grad_norm": 10.743741035461426,
        "learning_rate": 8.972542072630648e-06,
        "epoch": 1.0274579273693534,
        "step": 1160
    },
    {
        "loss": 0.3809,
        "grad_norm": 11.49738883972168,
        "learning_rate": 8.963684676705048e-06,
        "epoch": 1.0363153232949514,
        "step": 1170
    },
    {
        "loss": 0.3884,
        "grad_norm": 19.740415573120117,
        "learning_rate": 8.954827280779452e-06,
        "epoch": 1.045172719220549,
        "step": 1180
    },
    {
        "loss": 0.4153,
        "grad_norm": 10.032486915588379,
        "learning_rate": 8.945969884853853e-06,
        "epoch": 1.054030115146147,
        "step": 1190
    },
    {
        "loss": 0.3982,
        "grad_norm": 16.019609451293945,
        "learning_rate": 8.937112488928255e-06,
        "epoch": 1.0628875110717448,
        "step": 1200
    },
    {
        "loss": 0.364,
        "grad_norm": 11.175772666931152,
        "learning_rate": 8.928255093002658e-06,
        "epoch": 1.0717449069973428,
        "step": 1210
    },
    {
        "loss": 0.3418,
        "grad_norm": 7.970484733581543,
        "learning_rate": 8.91939769707706e-06,
        "epoch": 1.0806023029229406,
        "step": 1220
    },
    {
        "loss": 0.3214,
        "grad_norm": 27.435836791992188,
        "learning_rate": 8.910540301151463e-06,
        "epoch": 1.0894596988485385,
        "step": 1230
    },
    {
        "loss": 0.431,
        "grad_norm": 9.084474563598633,
        "learning_rate": 8.901682905225865e-06,
        "epoch": 1.0983170947741363,
        "step": 1240
    },
    {
        "loss": 0.3435,
        "grad_norm": 10.291875839233398,
        "learning_rate": 8.892825509300266e-06,
        "epoch": 1.1071744906997343,
        "step": 1250
    },
    {
        "loss": 0.3963,
        "grad_norm": 10.066049575805664,
        "learning_rate": 8.883968113374668e-06,
        "epoch": 1.1160318866253323,
        "step": 1260
    },
    {
        "loss": 0.2682,
        "grad_norm": 11.163097381591797,
        "learning_rate": 8.87511071744907e-06,
        "epoch": 1.12488928255093,
        "step": 1270
    },
    {
        "loss": 0.3393,
        "grad_norm": 15.168447494506836,
        "learning_rate": 8.866253321523473e-06,
        "epoch": 1.133746678476528,
        "step": 1280
    },
    {
        "loss": 0.409,
        "grad_norm": 22.200868606567383,
        "learning_rate": 8.857395925597874e-06,
        "epoch": 1.1426040744021257,
        "step": 1290
    },
    {
        "loss": 0.387,
        "grad_norm": 13.684958457946777,
        "learning_rate": 8.848538529672278e-06,
        "epoch": 1.1514614703277237,
        "step": 1300
    },
    {
        "loss": 0.4451,
        "grad_norm": 24.40410804748535,
        "learning_rate": 8.83968113374668e-06,
        "epoch": 1.1603188662533215,
        "step": 1310
    },
    {
        "loss": 0.3961,
        "grad_norm": 22.50666618347168,
        "learning_rate": 8.830823737821081e-06,
        "epoch": 1.1691762621789195,
        "step": 1320
    },
    {
        "loss": 0.3713,
        "grad_norm": 17.415361404418945,
        "learning_rate": 8.821966341895484e-06,
        "epoch": 1.1780336581045172,
        "step": 1330
    },
    {
        "loss": 0.4093,
        "grad_norm": 17.29610824584961,
        "learning_rate": 8.813108945969886e-06,
        "epoch": 1.1868910540301152,
        "step": 1340
    },
    {
        "loss": 0.318,
        "grad_norm": 13.7772855758667,
        "learning_rate": 8.804251550044287e-06,
        "epoch": 1.195748449955713,
        "step": 1350
    },
    {
        "loss": 0.2875,
        "grad_norm": 13.150378227233887,
        "learning_rate": 8.795394154118689e-06,
        "epoch": 1.204605845881311,
        "step": 1360
    },
    {
        "loss": 0.2692,
        "grad_norm": 19.51985740661621,
        "learning_rate": 8.786536758193092e-06,
        "epoch": 1.2134632418069087,
        "step": 1370
    },
    {
        "loss": 0.3772,
        "grad_norm": 28.288742065429688,
        "learning_rate": 8.777679362267494e-06,
        "epoch": 1.2223206377325067,
        "step": 1380
    },
    {
        "loss": 0.3973,
        "grad_norm": 14.57874584197998,
        "learning_rate": 8.768821966341896e-06,
        "epoch": 1.2311780336581046,
        "step": 1390
    },
    {
        "loss": 0.4408,
        "grad_norm": 35.852691650390625,
        "learning_rate": 8.759964570416299e-06,
        "epoch": 1.2400354295837024,
        "step": 1400
    },
    {
        "loss": 0.4,
        "grad_norm": 14.868095397949219,
        "learning_rate": 8.7511071744907e-06,
        "epoch": 1.2488928255093001,
        "step": 1410
    },
    {
        "loss": 0.3166,
        "grad_norm": 13.894383430480957,
        "learning_rate": 8.742249778565102e-06,
        "epoch": 1.2577502214348981,
        "step": 1420
    },
    {
        "loss": 0.2681,
        "grad_norm": 15.784101486206055,
        "learning_rate": 8.733392382639505e-06,
        "epoch": 1.266607617360496,
        "step": 1430
    },
    {
        "loss": 0.333,
        "grad_norm": 7.688616752624512,
        "learning_rate": 8.724534986713907e-06,
        "epoch": 1.2754650132860939,
        "step": 1440
    },
    {
        "loss": 0.349,
        "grad_norm": 30.947416305541992,
        "learning_rate": 8.715677590788309e-06,
        "epoch": 1.2843224092116918,
        "step": 1450
    },
    {
        "loss": 0.3741,
        "grad_norm": 18.31273078918457,
        "learning_rate": 8.70682019486271e-06,
        "epoch": 1.2931798051372896,
        "step": 1460
    },
    {
        "loss": 0.3655,
        "grad_norm": 12.844465255737305,
        "learning_rate": 8.697962798937114e-06,
        "epoch": 1.3020372010628876,
        "step": 1470
    },
    {
        "loss": 0.2748,
        "grad_norm": 13.450091361999512,
        "learning_rate": 8.689105403011515e-06,
        "epoch": 1.3108945969884853,
        "step": 1480
    },
    {
        "loss": 0.3406,
        "grad_norm": 15.962504386901855,
        "learning_rate": 8.680248007085917e-06,
        "epoch": 1.3197519929140833,
        "step": 1490
    },
    {
        "loss": 0.3546,
        "grad_norm": 35.095462799072266,
        "learning_rate": 8.67139061116032e-06,
        "epoch": 1.328609388839681,
        "step": 1500
    },
    {
        "loss": 0.429,
        "grad_norm": 29.122020721435547,
        "learning_rate": 8.662533215234722e-06,
        "epoch": 1.337466784765279,
        "step": 1510
    },
    {
        "loss": 0.358,
        "grad_norm": 20.87422752380371,
        "learning_rate": 8.653675819309125e-06,
        "epoch": 1.346324180690877,
        "step": 1520
    },
    {
        "loss": 0.3433,
        "grad_norm": 9.9850492477417,
        "learning_rate": 8.644818423383527e-06,
        "epoch": 1.3551815766164748,
        "step": 1530
    },
    {
        "loss": 0.3753,
        "grad_norm": 15.885647773742676,
        "learning_rate": 8.635961027457928e-06,
        "epoch": 1.3640389725420725,
        "step": 1540
    },
    {
        "loss": 0.3804,
        "grad_norm": 18.036148071289062,
        "learning_rate": 8.62710363153233e-06,
        "epoch": 1.3728963684676705,
        "step": 1550
    },
    {
        "loss": 0.3669,
        "grad_norm": 12.834843635559082,
        "learning_rate": 8.618246235606731e-06,
        "epoch": 1.3817537643932685,
        "step": 1560
    },
    {
        "loss": 0.3058,
        "grad_norm": 19.93909454345703,
        "learning_rate": 8.609388839681135e-06,
        "epoch": 1.3906111603188662,
        "step": 1570
    },
    {
        "loss": 0.2813,
        "grad_norm": 20.233308792114258,
        "learning_rate": 8.600531443755536e-06,
        "epoch": 1.3994685562444642,
        "step": 1580
    },
    {
        "loss": 0.3686,
        "grad_norm": 10.237378120422363,
        "learning_rate": 8.591674047829938e-06,
        "epoch": 1.408325952170062,
        "step": 1590
    },
    {
        "loss": 0.3024,
        "grad_norm": 13.583871841430664,
        "learning_rate": 8.582816651904341e-06,
        "epoch": 1.41718334809566,
        "step": 1600
    },
    {
        "loss": 0.2182,
        "grad_norm": 19.56892967224121,
        "learning_rate": 8.573959255978743e-06,
        "epoch": 1.4260407440212577,
        "step": 1610
    },
    {
        "loss": 0.3762,
        "grad_norm": 20.188283920288086,
        "learning_rate": 8.565101860053146e-06,
        "epoch": 1.4348981399468557,
        "step": 1620
    },
    {
        "loss": 0.3262,
        "grad_norm": 25.318334579467773,
        "learning_rate": 8.556244464127548e-06,
        "epoch": 1.4437555358724534,
        "step": 1630
    },
    {
        "loss": 0.3433,
        "grad_norm": 11.699883460998535,
        "learning_rate": 8.54738706820195e-06,
        "epoch": 1.4526129317980514,
        "step": 1640
    },
    {
        "loss": 0.2433,
        "grad_norm": 14.221207618713379,
        "learning_rate": 8.538529672276351e-06,
        "epoch": 1.4614703277236494,
        "step": 1650
    },
    {
        "loss": 0.417,
        "grad_norm": 17.618247985839844,
        "learning_rate": 8.529672276350753e-06,
        "epoch": 1.4703277236492471,
        "step": 1660
    },
    {
        "loss": 0.3134,
        "grad_norm": 17.846881866455078,
        "learning_rate": 8.520814880425156e-06,
        "epoch": 1.4791851195748449,
        "step": 1670
    },
    {
        "loss": 0.4047,
        "grad_norm": 24.21932029724121,
        "learning_rate": 8.511957484499558e-06,
        "epoch": 1.4880425155004429,
        "step": 1680
    },
    {
        "loss": 0.2729,
        "grad_norm": 19.443641662597656,
        "learning_rate": 8.50310008857396e-06,
        "epoch": 1.4968999114260408,
        "step": 1690
    },
    {
        "loss": 0.3118,
        "grad_norm": 12.084664344787598,
        "learning_rate": 8.494242692648362e-06,
        "epoch": 1.5057573073516386,
        "step": 1700
    },
    {
        "loss": 0.3128,
        "grad_norm": 10.60700798034668,
        "learning_rate": 8.485385296722764e-06,
        "epoch": 1.5146147032772364,
        "step": 1710
    },
    {
        "loss": 0.228,
        "grad_norm": 20.312623977661133,
        "learning_rate": 8.476527900797167e-06,
        "epoch": 1.5234720992028343,
        "step": 1720
    },
    {
        "loss": 0.3171,
        "grad_norm": 13.560127258300781,
        "learning_rate": 8.467670504871567e-06,
        "epoch": 1.5323294951284323,
        "step": 1730
    },
    {
        "loss": 0.3631,
        "grad_norm": 17.029394149780273,
        "learning_rate": 8.45881310894597e-06,
        "epoch": 1.54118689105403,
        "step": 1740
    },
    {
        "loss": 0.212,
        "grad_norm": 18.852136611938477,
        "learning_rate": 8.449955713020372e-06,
        "epoch": 1.550044286979628,
        "step": 1750
    },
    {
        "loss": 0.2916,
        "grad_norm": 17.87649917602539,
        "learning_rate": 8.441098317094775e-06,
        "epoch": 1.5589016829052258,
        "step": 1760
    },
    {
        "loss": 0.4025,
        "grad_norm": 38.44598388671875,
        "learning_rate": 8.432240921169177e-06,
        "epoch": 1.5677590788308238,
        "step": 1770
    },
    {
        "loss": 0.2978,
        "grad_norm": 23.074169158935547,
        "learning_rate": 8.423383525243579e-06,
        "epoch": 1.5766164747564217,
        "step": 1780
    },
    {
        "loss": 0.2774,
        "grad_norm": 23.774911880493164,
        "learning_rate": 8.414526129317982e-06,
        "epoch": 1.5854738706820195,
        "step": 1790
    },
    {
        "loss": 0.3992,
        "grad_norm": 21.88105010986328,
        "learning_rate": 8.405668733392384e-06,
        "epoch": 1.5943312666076173,
        "step": 1800
    },
    {
        "loss": 0.344,
        "grad_norm": 18.86817741394043,
        "learning_rate": 8.396811337466785e-06,
        "epoch": 1.6031886625332152,
        "step": 1810
    },
    {
        "loss": 0.3108,
        "grad_norm": 43.184993743896484,
        "learning_rate": 8.387953941541187e-06,
        "epoch": 1.6120460584588132,
        "step": 1820
    },
    {
        "loss": 0.3047,
        "grad_norm": 26.57236671447754,
        "learning_rate": 8.37909654561559e-06,
        "epoch": 1.620903454384411,
        "step": 1830
    },
    {
        "loss": 0.3312,
        "grad_norm": 18.682682037353516,
        "learning_rate": 8.370239149689992e-06,
        "epoch": 1.6297608503100087,
        "step": 1840
    },
    {
        "loss": 0.3038,
        "grad_norm": 16.791128158569336,
        "learning_rate": 8.361381753764393e-06,
        "epoch": 1.6386182462356067,
        "step": 1850
    },
    {
        "loss": 0.3449,
        "grad_norm": 13.890902519226074,
        "learning_rate": 8.352524357838797e-06,
        "epoch": 1.6474756421612047,
        "step": 1860
    },
    {
        "loss": 0.2788,
        "grad_norm": 12.156997680664062,
        "learning_rate": 8.343666961913198e-06,
        "epoch": 1.6563330380868024,
        "step": 1870
    },
    {
        "loss": 0.2716,
        "grad_norm": 13.944175720214844,
        "learning_rate": 8.3348095659876e-06,
        "epoch": 1.6651904340124002,
        "step": 1880
    },
    {
        "loss": 0.2991,
        "grad_norm": 12.0717191696167,
        "learning_rate": 8.325952170062003e-06,
        "epoch": 1.6740478299379982,
        "step": 1890
    },
    {
        "loss": 0.1965,
        "grad_norm": 4.205066204071045,
        "learning_rate": 8.317094774136405e-06,
        "epoch": 1.6829052258635961,
        "step": 1900
    },
    {
        "loss": 0.212,
        "grad_norm": 12.676177024841309,
        "learning_rate": 8.308237378210808e-06,
        "epoch": 1.6917626217891941,
        "step": 1910
    },
    {
        "loss": 0.3162,
        "grad_norm": 19.13896369934082,
        "learning_rate": 8.299379982285208e-06,
        "epoch": 1.7006200177147919,
        "step": 1920
    },
    {
        "loss": 0.2724,
        "grad_norm": 17.141809463500977,
        "learning_rate": 8.290522586359611e-06,
        "epoch": 1.7094774136403896,
        "step": 1930
    },
    {
        "loss": 0.2779,
        "grad_norm": 19.336971282958984,
        "learning_rate": 8.281665190434013e-06,
        "epoch": 1.7183348095659876,
        "step": 1940
    },
    {
        "loss": 0.2242,
        "grad_norm": 10.90251350402832,
        "learning_rate": 8.272807794508414e-06,
        "epoch": 1.7271922054915856,
        "step": 1950
    },
    {
        "loss": 0.3213,
        "grad_norm": 23.102916717529297,
        "learning_rate": 8.263950398582818e-06,
        "epoch": 1.7360496014171833,
        "step": 1960
    },
    {
        "loss": 0.1848,
        "grad_norm": 5.316694736480713,
        "learning_rate": 8.25509300265722e-06,
        "epoch": 1.744906997342781,
        "step": 1970
    },
    {
        "loss": 0.2703,
        "grad_norm": 13.811529159545898,
        "learning_rate": 8.246235606731621e-06,
        "epoch": 1.753764393268379,
        "step": 1980
    },
    {
        "loss": 0.2791,
        "grad_norm": 22.32870864868164,
        "learning_rate": 8.237378210806024e-06,
        "epoch": 1.762621789193977,
        "step": 1990
    },
    {
        "loss": 0.2016,
        "grad_norm": 24.196523666381836,
        "learning_rate": 8.228520814880426e-06,
        "epoch": 1.7714791851195748,
        "step": 2000
    },
    {
        "loss": 0.3353,
        "grad_norm": 20.65818214416504,
        "learning_rate": 8.219663418954828e-06,
        "epoch": 1.7803365810451726,
        "step": 2010
    },
    {
        "loss": 0.265,
        "grad_norm": 18.664794921875,
        "learning_rate": 8.210806023029229e-06,
        "epoch": 1.7891939769707705,
        "step": 2020
    },
    {
        "loss": 0.365,
        "grad_norm": 21.750293731689453,
        "learning_rate": 8.201948627103632e-06,
        "epoch": 1.7980513728963685,
        "step": 2030
    },
    {
        "loss": 0.1595,
        "grad_norm": 8.455451011657715,
        "learning_rate": 8.193091231178034e-06,
        "epoch": 1.8069087688219665,
        "step": 2040
    },
    {
        "loss": 0.1924,
        "grad_norm": 18.9792537689209,
        "learning_rate": 8.184233835252436e-06,
        "epoch": 1.8157661647475642,
        "step": 2050
    },
    {
        "loss": 0.3531,
        "grad_norm": 25.467439651489258,
        "learning_rate": 8.175376439326839e-06,
        "epoch": 1.824623560673162,
        "step": 2060
    },
    {
        "loss": 0.3076,
        "grad_norm": 20.88355827331543,
        "learning_rate": 8.16651904340124e-06,
        "epoch": 1.83348095659876,
        "step": 2070
    },
    {
        "loss": 0.2216,
        "grad_norm": 21.705873489379883,
        "learning_rate": 8.157661647475644e-06,
        "epoch": 1.842338352524358,
        "step": 2080
    },
    {
        "loss": 0.2778,
        "grad_norm": 19.14857292175293,
        "learning_rate": 8.148804251550045e-06,
        "epoch": 1.8511957484499557,
        "step": 2090
    },
    {
        "loss": 0.3197,
        "grad_norm": 13.280537605285645,
        "learning_rate": 8.139946855624447e-06,
        "epoch": 1.8600531443755535,
        "step": 2100
    },
    {
        "loss": 0.1966,
        "grad_norm": 13.637239456176758,
        "learning_rate": 8.131089459698849e-06,
        "epoch": 1.8689105403011514,
        "step": 2110
    },
    {
        "loss": 0.176,
        "grad_norm": 8.594023704528809,
        "learning_rate": 8.12223206377325e-06,
        "epoch": 1.8777679362267494,
        "step": 2120
    },
    {
        "loss": 0.2275,
        "grad_norm": 20.72347640991211,
        "learning_rate": 8.113374667847654e-06,
        "epoch": 1.8866253321523472,
        "step": 2130
    },
    {
        "loss": 0.2079,
        "grad_norm": 30.085844039916992,
        "learning_rate": 8.104517271922055e-06,
        "epoch": 1.895482728077945,
        "step": 2140
    },
    {
        "loss": 0.1614,
        "grad_norm": 21.850725173950195,
        "learning_rate": 8.095659875996459e-06,
        "epoch": 1.904340124003543,
        "step": 2150
    },
    {
        "loss": 0.2544,
        "grad_norm": 26.85651206970215,
        "learning_rate": 8.08680248007086e-06,
        "epoch": 1.9131975199291409,
        "step": 2160
    },
    {
        "loss": 0.2976,
        "grad_norm": 17.358930587768555,
        "learning_rate": 8.077945084145262e-06,
        "epoch": 1.9220549158547389,
        "step": 2170
    },
    {
        "loss": 0.3569,
        "grad_norm": 20.284631729125977,
        "learning_rate": 8.069087688219665e-06,
        "epoch": 1.9309123117803366,
        "step": 2180
    },
    {
        "loss": 0.2751,
        "grad_norm": 27.237184524536133,
        "learning_rate": 8.060230292294067e-06,
        "epoch": 1.9397697077059344,
        "step": 2190
    },
    {
        "loss": 0.2876,
        "grad_norm": 33.11233139038086,
        "learning_rate": 8.051372896368468e-06,
        "epoch": 1.9486271036315324,
        "step": 2200
    },
    {
        "loss": 0.212,
        "grad_norm": 15.309406280517578,
        "learning_rate": 8.04251550044287e-06,
        "epoch": 1.9574844995571303,
        "step": 2210
    },
    {
        "loss": 0.2143,
        "grad_norm": 24.037601470947266,
        "learning_rate": 8.033658104517273e-06,
        "epoch": 1.966341895482728,
        "step": 2220
    },
    {
        "loss": 0.2644,
        "grad_norm": 19.707551956176758,
        "learning_rate": 8.024800708591675e-06,
        "epoch": 1.9751992914083258,
        "step": 2230
    },
    {
        "loss": 0.1738,
        "grad_norm": 19.915380477905273,
        "learning_rate": 8.015943312666076e-06,
        "epoch": 1.9840566873339238,
        "step": 2240
    },
    {
        "loss": 0.2964,
        "grad_norm": 13.394295692443848,
        "learning_rate": 8.00708591674048e-06,
        "epoch": 1.9929140832595218,
        "step": 2250
    },
    {
        "eval_loss": 0.20644652843475342,
        "eval_accuracy": 0.92814,
        "eval_precision": 0.91095,
        "eval_recall": 0.94907,
        "eval_f1": 0.92962,
        "eval_runtime": 149.4904,
        "eval_samples_per_second": 60.419,
        "eval_steps_per_second": 3.78,
        "epoch": 2.0,
        "step": 2258
    },
    {
        "loss": 0.2126,
        "grad_norm": 0.9356791377067566,
        "learning_rate": 7.998228520814881e-06,
        "epoch": 2.0017714791851198,
        "step": 2260
    },
    {
        "loss": 0.2229,
        "grad_norm": 31.50507354736328,
        "learning_rate": 7.989371124889283e-06,
        "epoch": 2.0106288751107173,
        "step": 2270
    },
    {
        "loss": 0.1719,
        "grad_norm": 20.665695190429688,
        "learning_rate": 7.980513728963686e-06,
        "epoch": 2.0194862710363153,
        "step": 2280
    },
    {
        "loss": 0.1944,
        "grad_norm": 37.672088623046875,
        "learning_rate": 7.971656333038086e-06,
        "epoch": 2.0283436669619133,
        "step": 2290
    },
    {
        "loss": 0.1093,
        "grad_norm": 25.199565887451172,
        "learning_rate": 7.96279893711249e-06,
        "epoch": 2.0372010628875112,
        "step": 2300
    },
    {
        "loss": 0.207,
        "grad_norm": 23.294191360473633,
        "learning_rate": 7.953941541186891e-06,
        "epoch": 2.0460584588131088,
        "step": 2310
    },
    {
        "loss": 0.1555,
        "grad_norm": 41.11394500732422,
        "learning_rate": 7.945084145261294e-06,
        "epoch": 2.0549158547387067,
        "step": 2320
    },
    {
        "loss": 0.1398,
        "grad_norm": 22.136579513549805,
        "learning_rate": 7.936226749335696e-06,
        "epoch": 2.0637732506643047,
        "step": 2330
    },
    {
        "loss": 0.1468,
        "grad_norm": 26.675701141357422,
        "learning_rate": 7.927369353410098e-06,
        "epoch": 2.0726306465899027,
        "step": 2340
    },
    {
        "loss": 0.2062,
        "grad_norm": 13.940982818603516,
        "learning_rate": 7.918511957484501e-06,
        "epoch": 2.0814880425155002,
        "step": 2350
    },
    {
        "loss": 0.1941,
        "grad_norm": 21.324844360351562,
        "learning_rate": 7.909654561558902e-06,
        "epoch": 2.090345438441098,
        "step": 2360
    },
    {
        "loss": 0.156,
        "grad_norm": 27.599008560180664,
        "learning_rate": 7.900797165633304e-06,
        "epoch": 2.099202834366696,
        "step": 2370
    },
    {
        "loss": 0.2169,
        "grad_norm": 15.940502166748047,
        "learning_rate": 7.891939769707706e-06,
        "epoch": 2.108060230292294,
        "step": 2380
    },
    {
        "loss": 0.1519,
        "grad_norm": 32.4281120300293,
        "learning_rate": 7.883082373782109e-06,
        "epoch": 2.116917626217892,
        "step": 2390
    },
    {
        "loss": 0.1334,
        "grad_norm": 41.60725402832031,
        "learning_rate": 7.87422497785651e-06,
        "epoch": 2.1257750221434897,
        "step": 2400
    },
    {
        "loss": 0.1927,
        "grad_norm": 25.25992774963379,
        "learning_rate": 7.865367581930912e-06,
        "epoch": 2.1346324180690877,
        "step": 2410
    },
    {
        "loss": 0.2509,
        "grad_norm": 28.413455963134766,
        "learning_rate": 7.856510186005316e-06,
        "epoch": 2.1434898139946856,
        "step": 2420
    },
    {
        "loss": 0.1181,
        "grad_norm": 4.84895658493042,
        "learning_rate": 7.847652790079717e-06,
        "epoch": 2.1523472099202836,
        "step": 2430
    },
    {
        "loss": 0.1493,
        "grad_norm": 20.278404235839844,
        "learning_rate": 7.838795394154119e-06,
        "epoch": 2.161204605845881,
        "step": 2440
    },
    {
        "loss": 0.1672,
        "grad_norm": 39.68865203857422,
        "learning_rate": 7.829937998228522e-06,
        "epoch": 2.170062001771479,
        "step": 2450
    },
    {
        "loss": 0.1516,
        "grad_norm": 45.28266525268555,
        "learning_rate": 7.821080602302924e-06,
        "epoch": 2.178919397697077,
        "step": 2460
    },
    {
        "loss": 0.1,
        "grad_norm": 72.67395782470703,
        "learning_rate": 7.812223206377327e-06,
        "epoch": 2.187776793622675,
        "step": 2470
    },
    {
        "loss": 0.0461,
        "grad_norm": 3.593750476837158,
        "learning_rate": 7.803365810451727e-06,
        "epoch": 2.1966341895482726,
        "step": 2480
    },
    {
        "loss": 0.1121,
        "grad_norm": 45.266090393066406,
        "learning_rate": 7.79450841452613e-06,
        "epoch": 2.2054915854738706,
        "step": 2490
    },
    {
        "loss": 0.2447,
        "grad_norm": 50.934383392333984,
        "learning_rate": 7.785651018600532e-06,
        "epoch": 2.2143489813994686,
        "step": 2500
    },
    {
        "loss": 0.3109,
        "grad_norm": 50.03815841674805,
        "learning_rate": 7.776793622674933e-06,
        "epoch": 2.2232063773250665,
        "step": 2510
    },
    {
        "loss": 0.1451,
        "grad_norm": 54.36135482788086,
        "learning_rate": 7.767936226749337e-06,
        "epoch": 2.2320637732506645,
        "step": 2520
    },
    {
        "loss": 0.194,
        "grad_norm": 18.209774017333984,
        "learning_rate": 7.759078830823738e-06,
        "epoch": 2.240921169176262,
        "step": 2530
    },
    {
        "loss": 0.2156,
        "grad_norm": 8.032845497131348,
        "learning_rate": 7.750221434898142e-06,
        "epoch": 2.24977856510186,
        "step": 2540
    },
    {
        "loss": 0.1953,
        "grad_norm": 5.135299205780029,
        "learning_rate": 7.741364038972543e-06,
        "epoch": 2.258635961027458,
        "step": 2550
    },
    {
        "loss": 0.1472,
        "grad_norm": 27.614700317382812,
        "learning_rate": 7.732506643046945e-06,
        "epoch": 2.267493356953056,
        "step": 2560
    },
    {
        "loss": 0.1052,
        "grad_norm": 1.170892596244812,
        "learning_rate": 7.723649247121346e-06,
        "epoch": 2.2763507528786535,
        "step": 2570
    },
    {
        "loss": 0.1429,
        "grad_norm": 50.75313949584961,
        "learning_rate": 7.714791851195748e-06,
        "epoch": 2.2852081488042515,
        "step": 2580
    },
    {
        "loss": 0.1732,
        "grad_norm": 24.94674301147461,
        "learning_rate": 7.705934455270151e-06,
        "epoch": 2.2940655447298495,
        "step": 2590
    },
    {
        "loss": 0.1839,
        "grad_norm": 44.825687408447266,
        "learning_rate": 7.697077059344553e-06,
        "epoch": 2.3029229406554474,
        "step": 2600
    },
    {
        "loss": 0.1164,
        "grad_norm": 44.7351188659668,
        "learning_rate": 7.688219663418956e-06,
        "epoch": 2.311780336581045,
        "step": 2610
    },
    {
        "loss": 0.3132,
        "grad_norm": 27.001249313354492,
        "learning_rate": 7.679362267493358e-06,
        "epoch": 2.320637732506643,
        "step": 2620
    },
    {
        "loss": 0.2033,
        "grad_norm": 42.79821014404297,
        "learning_rate": 7.67050487156776e-06,
        "epoch": 2.329495128432241,
        "step": 2630
    },
    {
        "loss": 0.1137,
        "grad_norm": 35.80387878417969,
        "learning_rate": 7.661647475642163e-06,
        "epoch": 2.338352524357839,
        "step": 2640
    },
    {
        "loss": 0.1313,
        "grad_norm": 13.073899269104004,
        "learning_rate": 7.652790079716564e-06,
        "epoch": 2.3472099202834364,
        "step": 2650
    },
    {
        "loss": 0.2732,
        "grad_norm": 0.6827589273452759,
        "learning_rate": 7.643932683790966e-06,
        "epoch": 2.3560673162090344,
        "step": 2660
    },
    {
        "loss": 0.1897,
        "grad_norm": 18.122718811035156,
        "learning_rate": 7.635075287865368e-06,
        "epoch": 2.3649247121346324,
        "step": 2670
    },
    {
        "loss": 0.1723,
        "grad_norm": 57.21292495727539,
        "learning_rate": 7.62621789193977e-06,
        "epoch": 2.3737821080602304,
        "step": 2680
    },
    {
        "loss": 0.1896,
        "grad_norm": 56.00211715698242,
        "learning_rate": 7.6173604960141725e-06,
        "epoch": 2.3826395039858284,
        "step": 2690
    },
    {
        "loss": 0.0794,
        "grad_norm": 40.619911193847656,
        "learning_rate": 7.608503100088574e-06,
        "epoch": 2.391496899911426,
        "step": 2700
    },
    {
        "loss": 0.1318,
        "grad_norm": 24.870254516601562,
        "learning_rate": 7.599645704162977e-06,
        "epoch": 2.400354295837024,
        "step": 2710
    },
    {
        "loss": 0.1067,
        "grad_norm": 10.262816429138184,
        "learning_rate": 7.590788308237379e-06,
        "epoch": 2.409211691762622,
        "step": 2720
    },
    {
        "loss": 0.1541,
        "grad_norm": 6.4874467849731445,
        "learning_rate": 7.5819309123117815e-06,
        "epoch": 2.41806908768822,
        "step": 2730
    },
    {
        "loss": 0.1397,
        "grad_norm": 22.323883056640625,
        "learning_rate": 7.573073516386183e-06,
        "epoch": 2.4269264836138174,
        "step": 2740
    },
    {
        "loss": 0.2563,
        "grad_norm": 59.00233459472656,
        "learning_rate": 7.5642161204605856e-06,
        "epoch": 2.4357838795394153,
        "step": 2750
    },
    {
        "loss": 0.0907,
        "grad_norm": 30.32655143737793,
        "learning_rate": 7.555358724534987e-06,
        "epoch": 2.4446412754650133,
        "step": 2760
    },
    {
        "loss": 0.087,
        "grad_norm": 4.682273864746094,
        "learning_rate": 7.546501328609389e-06,
        "epoch": 2.4534986713906113,
        "step": 2770
    },
    {
        "loss": 0.2003,
        "grad_norm": 40.9405517578125,
        "learning_rate": 7.537643932683791e-06,
        "epoch": 2.4623560673162093,
        "step": 2780
    },
    {
        "loss": 0.2541,
        "grad_norm": 31.286697387695312,
        "learning_rate": 7.528786536758194e-06,
        "epoch": 2.471213463241807,
        "step": 2790
    },
    {
        "loss": 0.2168,
        "grad_norm": 61.78007125854492,
        "learning_rate": 7.519929140832596e-06,
        "epoch": 2.4800708591674048,
        "step": 2800
    },
    {
        "loss": 0.1944,
        "grad_norm": 24.638132095336914,
        "learning_rate": 7.511071744906998e-06,
        "epoch": 2.4889282550930028,
        "step": 2810
    },
    {
        "loss": 0.0853,
        "grad_norm": 21.01214599609375,
        "learning_rate": 7.5022143489814e-06,
        "epoch": 2.4977856510186003,
        "step": 2820
    },
    {
        "loss": 0.113,
        "grad_norm": 20.29827308654785,
        "learning_rate": 7.493356953055803e-06,
        "epoch": 2.5066430469441983,
        "step": 2830
    },
    {
        "loss": 0.137,
        "grad_norm": 22.41326904296875,
        "learning_rate": 7.484499557130205e-06,
        "epoch": 2.5155004428697962,
        "step": 2840
    },
    {
        "loss": 0.1244,
        "grad_norm": 39.339420318603516,
        "learning_rate": 7.475642161204606e-06,
        "epoch": 2.524357838795394,
        "step": 2850
    },
    {
        "loss": 0.1765,
        "grad_norm": 41.53940200805664,
        "learning_rate": 7.466784765279008e-06,
        "epoch": 2.533215234720992,
        "step": 2860
    },
    {
        "loss": 0.1039,
        "grad_norm": 51.20173645019531,
        "learning_rate": 7.457927369353411e-06,
        "epoch": 2.54207263064659,
        "step": 2870
    },
    {
        "loss": 0.1494,
        "grad_norm": 45.5015983581543,
        "learning_rate": 7.449069973427812e-06,
        "epoch": 2.5509300265721877,
        "step": 2880
    },
    {
        "loss": 0.063,
        "grad_norm": 12.539859771728516,
        "learning_rate": 7.440212577502215e-06,
        "epoch": 2.5597874224977857,
        "step": 2890
    },
    {
        "loss": 0.1386,
        "grad_norm": 59.52016067504883,
        "learning_rate": 7.431355181576617e-06,
        "epoch": 2.5686448184233837,
        "step": 2900
    },
    {
        "loss": 0.1326,
        "grad_norm": 1.0295400619506836,
        "learning_rate": 7.42249778565102e-06,
        "epoch": 2.577502214348981,
        "step": 2910
    },
    {
        "loss": 0.2854,
        "grad_norm": 0.140315443277359,
        "learning_rate": 7.413640389725421e-06,
        "epoch": 2.586359610274579,
        "step": 2920
    },
    {
        "loss": 0.2562,
        "grad_norm": 60.700740814208984,
        "learning_rate": 7.404782993799824e-06,
        "epoch": 2.595217006200177,
        "step": 2930
    },
    {
        "loss": 0.0754,
        "grad_norm": 0.12602826952934265,
        "learning_rate": 7.3959255978742254e-06,
        "epoch": 2.604074402125775,
        "step": 2940
    },
    {
        "loss": 0.1813,
        "grad_norm": 0.19570691883563995,
        "learning_rate": 7.387068201948627e-06,
        "epoch": 2.612931798051373,
        "step": 2950
    },
    {
        "loss": 0.0259,
        "grad_norm": 27.62820053100586,
        "learning_rate": 7.3782108060230295e-06,
        "epoch": 2.6217891939769706,
        "step": 2960
    },
    {
        "loss": 0.1253,
        "grad_norm": 16.40363883972168,
        "learning_rate": 7.369353410097432e-06,
        "epoch": 2.6306465899025686,
        "step": 2970
    },
    {
        "loss": 0.1712,
        "grad_norm": 27.74159049987793,
        "learning_rate": 7.3604960141718344e-06,
        "epoch": 2.6395039858281666,
        "step": 2980
    },
    {
        "loss": 0.2524,
        "grad_norm": 4.153951644897461,
        "learning_rate": 7.351638618246236e-06,
        "epoch": 2.648361381753764,
        "step": 2990
    },
    {
        "loss": 0.101,
        "grad_norm": 54.26356506347656,
        "learning_rate": 7.3427812223206385e-06,
        "epoch": 2.657218777679362,
        "step": 3000
    },
    {
        "loss": 0.3131,
        "grad_norm": 0.5031055212020874,
        "learning_rate": 7.333923826395041e-06,
        "epoch": 2.66607617360496,
        "step": 3010
    },
    {
        "loss": 0.3285,
        "grad_norm": 31.388465881347656,
        "learning_rate": 7.325066430469443e-06,
        "epoch": 2.674933569530558,
        "step": 3020
    },
    {
        "loss": 0.2085,
        "grad_norm": 24.805978775024414,
        "learning_rate": 7.316209034543845e-06,
        "epoch": 2.683790965456156,
        "step": 3030
    },
    {
        "loss": 0.083,
        "grad_norm": 81.22382354736328,
        "learning_rate": 7.307351638618247e-06,
        "epoch": 2.692648361381754,
        "step": 3040
    },
    {
        "loss": 0.1874,
        "grad_norm": 52.53583526611328,
        "learning_rate": 7.298494242692648e-06,
        "epoch": 2.7015057573073515,
        "step": 3050
    },
    {
        "loss": 0.1475,
        "grad_norm": 48.74852752685547,
        "learning_rate": 7.289636846767051e-06,
        "epoch": 2.7103631532329495,
        "step": 3060
    },
    {
        "loss": 0.0661,
        "grad_norm": 10.380558013916016,
        "learning_rate": 7.280779450841453e-06,
        "epoch": 2.7192205491585475,
        "step": 3070
    },
    {
        "loss": 0.1659,
        "grad_norm": 27.06472396850586,
        "learning_rate": 7.271922054915856e-06,
        "epoch": 2.728077945084145,
        "step": 3080
    },
    {
        "loss": 0.1884,
        "grad_norm": 10.620587348937988,
        "learning_rate": 7.263064658990257e-06,
        "epoch": 2.736935341009743,
        "step": 3090
    },
    {
        "loss": 0.1177,
        "grad_norm": 33.69716262817383,
        "learning_rate": 7.25420726306466e-06,
        "epoch": 2.745792736935341,
        "step": 3100
    },
    {
        "loss": 0.1231,
        "grad_norm": 2.338148355484009,
        "learning_rate": 7.245349867139062e-06,
        "epoch": 2.754650132860939,
        "step": 3110
    },
    {
        "loss": 0.0906,
        "grad_norm": 49.456336975097656,
        "learning_rate": 7.2364924712134646e-06,
        "epoch": 2.763507528786537,
        "step": 3120
    },
    {
        "loss": 0.0196,
        "grad_norm": 3.0644073486328125,
        "learning_rate": 7.227635075287865e-06,
        "epoch": 2.7723649247121345,
        "step": 3130
    },
    {
        "loss": 0.1518,
        "grad_norm": 43.92347717285156,
        "learning_rate": 7.218777679362268e-06,
        "epoch": 2.7812223206377324,
        "step": 3140
    },
    {
        "loss": 0.1453,
        "grad_norm": 19.53704261779785,
        "learning_rate": 7.20992028343667e-06,
        "epoch": 2.7900797165633304,
        "step": 3150
    },
    {
        "loss": 0.1763,
        "grad_norm": 22.330434799194336,
        "learning_rate": 7.201062887511072e-06,
        "epoch": 2.7989371124889284,
        "step": 3160
    },
    {
        "loss": 0.1208,
        "grad_norm": 26.73418617248535,
        "learning_rate": 7.192205491585474e-06,
        "epoch": 2.807794508414526,
        "step": 3170
    },
    {
        "loss": 0.2268,
        "grad_norm": 98.22078704833984,
        "learning_rate": 7.183348095659877e-06,
        "epoch": 2.816651904340124,
        "step": 3180
    },
    {
        "loss": 0.1791,
        "grad_norm": 28.988025665283203,
        "learning_rate": 7.174490699734279e-06,
        "epoch": 2.825509300265722,
        "step": 3190
    },
    {
        "loss": 0.1744,
        "grad_norm": 37.82807922363281,
        "learning_rate": 7.165633303808681e-06,
        "epoch": 2.83436669619132,
        "step": 3200
    },
    {
        "loss": 0.1323,
        "grad_norm": 1.4505927562713623,
        "learning_rate": 7.156775907883083e-06,
        "epoch": 2.843224092116918,
        "step": 3210
    },
    {
        "loss": 0.1257,
        "grad_norm": 52.109291076660156,
        "learning_rate": 7.147918511957485e-06,
        "epoch": 2.8520814880425154,
        "step": 3220
    },
    {
        "loss": 0.1247,
        "grad_norm": 0.12169750034809113,
        "learning_rate": 7.1390611160318865e-06,
        "epoch": 2.8609388839681134,
        "step": 3230
    },
    {
        "loss": 0.141,
        "grad_norm": 11.719442367553711,
        "learning_rate": 7.130203720106289e-06,
        "epoch": 2.8697962798937113,
        "step": 3240
    },
    {
        "loss": 0.1187,
        "grad_norm": 109.79389953613281,
        "learning_rate": 7.121346324180691e-06,
        "epoch": 2.878653675819309,
        "step": 3250
    },
    {
        "loss": 0.212,
        "grad_norm": 30.3151912689209,
        "learning_rate": 7.112488928255094e-06,
        "epoch": 2.887511071744907,
        "step": 3260
    },
    {
        "loss": 0.1544,
        "grad_norm": 12.04631519317627,
        "learning_rate": 7.1036315323294955e-06,
        "epoch": 2.896368467670505,
        "step": 3270
    },
    {
        "loss": 0.1931,
        "grad_norm": 53.73564529418945,
        "learning_rate": 7.094774136403898e-06,
        "epoch": 2.905225863596103,
        "step": 3280
    },
    {
        "loss": 0.1496,
        "grad_norm": 41.3212890625,
        "learning_rate": 7.0859167404783e-06,
        "epoch": 2.9140832595217008,
        "step": 3290
    },
    {
        "loss": 0.1342,
        "grad_norm": 0.6516440510749817,
        "learning_rate": 7.077059344552703e-06,
        "epoch": 2.9229406554472988,
        "step": 3300
    },
    {
        "loss": 0.1325,
        "grad_norm": 56.34178161621094,
        "learning_rate": 7.0682019486271045e-06,
        "epoch": 2.9317980513728963,
        "step": 3310
    },
    {
        "loss": 0.1472,
        "grad_norm": 0.1613711714744568,
        "learning_rate": 7.059344552701506e-06,
        "epoch": 2.9406554472984943,
        "step": 3320
    },
    {
        "loss": 0.0686,
        "grad_norm": 2.8258652687072754,
        "learning_rate": 7.0504871567759085e-06,
        "epoch": 2.9495128432240922,
        "step": 3330
    },
    {
        "loss": 0.1769,
        "grad_norm": 22.239778518676758,
        "learning_rate": 7.04162976085031e-06,
        "epoch": 2.9583702391496898,
        "step": 3340
    },
    {
        "loss": 0.129,
        "grad_norm": 86.6312484741211,
        "learning_rate": 7.032772364924713e-06,
        "epoch": 2.9672276350752878,
        "step": 3350
    },
    {
        "loss": 0.2834,
        "grad_norm": 8.959893226623535,
        "learning_rate": 7.023914968999115e-06,
        "epoch": 2.9760850310008857,
        "step": 3360
    },
    {
        "loss": 0.2047,
        "grad_norm": 1.790217399597168,
        "learning_rate": 7.0150575730735175e-06,
        "epoch": 2.9849424269264837,
        "step": 3370
    },
    {
        "loss": 0.1239,
        "grad_norm": 78.91816711425781,
        "learning_rate": 7.006200177147919e-06,
        "epoch": 2.9937998228520817,
        "step": 3380
    },
    {
        "eval_loss": 0.15662343800067902,
        "eval_accuracy": 0.9618,
        "eval_precision": 0.95092,
        "eval_recall": 0.97387,
        "eval_f1": 0.96226,
        "eval_runtime": 149.533,
        "eval_samples_per_second": 60.401,
        "eval_steps_per_second": 3.778,
        "epoch": 3.0,
        "step": 3387
    },
    {
        "loss": 0.055,
        "grad_norm": 22.772157669067383,
        "learning_rate": 6.9973427812223216e-06,
        "epoch": 3.002657218777679,
        "step": 3390
    },
    {
        "loss": 0.0207,
        "grad_norm": 43.60581588745117,
        "learning_rate": 6.988485385296724e-06,
        "epoch": 3.011514614703277,
        "step": 3400
    },
    {
        "loss": 0.1226,
        "grad_norm": 94.49275207519531,
        "learning_rate": 6.979627989371125e-06,
        "epoch": 3.020372010628875,
        "step": 3410
    },
    {
        "loss": 0.077,
        "grad_norm": 0.20446078479290009,
        "learning_rate": 6.970770593445527e-06,
        "epoch": 3.029229406554473,
        "step": 3420
    },
    {
        "loss": 0.0646,
        "grad_norm": 0.28247925639152527,
        "learning_rate": 6.96191319751993e-06,
        "epoch": 3.0380868024800707,
        "step": 3430
    },
    {
        "loss": 0.094,
        "grad_norm": 0.04045584052801132,
        "learning_rate": 6.953055801594331e-06,
        "epoch": 3.0469441984056687,
        "step": 3440
    },
    {
        "loss": 0.1298,
        "grad_norm": 42.7396354675293,
        "learning_rate": 6.944198405668734e-06,
        "epoch": 3.0558015943312666,
        "step": 3450
    },
    {
        "loss": 0.0964,
        "grad_norm": 1.457053780555725,
        "learning_rate": 6.935341009743136e-06,
        "epoch": 3.0646589902568646,
        "step": 3460
    },
    {
        "loss": 0.0828,
        "grad_norm": 67.2635498046875,
        "learning_rate": 6.926483613817539e-06,
        "epoch": 3.073516386182462,
        "step": 3470
    },
    {
        "loss": 0.1334,
        "grad_norm": 77.87393951416016,
        "learning_rate": 6.91762621789194e-06,
        "epoch": 3.08237378210806,
        "step": 3480
    },
    {
        "loss": 0.1087,
        "grad_norm": 1.1508995294570923,
        "learning_rate": 6.908768821966343e-06,
        "epoch": 3.091231178033658,
        "step": 3490
    },
    {
        "loss": 0.0805,
        "grad_norm": 20.013673782348633,
        "learning_rate": 6.899911426040744e-06,
        "epoch": 3.100088573959256,
        "step": 3500
    },
    {
        "loss": 0.087,
        "grad_norm": 104.9223403930664,
        "learning_rate": 6.891054030115146e-06,
        "epoch": 3.108945969884854,
        "step": 3510
    },
    {
        "loss": 0.1559,
        "grad_norm": 48.31034851074219,
        "learning_rate": 6.882196634189548e-06,
        "epoch": 3.1178033658104516,
        "step": 3520
    },
    {
        "loss": 0.1031,
        "grad_norm": 116.23880767822266,
        "learning_rate": 6.873339238263951e-06,
        "epoch": 3.1266607617360496,
        "step": 3530
    },
    {
        "loss": 0.0654,
        "grad_norm": 0.11743628978729248,
        "learning_rate": 6.864481842338353e-06,
        "epoch": 3.1355181576616475,
        "step": 3540
    },
    {
        "loss": 0.0676,
        "grad_norm": 27.934528350830078,
        "learning_rate": 6.855624446412755e-06,
        "epoch": 3.1443755535872455,
        "step": 3550
    },
    {
        "loss": 0.0193,
        "grad_norm": 0.5618028044700623,
        "learning_rate": 6.846767050487157e-06,
        "epoch": 3.153232949512843,
        "step": 3560
    },
    {
        "loss": 0.1929,
        "grad_norm": 80.20512390136719,
        "learning_rate": 6.83790965456156e-06,
        "epoch": 3.162090345438441,
        "step": 3570
    },
    {
        "loss": 0.1219,
        "grad_norm": 31.365215301513672,
        "learning_rate": 6.829052258635962e-06,
        "epoch": 3.170947741364039,
        "step": 3580
    },
    {
        "loss": 0.0521,
        "grad_norm": 0.04507072642445564,
        "learning_rate": 6.820194862710364e-06,
        "epoch": 3.179805137289637,
        "step": 3590
    },
    {
        "loss": 0.0561,
        "grad_norm": 0.6058123111724854,
        "learning_rate": 6.8113374667847655e-06,
        "epoch": 3.1886625332152345,
        "step": 3600
    },
    {
        "loss": 0.1821,
        "grad_norm": 112.81619262695312,
        "learning_rate": 6.802480070859168e-06,
        "epoch": 3.1975199291408325,
        "step": 3610
    },
    {
        "loss": 0.0757,
        "grad_norm": 0.07864123582839966,
        "learning_rate": 6.79362267493357e-06,
        "epoch": 3.2063773250664305,
        "step": 3620
    },
    {
        "loss": 0.13,
        "grad_norm": 0.03623652085661888,
        "learning_rate": 6.784765279007972e-06,
        "epoch": 3.2152347209920284,
        "step": 3630
    },
    {
        "loss": 0.0601,
        "grad_norm": 57.54314041137695,
        "learning_rate": 6.7759078830823745e-06,
        "epoch": 3.2240921169176264,
        "step": 3640
    },
    {
        "loss": 0.1052,
        "grad_norm": 18.960224151611328,
        "learning_rate": 6.767050487156777e-06,
        "epoch": 3.232949512843224,
        "step": 3650
    },
    {
        "loss": 0.1133,
        "grad_norm": 0.051413021981716156,
        "learning_rate": 6.7581930912311786e-06,
        "epoch": 3.241806908768822,
        "step": 3660
    },
    {
        "loss": 0.1073,
        "grad_norm": 72.5750732421875,
        "learning_rate": 6.749335695305581e-06,
        "epoch": 3.25066430469442,
        "step": 3670
    },
    {
        "loss": 0.0917,
        "grad_norm": 0.5126760601997375,
        "learning_rate": 6.7404782993799835e-06,
        "epoch": 3.259521700620018,
        "step": 3680
    },
    {
        "loss": 0.0691,
        "grad_norm": 27.569957733154297,
        "learning_rate": 6.731620903454384e-06,
        "epoch": 3.2683790965456154,
        "step": 3690
    },
    {
        "loss": 0.2437,
        "grad_norm": 7.609433650970459,
        "learning_rate": 6.722763507528787e-06,
        "epoch": 3.2772364924712134,
        "step": 3700
    },
    {
        "loss": 0.1002,
        "grad_norm": 51.26449966430664,
        "learning_rate": 6.713906111603189e-06,
        "epoch": 3.2860938883968114,
        "step": 3710
    },
    {
        "loss": 0.0912,
        "grad_norm": 31.364940643310547,
        "learning_rate": 6.705048715677592e-06,
        "epoch": 3.2949512843224094,
        "step": 3720
    },
    {
        "loss": 0.0434,
        "grad_norm": 2.4984633922576904,
        "learning_rate": 6.696191319751993e-06,
        "epoch": 3.3038086802480073,
        "step": 3730
    },
    {
        "loss": 0.012,
        "grad_norm": 0.04929646849632263,
        "learning_rate": 6.687333923826396e-06,
        "epoch": 3.312666076173605,
        "step": 3740
    },
    {
        "loss": 0.0642,
        "grad_norm": 66.35125732421875,
        "learning_rate": 6.678476527900798e-06,
        "epoch": 3.321523472099203,
        "step": 3750
    },
    {
        "loss": 0.0357,
        "grad_norm": 84.56133270263672,
        "learning_rate": 6.6696191319752006e-06,
        "epoch": 3.330380868024801,
        "step": 3760
    },
    {
        "loss": 0.1812,
        "grad_norm": 3.7843775749206543,
        "learning_rate": 6.660761736049602e-06,
        "epoch": 3.3392382639503984,
        "step": 3770
    },
    {
        "loss": 0.0916,
        "grad_norm": 42.474143981933594,
        "learning_rate": 6.651904340124004e-06,
        "epoch": 3.3480956598759963,
        "step": 3780
    },
    {
        "loss": 0.2274,
        "grad_norm": 0.5381497740745544,
        "learning_rate": 6.643046944198405e-06,
        "epoch": 3.3569530558015943,
        "step": 3790
    },
    {
        "loss": 0.0095,
        "grad_norm": 0.03607457876205444,
        "learning_rate": 6.634189548272808e-06,
        "epoch": 3.3658104517271923,
        "step": 3800
    },
    {
        "loss": 0.0785,
        "grad_norm": 0.16327300667762756,
        "learning_rate": 6.62533215234721e-06,
        "epoch": 3.3746678476527903,
        "step": 3810
    },
    {
        "loss": 0.0912,
        "grad_norm": 1.409856915473938,
        "learning_rate": 6.616474756421613e-06,
        "epoch": 3.383525243578388,
        "step": 3820
    },
    {
        "loss": 0.0584,
        "grad_norm": 0.016923541203141212,
        "learning_rate": 6.607617360496014e-06,
        "epoch": 3.3923826395039858,
        "step": 3830
    },
    {
        "loss": 0.0307,
        "grad_norm": 0.37117961049079895,
        "learning_rate": 6.598759964570417e-06,
        "epoch": 3.4012400354295838,
        "step": 3840
    },
    {
        "loss": 0.14,
        "grad_norm": 88.50670623779297,
        "learning_rate": 6.589902568644819e-06,
        "epoch": 3.4100974313551817,
        "step": 3850
    },
    {
        "loss": 0.0167,
        "grad_norm": 99.39048767089844,
        "learning_rate": 6.581045172719222e-06,
        "epoch": 3.4189548272807793,
        "step": 3860
    },
    {
        "loss": 0.0537,
        "grad_norm": 9.268073081970215,
        "learning_rate": 6.572187776793623e-06,
        "epoch": 3.4278122232063772,
        "step": 3870
    },
    {
        "loss": 0.0507,
        "grad_norm": 98.39376831054688,
        "learning_rate": 6.563330380868025e-06,
        "epoch": 3.436669619131975,
        "step": 3880
    },
    {
        "loss": 0.1037,
        "grad_norm": 4.992576599121094,
        "learning_rate": 6.554472984942427e-06,
        "epoch": 3.445527015057573,
        "step": 3890
    },
    {
        "loss": 0.2509,
        "grad_norm": 3.524918794631958,
        "learning_rate": 6.545615589016829e-06,
        "epoch": 3.454384410983171,
        "step": 3900
    },
    {
        "loss": 0.144,
        "grad_norm": 22.94118309020996,
        "learning_rate": 6.5367581930912315e-06,
        "epoch": 3.4632418069087687,
        "step": 3910
    },
    {
        "loss": 0.0473,
        "grad_norm": 5.522390365600586,
        "learning_rate": 6.527900797165634e-06,
        "epoch": 3.4720992028343667,
        "step": 3920
    },
    {
        "loss": 0.1143,
        "grad_norm": 52.54463195800781,
        "learning_rate": 6.519043401240036e-06,
        "epoch": 3.4809565987599647,
        "step": 3930
    },
    {
        "loss": 0.1665,
        "grad_norm": 132.6962890625,
        "learning_rate": 6.510186005314438e-06,
        "epoch": 3.4898139946855626,
        "step": 3940
    },
    {
        "loss": 0.1674,
        "grad_norm": 0.4021415412425995,
        "learning_rate": 6.5013286093888405e-06,
        "epoch": 3.49867139061116,
        "step": 3950
    },
    {
        "loss": 0.0689,
        "grad_norm": 102.67245483398438,
        "learning_rate": 6.492471213463243e-06,
        "epoch": 3.507528786536758,
        "step": 3960
    },
    {
        "loss": 0.0418,
        "grad_norm": 1.8159995079040527,
        "learning_rate": 6.483613817537644e-06,
        "epoch": 3.516386182462356,
        "step": 3970
    },
    {
        "loss": 0.0245,
        "grad_norm": 2.0148086547851562,
        "learning_rate": 6.474756421612046e-06,
        "epoch": 3.525243578387954,
        "step": 3980
    },
    {
        "loss": 0.0772,
        "grad_norm": 155.84002685546875,
        "learning_rate": 6.465899025686449e-06,
        "epoch": 3.534100974313552,
        "step": 3990
    },
    {
        "loss": 0.1797,
        "grad_norm": 0.04537257179617882,
        "learning_rate": 6.457041629760851e-06,
        "epoch": 3.5429583702391496,
        "step": 4000
    },
    {
        "loss": 0.149,
        "grad_norm": 55.51865005493164,
        "learning_rate": 6.448184233835253e-06,
        "epoch": 3.5518157661647476,
        "step": 4010
    },
    {
        "loss": 0.1451,
        "grad_norm": 1.3393605947494507,
        "learning_rate": 6.439326837909655e-06,
        "epoch": 3.5606731620903456,
        "step": 4020
    },
    {
        "loss": 0.1857,
        "grad_norm": 0.2784266173839569,
        "learning_rate": 6.4304694419840576e-06,
        "epoch": 3.569530558015943,
        "step": 4030
    },
    {
        "loss": 0.1381,
        "grad_norm": 0.1690576672554016,
        "learning_rate": 6.42161204605846e-06,
        "epoch": 3.578387953941541,
        "step": 4040
    },
    {
        "loss": 0.0488,
        "grad_norm": 163.82859802246094,
        "learning_rate": 6.412754650132862e-06,
        "epoch": 3.587245349867139,
        "step": 4050
    },
    {
        "loss": 0.1252,
        "grad_norm": 81.7186279296875,
        "learning_rate": 6.403897254207263e-06,
        "epoch": 3.596102745792737,
        "step": 4060
    },
    {
        "loss": 0.0743,
        "grad_norm": 136.28553771972656,
        "learning_rate": 6.395039858281666e-06,
        "epoch": 3.604960141718335,
        "step": 4070
    },
    {
        "loss": 0.0123,
        "grad_norm": 0.20986607670783997,
        "learning_rate": 6.386182462356067e-06,
        "epoch": 3.6138175376439325,
        "step": 4080
    },
    {
        "loss": 0.0893,
        "grad_norm": 69.49472045898438,
        "learning_rate": 6.37732506643047e-06,
        "epoch": 3.6226749335695305,
        "step": 4090
    },
    {
        "loss": 0.0355,
        "grad_norm": 60.37083435058594,
        "learning_rate": 6.368467670504872e-06,
        "epoch": 3.6315323294951285,
        "step": 4100
    },
    {
        "loss": 0.0296,
        "grad_norm": 1.3747742176055908,
        "learning_rate": 6.359610274579275e-06,
        "epoch": 3.640389725420726,
        "step": 4110
    },
    {
        "loss": 0.2244,
        "grad_norm": 0.1699880212545395,
        "learning_rate": 6.350752878653676e-06,
        "epoch": 3.649247121346324,
        "step": 4120
    },
    {
        "loss": 0.0579,
        "grad_norm": 83.56120300292969,
        "learning_rate": 6.341895482728079e-06,
        "epoch": 3.658104517271922,
        "step": 4130
    },
    {
        "loss": 0.1187,
        "grad_norm": 26.965723037719727,
        "learning_rate": 6.333038086802481e-06,
        "epoch": 3.66696191319752,
        "step": 4140
    },
    {
        "loss": 0.0748,
        "grad_norm": 1.4313411712646484,
        "learning_rate": 6.324180690876884e-06,
        "epoch": 3.675819309123118,
        "step": 4150
    },
    {
        "loss": 0.1107,
        "grad_norm": 0.07050814479589462,
        "learning_rate": 6.315323294951284e-06,
        "epoch": 3.684676705048716,
        "step": 4160
    },
    {
        "loss": 0.1237,
        "grad_norm": 21.96758270263672,
        "learning_rate": 6.306465899025687e-06,
        "epoch": 3.6935341009743134,
        "step": 4170
    },
    {
        "loss": 0.0922,
        "grad_norm": 99.40241241455078,
        "learning_rate": 6.2976085031000885e-06,
        "epoch": 3.7023914968999114,
        "step": 4180
    },
    {
        "loss": 0.1009,
        "grad_norm": 109.20279693603516,
        "learning_rate": 6.288751107174491e-06,
        "epoch": 3.7112488928255094,
        "step": 4190
    },
    {
        "loss": 0.0463,
        "grad_norm": 0.5913460850715637,
        "learning_rate": 6.279893711248893e-06,
        "epoch": 3.720106288751107,
        "step": 4200
    },
    {
        "loss": 0.1761,
        "grad_norm": 0.01461225375533104,
        "learning_rate": 6.271036315323296e-06,
        "epoch": 3.728963684676705,
        "step": 4210
    },
    {
        "loss": 0.0924,
        "grad_norm": 100.78987121582031,
        "learning_rate": 6.2621789193976975e-06,
        "epoch": 3.737821080602303,
        "step": 4220
    },
    {
        "loss": 0.1505,
        "grad_norm": 0.06343379616737366,
        "learning_rate": 6.2533215234721e-06,
        "epoch": 3.746678476527901,
        "step": 4230
    },
    {
        "loss": 0.1049,
        "grad_norm": 0.022701425477862358,
        "learning_rate": 6.244464127546502e-06,
        "epoch": 3.755535872453499,
        "step": 4240
    },
    {
        "loss": 0.0101,
        "grad_norm": 0.19778968393802643,
        "learning_rate": 6.235606731620903e-06,
        "epoch": 3.7643932683790964,
        "step": 4250
    },
    {
        "loss": 0.2723,
        "grad_norm": 21.094011306762695,
        "learning_rate": 6.226749335695306e-06,
        "epoch": 3.7732506643046944,
        "step": 4260
    },
    {
        "loss": 0.0646,
        "grad_norm": 0.019272366538643837,
        "learning_rate": 6.217891939769708e-06,
        "epoch": 3.7821080602302923,
        "step": 4270
    },
    {
        "loss": 0.1984,
        "grad_norm": 79.6850814819336,
        "learning_rate": 6.2090345438441105e-06,
        "epoch": 3.7909654561558903,
        "step": 4280
    },
    {
        "loss": 0.0859,
        "grad_norm": 63.93764114379883,
        "learning_rate": 6.200177147918512e-06,
        "epoch": 3.799822852081488,
        "step": 4290
    },
    {
        "loss": 0.0879,
        "grad_norm": 0.48588070273399353,
        "learning_rate": 6.1913197519929146e-06,
        "epoch": 3.808680248007086,
        "step": 4300
    },
    {
        "loss": 0.141,
        "grad_norm": 11.498841285705566,
        "learning_rate": 6.182462356067317e-06,
        "epoch": 3.817537643932684,
        "step": 4310
    },
    {
        "loss": 0.0145,
        "grad_norm": 0.04479717090725899,
        "learning_rate": 6.1736049601417195e-06,
        "epoch": 3.8263950398582818,
        "step": 4320
    },
    {
        "loss": 0.1408,
        "grad_norm": 138.0238800048828,
        "learning_rate": 6.164747564216121e-06,
        "epoch": 3.8352524357838798,
        "step": 4330
    },
    {
        "loss": 0.2786,
        "grad_norm": 50.267433166503906,
        "learning_rate": 6.155890168290523e-06,
        "epoch": 3.8441098317094773,
        "step": 4340
    },
    {
        "loss": 0.1476,
        "grad_norm": 0.05996876209974289,
        "learning_rate": 6.147032772364925e-06,
        "epoch": 3.8529672276350753,
        "step": 4350
    },
    {
        "loss": 0.0584,
        "grad_norm": 23.748409271240234,
        "learning_rate": 6.138175376439327e-06,
        "epoch": 3.8618246235606732,
        "step": 4360
    },
    {
        "loss": 0.0981,
        "grad_norm": 5.627389430999756,
        "learning_rate": 6.129317980513729e-06,
        "epoch": 3.8706820194862708,
        "step": 4370
    },
    {
        "loss": 0.1067,
        "grad_norm": 14.878349304199219,
        "learning_rate": 6.120460584588132e-06,
        "epoch": 3.8795394154118688,
        "step": 4380
    },
    {
        "loss": 0.1069,
        "grad_norm": 76.66682434082031,
        "learning_rate": 6.111603188662534e-06,
        "epoch": 3.8883968113374667,
        "step": 4390
    },
    {
        "loss": 0.1585,
        "grad_norm": 15.211714744567871,
        "learning_rate": 6.102745792736936e-06,
        "epoch": 3.8972542072630647,
        "step": 4400
    },
    {
        "loss": 0.2156,
        "grad_norm": 191.55311584472656,
        "learning_rate": 6.093888396811338e-06,
        "epoch": 3.9061116031886627,
        "step": 4410
    },
    {
        "loss": 0.1109,
        "grad_norm": 63.40549850463867,
        "learning_rate": 6.085031000885741e-06,
        "epoch": 3.9149689991142607,
        "step": 4420
    },
    {
        "loss": 0.087,
        "grad_norm": 213.6570281982422,
        "learning_rate": 6.076173604960143e-06,
        "epoch": 3.923826395039858,
        "step": 4430
    },
    {
        "loss": 0.0708,
        "grad_norm": 0.017865808680653572,
        "learning_rate": 6.067316209034544e-06,
        "epoch": 3.932683790965456,
        "step": 4440
    },
    {
        "loss": 0.0332,
        "grad_norm": 0.03498532623052597,
        "learning_rate": 6.058458813108946e-06,
        "epoch": 3.941541186891054,
        "step": 4450
    },
    {
        "loss": 0.1209,
        "grad_norm": 0.03895261883735657,
        "learning_rate": 6.049601417183349e-06,
        "epoch": 3.9503985828166517,
        "step": 4460
    },
    {
        "loss": 0.1043,
        "grad_norm": 7.6532697677612305,
        "learning_rate": 6.04074402125775e-06,
        "epoch": 3.9592559787422497,
        "step": 4470
    },
    {
        "loss": 0.1062,
        "grad_norm": 0.07496447116136551,
        "learning_rate": 6.031886625332153e-06,
        "epoch": 3.9681133746678476,
        "step": 4480
    },
    {
        "loss": 0.0313,
        "grad_norm": 0.0186375230550766,
        "learning_rate": 6.023029229406555e-06,
        "epoch": 3.9769707705934456,
        "step": 4490
    },
    {
        "loss": 0.1629,
        "grad_norm": 165.75936889648438,
        "learning_rate": 6.014171833480958e-06,
        "epoch": 3.9858281665190436,
        "step": 4500
    },
    {
        "loss": 0.0477,
        "grad_norm": 47.027923583984375,
        "learning_rate": 6.005314437555359e-06,
        "epoch": 3.994685562444641,
        "step": 4510
    },
    {
        "eval_loss": 0.1961497813463211,
        "eval_accuracy": 0.96424,
        "eval_precision": 0.94277,
        "eval_recall": 0.98849,
        "eval_f1": 0.96508,
        "eval_runtime": 149.4581,
        "eval_samples_per_second": 60.432,
        "eval_steps_per_second": 3.78,
        "epoch": 4.0,
        "step": 4516
    },
    {
        "loss": 0.0983,
        "grad_norm": 0.022788414731621742,
        "learning_rate": 5.996457041629762e-06,
        "epoch": 4.0035429583702395,
        "step": 4520
    },
    {
        "loss": 0.0565,
        "grad_norm": 1.392458200454712,
        "learning_rate": 5.9875996457041626e-06,
        "epoch": 4.012400354295837,
        "step": 4530
    },
    {
        "loss": 0.1601,
        "grad_norm": 23.65541648864746,
        "learning_rate": 5.978742249778565e-06,
        "epoch": 4.021257750221435,
        "step": 4540
    },
    {
        "loss": 0.0856,
        "grad_norm": 0.022951902821660042,
        "learning_rate": 5.9698848538529675e-06,
        "epoch": 4.030115146147033,
        "step": 4550
    },
    {
        "loss": 0.0619,
        "grad_norm": 37.72231674194336,
        "learning_rate": 5.96102745792737e-06,
        "epoch": 4.038972542072631,
        "step": 4560
    },
    {
        "loss": 0.0443,
        "grad_norm": 0.039096083492040634,
        "learning_rate": 5.9521700620017716e-06,
        "epoch": 4.0478299379982285,
        "step": 4570
    },
    {
        "loss": 0.1036,
        "grad_norm": 90.31060791015625,
        "learning_rate": 5.943312666076174e-06,
        "epoch": 4.0566873339238265,
        "step": 4580
    },
    {
        "loss": 0.1217,
        "grad_norm": 7.056840419769287,
        "learning_rate": 5.9344552701505765e-06,
        "epoch": 4.0655447298494245,
        "step": 4590
    },
    {
        "loss": 0.0073,
        "grad_norm": 30.522029876708984,
        "learning_rate": 5.925597874224979e-06,
        "epoch": 4.0744021257750225,
        "step": 4600
    },
    {
        "loss": 0.0238,
        "grad_norm": 0.019773218780755997,
        "learning_rate": 5.9167404782993805e-06,
        "epoch": 4.0832595217006205,
        "step": 4610
    },
    {
        "loss": 0.1255,
        "grad_norm": 48.478294372558594,
        "learning_rate": 5.907883082373782e-06,
        "epoch": 4.0921169176262175,
        "step": 4620
    },
    {
        "loss": 0.0916,
        "grad_norm": 0.1374482810497284,
        "learning_rate": 5.899025686448185e-06,
        "epoch": 4.1009743135518155,
        "step": 4630
    },
    {
        "loss": 0.0295,
        "grad_norm": 0.01820957101881504,
        "learning_rate": 5.890168290522586e-06,
        "epoch": 4.1098317094774135,
        "step": 4640
    },
    {
        "loss": 0.0307,
        "grad_norm": 0.012116176076233387,
        "learning_rate": 5.881310894596989e-06,
        "epoch": 4.1186891054030115,
        "step": 4650
    },
    {
        "loss": 0.0549,
        "grad_norm": 14.422346115112305,
        "learning_rate": 5.872453498671391e-06,
        "epoch": 4.1275465013286095,
        "step": 4660
    },
    {
        "loss": 0.1079,
        "grad_norm": 0.02318214252591133,
        "learning_rate": 5.8635961027457936e-06,
        "epoch": 4.136403897254207,
        "step": 4670
    },
    {
        "loss": 0.1192,
        "grad_norm": 15.024823188781738,
        "learning_rate": 5.854738706820195e-06,
        "epoch": 4.145261293179805,
        "step": 4680
    },
    {
        "loss": 0.0797,
        "grad_norm": 0.11039409786462784,
        "learning_rate": 5.845881310894598e-06,
        "epoch": 4.154118689105403,
        "step": 4690
    },
    {
        "loss": 0.1128,
        "grad_norm": 49.201637268066406,
        "learning_rate": 5.837023914969e-06,
        "epoch": 4.1629760850310005,
        "step": 4700
    },
    {
        "loss": 0.0726,
        "grad_norm": 119.04674530029297,
        "learning_rate": 5.8281665190434025e-06,
        "epoch": 4.1718334809565985,
        "step": 4710
    },
    {
        "loss": 0.1215,
        "grad_norm": 187.433837890625,
        "learning_rate": 5.819309123117803e-06,
        "epoch": 4.180690876882196,
        "step": 4720
    },
    {
        "loss": 0.0433,
        "grad_norm": 0.1786821335554123,
        "learning_rate": 5.810451727192206e-06,
        "epoch": 4.189548272807794,
        "step": 4730
    },
    {
        "loss": 0.0975,
        "grad_norm": 0.42395713925361633,
        "learning_rate": 5.801594331266608e-06,
        "epoch": 4.198405668733392,
        "step": 4740
    },
    {
        "loss": 0.09,
        "grad_norm": 0.07603110373020172,
        "learning_rate": 5.79273693534101e-06,
        "epoch": 4.20726306465899,
        "step": 4750
    },
    {
        "loss": 0.0295,
        "grad_norm": 0.06141989678144455,
        "learning_rate": 5.783879539415412e-06,
        "epoch": 4.216120460584588,
        "step": 4760
    },
    {
        "loss": 0.1015,
        "grad_norm": 17.519580841064453,
        "learning_rate": 5.775022143489815e-06,
        "epoch": 4.224977856510186,
        "step": 4770
    },
    {
        "loss": 0.1814,
        "grad_norm": 110.30821228027344,
        "learning_rate": 5.766164747564217e-06,
        "epoch": 4.233835252435784,
        "step": 4780
    },
    {
        "loss": 0.1183,
        "grad_norm": 45.684776306152344,
        "learning_rate": 5.757307351638619e-06,
        "epoch": 4.242692648361381,
        "step": 4790
    },
    {
        "loss": 0.0726,
        "grad_norm": 5.14582633972168,
        "learning_rate": 5.748449955713021e-06,
        "epoch": 4.251550044286979,
        "step": 4800
    },
    {
        "loss": 0.0467,
        "grad_norm": 0.04384304955601692,
        "learning_rate": 5.739592559787423e-06,
        "epoch": 4.260407440212577,
        "step": 4810
    },
    {
        "loss": 0.1169,
        "grad_norm": 0.035655710846185684,
        "learning_rate": 5.7307351638618245e-06,
        "epoch": 4.269264836138175,
        "step": 4820
    },
    {
        "loss": 0.1354,
        "grad_norm": 17.49273109436035,
        "learning_rate": 5.721877767936227e-06,
        "epoch": 4.278122232063773,
        "step": 4830
    },
    {
        "loss": 0.0226,
        "grad_norm": 16.701705932617188,
        "learning_rate": 5.713020372010629e-06,
        "epoch": 4.286979627989371,
        "step": 4840
    },
    {
        "loss": 0.1199,
        "grad_norm": 41.74666976928711,
        "learning_rate": 5.704162976085032e-06,
        "epoch": 4.295837023914969,
        "step": 4850
    },
    {
        "loss": 0.1234,
        "grad_norm": 6.671619415283203,
        "learning_rate": 5.6953055801594335e-06,
        "epoch": 4.304694419840567,
        "step": 4860
    },
    {
        "loss": 0.081,
        "grad_norm": 1.009412407875061,
        "learning_rate": 5.686448184233836e-06,
        "epoch": 4.313551815766164,
        "step": 4870
    },
    {
        "loss": 0.0122,
        "grad_norm": 0.10536660254001617,
        "learning_rate": 5.677590788308238e-06,
        "epoch": 4.322409211691762,
        "step": 4880
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.18475811183452606,
        "learning_rate": 5.668733392382641e-06,
        "epoch": 4.33126660761736,
        "step": 4890
    },
    {
        "loss": 0.0378,
        "grad_norm": 0.09221511334180832,
        "learning_rate": 5.659875996457042e-06,
        "epoch": 4.340124003542958,
        "step": 4900
    },
    {
        "loss": 0.1196,
        "grad_norm": 6.459842681884766,
        "learning_rate": 5.651018600531444e-06,
        "epoch": 4.348981399468556,
        "step": 4910
    },
    {
        "loss": 0.0627,
        "grad_norm": 1.1714153289794922,
        "learning_rate": 5.642161204605846e-06,
        "epoch": 4.357838795394154,
        "step": 4920
    },
    {
        "loss": 0.044,
        "grad_norm": 13.208462715148926,
        "learning_rate": 5.633303808680248e-06,
        "epoch": 4.366696191319752,
        "step": 4930
    },
    {
        "loss": 0.0271,
        "grad_norm": 0.04016150161623955,
        "learning_rate": 5.6244464127546506e-06,
        "epoch": 4.37555358724535,
        "step": 4940
    },
    {
        "loss": 0.0542,
        "grad_norm": 0.032340411096811295,
        "learning_rate": 5.615589016829053e-06,
        "epoch": 4.384410983170948,
        "step": 4950
    },
    {
        "loss": 0.0878,
        "grad_norm": 14.652563095092773,
        "learning_rate": 5.606731620903455e-06,
        "epoch": 4.393268379096545,
        "step": 4960
    },
    {
        "loss": 0.0627,
        "grad_norm": 2.8753671646118164,
        "learning_rate": 5.597874224977857e-06,
        "epoch": 4.402125775022143,
        "step": 4970
    },
    {
        "loss": 0.0605,
        "grad_norm": 0.007457172032445669,
        "learning_rate": 5.5890168290522595e-06,
        "epoch": 4.410983170947741,
        "step": 4980
    },
    {
        "loss": 0.153,
        "grad_norm": 60.478515625,
        "learning_rate": 5.580159433126662e-06,
        "epoch": 4.419840566873339,
        "step": 4990
    },
    {
        "loss": 0.2786,
        "grad_norm": 0.3590396046638489,
        "learning_rate": 5.571302037201063e-06,
        "epoch": 4.428697962798937,
        "step": 5000
    },
    {
        "loss": 0.0852,
        "grad_norm": 0.012280156835913658,
        "learning_rate": 5.562444641275465e-06,
        "epoch": 4.437555358724535,
        "step": 5010
    },
    {
        "loss": 0.0912,
        "grad_norm": 2.115750551223755,
        "learning_rate": 5.553587245349868e-06,
        "epoch": 4.446412754650133,
        "step": 5020
    },
    {
        "loss": 0.0562,
        "grad_norm": 1.653451919555664,
        "learning_rate": 5.544729849424269e-06,
        "epoch": 4.455270150575731,
        "step": 5030
    },
    {
        "loss": 0.0299,
        "grad_norm": 0.06308093667030334,
        "learning_rate": 5.535872453498672e-06,
        "epoch": 4.464127546501329,
        "step": 5040
    },
    {
        "loss": 0.0305,
        "grad_norm": 0.014925112947821617,
        "learning_rate": 5.527015057573074e-06,
        "epoch": 4.472984942426926,
        "step": 5050
    },
    {
        "loss": 0.0309,
        "grad_norm": 91.45600891113281,
        "learning_rate": 5.518157661647477e-06,
        "epoch": 4.481842338352524,
        "step": 5060
    },
    {
        "loss": 0.0102,
        "grad_norm": 0.0141793517395854,
        "learning_rate": 5.509300265721878e-06,
        "epoch": 4.490699734278122,
        "step": 5070
    },
    {
        "loss": 0.0304,
        "grad_norm": 3.325186252593994,
        "learning_rate": 5.500442869796281e-06,
        "epoch": 4.49955713020372,
        "step": 5080
    },
    {
        "loss": 0.0224,
        "grad_norm": 110.94698333740234,
        "learning_rate": 5.491585473870682e-06,
        "epoch": 4.508414526129318,
        "step": 5090
    },
    {
        "loss": 0.0083,
        "grad_norm": 0.012549732811748981,
        "learning_rate": 5.482728077945084e-06,
        "epoch": 4.517271922054916,
        "step": 5100
    },
    {
        "loss": 0.1175,
        "grad_norm": 0.01493533793836832,
        "learning_rate": 5.473870682019486e-06,
        "epoch": 4.526129317980514,
        "step": 5110
    },
    {
        "loss": 0.045,
        "grad_norm": 0.008024248294532299,
        "learning_rate": 5.465013286093889e-06,
        "epoch": 4.534986713906112,
        "step": 5120
    },
    {
        "loss": 0.0102,
        "grad_norm": 0.010318354703485966,
        "learning_rate": 5.456155890168291e-06,
        "epoch": 4.54384410983171,
        "step": 5130
    },
    {
        "loss": 0.0686,
        "grad_norm": 0.053623348474502563,
        "learning_rate": 5.447298494242693e-06,
        "epoch": 4.552701505757307,
        "step": 5140
    },
    {
        "loss": 0.0682,
        "grad_norm": 1.187459111213684,
        "learning_rate": 5.438441098317095e-06,
        "epoch": 4.561558901682905,
        "step": 5150
    },
    {
        "loss": 0.1173,
        "grad_norm": 157.77938842773438,
        "learning_rate": 5.429583702391498e-06,
        "epoch": 4.570416297608503,
        "step": 5160
    },
    {
        "loss": 0.1412,
        "grad_norm": 59.47705841064453,
        "learning_rate": 5.4207263064659e-06,
        "epoch": 4.579273693534101,
        "step": 5170
    },
    {
        "loss": 0.0757,
        "grad_norm": 0.017702162265777588,
        "learning_rate": 5.411868910540301e-06,
        "epoch": 4.588131089459699,
        "step": 5180
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.011380654759705067,
        "learning_rate": 5.4030115146147035e-06,
        "epoch": 4.596988485385297,
        "step": 5190
    },
    {
        "loss": 0.0327,
        "grad_norm": 0.020333394408226013,
        "learning_rate": 5.394154118689106e-06,
        "epoch": 4.605845881310895,
        "step": 5200
    },
    {
        "loss": 0.1247,
        "grad_norm": 0.014118916355073452,
        "learning_rate": 5.3852967227635076e-06,
        "epoch": 4.614703277236492,
        "step": 5210
    },
    {
        "loss": 0.1902,
        "grad_norm": 32.58689498901367,
        "learning_rate": 5.37643932683791e-06,
        "epoch": 4.62356067316209,
        "step": 5220
    },
    {
        "loss": 0.0097,
        "grad_norm": 43.40483093261719,
        "learning_rate": 5.3675819309123125e-06,
        "epoch": 4.632418069087688,
        "step": 5230
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.01663234643638134,
        "learning_rate": 5.358724534986715e-06,
        "epoch": 4.641275465013286,
        "step": 5240
    },
    {
        "loss": 0.055,
        "grad_norm": 65.61286926269531,
        "learning_rate": 5.3498671390611165e-06,
        "epoch": 4.650132860938884,
        "step": 5250
    },
    {
        "loss": 0.0301,
        "grad_norm": 9.592948913574219,
        "learning_rate": 5.341009743135519e-06,
        "epoch": 4.658990256864482,
        "step": 5260
    },
    {
        "loss": 0.0601,
        "grad_norm": 4.249587059020996,
        "learning_rate": 5.3321523472099214e-06,
        "epoch": 4.66784765279008,
        "step": 5270
    },
    {
        "loss": 0.1721,
        "grad_norm": 156.49295043945312,
        "learning_rate": 5.323294951284322e-06,
        "epoch": 4.676705048715678,
        "step": 5280
    },
    {
        "loss": 0.1324,
        "grad_norm": 0.012604180723428726,
        "learning_rate": 5.314437555358725e-06,
        "epoch": 4.685562444641276,
        "step": 5290
    },
    {
        "loss": 0.0066,
        "grad_norm": 0.02058078907430172,
        "learning_rate": 5.305580159433127e-06,
        "epoch": 4.694419840566873,
        "step": 5300
    },
    {
        "loss": 0.2599,
        "grad_norm": 0.04995084926486015,
        "learning_rate": 5.296722763507529e-06,
        "epoch": 4.703277236492471,
        "step": 5310
    },
    {
        "loss": 0.1158,
        "grad_norm": 0.1538383811712265,
        "learning_rate": 5.287865367581931e-06,
        "epoch": 4.712134632418069,
        "step": 5320
    },
    {
        "loss": 0.0277,
        "grad_norm": 0.22161443531513214,
        "learning_rate": 5.279007971656334e-06,
        "epoch": 4.720992028343667,
        "step": 5330
    },
    {
        "loss": 0.013,
        "grad_norm": 0.6030059456825256,
        "learning_rate": 5.270150575730736e-06,
        "epoch": 4.729849424269265,
        "step": 5340
    },
    {
        "loss": 0.0911,
        "grad_norm": 72.7938232421875,
        "learning_rate": 5.261293179805138e-06,
        "epoch": 4.738706820194863,
        "step": 5350
    },
    {
        "loss": 0.0646,
        "grad_norm": 25.359567642211914,
        "learning_rate": 5.25243578387954e-06,
        "epoch": 4.747564216120461,
        "step": 5360
    },
    {
        "loss": 0.0313,
        "grad_norm": 0.07603631168603897,
        "learning_rate": 5.243578387953942e-06,
        "epoch": 4.756421612046059,
        "step": 5370
    },
    {
        "loss": 0.0092,
        "grad_norm": 0.009210668504238129,
        "learning_rate": 5.234720992028343e-06,
        "epoch": 4.765279007971657,
        "step": 5380
    },
    {
        "loss": 0.0482,
        "grad_norm": 131.0310821533203,
        "learning_rate": 5.225863596102746e-06,
        "epoch": 4.774136403897254,
        "step": 5390
    },
    {
        "loss": 0.145,
        "grad_norm": 125.34062194824219,
        "learning_rate": 5.217006200177148e-06,
        "epoch": 4.782993799822852,
        "step": 5400
    },
    {
        "loss": 0.0903,
        "grad_norm": 0.5623195767402649,
        "learning_rate": 5.208148804251551e-06,
        "epoch": 4.79185119574845,
        "step": 5410
    },
    {
        "loss": 0.102,
        "grad_norm": 0.3065602779388428,
        "learning_rate": 5.199291408325952e-06,
        "epoch": 4.800708591674048,
        "step": 5420
    },
    {
        "loss": 0.0808,
        "grad_norm": 0.07109073549509048,
        "learning_rate": 5.190434012400355e-06,
        "epoch": 4.809565987599646,
        "step": 5430
    },
    {
        "loss": 0.1417,
        "grad_norm": 0.1947515457868576,
        "learning_rate": 5.181576616474757e-06,
        "epoch": 4.818423383525244,
        "step": 5440
    },
    {
        "loss": 0.049,
        "grad_norm": 0.0660146102309227,
        "learning_rate": 5.17271922054916e-06,
        "epoch": 4.827280779450842,
        "step": 5450
    },
    {
        "loss": 0.0063,
        "grad_norm": 5.31948184967041,
        "learning_rate": 5.1638618246235605e-06,
        "epoch": 4.83613817537644,
        "step": 5460
    },
    {
        "loss": 0.1555,
        "grad_norm": 0.17550992965698242,
        "learning_rate": 5.155004428697963e-06,
        "epoch": 4.844995571302038,
        "step": 5470
    },
    {
        "loss": 0.0236,
        "grad_norm": 0.07032634317874908,
        "learning_rate": 5.146147032772365e-06,
        "epoch": 4.853852967227635,
        "step": 5480
    },
    {
        "loss": 0.0212,
        "grad_norm": 5.100058555603027,
        "learning_rate": 5.137289636846767e-06,
        "epoch": 4.862710363153233,
        "step": 5490
    },
    {
        "loss": 0.0501,
        "grad_norm": 24.85572052001953,
        "learning_rate": 5.1284322409211695e-06,
        "epoch": 4.871567759078831,
        "step": 5500
    },
    {
        "loss": 0.1208,
        "grad_norm": 86.51567077636719,
        "learning_rate": 5.119574844995572e-06,
        "epoch": 4.880425155004429,
        "step": 5510
    },
    {
        "loss": 0.0018,
        "grad_norm": 0.08681479096412659,
        "learning_rate": 5.110717449069974e-06,
        "epoch": 4.889282550930027,
        "step": 5520
    },
    {
        "loss": 0.0022,
        "grad_norm": 0.42010125517845154,
        "learning_rate": 5.101860053144376e-06,
        "epoch": 4.898139946855625,
        "step": 5530
    },
    {
        "loss": 0.1363,
        "grad_norm": 0.006923585198819637,
        "learning_rate": 5.0930026572187784e-06,
        "epoch": 4.906997342781223,
        "step": 5540
    },
    {
        "loss": 0.0009,
        "grad_norm": 1.4799823760986328,
        "learning_rate": 5.084145261293181e-06,
        "epoch": 4.9158547387068205,
        "step": 5550
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.5490476489067078,
        "learning_rate": 5.075287865367582e-06,
        "epoch": 4.9247121346324185,
        "step": 5560
    },
    {
        "loss": 0.0757,
        "grad_norm": 0.09845152497291565,
        "learning_rate": 5.066430469441984e-06,
        "epoch": 4.933569530558016,
        "step": 5570
    },
    {
        "loss": 0.0273,
        "grad_norm": 0.13970491290092468,
        "learning_rate": 5.0575730735163866e-06,
        "epoch": 4.942426926483614,
        "step": 5580
    },
    {
        "loss": 0.001,
        "grad_norm": 0.0070790573954582214,
        "learning_rate": 5.048715677590789e-06,
        "epoch": 4.951284322409212,
        "step": 5590
    },
    {
        "loss": 0.0653,
        "grad_norm": 0.03945649787783623,
        "learning_rate": 5.039858281665191e-06,
        "epoch": 4.9601417183348095,
        "step": 5600
    },
    {
        "loss": 0.1019,
        "grad_norm": 0.029085107147693634,
        "learning_rate": 5.031000885739593e-06,
        "epoch": 4.9689991142604075,
        "step": 5610
    },
    {
        "loss": 0.0042,
        "grad_norm": 0.01177916582673788,
        "learning_rate": 5.0221434898139955e-06,
        "epoch": 4.9778565101860055,
        "step": 5620
    },
    {
        "loss": 0.0527,
        "grad_norm": 2.5290472507476807,
        "learning_rate": 5.013286093888398e-06,
        "epoch": 4.9867139061116035,
        "step": 5630
    },
    {
        "loss": 0.1209,
        "grad_norm": 0.014283645898103714,
        "learning_rate": 5.0044286979628e-06,
        "epoch": 4.995571302037201,
        "step": 5640
    },
    {
        "eval_loss": 0.13021355867385864,
        "eval_accuracy": 0.98118,
        "eval_precision": 0.97863,
        "eval_recall": 0.98384,
        "eval_f1": 0.98123,
        "eval_runtime": 157.8569,
        "eval_samples_per_second": 57.216,
        "eval_steps_per_second": 3.579,
        "epoch": 5.0,
        "step": 5645
    },
    {
        "loss": 0.0488,
        "grad_norm": 0.026146747171878815,
        "learning_rate": 4.995571302037201e-06,
        "epoch": 5.0044286979627985,
        "step": 5650
    },
    {
        "loss": 0.0442,
        "grad_norm": 48.354156494140625,
        "learning_rate": 4.986713906111604e-06,
        "epoch": 5.0132860938883965,
        "step": 5660
    },
    {
        "loss": 0.0683,
        "grad_norm": 0.008954648859798908,
        "learning_rate": 4.977856510186005e-06,
        "epoch": 5.0221434898139945,
        "step": 5670
    },
    {
        "loss": 0.0434,
        "grad_norm": 0.011998138390481472,
        "learning_rate": 4.968999114260408e-06,
        "epoch": 5.0310008857395925,
        "step": 5680
    },
    {
        "loss": 0.0028,
        "grad_norm": 47.8642578125,
        "learning_rate": 4.96014171833481e-06,
        "epoch": 5.0398582816651905,
        "step": 5690
    },
    {
        "loss": 0.002,
        "grad_norm": 0.012387741357088089,
        "learning_rate": 4.951284322409212e-06,
        "epoch": 5.048715677590788,
        "step": 5700
    },
    {
        "loss": 0.0287,
        "grad_norm": 0.005718394182622433,
        "learning_rate": 4.942426926483614e-06,
        "epoch": 5.057573073516386,
        "step": 5710
    },
    {
        "loss": 0.0629,
        "grad_norm": 34.554203033447266,
        "learning_rate": 4.933569530558016e-06,
        "epoch": 5.066430469441984,
        "step": 5720
    },
    {
        "loss": 0.0761,
        "grad_norm": 0.007992503233253956,
        "learning_rate": 4.924712134632418e-06,
        "epoch": 5.075287865367582,
        "step": 5730
    },
    {
        "loss": 0.0432,
        "grad_norm": 0.004541035275906324,
        "learning_rate": 4.915854738706821e-06,
        "epoch": 5.0841452612931795,
        "step": 5740
    },
    {
        "loss": 0.0065,
        "grad_norm": 145.48497009277344,
        "learning_rate": 4.906997342781223e-06,
        "epoch": 5.093002657218777,
        "step": 5750
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.8664696216583252,
        "learning_rate": 4.898139946855625e-06,
        "epoch": 5.101860053144375,
        "step": 5760
    },
    {
        "loss": 0.0533,
        "grad_norm": 4.397709369659424,
        "learning_rate": 4.8892825509300264e-06,
        "epoch": 5.110717449069973,
        "step": 5770
    },
    {
        "loss": 0.2527,
        "grad_norm": 10.805120468139648,
        "learning_rate": 4.880425155004429e-06,
        "epoch": 5.119574844995571,
        "step": 5780
    },
    {
        "loss": 0.2008,
        "grad_norm": 0.011856453493237495,
        "learning_rate": 4.871567759078831e-06,
        "epoch": 5.128432240921169,
        "step": 5790
    },
    {
        "loss": 0.016,
        "grad_norm": 4.006448268890381,
        "learning_rate": 4.862710363153234e-06,
        "epoch": 5.137289636846767,
        "step": 5800
    },
    {
        "loss": 0.0865,
        "grad_norm": 111.66529846191406,
        "learning_rate": 4.8538529672276354e-06,
        "epoch": 5.146147032772365,
        "step": 5810
    },
    {
        "loss": 0.0948,
        "grad_norm": 94.03793334960938,
        "learning_rate": 4.844995571302038e-06,
        "epoch": 5.155004428697962,
        "step": 5820
    },
    {
        "loss": 0.0447,
        "grad_norm": 0.6405987739562988,
        "learning_rate": 4.8361381753764395e-06,
        "epoch": 5.16386182462356,
        "step": 5830
    },
    {
        "loss": 0.0361,
        "grad_norm": 74.1299057006836,
        "learning_rate": 4.827280779450842e-06,
        "epoch": 5.172719220549158,
        "step": 5840
    },
    {
        "loss": 0.0484,
        "grad_norm": 0.02955629862844944,
        "learning_rate": 4.818423383525244e-06,
        "epoch": 5.181576616474756,
        "step": 5850
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.09674959629774094,
        "learning_rate": 4.809565987599646e-06,
        "epoch": 5.190434012400354,
        "step": 5860
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.005283292382955551,
        "learning_rate": 4.8007085916740485e-06,
        "epoch": 5.199291408325952,
        "step": 5870
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.01825178787112236,
        "learning_rate": 4.79185119574845e-06,
        "epoch": 5.20814880425155,
        "step": 5880
    },
    {
        "loss": 0.0047,
        "grad_norm": 77.45492553710938,
        "learning_rate": 4.7829937998228525e-06,
        "epoch": 5.217006200177148,
        "step": 5890
    },
    {
        "loss": 0.0152,
        "grad_norm": 47.01200485229492,
        "learning_rate": 4.774136403897255e-06,
        "epoch": 5.225863596102746,
        "step": 5900
    },
    {
        "loss": 0.0359,
        "grad_norm": 67.34502410888672,
        "learning_rate": 4.765279007971657e-06,
        "epoch": 5.234720992028343,
        "step": 5910
    },
    {
        "loss": 0.001,
        "grad_norm": 0.3209746181964874,
        "learning_rate": 4.756421612046059e-06,
        "epoch": 5.243578387953941,
        "step": 5920
    },
    {
        "loss": 0.0279,
        "grad_norm": 0.006717630662024021,
        "learning_rate": 4.747564216120461e-06,
        "epoch": 5.252435783879539,
        "step": 5930
    },
    {
        "loss": 0.0945,
        "grad_norm": 0.01576186716556549,
        "learning_rate": 4.738706820194863e-06,
        "epoch": 5.261293179805137,
        "step": 5940
    },
    {
        "loss": 0.0527,
        "grad_norm": 0.02292381227016449,
        "learning_rate": 4.729849424269265e-06,
        "epoch": 5.270150575730735,
        "step": 5950
    },
    {
        "loss": 0.0626,
        "grad_norm": 0.39457425475120544,
        "learning_rate": 4.720992028343667e-06,
        "epoch": 5.279007971656333,
        "step": 5960
    },
    {
        "loss": 0.062,
        "grad_norm": 0.004435464274138212,
        "learning_rate": 4.71213463241807e-06,
        "epoch": 5.287865367581931,
        "step": 5970
    },
    {
        "loss": 0.083,
        "grad_norm": 0.005965487565845251,
        "learning_rate": 4.703277236492472e-06,
        "epoch": 5.296722763507529,
        "step": 5980
    },
    {
        "loss": 0.0764,
        "grad_norm": 0.011169989593327045,
        "learning_rate": 4.694419840566874e-06,
        "epoch": 5.305580159433127,
        "step": 5990
    },
    {
        "loss": 0.0321,
        "grad_norm": 122.07823944091797,
        "learning_rate": 4.685562444641275e-06,
        "epoch": 5.314437555358724,
        "step": 6000
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.004934108350425959,
        "learning_rate": 4.676705048715678e-06,
        "epoch": 5.323294951284322,
        "step": 6010
    },
    {
        "loss": 0.0463,
        "grad_norm": 0.07419291138648987,
        "learning_rate": 4.66784765279008e-06,
        "epoch": 5.33215234720992,
        "step": 6020
    },
    {
        "loss": 0.0003,
        "grad_norm": 2.4770517349243164,
        "learning_rate": 4.658990256864483e-06,
        "epoch": 5.341009743135518,
        "step": 6030
    },
    {
        "loss": 0.0024,
        "grad_norm": 0.04250304773449898,
        "learning_rate": 4.650132860938884e-06,
        "epoch": 5.349867139061116,
        "step": 6040
    },
    {
        "loss": 0.0917,
        "grad_norm": 63.289390563964844,
        "learning_rate": 4.641275465013286e-06,
        "epoch": 5.358724534986714,
        "step": 6050
    },
    {
        "loss": 0.0861,
        "grad_norm": 0.9729606509208679,
        "learning_rate": 4.632418069087688e-06,
        "epoch": 5.367581930912312,
        "step": 6060
    },
    {
        "loss": 0.068,
        "grad_norm": 0.04872077703475952,
        "learning_rate": 4.623560673162091e-06,
        "epoch": 5.37643932683791,
        "step": 6070
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.6593778133392334,
        "learning_rate": 4.614703277236493e-06,
        "epoch": 5.385296722763507,
        "step": 6080
    },
    {
        "loss": 0.0004,
        "grad_norm": 1.6976988315582275,
        "learning_rate": 4.605845881310895e-06,
        "epoch": 5.394154118689105,
        "step": 6090
    },
    {
        "loss": 0.0157,
        "grad_norm": 149.04685974121094,
        "learning_rate": 4.596988485385297e-06,
        "epoch": 5.403011514614703,
        "step": 6100
    },
    {
        "loss": 0.023,
        "grad_norm": 0.005063650198280811,
        "learning_rate": 4.588131089459699e-06,
        "epoch": 5.411868910540301,
        "step": 6110
    },
    {
        "loss": 0.0423,
        "grad_norm": 0.012517929077148438,
        "learning_rate": 4.579273693534101e-06,
        "epoch": 5.420726306465899,
        "step": 6120
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.23990662395954132,
        "learning_rate": 4.570416297608504e-06,
        "epoch": 5.429583702391497,
        "step": 6130
    },
    {
        "loss": 0.0219,
        "grad_norm": 1.4839861392974854,
        "learning_rate": 4.5615589016829055e-06,
        "epoch": 5.438441098317095,
        "step": 6140
    },
    {
        "loss": 0.0215,
        "grad_norm": 0.062151096761226654,
        "learning_rate": 4.552701505757308e-06,
        "epoch": 5.447298494242693,
        "step": 6150
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.020749107003211975,
        "learning_rate": 4.5438441098317095e-06,
        "epoch": 5.45615589016829,
        "step": 6160
    },
    {
        "loss": 0.1745,
        "grad_norm": 0.04338511824607849,
        "learning_rate": 4.534986713906112e-06,
        "epoch": 5.465013286093888,
        "step": 6170
    },
    {
        "loss": 0.0544,
        "grad_norm": 96.01053619384766,
        "learning_rate": 4.5261293179805144e-06,
        "epoch": 5.473870682019486,
        "step": 6180
    },
    {
        "loss": 0.0247,
        "grad_norm": 0.0031598254572600126,
        "learning_rate": 4.517271922054916e-06,
        "epoch": 5.482728077945084,
        "step": 6190
    },
    {
        "loss": 0.0037,
        "grad_norm": 0.01119913998991251,
        "learning_rate": 4.5084145261293185e-06,
        "epoch": 5.491585473870682,
        "step": 6200
    },
    {
        "loss": 0.0485,
        "grad_norm": 0.004086337983608246,
        "learning_rate": 4.499557130203721e-06,
        "epoch": 5.50044286979628,
        "step": 6210
    },
    {
        "loss": 0.0724,
        "grad_norm": 0.0034327246248722076,
        "learning_rate": 4.4906997342781226e-06,
        "epoch": 5.509300265721878,
        "step": 6220
    },
    {
        "loss": 0.0934,
        "grad_norm": 64.36473083496094,
        "learning_rate": 4.481842338352524e-06,
        "epoch": 5.518157661647476,
        "step": 6230
    },
    {
        "loss": 0.0036,
        "grad_norm": 0.0045289332047104836,
        "learning_rate": 4.472984942426927e-06,
        "epoch": 5.527015057573074,
        "step": 6240
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.034064315259456635,
        "learning_rate": 4.464127546501329e-06,
        "epoch": 5.535872453498671,
        "step": 6250
    },
    {
        "loss": 0.0522,
        "grad_norm": 0.7195605635643005,
        "learning_rate": 4.4552701505757315e-06,
        "epoch": 5.544729849424269,
        "step": 6260
    },
    {
        "loss": 0.0553,
        "grad_norm": 0.01106947660446167,
        "learning_rate": 4.446412754650133e-06,
        "epoch": 5.553587245349867,
        "step": 6270
    },
    {
        "loss": 0.0819,
        "grad_norm": 35.06084060668945,
        "learning_rate": 4.437555358724535e-06,
        "epoch": 5.562444641275465,
        "step": 6280
    },
    {
        "loss": 0.0778,
        "grad_norm": 0.024906396865844727,
        "learning_rate": 4.428697962798937e-06,
        "epoch": 5.571302037201063,
        "step": 6290
    },
    {
        "loss": 0.0919,
        "grad_norm": 17.87116050720215,
        "learning_rate": 4.41984056687334e-06,
        "epoch": 5.580159433126661,
        "step": 6300
    },
    {
        "loss": 0.0429,
        "grad_norm": 0.048324890434741974,
        "learning_rate": 4.410983170947742e-06,
        "epoch": 5.589016829052259,
        "step": 6310
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.05066429451107979,
        "learning_rate": 4.402125775022144e-06,
        "epoch": 5.597874224977857,
        "step": 6320
    },
    {
        "loss": 0.0734,
        "grad_norm": 0.007426979020237923,
        "learning_rate": 4.393268379096546e-06,
        "epoch": 5.606731620903455,
        "step": 6330
    },
    {
        "loss": 0.0768,
        "grad_norm": 0.030813390389084816,
        "learning_rate": 4.384410983170948e-06,
        "epoch": 5.615589016829052,
        "step": 6340
    },
    {
        "loss": 0.0352,
        "grad_norm": 0.004835166037082672,
        "learning_rate": 4.37555358724535e-06,
        "epoch": 5.62444641275465,
        "step": 6350
    },
    {
        "loss": 0.0151,
        "grad_norm": 0.005390066187828779,
        "learning_rate": 4.366696191319753e-06,
        "epoch": 5.633303808680248,
        "step": 6360
    },
    {
        "loss": 0.049,
        "grad_norm": 1.4129998683929443,
        "learning_rate": 4.357838795394154e-06,
        "epoch": 5.642161204605846,
        "step": 6370
    },
    {
        "loss": 0.0692,
        "grad_norm": 59.610958099365234,
        "learning_rate": 4.348981399468557e-06,
        "epoch": 5.651018600531444,
        "step": 6380
    },
    {
        "loss": 0.026,
        "grad_norm": 0.1331091672182083,
        "learning_rate": 4.340124003542958e-06,
        "epoch": 5.659875996457042,
        "step": 6390
    },
    {
        "loss": 0.0059,
        "grad_norm": 0.008052549324929714,
        "learning_rate": 4.331266607617361e-06,
        "epoch": 5.66873339238264,
        "step": 6400
    },
    {
        "loss": 0.0443,
        "grad_norm": 0.020475808531045914,
        "learning_rate": 4.322409211691763e-06,
        "epoch": 5.677590788308238,
        "step": 6410
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.020363185554742813,
        "learning_rate": 4.313551815766165e-06,
        "epoch": 5.686448184233836,
        "step": 6420
    },
    {
        "loss": 0.0553,
        "grad_norm": 1.8647489547729492,
        "learning_rate": 4.304694419840567e-06,
        "epoch": 5.695305580159433,
        "step": 6430
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.09339216351509094,
        "learning_rate": 4.295837023914969e-06,
        "epoch": 5.704162976085031,
        "step": 6440
    },
    {
        "loss": 0.1085,
        "grad_norm": 153.3486785888672,
        "learning_rate": 4.2869796279893714e-06,
        "epoch": 5.713020372010629,
        "step": 6450
    },
    {
        "loss": 0.1134,
        "grad_norm": 38.35995864868164,
        "learning_rate": 4.278122232063774e-06,
        "epoch": 5.721877767936227,
        "step": 6460
    },
    {
        "loss": 0.0031,
        "grad_norm": 0.015696736052632332,
        "learning_rate": 4.2692648361381755e-06,
        "epoch": 5.730735163861825,
        "step": 6470
    },
    {
        "loss": 0.0028,
        "grad_norm": 0.00583844305947423,
        "learning_rate": 4.260407440212578e-06,
        "epoch": 5.739592559787423,
        "step": 6480
    },
    {
        "loss": 0.0236,
        "grad_norm": 117.48799133300781,
        "learning_rate": 4.25155004428698e-06,
        "epoch": 5.748449955713021,
        "step": 6490
    },
    {
        "loss": 0.0874,
        "grad_norm": 0.005414630752056837,
        "learning_rate": 4.242692648361382e-06,
        "epoch": 5.757307351638619,
        "step": 6500
    },
    {
        "loss": 0.2273,
        "grad_norm": 159.59585571289062,
        "learning_rate": 4.233835252435784e-06,
        "epoch": 5.766164747564217,
        "step": 6510
    },
    {
        "loss": 0.0026,
        "grad_norm": 0.0257932860404253,
        "learning_rate": 4.224977856510186e-06,
        "epoch": 5.775022143489814,
        "step": 6520
    },
    {
        "loss": 0.058,
        "grad_norm": 0.007391957566142082,
        "learning_rate": 4.2161204605845885e-06,
        "epoch": 5.783879539415412,
        "step": 6530
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.02941369079053402,
        "learning_rate": 4.207263064658991e-06,
        "epoch": 5.79273693534101,
        "step": 6540
    },
    {
        "loss": 0.0992,
        "grad_norm": 0.007548847701400518,
        "learning_rate": 4.198405668733393e-06,
        "epoch": 5.801594331266608,
        "step": 6550
    },
    {
        "loss": 0.0764,
        "grad_norm": 0.06985268741846085,
        "learning_rate": 4.189548272807795e-06,
        "epoch": 5.810451727192206,
        "step": 6560
    },
    {
        "loss": 0.0641,
        "grad_norm": 0.0586896575987339,
        "learning_rate": 4.180690876882197e-06,
        "epoch": 5.819309123117804,
        "step": 6570
    },
    {
        "loss": 0.0074,
        "grad_norm": 112.68048095703125,
        "learning_rate": 4.171833480956599e-06,
        "epoch": 5.8281665190434015,
        "step": 6580
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.008335316553711891,
        "learning_rate": 4.1629760850310016e-06,
        "epoch": 5.837023914968999,
        "step": 6590
    },
    {
        "loss": 0.0083,
        "grad_norm": 0.004620834719389677,
        "learning_rate": 4.154118689105404e-06,
        "epoch": 5.845881310894597,
        "step": 6600
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.07602238655090332,
        "learning_rate": 4.145261293179806e-06,
        "epoch": 5.854738706820195,
        "step": 6610
    },
    {
        "loss": 0.0647,
        "grad_norm": 103.8033447265625,
        "learning_rate": 4.136403897254207e-06,
        "epoch": 5.863596102745793,
        "step": 6620
    },
    {
        "loss": 0.0362,
        "grad_norm": 0.006619636435061693,
        "learning_rate": 4.12754650132861e-06,
        "epoch": 5.8724534986713905,
        "step": 6630
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.5383566617965698,
        "learning_rate": 4.118689105403012e-06,
        "epoch": 5.8813108945969885,
        "step": 6640
    },
    {
        "loss": 0.0414,
        "grad_norm": 259.682861328125,
        "learning_rate": 4.109831709477414e-06,
        "epoch": 5.8901682905225865,
        "step": 6650
    },
    {
        "loss": 0.064,
        "grad_norm": 32.652565002441406,
        "learning_rate": 4.100974313551816e-06,
        "epoch": 5.8990256864481845,
        "step": 6660
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.03191513568162918,
        "learning_rate": 4.092116917626218e-06,
        "epoch": 5.9078830823737825,
        "step": 6670
    },
    {
        "loss": 0.1046,
        "grad_norm": 0.3346658945083618,
        "learning_rate": 4.08325952170062e-06,
        "epoch": 5.9167404782993795,
        "step": 6680
    },
    {
        "loss": 0.0399,
        "grad_norm": 101.82422637939453,
        "learning_rate": 4.074402125775023e-06,
        "epoch": 5.9255978742249775,
        "step": 6690
    },
    {
        "loss": 0.0289,
        "grad_norm": 0.00846145860850811,
        "learning_rate": 4.065544729849424e-06,
        "epoch": 5.9344552701505755,
        "step": 6700
    },
    {
        "loss": 0.0579,
        "grad_norm": 82.67321014404297,
        "learning_rate": 4.056687333923827e-06,
        "epoch": 5.9433126660761735,
        "step": 6710
    },
    {
        "loss": 0.0923,
        "grad_norm": 0.006510528270155191,
        "learning_rate": 4.047829937998229e-06,
        "epoch": 5.9521700620017715,
        "step": 6720
    },
    {
        "loss": 0.0341,
        "grad_norm": 0.011222545057535172,
        "learning_rate": 4.038972542072631e-06,
        "epoch": 5.961027457927369,
        "step": 6730
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.006181495729833841,
        "learning_rate": 4.030115146147033e-06,
        "epoch": 5.969884853852967,
        "step": 6740
    },
    {
        "loss": 0.0086,
        "grad_norm": 0.10356327146291733,
        "learning_rate": 4.021257750221435e-06,
        "epoch": 5.978742249778565,
        "step": 6750
    },
    {
        "loss": 0.0463,
        "grad_norm": 0.0062147146090865135,
        "learning_rate": 4.012400354295837e-06,
        "epoch": 5.987599645704163,
        "step": 6760
    },
    {
        "loss": 0.0828,
        "grad_norm": 7.982077598571777,
        "learning_rate": 4.00354295837024e-06,
        "epoch": 5.9964570416297605,
        "step": 6770
    },
    {
        "eval_loss": 0.11439073830842972,
        "eval_accuracy": 0.98428,
        "eval_precision": 0.98129,
        "eval_recall": 0.98738,
        "eval_f1": 0.98433,
        "eval_runtime": 222.5146,
        "eval_samples_per_second": 40.591,
        "eval_steps_per_second": 2.539,
        "epoch": 6.0,
        "step": 6774
    },
    {
        "loss": 0.0131,
        "grad_norm": 7.336639881134033,
        "learning_rate": 3.9946855624446415e-06,
        "epoch": 6.005314437555358,
        "step": 6780
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.01753934472799301,
        "learning_rate": 3.985828166519043e-06,
        "epoch": 6.014171833480956,
        "step": 6790
    },
    {
        "loss": 0.0451,
        "grad_norm": 0.021456636488437653,
        "learning_rate": 3.9769707705934455e-06,
        "epoch": 6.023029229406554,
        "step": 6800
    },
    {
        "loss": 0.0043,
        "grad_norm": 0.0042701605707407,
        "learning_rate": 3.968113374667848e-06,
        "epoch": 6.031886625332152,
        "step": 6810
    },
    {
        "loss": 0.0174,
        "grad_norm": 0.004190273117274046,
        "learning_rate": 3.9592559787422504e-06,
        "epoch": 6.04074402125775,
        "step": 6820
    },
    {
        "loss": 0.0129,
        "grad_norm": 0.016663361340761185,
        "learning_rate": 3.950398582816652e-06,
        "epoch": 6.049601417183348,
        "step": 6830
    },
    {
        "loss": 0.0289,
        "grad_norm": 0.008234381675720215,
        "learning_rate": 3.9415411868910545e-06,
        "epoch": 6.058458813108946,
        "step": 6840
    },
    {
        "loss": 0.056,
        "grad_norm": 0.005025110207498074,
        "learning_rate": 3.932683790965456e-06,
        "epoch": 6.067316209034544,
        "step": 6850
    },
    {
        "loss": 0.0289,
        "grad_norm": 0.004986453335732222,
        "learning_rate": 3.9238263950398586e-06,
        "epoch": 6.076173604960141,
        "step": 6860
    },
    {
        "loss": 0.0749,
        "grad_norm": 0.006489230785518885,
        "learning_rate": 3.914968999114261e-06,
        "epoch": 6.085031000885739,
        "step": 6870
    },
    {
        "loss": 0.0019,
        "grad_norm": 3.402217149734497,
        "learning_rate": 3.9061116031886635e-06,
        "epoch": 6.093888396811337,
        "step": 6880
    },
    {
        "loss": 0.0343,
        "grad_norm": 109.49893188476562,
        "learning_rate": 3.897254207263065e-06,
        "epoch": 6.102745792736935,
        "step": 6890
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.0502556748688221,
        "learning_rate": 3.888396811337467e-06,
        "epoch": 6.111603188662533,
        "step": 6900
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.009473915211856365,
        "learning_rate": 3.879539415411869e-06,
        "epoch": 6.120460584588131,
        "step": 6910
    },
    {
        "loss": 0.0975,
        "grad_norm": 0.06469311565160751,
        "learning_rate": 3.870682019486272e-06,
        "epoch": 6.129317980513729,
        "step": 6920
    },
    {
        "loss": 0.0467,
        "grad_norm": 0.06065325438976288,
        "learning_rate": 3.861824623560673e-06,
        "epoch": 6.138175376439327,
        "step": 6930
    },
    {
        "loss": 0.0392,
        "grad_norm": 101.99474334716797,
        "learning_rate": 3.852967227635076e-06,
        "epoch": 6.147032772364924,
        "step": 6940
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005829932633787394,
        "learning_rate": 3.844109831709478e-06,
        "epoch": 6.155890168290522,
        "step": 6950
    },
    {
        "loss": 0.0362,
        "grad_norm": 0.0253328625112772,
        "learning_rate": 3.83525243578388e-06,
        "epoch": 6.16474756421612,
        "step": 6960
    },
    {
        "loss": 0.0385,
        "grad_norm": 0.008257823064923286,
        "learning_rate": 3.826395039858282e-06,
        "epoch": 6.173604960141718,
        "step": 6970
    },
    {
        "loss": 0.002,
        "grad_norm": 33.349525451660156,
        "learning_rate": 3.817537643932684e-06,
        "epoch": 6.182462356067316,
        "step": 6980
    },
    {
        "loss": 0.1057,
        "grad_norm": 0.03121296502649784,
        "learning_rate": 3.8086802480070863e-06,
        "epoch": 6.191319751992914,
        "step": 6990
    },
    {
        "loss": 0.03,
        "grad_norm": 0.06365993618965149,
        "learning_rate": 3.7998228520814883e-06,
        "epoch": 6.200177147918512,
        "step": 7000
    },
    {
        "loss": 0.042,
        "grad_norm": 82.44668579101562,
        "learning_rate": 3.7909654561558907e-06,
        "epoch": 6.20903454384411,
        "step": 7010
    },
    {
        "loss": 0.0179,
        "grad_norm": 0.06089767441153526,
        "learning_rate": 3.7821080602302928e-06,
        "epoch": 6.217891939769708,
        "step": 7020
    },
    {
        "loss": 0.0531,
        "grad_norm": 0.20799928903579712,
        "learning_rate": 3.7732506643046944e-06,
        "epoch": 6.226749335695305,
        "step": 7030
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.0264402087777853,
        "learning_rate": 3.764393268379097e-06,
        "epoch": 6.235606731620903,
        "step": 7040
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.012976841069757938,
        "learning_rate": 3.755535872453499e-06,
        "epoch": 6.244464127546501,
        "step": 7050
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.005544003564864397,
        "learning_rate": 3.7466784765279013e-06,
        "epoch": 6.253321523472099,
        "step": 7060
    },
    {
        "loss": 0.0145,
        "grad_norm": 0.0028454421553760767,
        "learning_rate": 3.737821080602303e-06,
        "epoch": 6.262178919397697,
        "step": 7070
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005631655920296907,
        "learning_rate": 3.7289636846767054e-06,
        "epoch": 6.271036315323295,
        "step": 7080
    },
    {
        "loss": 0.0124,
        "grad_norm": 0.18659059703350067,
        "learning_rate": 3.7201062887511074e-06,
        "epoch": 6.279893711248893,
        "step": 7090
    },
    {
        "loss": 0.083,
        "grad_norm": 0.007016126066446304,
        "learning_rate": 3.71124889282551e-06,
        "epoch": 6.288751107174491,
        "step": 7100
    },
    {
        "loss": 0.0002,
        "grad_norm": 1.1315838098526,
        "learning_rate": 3.702391496899912e-06,
        "epoch": 6.297608503100088,
        "step": 7110
    },
    {
        "loss": 0.0018,
        "grad_norm": 30.412097930908203,
        "learning_rate": 3.6935341009743135e-06,
        "epoch": 6.306465899025686,
        "step": 7120
    },
    {
        "loss": 0.0398,
        "grad_norm": 135.3396453857422,
        "learning_rate": 3.684676705048716e-06,
        "epoch": 6.315323294951284,
        "step": 7130
    },
    {
        "loss": 0.0146,
        "grad_norm": 0.32305899262428284,
        "learning_rate": 3.675819309123118e-06,
        "epoch": 6.324180690876882,
        "step": 7140
    },
    {
        "loss": 0.105,
        "grad_norm": 87.89608001708984,
        "learning_rate": 3.6669619131975205e-06,
        "epoch": 6.33303808680248,
        "step": 7150
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004671889822930098,
        "learning_rate": 3.6581045172719225e-06,
        "epoch": 6.341895482728078,
        "step": 7160
    },
    {
        "loss": 0.001,
        "grad_norm": 0.1550748199224472,
        "learning_rate": 3.649247121346324e-06,
        "epoch": 6.350752878653676,
        "step": 7170
    },
    {
        "loss": 0.0323,
        "grad_norm": 80.28584289550781,
        "learning_rate": 3.6403897254207266e-06,
        "epoch": 6.359610274579274,
        "step": 7180
    },
    {
        "loss": 0.012,
        "grad_norm": 0.4031867980957031,
        "learning_rate": 3.6315323294951286e-06,
        "epoch": 6.368467670504872,
        "step": 7190
    },
    {
        "loss": 0.0549,
        "grad_norm": 9.22652530670166,
        "learning_rate": 3.622674933569531e-06,
        "epoch": 6.377325066430469,
        "step": 7200
    },
    {
        "loss": 0.0283,
        "grad_norm": 0.030067013576626778,
        "learning_rate": 3.6138175376439327e-06,
        "epoch": 6.386182462356067,
        "step": 7210
    },
    {
        "loss": 0.0824,
        "grad_norm": 0.008238221518695354,
        "learning_rate": 3.604960141718335e-06,
        "epoch": 6.395039858281665,
        "step": 7220
    },
    {
        "loss": 0.0304,
        "grad_norm": 84.1891098022461,
        "learning_rate": 3.596102745792737e-06,
        "epoch": 6.403897254207263,
        "step": 7230
    },
    {
        "loss": 0.0501,
        "grad_norm": 0.003290942870080471,
        "learning_rate": 3.5872453498671396e-06,
        "epoch": 6.412754650132861,
        "step": 7240
    },
    {
        "loss": 0.0593,
        "grad_norm": 0.07551200687885284,
        "learning_rate": 3.5783879539415416e-06,
        "epoch": 6.421612046058459,
        "step": 7250
    },
    {
        "loss": 0.0668,
        "grad_norm": 14.488677978515625,
        "learning_rate": 3.5695305580159433e-06,
        "epoch": 6.430469441984057,
        "step": 7260
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.14687149226665497,
        "learning_rate": 3.5606731620903457e-06,
        "epoch": 6.439326837909655,
        "step": 7270
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.29161524772644043,
        "learning_rate": 3.5518157661647477e-06,
        "epoch": 6.448184233835253,
        "step": 7280
    },
    {
        "loss": 0.0003,
        "grad_norm": 2.587254524230957,
        "learning_rate": 3.54295837023915e-06,
        "epoch": 6.45704162976085,
        "step": 7290
    },
    {
        "loss": 0.0033,
        "grad_norm": 0.004223945550620556,
        "learning_rate": 3.5341009743135522e-06,
        "epoch": 6.465899025686448,
        "step": 7300
    },
    {
        "loss": 0.0513,
        "grad_norm": 199.01153564453125,
        "learning_rate": 3.5252435783879543e-06,
        "epoch": 6.474756421612046,
        "step": 7310
    },
    {
        "loss": 0.0527,
        "grad_norm": 0.08897023648023605,
        "learning_rate": 3.5163861824623563e-06,
        "epoch": 6.483613817537644,
        "step": 7320
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.04304524511098862,
        "learning_rate": 3.5075287865367587e-06,
        "epoch": 6.492471213463242,
        "step": 7330
    },
    {
        "loss": 0.0029,
        "grad_norm": 0.004396169446408749,
        "learning_rate": 3.4986713906111608e-06,
        "epoch": 6.50132860938884,
        "step": 7340
    },
    {
        "loss": 0.0224,
        "grad_norm": 0.007786516100168228,
        "learning_rate": 3.4898139946855624e-06,
        "epoch": 6.510186005314438,
        "step": 7350
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.005211179610341787,
        "learning_rate": 3.480956598759965e-06,
        "epoch": 6.519043401240036,
        "step": 7360
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.08137015998363495,
        "learning_rate": 3.472099202834367e-06,
        "epoch": 6.527900797165634,
        "step": 7370
    },
    {
        "loss": 0.0406,
        "grad_norm": 0.005014232359826565,
        "learning_rate": 3.4632418069087693e-06,
        "epoch": 6.536758193091231,
        "step": 7380
    },
    {
        "loss": 0.0459,
        "grad_norm": 1.3171948194503784,
        "learning_rate": 3.4543844109831714e-06,
        "epoch": 6.545615589016829,
        "step": 7390
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.02291654609143734,
        "learning_rate": 3.445527015057573e-06,
        "epoch": 6.554472984942427,
        "step": 7400
    },
    {
        "loss": 0.0479,
        "grad_norm": 0.01871674694120884,
        "learning_rate": 3.4366696191319754e-06,
        "epoch": 6.563330380868025,
        "step": 7410
    },
    {
        "loss": 0.0374,
        "grad_norm": 0.22510181367397308,
        "learning_rate": 3.4278122232063775e-06,
        "epoch": 6.572187776793623,
        "step": 7420
    },
    {
        "loss": 0.0105,
        "grad_norm": 0.0058472841046750546,
        "learning_rate": 3.41895482728078e-06,
        "epoch": 6.581045172719221,
        "step": 7430
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.009103615768253803,
        "learning_rate": 3.410097431355182e-06,
        "epoch": 6.589902568644819,
        "step": 7440
    },
    {
        "loss": 0.0477,
        "grad_norm": 0.010071134194731712,
        "learning_rate": 3.401240035429584e-06,
        "epoch": 6.598759964570416,
        "step": 7450
    },
    {
        "loss": 0.0586,
        "grad_norm": 0.004032707307487726,
        "learning_rate": 3.392382639503986e-06,
        "epoch": 6.607617360496015,
        "step": 7460
    },
    {
        "loss": 0.0024,
        "grad_norm": 0.007026607170701027,
        "learning_rate": 3.3835252435783885e-06,
        "epoch": 6.616474756421612,
        "step": 7470
    },
    {
        "loss": 0.0576,
        "grad_norm": 1.2085751295089722,
        "learning_rate": 3.3746678476527905e-06,
        "epoch": 6.62533215234721,
        "step": 7480
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.007655762601643801,
        "learning_rate": 3.365810451727192e-06,
        "epoch": 6.634189548272808,
        "step": 7490
    },
    {
        "loss": 0.0516,
        "grad_norm": 1.9344924688339233,
        "learning_rate": 3.3569530558015946e-06,
        "epoch": 6.643046944198406,
        "step": 7500
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0407109297811985,
        "learning_rate": 3.3480956598759966e-06,
        "epoch": 6.651904340124004,
        "step": 7510
    },
    {
        "loss": 0.0639,
        "grad_norm": 0.1364089548587799,
        "learning_rate": 3.339238263950399e-06,
        "epoch": 6.660761736049602,
        "step": 7520
    },
    {
        "loss": 0.0955,
        "grad_norm": 0.5776388049125671,
        "learning_rate": 3.330380868024801e-06,
        "epoch": 6.6696191319752,
        "step": 7530
    },
    {
        "loss": 0.0325,
        "grad_norm": 61.18244934082031,
        "learning_rate": 3.3215234720992027e-06,
        "epoch": 6.678476527900797,
        "step": 7540
    },
    {
        "loss": 0.0028,
        "grad_norm": 0.3988538384437561,
        "learning_rate": 3.312666076173605e-06,
        "epoch": 6.687333923826395,
        "step": 7550
    },
    {
        "loss": 0.0039,
        "grad_norm": 101.07730865478516,
        "learning_rate": 3.303808680248007e-06,
        "epoch": 6.696191319751993,
        "step": 7560
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.003661740105599165,
        "learning_rate": 3.2949512843224096e-06,
        "epoch": 6.705048715677591,
        "step": 7570
    },
    {
        "loss": 0.0057,
        "grad_norm": 0.04982367902994156,
        "learning_rate": 3.2860938883968117e-06,
        "epoch": 6.713906111603189,
        "step": 7580
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.003975901287049055,
        "learning_rate": 3.2772364924712137e-06,
        "epoch": 6.722763507528787,
        "step": 7590
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.006290156859904528,
        "learning_rate": 3.2683790965456157e-06,
        "epoch": 6.731620903454385,
        "step": 7600
    },
    {
        "loss": 0.0148,
        "grad_norm": 0.007387159392237663,
        "learning_rate": 3.259521700620018e-06,
        "epoch": 6.7404782993799826,
        "step": 7610
    },
    {
        "loss": 0.007,
        "grad_norm": 0.0139738405123353,
        "learning_rate": 3.2506643046944202e-06,
        "epoch": 6.7493356953055805,
        "step": 7620
    },
    {
        "loss": 0.0012,
        "grad_norm": 0.007752130273729563,
        "learning_rate": 3.241806908768822e-06,
        "epoch": 6.758193091231178,
        "step": 7630
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005162818357348442,
        "learning_rate": 3.2329495128432243e-06,
        "epoch": 6.767050487156776,
        "step": 7640
    },
    {
        "loss": 0.0088,
        "grad_norm": 0.2813684940338135,
        "learning_rate": 3.2240921169176263e-06,
        "epoch": 6.775907883082374,
        "step": 7650
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005624684039503336,
        "learning_rate": 3.2152347209920288e-06,
        "epoch": 6.7847652790079716,
        "step": 7660
    },
    {
        "loss": 0.0335,
        "grad_norm": 0.02697231061756611,
        "learning_rate": 3.206377325066431e-06,
        "epoch": 6.7936226749335695,
        "step": 7670
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.010826388373970985,
        "learning_rate": 3.197519929140833e-06,
        "epoch": 6.8024800708591675,
        "step": 7680
    },
    {
        "loss": 0.0195,
        "grad_norm": 220.61895751953125,
        "learning_rate": 3.188662533215235e-06,
        "epoch": 6.8113374667847655,
        "step": 7690
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0027806456200778484,
        "learning_rate": 3.1798051372896373e-06,
        "epoch": 6.8201948627103635,
        "step": 7700
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.005161018576472998,
        "learning_rate": 3.1709477413640394e-06,
        "epoch": 6.829052258635961,
        "step": 7710
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.002724287798628211,
        "learning_rate": 3.162090345438442e-06,
        "epoch": 6.8379096545615585,
        "step": 7720
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00900852121412754,
        "learning_rate": 3.1532329495128434e-06,
        "epoch": 6.8467670504871565,
        "step": 7730
    },
    {
        "loss": 0.0735,
        "grad_norm": 174.45921325683594,
        "learning_rate": 3.1443755535872455e-06,
        "epoch": 6.8556244464127545,
        "step": 7740
    },
    {
        "loss": 0.0923,
        "grad_norm": 0.12775219976902008,
        "learning_rate": 3.135518157661648e-06,
        "epoch": 6.8644818423383525,
        "step": 7750
    },
    {
        "loss": 0.0022,
        "grad_norm": 0.002814012812450528,
        "learning_rate": 3.12666076173605e-06,
        "epoch": 6.87333923826395,
        "step": 7760
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.009351071901619434,
        "learning_rate": 3.1178033658104516e-06,
        "epoch": 6.882196634189548,
        "step": 7770
    },
    {
        "loss": 0.0607,
        "grad_norm": 0.05991753935813904,
        "learning_rate": 3.108945969884854e-06,
        "epoch": 6.891054030115146,
        "step": 7780
    },
    {
        "loss": 0.0579,
        "grad_norm": 0.11259757727384567,
        "learning_rate": 3.100088573959256e-06,
        "epoch": 6.899911426040744,
        "step": 7790
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.019935010001063347,
        "learning_rate": 3.0912311780336585e-06,
        "epoch": 6.908768821966342,
        "step": 7800
    },
    {
        "loss": 0.0709,
        "grad_norm": 24.761140823364258,
        "learning_rate": 3.0823737821080605e-06,
        "epoch": 6.917626217891939,
        "step": 7810
    },
    {
        "loss": 0.0065,
        "grad_norm": 0.004062014631927013,
        "learning_rate": 3.0735163861824626e-06,
        "epoch": 6.926483613817537,
        "step": 7820
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0054754107259213924,
        "learning_rate": 3.0646589902568646e-06,
        "epoch": 6.935341009743135,
        "step": 7830
    },
    {
        "loss": 0.0022,
        "grad_norm": 0.004801832139492035,
        "learning_rate": 3.055801594331267e-06,
        "epoch": 6.944198405668733,
        "step": 7840
    },
    {
        "loss": 0.0009,
        "grad_norm": 0.0036358078941702843,
        "learning_rate": 3.046944198405669e-06,
        "epoch": 6.953055801594331,
        "step": 7850
    },
    {
        "loss": 0.0497,
        "grad_norm": 0.004323617555201054,
        "learning_rate": 3.0380868024800715e-06,
        "epoch": 6.961913197519929,
        "step": 7860
    },
    {
        "loss": 0.019,
        "grad_norm": 265.6214294433594,
        "learning_rate": 3.029229406554473e-06,
        "epoch": 6.970770593445527,
        "step": 7870
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.004382128361612558,
        "learning_rate": 3.020372010628875e-06,
        "epoch": 6.979627989371125,
        "step": 7880
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.0035209699999541044,
        "learning_rate": 3.0115146147032776e-06,
        "epoch": 6.988485385296723,
        "step": 7890
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.013736351393163204,
        "learning_rate": 3.0026572187776797e-06,
        "epoch": 6.99734278122232,
        "step": 7900
    },
    {
        "eval_loss": 0.1073535606265068,
        "eval_accuracy": 0.98594,
        "eval_precision": 0.98476,
        "eval_recall": 0.98716,
        "eval_f1": 0.98596,
        "eval_runtime": 192.5902,
        "eval_samples_per_second": 46.898,
        "eval_steps_per_second": 2.934,
        "epoch": 7.0,
        "step": 7903
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.008898179046809673,
        "learning_rate": 2.9937998228520813e-06,
        "epoch": 7.006200177147918,
        "step": 7910
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0051063657738268375,
        "learning_rate": 2.9849424269264837e-06,
        "epoch": 7.015057573073516,
        "step": 7920
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0030254609882831573,
        "learning_rate": 2.9760850310008858e-06,
        "epoch": 7.023914968999114,
        "step": 7930
    },
    {
        "loss": 0.001,
        "grad_norm": 0.016307512298226357,
        "learning_rate": 2.9672276350752882e-06,
        "epoch": 7.032772364924712,
        "step": 7940
    },
    {
        "loss": 0.0429,
        "grad_norm": 123.33154296875,
        "learning_rate": 2.9583702391496903e-06,
        "epoch": 7.04162976085031,
        "step": 7950
    },
    {
        "loss": 0.0098,
        "grad_norm": 225.50537109375,
        "learning_rate": 2.9495128432240923e-06,
        "epoch": 7.050487156775908,
        "step": 7960
    },
    {
        "loss": 0.0221,
        "grad_norm": 0.006202484481036663,
        "learning_rate": 2.9406554472984943e-06,
        "epoch": 7.059344552701506,
        "step": 7970
    },
    {
        "loss": 0.0465,
        "grad_norm": 0.005107435397803783,
        "learning_rate": 2.9317980513728968e-06,
        "epoch": 7.068201948627103,
        "step": 7980
    },
    {
        "loss": 0.0337,
        "grad_norm": 0.014838438481092453,
        "learning_rate": 2.922940655447299e-06,
        "epoch": 7.077059344552701,
        "step": 7990
    },
    {
        "loss": 0.0312,
        "grad_norm": 0.013477289117872715,
        "learning_rate": 2.9140832595217013e-06,
        "epoch": 7.085916740478299,
        "step": 8000
    },
    {
        "loss": 0.0526,
        "grad_norm": 0.0031214093323796988,
        "learning_rate": 2.905225863596103e-06,
        "epoch": 7.094774136403897,
        "step": 8010
    },
    {
        "loss": 0.0169,
        "grad_norm": 0.014854682609438896,
        "learning_rate": 2.896368467670505e-06,
        "epoch": 7.103631532329495,
        "step": 8020
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.002750505693256855,
        "learning_rate": 2.8875110717449074e-06,
        "epoch": 7.112488928255093,
        "step": 8030
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.003135554725304246,
        "learning_rate": 2.8786536758193094e-06,
        "epoch": 7.121346324180691,
        "step": 8040
    },
    {
        "loss": 0.0616,
        "grad_norm": 0.004380523692816496,
        "learning_rate": 2.8697962798937114e-06,
        "epoch": 7.130203720106289,
        "step": 8050
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.22672858834266663,
        "learning_rate": 2.8609388839681135e-06,
        "epoch": 7.139061116031886,
        "step": 8060
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0038129608146846294,
        "learning_rate": 2.852081488042516e-06,
        "epoch": 7.147918511957484,
        "step": 8070
    },
    {
        "loss": 0.0548,
        "grad_norm": 0.00785392802208662,
        "learning_rate": 2.843224092116918e-06,
        "epoch": 7.156775907883082,
        "step": 8080
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0182658638805151,
        "learning_rate": 2.8343666961913204e-06,
        "epoch": 7.16563330380868,
        "step": 8090
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.002700281795114279,
        "learning_rate": 2.825509300265722e-06,
        "epoch": 7.174490699734278,
        "step": 8100
    },
    {
        "loss": 0.0092,
        "grad_norm": 0.04865945130586624,
        "learning_rate": 2.816651904340124e-06,
        "epoch": 7.183348095659876,
        "step": 8110
    },
    {
        "loss": 0.0584,
        "grad_norm": 0.015778303146362305,
        "learning_rate": 2.8077945084145265e-06,
        "epoch": 7.192205491585474,
        "step": 8120
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0038329639937728643,
        "learning_rate": 2.7989371124889285e-06,
        "epoch": 7.201062887511072,
        "step": 8130
    },
    {
        "loss": 0.0679,
        "grad_norm": 0.0074930088594555855,
        "learning_rate": 2.790079716563331e-06,
        "epoch": 7.20992028343667,
        "step": 8140
    },
    {
        "loss": 0.0136,
        "grad_norm": 0.009787265211343765,
        "learning_rate": 2.7812223206377326e-06,
        "epoch": 7.218777679362267,
        "step": 8150
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.006130199413746595,
        "learning_rate": 2.7723649247121346e-06,
        "epoch": 7.227635075287865,
        "step": 8160
    },
    {
        "loss": 0.0217,
        "grad_norm": 0.05122368037700653,
        "learning_rate": 2.763507528786537e-06,
        "epoch": 7.236492471213463,
        "step": 8170
    },
    {
        "loss": 0.0553,
        "grad_norm": 0.04537239298224449,
        "learning_rate": 2.754650132860939e-06,
        "epoch": 7.245349867139061,
        "step": 8180
    },
    {
        "loss": 0.0417,
        "grad_norm": 0.06174313649535179,
        "learning_rate": 2.745792736935341e-06,
        "epoch": 7.254207263064659,
        "step": 8190
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.0035926857963204384,
        "learning_rate": 2.736935341009743e-06,
        "epoch": 7.263064658990257,
        "step": 8200
    },
    {
        "loss": 0.0182,
        "grad_norm": 0.005438906140625477,
        "learning_rate": 2.7280779450841456e-06,
        "epoch": 7.271922054915855,
        "step": 8210
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0034283252898603678,
        "learning_rate": 2.7192205491585477e-06,
        "epoch": 7.280779450841453,
        "step": 8220
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.003599622054025531,
        "learning_rate": 2.71036315323295e-06,
        "epoch": 7.289636846767051,
        "step": 8230
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.01547163538634777,
        "learning_rate": 2.7015057573073517e-06,
        "epoch": 7.298494242692648,
        "step": 8240
    },
    {
        "loss": 0.0014,
        "grad_norm": 0.004208758007735014,
        "learning_rate": 2.6926483613817538e-06,
        "epoch": 7.307351638618246,
        "step": 8250
    },
    {
        "loss": 0.0127,
        "grad_norm": 0.0027829117607325315,
        "learning_rate": 2.6837909654561562e-06,
        "epoch": 7.316209034543844,
        "step": 8260
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01073489524424076,
        "learning_rate": 2.6749335695305583e-06,
        "epoch": 7.325066430469442,
        "step": 8270
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005699845030903816,
        "learning_rate": 2.6660761736049607e-06,
        "epoch": 7.33392382639504,
        "step": 8280
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.003045725869014859,
        "learning_rate": 2.6572187776793623e-06,
        "epoch": 7.342781222320638,
        "step": 8290
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0030501713044941425,
        "learning_rate": 2.6483613817537644e-06,
        "epoch": 7.351638618246236,
        "step": 8300
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.26742565631866455,
        "learning_rate": 2.639503985828167e-06,
        "epoch": 7.360496014171834,
        "step": 8310
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.0031216777861118317,
        "learning_rate": 2.630646589902569e-06,
        "epoch": 7.369353410097431,
        "step": 8320
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.016911884769797325,
        "learning_rate": 2.621789193976971e-06,
        "epoch": 7.378210806023029,
        "step": 8330
    },
    {
        "loss": 0.0054,
        "grad_norm": 0.013258240185678005,
        "learning_rate": 2.612931798051373e-06,
        "epoch": 7.387068201948627,
        "step": 8340
    },
    {
        "loss": 0.0021,
        "grad_norm": 76.17963409423828,
        "learning_rate": 2.6040744021257754e-06,
        "epoch": 7.395925597874225,
        "step": 8350
    },
    {
        "loss": 0.0605,
        "grad_norm": 0.006175151094794273,
        "learning_rate": 2.5952170062001774e-06,
        "epoch": 7.404782993799823,
        "step": 8360
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.0031392420642077923,
        "learning_rate": 2.58635961027458e-06,
        "epoch": 7.413640389725421,
        "step": 8370
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.003958085551857948,
        "learning_rate": 2.5775022143489815e-06,
        "epoch": 7.422497785651019,
        "step": 8380
    },
    {
        "loss": 0.0167,
        "grad_norm": 157.66473388671875,
        "learning_rate": 2.5686448184233835e-06,
        "epoch": 7.431355181576617,
        "step": 8390
    },
    {
        "loss": 0.0306,
        "grad_norm": 0.8953808546066284,
        "learning_rate": 2.559787422497786e-06,
        "epoch": 7.440212577502215,
        "step": 8400
    },
    {
        "loss": 0.0392,
        "grad_norm": 0.004229250829666853,
        "learning_rate": 2.550930026572188e-06,
        "epoch": 7.449069973427812,
        "step": 8410
    },
    {
        "loss": 0.0043,
        "grad_norm": 0.006374940741807222,
        "learning_rate": 2.5420726306465904e-06,
        "epoch": 7.45792736935341,
        "step": 8420
    },
    {
        "loss": 0.0174,
        "grad_norm": 0.0036661054473370314,
        "learning_rate": 2.533215234720992e-06,
        "epoch": 7.466784765279008,
        "step": 8430
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002230624435469508,
        "learning_rate": 2.5243578387953945e-06,
        "epoch": 7.475642161204606,
        "step": 8440
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.026170961558818817,
        "learning_rate": 2.5155004428697965e-06,
        "epoch": 7.484499557130204,
        "step": 8450
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.018459375947713852,
        "learning_rate": 2.506643046944199e-06,
        "epoch": 7.493356953055802,
        "step": 8460
    },
    {
        "loss": 0.0468,
        "grad_norm": 265.3800048828125,
        "learning_rate": 2.4977856510186006e-06,
        "epoch": 7.5022143489814,
        "step": 8470
    },
    {
        "loss": 0.0047,
        "grad_norm": 0.00341263716109097,
        "learning_rate": 2.4889282550930026e-06,
        "epoch": 7.511071744906998,
        "step": 8480
    },
    {
        "loss": 0.0662,
        "grad_norm": 0.0018540211021900177,
        "learning_rate": 2.480070859167405e-06,
        "epoch": 7.519929140832595,
        "step": 8490
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.036946363747119904,
        "learning_rate": 2.471213463241807e-06,
        "epoch": 7.528786536758193,
        "step": 8500
    },
    {
        "loss": 0.0514,
        "grad_norm": 0.28101053833961487,
        "learning_rate": 2.462356067316209e-06,
        "epoch": 7.537643932683791,
        "step": 8510
    },
    {
        "loss": 0.0409,
        "grad_norm": 109.21913146972656,
        "learning_rate": 2.4534986713906116e-06,
        "epoch": 7.546501328609389,
        "step": 8520
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.07758984714746475,
        "learning_rate": 2.4446412754650132e-06,
        "epoch": 7.555358724534987,
        "step": 8530
    },
    {
        "loss": 0.1051,
        "grad_norm": 0.9664977788925171,
        "learning_rate": 2.4357838795394157e-06,
        "epoch": 7.564216120460585,
        "step": 8540
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0038405798841267824,
        "learning_rate": 2.4269264836138177e-06,
        "epoch": 7.573073516386183,
        "step": 8550
    },
    {
        "loss": 0.0494,
        "grad_norm": 50.539466857910156,
        "learning_rate": 2.4180690876882197e-06,
        "epoch": 7.581930912311781,
        "step": 8560
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.011457404121756554,
        "learning_rate": 2.409211691762622e-06,
        "epoch": 7.590788308237379,
        "step": 8570
    },
    {
        "loss": 0.0236,
        "grad_norm": 0.005057083908468485,
        "learning_rate": 2.4003542958370242e-06,
        "epoch": 7.599645704162976,
        "step": 8580
    },
    {
        "loss": 0.0577,
        "grad_norm": 0.05580130219459534,
        "learning_rate": 2.3914968999114263e-06,
        "epoch": 7.608503100088574,
        "step": 8590
    },
    {
        "loss": 0.0374,
        "grad_norm": 0.0025227400474250317,
        "learning_rate": 2.3826395039858283e-06,
        "epoch": 7.617360496014172,
        "step": 8600
    },
    {
        "loss": 0.044,
        "grad_norm": 0.17954358458518982,
        "learning_rate": 2.3737821080602303e-06,
        "epoch": 7.62621789193977,
        "step": 8610
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.002929887268692255,
        "learning_rate": 2.3649247121346324e-06,
        "epoch": 7.635075287865368,
        "step": 8620
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003975748550146818,
        "learning_rate": 2.356067316209035e-06,
        "epoch": 7.643932683790966,
        "step": 8630
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0030277909245342016,
        "learning_rate": 2.347209920283437e-06,
        "epoch": 7.6527900797165636,
        "step": 8640
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.004897566977888346,
        "learning_rate": 2.338352524357839e-06,
        "epoch": 7.6616474756421615,
        "step": 8650
    },
    {
        "loss": 0.0244,
        "grad_norm": 0.004881749860942364,
        "learning_rate": 2.3294951284322413e-06,
        "epoch": 7.6705048715677595,
        "step": 8660
    },
    {
        "loss": 0.0112,
        "grad_norm": 0.0060978056862950325,
        "learning_rate": 2.320637732506643e-06,
        "epoch": 7.679362267493357,
        "step": 8670
    },
    {
        "loss": 0.0406,
        "grad_norm": 0.003272140631452203,
        "learning_rate": 2.3117803365810454e-06,
        "epoch": 7.688219663418955,
        "step": 8680
    },
    {
        "loss": 0.0117,
        "grad_norm": 0.025973379611968994,
        "learning_rate": 2.3029229406554474e-06,
        "epoch": 7.6970770593445526,
        "step": 8690
    },
    {
        "loss": 0.0383,
        "grad_norm": 0.002865368500351906,
        "learning_rate": 2.2940655447298495e-06,
        "epoch": 7.7059344552701505,
        "step": 8700
    },
    {
        "loss": 0.0479,
        "grad_norm": 0.0021202925126999617,
        "learning_rate": 2.285208148804252e-06,
        "epoch": 7.7147918511957485,
        "step": 8710
    },
    {
        "loss": 0.0427,
        "grad_norm": 0.00256713037379086,
        "learning_rate": 2.276350752878654e-06,
        "epoch": 7.7236492471213465,
        "step": 8720
    },
    {
        "loss": 0.0377,
        "grad_norm": 0.0026328025851398706,
        "learning_rate": 2.267493356953056e-06,
        "epoch": 7.7325066430469445,
        "step": 8730
    },
    {
        "loss": 0.0257,
        "grad_norm": 0.0020437086932361126,
        "learning_rate": 2.258635961027458e-06,
        "epoch": 7.741364038972542,
        "step": 8740
    },
    {
        "loss": 0.0339,
        "grad_norm": 0.002355152042582631,
        "learning_rate": 2.2497785651018605e-06,
        "epoch": 7.75022143489814,
        "step": 8750
    },
    {
        "loss": 0.0017,
        "grad_norm": 0.002124781021848321,
        "learning_rate": 2.240921169176262e-06,
        "epoch": 7.7590788308237375,
        "step": 8760
    },
    {
        "loss": 0.0527,
        "grad_norm": 0.002333980053663254,
        "learning_rate": 2.2320637732506645e-06,
        "epoch": 7.7679362267493355,
        "step": 8770
    },
    {
        "loss": 0.0383,
        "grad_norm": 0.17546673119068146,
        "learning_rate": 2.2232063773250666e-06,
        "epoch": 7.7767936226749335,
        "step": 8780
    },
    {
        "loss": 0.0063,
        "grad_norm": 0.0036015568766742945,
        "learning_rate": 2.2143489813994686e-06,
        "epoch": 7.785651018600531,
        "step": 8790
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0032499595545232296,
        "learning_rate": 2.205491585473871e-06,
        "epoch": 7.794508414526129,
        "step": 8800
    },
    {
        "loss": 0.0218,
        "grad_norm": 0.003896158654242754,
        "learning_rate": 2.196634189548273e-06,
        "epoch": 7.803365810451727,
        "step": 8810
    },
    {
        "loss": 0.0437,
        "grad_norm": 0.0038188493344932795,
        "learning_rate": 2.187776793622675e-06,
        "epoch": 7.812223206377325,
        "step": 8820
    },
    {
        "loss": 0.0178,
        "grad_norm": 7.994170665740967,
        "learning_rate": 2.178919397697077e-06,
        "epoch": 7.8210806023029225,
        "step": 8830
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.029835890978574753,
        "learning_rate": 2.170062001771479e-06,
        "epoch": 7.82993799822852,
        "step": 8840
    },
    {
        "loss": 0.0024,
        "grad_norm": 0.0025932115968316793,
        "learning_rate": 2.1612046058458816e-06,
        "epoch": 7.838795394154118,
        "step": 8850
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0032906203996390104,
        "learning_rate": 2.1523472099202837e-06,
        "epoch": 7.847652790079716,
        "step": 8860
    },
    {
        "loss": 0.0591,
        "grad_norm": 0.0028791814111173153,
        "learning_rate": 2.1434898139946857e-06,
        "epoch": 7.856510186005314,
        "step": 8870
    },
    {
        "loss": 0.0015,
        "grad_norm": 0.0036019894760102034,
        "learning_rate": 2.1346324180690877e-06,
        "epoch": 7.865367581930912,
        "step": 8880
    },
    {
        "loss": 0.0006,
        "grad_norm": 1.0048340559005737,
        "learning_rate": 2.12577502214349e-06,
        "epoch": 7.87422497785651,
        "step": 8890
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003015671856701374,
        "learning_rate": 2.116917626217892e-06,
        "epoch": 7.883082373782108,
        "step": 8900
    },
    {
        "loss": 0.0522,
        "grad_norm": 0.029354622587561607,
        "learning_rate": 2.1080602302922943e-06,
        "epoch": 7.891939769707706,
        "step": 8910
    },
    {
        "loss": 0.0127,
        "grad_norm": 163.27337646484375,
        "learning_rate": 2.0992028343666963e-06,
        "epoch": 7.900797165633303,
        "step": 8920
    },
    {
        "loss": 0.0451,
        "grad_norm": 101.37964630126953,
        "learning_rate": 2.0903454384410983e-06,
        "epoch": 7.909654561558901,
        "step": 8930
    },
    {
        "loss": 0.0504,
        "grad_norm": 41.899105072021484,
        "learning_rate": 2.0814880425155008e-06,
        "epoch": 7.918511957484499,
        "step": 8940
    },
    {
        "loss": 0.0211,
        "grad_norm": 129.64407348632812,
        "learning_rate": 2.072630646589903e-06,
        "epoch": 7.927369353410097,
        "step": 8950
    },
    {
        "loss": 0.0426,
        "grad_norm": 0.039854373782873154,
        "learning_rate": 2.063773250664305e-06,
        "epoch": 7.936226749335695,
        "step": 8960
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0496508814394474,
        "learning_rate": 2.054915854738707e-06,
        "epoch": 7.945084145261293,
        "step": 8970
    },
    {
        "loss": 0.0454,
        "grad_norm": 0.009501299820840359,
        "learning_rate": 2.046058458813109e-06,
        "epoch": 7.953941541186891,
        "step": 8980
    },
    {
        "loss": 0.0414,
        "grad_norm": 0.0029301114846020937,
        "learning_rate": 2.0372010628875114e-06,
        "epoch": 7.962798937112489,
        "step": 8990
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.004829993937164545,
        "learning_rate": 2.0283436669619134e-06,
        "epoch": 7.971656333038087,
        "step": 9000
    },
    {
        "loss": 0.0142,
        "grad_norm": 0.0022257561795413494,
        "learning_rate": 2.0194862710363154e-06,
        "epoch": 7.980513728963684,
        "step": 9010
    },
    {
        "loss": 0.0229,
        "grad_norm": 0.003309954423457384,
        "learning_rate": 2.0106288751107175e-06,
        "epoch": 7.989371124889282,
        "step": 9020
    },
    {
        "loss": 0.0278,
        "grad_norm": 0.32745224237442017,
        "learning_rate": 2.00177147918512e-06,
        "epoch": 7.99822852081488,
        "step": 9030
    },
    {
        "eval_loss": 0.10739938914775848,
        "eval_accuracy": 0.98682,
        "eval_precision": 0.98372,
        "eval_recall": 0.99004,
        "eval_f1": 0.98687,
        "eval_runtime": 197.0195,
        "eval_samples_per_second": 45.843,
        "eval_steps_per_second": 2.868,
        "epoch": 8.0,
        "step": 9032
    },
    {
        "loss": 0.0197,
        "grad_norm": 121.3583755493164,
        "learning_rate": 1.9929140832595215e-06,
        "epoch": 8.007085916740479,
        "step": 9040
    },
    {
        "loss": 0.0011,
        "grad_norm": 0.004891019314527512,
        "learning_rate": 1.984056687333924e-06,
        "epoch": 8.015943312666076,
        "step": 9050
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.012536471709609032,
        "learning_rate": 1.975199291408326e-06,
        "epoch": 8.024800708591673,
        "step": 9060
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0024223162326961756,
        "learning_rate": 1.966341895482728e-06,
        "epoch": 8.033658104517272,
        "step": 9070
    },
    {
        "loss": 0.0154,
        "grad_norm": 0.002079708268865943,
        "learning_rate": 1.9574844995571305e-06,
        "epoch": 8.04251550044287,
        "step": 9080
    },
    {
        "loss": 0.0513,
        "grad_norm": 0.005125498864799738,
        "learning_rate": 1.9486271036315325e-06,
        "epoch": 8.051372896368468,
        "step": 9090
    },
    {
        "loss": 0.019,
        "grad_norm": 0.002535531297326088,
        "learning_rate": 1.9397697077059346e-06,
        "epoch": 8.060230292294065,
        "step": 9100
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0026130331680178642,
        "learning_rate": 1.9309123117803366e-06,
        "epoch": 8.069087688219664,
        "step": 9110
    },
    {
        "loss": 0.0613,
        "grad_norm": 0.017390210181474686,
        "learning_rate": 1.922054915854739e-06,
        "epoch": 8.077945084145261,
        "step": 9120
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.015579557977616787,
        "learning_rate": 1.913197519929141e-06,
        "epoch": 8.08680248007086,
        "step": 9130
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002525792457163334,
        "learning_rate": 1.9043401240035431e-06,
        "epoch": 8.095659875996457,
        "step": 9140
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005073105450719595,
        "learning_rate": 1.8954827280779454e-06,
        "epoch": 8.104517271922054,
        "step": 9150
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.002873942954465747,
        "learning_rate": 1.8866253321523472e-06,
        "epoch": 8.113374667847653,
        "step": 9160
    },
    {
        "loss": 0.0531,
        "grad_norm": 0.003296883776783943,
        "learning_rate": 1.8777679362267494e-06,
        "epoch": 8.12223206377325,
        "step": 9170
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0030002424027770758,
        "learning_rate": 1.8689105403011515e-06,
        "epoch": 8.131089459698849,
        "step": 9180
    },
    {
        "loss": 0.073,
        "grad_norm": 0.0027780309319496155,
        "learning_rate": 1.8600531443755537e-06,
        "epoch": 8.139946855624446,
        "step": 9190
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0036970446817576885,
        "learning_rate": 1.851195748449956e-06,
        "epoch": 8.148804251550045,
        "step": 9200
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0030631411354988813,
        "learning_rate": 1.842338352524358e-06,
        "epoch": 8.157661647475642,
        "step": 9210
    },
    {
        "loss": 0.066,
        "grad_norm": 0.003168970113620162,
        "learning_rate": 1.8334809565987602e-06,
        "epoch": 8.166519043401241,
        "step": 9220
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.019428659230470657,
        "learning_rate": 1.824623560673162e-06,
        "epoch": 8.175376439326838,
        "step": 9230
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.2312772274017334,
        "learning_rate": 1.8157661647475643e-06,
        "epoch": 8.184233835252435,
        "step": 9240
    },
    {
        "loss": 0.0428,
        "grad_norm": 0.003640278009697795,
        "learning_rate": 1.8069087688219663e-06,
        "epoch": 8.193091231178034,
        "step": 9250
    },
    {
        "loss": 0.0172,
        "grad_norm": 0.08407146483659744,
        "learning_rate": 1.7980513728963686e-06,
        "epoch": 8.201948627103631,
        "step": 9260
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.012209688313305378,
        "learning_rate": 1.7891939769707708e-06,
        "epoch": 8.21080602302923,
        "step": 9270
    },
    {
        "loss": 0.0392,
        "grad_norm": 0.015086652711033821,
        "learning_rate": 1.7803365810451729e-06,
        "epoch": 8.219663418954827,
        "step": 9280
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.02851484902203083,
        "learning_rate": 1.771479185119575e-06,
        "epoch": 8.228520814880426,
        "step": 9290
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00303868530318141,
        "learning_rate": 1.7626217891939771e-06,
        "epoch": 8.237378210806023,
        "step": 9300
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0029166170861572027,
        "learning_rate": 1.7537643932683794e-06,
        "epoch": 8.24623560673162,
        "step": 9310
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.008206699974834919,
        "learning_rate": 1.7449069973427812e-06,
        "epoch": 8.255093002657219,
        "step": 9320
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003931018523871899,
        "learning_rate": 1.7360496014171834e-06,
        "epoch": 8.263950398582816,
        "step": 9330
    },
    {
        "loss": 0.0047,
        "grad_norm": 0.028344275429844856,
        "learning_rate": 1.7271922054915857e-06,
        "epoch": 8.272807794508415,
        "step": 9340
    },
    {
        "loss": 0.0008,
        "grad_norm": 0.01638471521437168,
        "learning_rate": 1.7183348095659877e-06,
        "epoch": 8.281665190434012,
        "step": 9350
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.013206243515014648,
        "learning_rate": 1.70947741364039e-06,
        "epoch": 8.29052258635961,
        "step": 9360
    },
    {
        "loss": 0.0679,
        "grad_norm": 0.006766651291400194,
        "learning_rate": 1.700620017714792e-06,
        "epoch": 8.299379982285208,
        "step": 9370
    },
    {
        "loss": 0.0533,
        "grad_norm": 0.0041854502633214,
        "learning_rate": 1.6917626217891942e-06,
        "epoch": 8.308237378210807,
        "step": 9380
    },
    {
        "loss": 0.0176,
        "grad_norm": 0.0036172806285321712,
        "learning_rate": 1.682905225863596e-06,
        "epoch": 8.317094774136404,
        "step": 9390
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.06303137540817261,
        "learning_rate": 1.6740478299379983e-06,
        "epoch": 8.325952170062001,
        "step": 9400
    },
    {
        "loss": 0.0044,
        "grad_norm": 0.0028252694755792618,
        "learning_rate": 1.6651904340124005e-06,
        "epoch": 8.3348095659876,
        "step": 9410
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0038614103104919195,
        "learning_rate": 1.6563330380868026e-06,
        "epoch": 8.343666961913197,
        "step": 9420
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00377708300948143,
        "learning_rate": 1.6474756421612048e-06,
        "epoch": 8.352524357838796,
        "step": 9430
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002409697510302067,
        "learning_rate": 1.6386182462356069e-06,
        "epoch": 8.361381753764393,
        "step": 9440
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.8079793453216553,
        "learning_rate": 1.629760850310009e-06,
        "epoch": 8.370239149689992,
        "step": 9450
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.015835892409086227,
        "learning_rate": 1.620903454384411e-06,
        "epoch": 8.379096545615589,
        "step": 9460
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006055975332856178,
        "learning_rate": 1.6120460584588132e-06,
        "epoch": 8.387953941541188,
        "step": 9470
    },
    {
        "loss": 0.0571,
        "grad_norm": 0.013430248945951462,
        "learning_rate": 1.6031886625332154e-06,
        "epoch": 8.396811337466785,
        "step": 9480
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002336338395252824,
        "learning_rate": 1.5943312666076174e-06,
        "epoch": 8.405668733392382,
        "step": 9490
    },
    {
        "loss": 0.0284,
        "grad_norm": 0.0033517968840897083,
        "learning_rate": 1.5854738706820197e-06,
        "epoch": 8.41452612931798,
        "step": 9500
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.06596076488494873,
        "learning_rate": 1.5766164747564217e-06,
        "epoch": 8.423383525243578,
        "step": 9510
    },
    {
        "loss": 0.0587,
        "grad_norm": 0.004658031743019819,
        "learning_rate": 1.567759078830824e-06,
        "epoch": 8.432240921169177,
        "step": 9520
    },
    {
        "loss": 0.0289,
        "grad_norm": 0.009519276209175587,
        "learning_rate": 1.5589016829052258e-06,
        "epoch": 8.441098317094774,
        "step": 9530
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0022861608304083347,
        "learning_rate": 1.550044286979628e-06,
        "epoch": 8.449955713020373,
        "step": 9540
    },
    {
        "loss": 0.007,
        "grad_norm": 14.752589225769043,
        "learning_rate": 1.5411868910540303e-06,
        "epoch": 8.45881310894597,
        "step": 9550
    },
    {
        "loss": 0.0337,
        "grad_norm": 0.0037270423490554094,
        "learning_rate": 1.5323294951284323e-06,
        "epoch": 8.467670504871569,
        "step": 9560
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.026782764121890068,
        "learning_rate": 1.5234720992028345e-06,
        "epoch": 8.476527900797166,
        "step": 9570
    },
    {
        "loss": 0.0417,
        "grad_norm": 29.45960235595703,
        "learning_rate": 1.5146147032772366e-06,
        "epoch": 8.485385296722763,
        "step": 9580
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0036864476278424263,
        "learning_rate": 1.5057573073516388e-06,
        "epoch": 8.494242692648362,
        "step": 9590
    },
    {
        "loss": 0.0097,
        "grad_norm": 0.012053300626575947,
        "learning_rate": 1.4968999114260406e-06,
        "epoch": 8.503100088573959,
        "step": 9600
    },
    {
        "loss": 0.0004,
        "grad_norm": 5.790648937225342,
        "learning_rate": 1.4880425155004429e-06,
        "epoch": 8.511957484499558,
        "step": 9610
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0021725695114582777,
        "learning_rate": 1.4791851195748451e-06,
        "epoch": 8.520814880425155,
        "step": 9620
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0024902571458369493,
        "learning_rate": 1.4703277236492472e-06,
        "epoch": 8.529672276350754,
        "step": 9630
    },
    {
        "loss": 0.0027,
        "grad_norm": 0.48461151123046875,
        "learning_rate": 1.4614703277236494e-06,
        "epoch": 8.53852967227635,
        "step": 9640
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0163298100233078,
        "learning_rate": 1.4526129317980514e-06,
        "epoch": 8.54738706820195,
        "step": 9650
    },
    {
        "loss": 0.0119,
        "grad_norm": 173.1444091796875,
        "learning_rate": 1.4437555358724537e-06,
        "epoch": 8.556244464127547,
        "step": 9660
    },
    {
        "loss": 0.0326,
        "grad_norm": 0.0029430901631712914,
        "learning_rate": 1.4348981399468557e-06,
        "epoch": 8.565101860053144,
        "step": 9670
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01719563640654087,
        "learning_rate": 1.426040744021258e-06,
        "epoch": 8.573959255978743,
        "step": 9680
    },
    {
        "loss": 0.0085,
        "grad_norm": 0.058161381632089615,
        "learning_rate": 1.4171833480956602e-06,
        "epoch": 8.58281665190434,
        "step": 9690
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.37733134627342224,
        "learning_rate": 1.408325952170062e-06,
        "epoch": 8.591674047829938,
        "step": 9700
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.005535627715289593,
        "learning_rate": 1.3994685562444643e-06,
        "epoch": 8.600531443755536,
        "step": 9710
    },
    {
        "loss": 0.0618,
        "grad_norm": 0.002361765131354332,
        "learning_rate": 1.3906111603188663e-06,
        "epoch": 8.609388839681134,
        "step": 9720
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0031112392898648977,
        "learning_rate": 1.3817537643932685e-06,
        "epoch": 8.618246235606732,
        "step": 9730
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004733136855065823,
        "learning_rate": 1.3728963684676706e-06,
        "epoch": 8.627103631532329,
        "step": 9740
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.014092438854277134,
        "learning_rate": 1.3640389725420728e-06,
        "epoch": 8.635961027457927,
        "step": 9750
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018339647212997079,
        "learning_rate": 1.355181576616475e-06,
        "epoch": 8.644818423383525,
        "step": 9760
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003954397514462471,
        "learning_rate": 1.3463241806908769e-06,
        "epoch": 8.653675819309123,
        "step": 9770
    },
    {
        "loss": 0.0021,
        "grad_norm": 0.0018680483335629106,
        "learning_rate": 1.3374667847652791e-06,
        "epoch": 8.66253321523472,
        "step": 9780
    },
    {
        "loss": 0.0315,
        "grad_norm": 0.0016047294484451413,
        "learning_rate": 1.3286093888396812e-06,
        "epoch": 8.67139061116032,
        "step": 9790
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0016717149410396814,
        "learning_rate": 1.3197519929140834e-06,
        "epoch": 8.680248007085916,
        "step": 9800
    },
    {
        "loss": 0.0361,
        "grad_norm": 0.035912755876779556,
        "learning_rate": 1.3108945969884854e-06,
        "epoch": 8.689105403011515,
        "step": 9810
    },
    {
        "loss": 0.0126,
        "grad_norm": 0.001981835113838315,
        "learning_rate": 1.3020372010628877e-06,
        "epoch": 8.697962798937112,
        "step": 9820
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002042351523414254,
        "learning_rate": 1.29317980513729e-06,
        "epoch": 8.706820194862711,
        "step": 9830
    },
    {
        "loss": 0.0546,
        "grad_norm": 0.0064516677521169186,
        "learning_rate": 1.2843224092116918e-06,
        "epoch": 8.715677590788308,
        "step": 9840
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.0019248725147917867,
        "learning_rate": 1.275465013286094e-06,
        "epoch": 8.724534986713905,
        "step": 9850
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.03832404688000679,
        "learning_rate": 1.266607617360496e-06,
        "epoch": 8.733392382639504,
        "step": 9860
    },
    {
        "loss": 0.003,
        "grad_norm": 72.73468017578125,
        "learning_rate": 1.2577502214348983e-06,
        "epoch": 8.742249778565101,
        "step": 9870
    },
    {
        "loss": 0.0504,
        "grad_norm": 0.0020718248561024666,
        "learning_rate": 1.2488928255093003e-06,
        "epoch": 8.7511071744907,
        "step": 9880
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.15793853998184204,
        "learning_rate": 1.2400354295837025e-06,
        "epoch": 8.759964570416297,
        "step": 9890
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003633685875684023,
        "learning_rate": 1.2311780336581046e-06,
        "epoch": 8.768821966341896,
        "step": 9900
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.00808077584952116,
        "learning_rate": 1.2223206377325066e-06,
        "epoch": 8.777679362267493,
        "step": 9910
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002244663890451193,
        "learning_rate": 1.2134632418069089e-06,
        "epoch": 8.78653675819309,
        "step": 9920
    },
    {
        "loss": 0.0506,
        "grad_norm": 0.0019356311531737447,
        "learning_rate": 1.204605845881311e-06,
        "epoch": 8.79539415411869,
        "step": 9930
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.00917534064501524,
        "learning_rate": 1.1957484499557131e-06,
        "epoch": 8.804251550044286,
        "step": 9940
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.017194172367453575,
        "learning_rate": 1.1868910540301152e-06,
        "epoch": 8.813108945969885,
        "step": 9950
    },
    {
        "loss": 0.0004,
        "grad_norm": 0.004464456811547279,
        "learning_rate": 1.1780336581045174e-06,
        "epoch": 8.821966341895482,
        "step": 9960
    },
    {
        "loss": 0.001,
        "grad_norm": 0.006479098927229643,
        "learning_rate": 1.1691762621789194e-06,
        "epoch": 8.830823737821081,
        "step": 9970
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0023236898705363274,
        "learning_rate": 1.1603188662533215e-06,
        "epoch": 8.839681133746678,
        "step": 9980
    },
    {
        "loss": 0.0007,
        "grad_norm": 0.0032100051175802946,
        "learning_rate": 1.1514614703277237e-06,
        "epoch": 8.848538529672277,
        "step": 9990
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002066223416477442,
        "learning_rate": 1.142604074402126e-06,
        "epoch": 8.857395925597874,
        "step": 10000
    },
    {
        "loss": 0.0398,
        "grad_norm": 0.014574586413800716,
        "learning_rate": 1.133746678476528e-06,
        "epoch": 8.866253321523471,
        "step": 10010
    },
    {
        "loss": 0.0423,
        "grad_norm": 0.0021830671466886997,
        "learning_rate": 1.1248892825509302e-06,
        "epoch": 8.87511071744907,
        "step": 10020
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0022952284198254347,
        "learning_rate": 1.1160318866253323e-06,
        "epoch": 8.883968113374667,
        "step": 10030
    },
    {
        "loss": 0.0292,
        "grad_norm": 0.001668806653469801,
        "learning_rate": 1.1071744906997343e-06,
        "epoch": 8.892825509300266,
        "step": 10040
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001671480480581522,
        "learning_rate": 1.0983170947741365e-06,
        "epoch": 8.901682905225863,
        "step": 10050
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018923991592600942,
        "learning_rate": 1.0894596988485386e-06,
        "epoch": 8.910540301151462,
        "step": 10060
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02160234935581684,
        "learning_rate": 1.0806023029229408e-06,
        "epoch": 8.91939769707706,
        "step": 10070
    },
    {
        "loss": 0.0293,
        "grad_norm": 0.0018860101699829102,
        "learning_rate": 1.0717449069973429e-06,
        "epoch": 8.928255093002658,
        "step": 10080
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.17414355278015137,
        "learning_rate": 1.062887511071745e-06,
        "epoch": 8.937112488928255,
        "step": 10090
    },
    {
        "loss": 0.0609,
        "grad_norm": 0.00335420249029994,
        "learning_rate": 1.0540301151461471e-06,
        "epoch": 8.945969884853852,
        "step": 10100
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0025005957577377558,
        "learning_rate": 1.0451727192205492e-06,
        "epoch": 8.954827280779451,
        "step": 10110
    },
    {
        "loss": 0.0312,
        "grad_norm": 0.009870623238384724,
        "learning_rate": 1.0363153232949514e-06,
        "epoch": 8.963684676705048,
        "step": 10120
    },
    {
        "loss": 0.0148,
        "grad_norm": 0.0032702304888516665,
        "learning_rate": 1.0274579273693534e-06,
        "epoch": 8.972542072630647,
        "step": 10130
    },
    {
        "loss": 0.0623,
        "grad_norm": 0.005773202050477266,
        "learning_rate": 1.0186005314437557e-06,
        "epoch": 8.981399468556244,
        "step": 10140
    },
    {
        "loss": 0.0003,
        "grad_norm": 8.777997016906738,
        "learning_rate": 1.0097431355181577e-06,
        "epoch": 8.990256864481843,
        "step": 10150
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002587835071608424,
        "learning_rate": 1.00088573959256e-06,
        "epoch": 8.99911426040744,
        "step": 10160
    },
    {
        "eval_loss": 0.11226428300142288,
        "eval_accuracy": 0.98694,
        "eval_precision": 0.98245,
        "eval_recall": 0.99159,
        "eval_f1": 0.987,
        "eval_runtime": 195.7027,
        "eval_samples_per_second": 46.152,
        "eval_steps_per_second": 2.887,
        "epoch": 9.0,
        "step": 10161
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.025056658312678337,
        "learning_rate": 9.92028343666962e-07,
        "epoch": 9.007971656333037,
        "step": 10170
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.034441981464624405,
        "learning_rate": 9.83170947741364e-07,
        "epoch": 9.016829052258636,
        "step": 10180
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0025832043029367924,
        "learning_rate": 9.743135518157663e-07,
        "epoch": 9.025686448184233,
        "step": 10190
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002695119706913829,
        "learning_rate": 9.654561558901683e-07,
        "epoch": 9.034543844109832,
        "step": 10200
    },
    {
        "loss": 0.0349,
        "grad_norm": 0.002899851417168975,
        "learning_rate": 9.565987599645705e-07,
        "epoch": 9.043401240035429,
        "step": 10210
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018618028843775392,
        "learning_rate": 9.477413640389727e-07,
        "epoch": 9.052258635961028,
        "step": 10220
    },
    {
        "loss": 0.0263,
        "grad_norm": 225.0641326904297,
        "learning_rate": 9.388839681133747e-07,
        "epoch": 9.061116031886625,
        "step": 10230
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006949900649487972,
        "learning_rate": 9.300265721877769e-07,
        "epoch": 9.069973427812224,
        "step": 10240
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0029411313589662313,
        "learning_rate": 9.21169176262179e-07,
        "epoch": 9.078830823737821,
        "step": 10250
    },
    {
        "loss": 0.0536,
        "grad_norm": 0.0022101833019405603,
        "learning_rate": 9.12311780336581e-07,
        "epoch": 9.087688219663418,
        "step": 10260
    },
    {
        "loss": 0.0236,
        "grad_norm": 0.0020037356298416853,
        "learning_rate": 9.034543844109832e-07,
        "epoch": 9.096545615589017,
        "step": 10270
    },
    {
        "loss": 0.0143,
        "grad_norm": 0.0430704690515995,
        "learning_rate": 8.945969884853854e-07,
        "epoch": 9.105403011514614,
        "step": 10280
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0016171078896149993,
        "learning_rate": 8.857395925597875e-07,
        "epoch": 9.114260407440213,
        "step": 10290
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.002198693808168173,
        "learning_rate": 8.768821966341897e-07,
        "epoch": 9.12311780336581,
        "step": 10300
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019146337872371078,
        "learning_rate": 8.680248007085917e-07,
        "epoch": 9.131975199291409,
        "step": 10310
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0015305269043892622,
        "learning_rate": 8.591674047829939e-07,
        "epoch": 9.140832595217006,
        "step": 10320
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007286589592695236,
        "learning_rate": 8.50310008857396e-07,
        "epoch": 9.149689991142605,
        "step": 10330
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0036722084041684866,
        "learning_rate": 8.41452612931798e-07,
        "epoch": 9.158547387068202,
        "step": 10340
    },
    {
        "loss": 0.037,
        "grad_norm": 0.003875470720231533,
        "learning_rate": 8.325952170062003e-07,
        "epoch": 9.167404782993799,
        "step": 10350
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0032258357387036085,
        "learning_rate": 8.237378210806024e-07,
        "epoch": 9.176262178919398,
        "step": 10360
    },
    {
        "loss": 0.049,
        "grad_norm": 3.4003758430480957,
        "learning_rate": 8.148804251550045e-07,
        "epoch": 9.185119574844995,
        "step": 10370
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.05833670124411583,
        "learning_rate": 8.060230292294066e-07,
        "epoch": 9.193976970770594,
        "step": 10380
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0015133667038753629,
        "learning_rate": 7.971656333038087e-07,
        "epoch": 9.202834366696191,
        "step": 10390
    },
    {
        "loss": 0.0016,
        "grad_norm": 0.0029631266370415688,
        "learning_rate": 7.883082373782109e-07,
        "epoch": 9.21169176262179,
        "step": 10400
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.007622488308697939,
        "learning_rate": 7.794508414526129e-07,
        "epoch": 9.220549158547387,
        "step": 10410
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0026823158841580153,
        "learning_rate": 7.705934455270151e-07,
        "epoch": 9.229406554472986,
        "step": 10420
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0014302438357844949,
        "learning_rate": 7.617360496014173e-07,
        "epoch": 9.238263950398583,
        "step": 10430
    },
    {
        "loss": 0.0087,
        "grad_norm": 2.1733267307281494,
        "learning_rate": 7.528786536758194e-07,
        "epoch": 9.24712134632418,
        "step": 10440
    },
    {
        "loss": 0.0005,
        "grad_norm": 0.0017987224273383617,
        "learning_rate": 7.440212577502214e-07,
        "epoch": 9.255978742249779,
        "step": 10450
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001351318322122097,
        "learning_rate": 7.351638618246236e-07,
        "epoch": 9.264836138175376,
        "step": 10460
    },
    {
        "loss": 0.0722,
        "grad_norm": 0.0019859338644891977,
        "learning_rate": 7.263064658990257e-07,
        "epoch": 9.273693534100975,
        "step": 10470
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.02567703276872635,
        "learning_rate": 7.174490699734279e-07,
        "epoch": 9.282550930026572,
        "step": 10480
    },
    {
        "loss": 0.0401,
        "grad_norm": 4.9531941413879395,
        "learning_rate": 7.085916740478301e-07,
        "epoch": 9.29140832595217,
        "step": 10490
    },
    {
        "loss": 0.0095,
        "grad_norm": 190.28330993652344,
        "learning_rate": 6.997342781222321e-07,
        "epoch": 9.300265721877768,
        "step": 10500
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019041490741074085,
        "learning_rate": 6.908768821966343e-07,
        "epoch": 9.309123117803367,
        "step": 10510
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019065669039264321,
        "learning_rate": 6.820194862710364e-07,
        "epoch": 9.317980513728964,
        "step": 10520
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0016653082566335797,
        "learning_rate": 6.731620903454384e-07,
        "epoch": 9.32683790965456,
        "step": 10530
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002493941690772772,
        "learning_rate": 6.643046944198406e-07,
        "epoch": 9.33569530558016,
        "step": 10540
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0015091722598299384,
        "learning_rate": 6.554472984942427e-07,
        "epoch": 9.344552701505757,
        "step": 10550
    },
    {
        "loss": 0.009,
        "grad_norm": 0.0016365089686587453,
        "learning_rate": 6.46589902568645e-07,
        "epoch": 9.353410097431356,
        "step": 10560
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.012276911176741123,
        "learning_rate": 6.37732506643047e-07,
        "epoch": 9.362267493356953,
        "step": 10570
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.011786186136305332,
        "learning_rate": 6.288751107174491e-07,
        "epoch": 9.371124889282552,
        "step": 10580
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0015605419175699353,
        "learning_rate": 6.200177147918513e-07,
        "epoch": 9.379982285208149,
        "step": 10590
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0014870286686345935,
        "learning_rate": 6.111603188662533e-07,
        "epoch": 9.388839681133746,
        "step": 10600
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001649978687055409,
        "learning_rate": 6.023029229406556e-07,
        "epoch": 9.397697077059345,
        "step": 10610
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0013397966977208853,
        "learning_rate": 5.934455270150576e-07,
        "epoch": 9.406554472984942,
        "step": 10620
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0015893743839114904,
        "learning_rate": 5.845881310894597e-07,
        "epoch": 9.41541186891054,
        "step": 10630
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019872882403433323,
        "learning_rate": 5.757307351638619e-07,
        "epoch": 9.424269264836138,
        "step": 10640
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.018416984006762505,
        "learning_rate": 5.66873339238264e-07,
        "epoch": 9.433126660761737,
        "step": 10650
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001835517236031592,
        "learning_rate": 5.580159433126661e-07,
        "epoch": 9.441984056687334,
        "step": 10660
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0014365306124091148,
        "learning_rate": 5.491585473870683e-07,
        "epoch": 9.450841452612933,
        "step": 10670
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0032735327258706093,
        "learning_rate": 5.403011514614704e-07,
        "epoch": 9.45969884853853,
        "step": 10680
    },
    {
        "loss": 0.0003,
        "grad_norm": 7.880948066711426,
        "learning_rate": 5.314437555358726e-07,
        "epoch": 9.468556244464127,
        "step": 10690
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006859919987618923,
        "learning_rate": 5.225863596102746e-07,
        "epoch": 9.477413640389726,
        "step": 10700
    },
    {
        "loss": 0.0031,
        "grad_norm": 0.0018743121763691306,
        "learning_rate": 5.137289636846767e-07,
        "epoch": 9.486271036315323,
        "step": 10710
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.38459673523902893,
        "learning_rate": 5.048715677590789e-07,
        "epoch": 9.495128432240922,
        "step": 10720
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0018109525553882122,
        "learning_rate": 4.96014171833481e-07,
        "epoch": 9.503985828166519,
        "step": 10730
    },
    {
        "loss": 0.0195,
        "grad_norm": 0.013945664279162884,
        "learning_rate": 4.871567759078831e-07,
        "epoch": 9.512843224092117,
        "step": 10740
    },
    {
        "loss": 0.0006,
        "grad_norm": 0.0080484664067626,
        "learning_rate": 4.782993799822853e-07,
        "epoch": 9.521700620017715,
        "step": 10750
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001451608375646174,
        "learning_rate": 4.6944198405668736e-07,
        "epoch": 9.530558015943313,
        "step": 10760
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0085075031965971,
        "learning_rate": 4.605845881310895e-07,
        "epoch": 9.53941541186891,
        "step": 10770
    },
    {
        "loss": 0.0062,
        "grad_norm": 0.003541467245668173,
        "learning_rate": 4.517271922054916e-07,
        "epoch": 9.548272807794508,
        "step": 10780
    },
    {
        "loss": 0.085,
        "grad_norm": 0.008237778209149837,
        "learning_rate": 4.428697962798938e-07,
        "epoch": 9.557130203720106,
        "step": 10790
    },
    {
        "loss": 0.0021,
        "grad_norm": 98.40746307373047,
        "learning_rate": 4.3401240035429586e-07,
        "epoch": 9.565987599645704,
        "step": 10800
    },
    {
        "loss": 0.0452,
        "grad_norm": 0.0013948132982477546,
        "learning_rate": 4.25155004428698e-07,
        "epoch": 9.574844995571302,
        "step": 10810
    },
    {
        "loss": 0.0003,
        "grad_norm": 0.0029063450638204813,
        "learning_rate": 4.1629760850310014e-07,
        "epoch": 9.5837023914969,
        "step": 10820
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0047261668369174,
        "learning_rate": 4.074402125775023e-07,
        "epoch": 9.592559787422498,
        "step": 10830
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002104370156303048,
        "learning_rate": 3.9858281665190436e-07,
        "epoch": 9.601417183348095,
        "step": 10840
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0013595817144960165,
        "learning_rate": 3.8972542072630645e-07,
        "epoch": 9.610274579273694,
        "step": 10850
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001782608567737043,
        "learning_rate": 3.8086802480070864e-07,
        "epoch": 9.619131975199291,
        "step": 10860
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.002942939754575491,
        "learning_rate": 3.720106288751107e-07,
        "epoch": 9.627989371124889,
        "step": 10870
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0024447068572044373,
        "learning_rate": 3.6315323294951286e-07,
        "epoch": 9.636846767050487,
        "step": 10880
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.0019783114548772573,
        "learning_rate": 3.5429583702391505e-07,
        "epoch": 9.645704162976084,
        "step": 10890
    },
    {
        "loss": 0.0001,
        "grad_norm": 1.1662018299102783,
        "learning_rate": 3.4543844109831714e-07,
        "epoch": 9.654561558901683,
        "step": 10900
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0015107806539162993,
        "learning_rate": 3.365810451727192e-07,
        "epoch": 9.66341895482728,
        "step": 10910
    },
    {
        "loss": 0.0073,
        "grad_norm": 0.15021109580993652,
        "learning_rate": 3.2772364924712136e-07,
        "epoch": 9.67227635075288,
        "step": 10920
    },
    {
        "loss": 0.0003,
        "grad_norm": 5.608591079711914,
        "learning_rate": 3.188662533215235e-07,
        "epoch": 9.681133746678476,
        "step": 10930
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0025627780705690384,
        "learning_rate": 3.1000885739592564e-07,
        "epoch": 9.689991142604075,
        "step": 10940
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.01663176342844963,
        "learning_rate": 3.011514614703278e-07,
        "epoch": 9.698848538529672,
        "step": 10950
    },
    {
        "loss": 0.0538,
        "grad_norm": 0.001638149144127965,
        "learning_rate": 2.9229406554472986e-07,
        "epoch": 9.70770593445527,
        "step": 10960
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0015097057912498713,
        "learning_rate": 2.83436669619132e-07,
        "epoch": 9.716563330380868,
        "step": 10970
    },
    {
        "loss": 0.0098,
        "grad_norm": 0.0017369602574035525,
        "learning_rate": 2.7457927369353414e-07,
        "epoch": 9.725420726306465,
        "step": 10980
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0027040201239287853,
        "learning_rate": 2.657218777679363e-07,
        "epoch": 9.734278122232064,
        "step": 10990
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0015163683565333486,
        "learning_rate": 2.5686448184233836e-07,
        "epoch": 9.743135518157661,
        "step": 11000
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.02322208695113659,
        "learning_rate": 2.480070859167405e-07,
        "epoch": 9.75199291408326,
        "step": 11010
    },
    {
        "loss": 0.0027,
        "grad_norm": 0.0020978066604584455,
        "learning_rate": 2.3914968999114264e-07,
        "epoch": 9.760850310008857,
        "step": 11020
    },
    {
        "loss": 0.0924,
        "grad_norm": 0.001479961327277124,
        "learning_rate": 2.3029229406554475e-07,
        "epoch": 9.769707705934454,
        "step": 11030
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.006121823564171791,
        "learning_rate": 2.214348981399469e-07,
        "epoch": 9.778565101860053,
        "step": 11040
    },
    {
        "loss": 0.0133,
        "grad_norm": 0.0014773285947740078,
        "learning_rate": 2.12577502214349e-07,
        "epoch": 9.78742249778565,
        "step": 11050
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003611747408285737,
        "learning_rate": 2.0372010628875114e-07,
        "epoch": 9.79627989371125,
        "step": 11060
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.011887090280652046,
        "learning_rate": 1.9486271036315322e-07,
        "epoch": 9.805137289636846,
        "step": 11070
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.004166779574006796,
        "learning_rate": 1.8600531443755536e-07,
        "epoch": 9.813994685562445,
        "step": 11080
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001405723625794053,
        "learning_rate": 1.7714791851195753e-07,
        "epoch": 9.822852081488042,
        "step": 11090
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.003148396499454975,
        "learning_rate": 1.682905225863596e-07,
        "epoch": 9.831709477413641,
        "step": 11100
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0037264067213982344,
        "learning_rate": 1.5943312666076175e-07,
        "epoch": 9.840566873339238,
        "step": 11110
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0012678520288318396,
        "learning_rate": 1.505757307351639e-07,
        "epoch": 9.849424269264837,
        "step": 11120
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0019786835182458162,
        "learning_rate": 1.41718334809566e-07,
        "epoch": 9.858281665190434,
        "step": 11130
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0025279480032622814,
        "learning_rate": 1.3286093888396814e-07,
        "epoch": 9.867139061116031,
        "step": 11140
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0016756104305386543,
        "learning_rate": 1.2400354295837025e-07,
        "epoch": 9.87599645704163,
        "step": 11150
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.012849077582359314,
        "learning_rate": 1.1514614703277237e-07,
        "epoch": 9.884853852967227,
        "step": 11160
    },
    {
        "loss": 0.0111,
        "grad_norm": 0.0018415325321257114,
        "learning_rate": 1.062887511071745e-07,
        "epoch": 9.893711248892826,
        "step": 11170
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001461897511035204,
        "learning_rate": 9.743135518157661e-08,
        "epoch": 9.902568644818423,
        "step": 11180
    },
    {
        "loss": 0.004,
        "grad_norm": 0.0015154307475313544,
        "learning_rate": 8.857395925597876e-08,
        "epoch": 9.911426040744022,
        "step": 11190
    },
    {
        "loss": 0.1083,
        "grad_norm": 0.006779214832931757,
        "learning_rate": 7.971656333038087e-08,
        "epoch": 9.920283436669619,
        "step": 11200
    },
    {
        "loss": 0.0558,
        "grad_norm": 0.0013744545867666602,
        "learning_rate": 7.0859167404783e-08,
        "epoch": 9.929140832595216,
        "step": 11210
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0016732790973037481,
        "learning_rate": 6.200177147918512e-08,
        "epoch": 9.937998228520815,
        "step": 11220
    },
    {
        "loss": 0.0013,
        "grad_norm": 0.0014402110828086734,
        "learning_rate": 5.314437555358725e-08,
        "epoch": 9.946855624446412,
        "step": 11230
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.0013204256538301706,
        "learning_rate": 4.428697962798938e-08,
        "epoch": 9.955713020372011,
        "step": 11240
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.009145787917077541,
        "learning_rate": 3.54295837023915e-08,
        "epoch": 9.964570416297608,
        "step": 11250
    },
    {
        "loss": 0.0002,
        "grad_norm": 0.0018132480327039957,
        "learning_rate": 2.6572187776793625e-08,
        "epoch": 9.973427812223207,
        "step": 11260
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.001304621808230877,
        "learning_rate": 1.771479185119575e-08,
        "epoch": 9.982285208148804,
        "step": 11270
    },
    {
        "loss": 0.0121,
        "grad_norm": 0.0018887619953602552,
        "learning_rate": 8.857395925597875e-09,
        "epoch": 9.991142604074403,
        "step": 11280
    },
    {
        "loss": 0.0001,
        "grad_norm": 0.005334016401320696,
        "learning_rate": 0.0,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "eval_loss": 0.11223093420267105,
        "eval_accuracy": 0.9876,
        "eval_precision": 0.98566,
        "eval_recall": 0.98959,
        "eval_f1": 0.98762,
        "eval_runtime": 208.5206,
        "eval_samples_per_second": 43.315,
        "eval_steps_per_second": 2.71,
        "epoch": 10.0,
        "step": 11290
    },
    {
        "train_runtime": 12162.6414,
        "train_samples_per_second": 14.851,
        "train_steps_per_second": 0.928,
        "total_flos": 2.37628749648384e+16,
        "train_loss": 0.1299601311727049,
        "epoch": 10.0,
        "step": 11290
    }
]