[
    {
        "loss": 0.6334,
        "grad_norm": 4.603395938873291,
        "learning_rate": 2.997232472324723e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.4961,
        "grad_norm": 6.424986362457275,
        "learning_rate": 2.9944649446494467e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.5361,
        "grad_norm": 6.051291465759277,
        "learning_rate": 2.9916974169741697e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.5034,
        "grad_norm": 6.020823001861572,
        "learning_rate": 2.9889298892988933e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.4667,
        "grad_norm": 2.228109121322632,
        "learning_rate": 2.9861623616236163e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.4756,
        "grad_norm": 11.426815032958984,
        "learning_rate": 2.9833948339483396e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.4814,
        "grad_norm": 1.2193667888641357,
        "learning_rate": 2.980627306273063e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.512,
        "grad_norm": 3.534852981567383,
        "learning_rate": 2.977859778597786e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.55,
        "grad_norm": 5.541342258453369,
        "learning_rate": 2.975092250922509e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.5059,
        "grad_norm": 2.5038914680480957,
        "learning_rate": 2.9723247232472325e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.3835,
        "grad_norm": 4.976895332336426,
        "learning_rate": 2.9695571955719558e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4424,
        "grad_norm": 3.3854992389678955,
        "learning_rate": 2.966789667896679e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4354,
        "grad_norm": 3.263096809387207,
        "learning_rate": 2.9640221402214024e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4392,
        "grad_norm": 4.522972583770752,
        "learning_rate": 2.9612546125461254e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4914,
        "grad_norm": 5.32689094543457,
        "learning_rate": 2.958487084870849e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.4262,
        "grad_norm": 7.024860382080078,
        "learning_rate": 2.955719557195572e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.4092,
        "grad_norm": 2.5704073905944824,
        "learning_rate": 2.9529520295202953e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.4862,
        "grad_norm": 3.384610176086426,
        "learning_rate": 2.9501845018450186e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4855,
        "grad_norm": 3.9044177532196045,
        "learning_rate": 2.9474169741697416e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4119,
        "grad_norm": 2.5658586025238037,
        "learning_rate": 2.9446494464944652e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.4107,
        "grad_norm": 1.6405354738235474,
        "learning_rate": 2.9418819188191882e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.386,
        "grad_norm": 3.984734296798706,
        "learning_rate": 2.9391143911439118e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.3819,
        "grad_norm": 3.254178285598755,
        "learning_rate": 2.9363468634686348e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.3928,
        "grad_norm": 2.4492876529693604,
        "learning_rate": 2.9335793357933578e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.4902,
        "grad_norm": 2.5450994968414307,
        "learning_rate": 2.9308118081180814e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4664,
        "grad_norm": 4.704545497894287,
        "learning_rate": 2.9280442804428044e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4466,
        "grad_norm": 3.4348113536834717,
        "learning_rate": 2.9252767527675277e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.48520994186401367,
        "eval_accuracy": 0.78044,
        "eval_precision": 0.71659,
        "eval_recall": 0.91557,
        "eval_f1": 0.80395,
        "eval_runtime": 18.154,
        "eval_samples_per_second": 59.711,
        "eval_steps_per_second": 3.746,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.511,
        "grad_norm": 2.3885550498962402,
        "learning_rate": 2.922509225092251e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4094,
        "grad_norm": 3.9160373210906982,
        "learning_rate": 2.9197416974169743e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.3821,
        "grad_norm": 2.528278112411499,
        "learning_rate": 2.9169741697416976e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.5671,
        "grad_norm": 1.8931317329406738,
        "learning_rate": 2.9142066420664206e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.3775,
        "grad_norm": 2.0740911960601807,
        "learning_rate": 2.911439114391144e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4639,
        "grad_norm": 1.7365885972976685,
        "learning_rate": 2.9086715867158672e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.4163,
        "grad_norm": 3.5736243724823,
        "learning_rate": 2.9059040590405905e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4005,
        "grad_norm": 3.3612935543060303,
        "learning_rate": 2.9031365313653138e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4558,
        "grad_norm": 3.530740737915039,
        "learning_rate": 2.900369003690037e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.4193,
        "grad_norm": 3.7855186462402344,
        "learning_rate": 2.89760147601476e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.5229,
        "grad_norm": 2.2787485122680664,
        "learning_rate": 2.8948339483394837e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4506,
        "grad_norm": 3.00805401802063,
        "learning_rate": 2.8920664206642067e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.4189,
        "grad_norm": 3.226081371307373,
        "learning_rate": 2.8892988929889297e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.5307,
        "grad_norm": 3.1750361919403076,
        "learning_rate": 2.8865313653136533e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3734,
        "grad_norm": 2.7867679595947266,
        "learning_rate": 2.8837638376383763e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.3337,
        "grad_norm": 3.7812414169311523,
        "learning_rate": 2.8809963099631e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.3852,
        "grad_norm": 2.9493017196655273,
        "learning_rate": 2.878228782287823e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.4594,
        "grad_norm": 6.170845031738281,
        "learning_rate": 2.8754612546125462e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.3942,
        "grad_norm": 2.0881032943725586,
        "learning_rate": 2.8726937269372695e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.3879,
        "grad_norm": 1.6575729846954346,
        "learning_rate": 2.8699261992619925e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.3957,
        "grad_norm": 1.8103736639022827,
        "learning_rate": 2.867158671586716e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.377,
        "grad_norm": 5.8135600090026855,
        "learning_rate": 2.864391143911439e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.3936,
        "grad_norm": 1.7882763147354126,
        "learning_rate": 2.8616236162361624e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.3324,
        "grad_norm": 2.2260613441467285,
        "learning_rate": 2.8588560885608857e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.4268,
        "grad_norm": 1.526055097579956,
        "learning_rate": 2.856088560885609e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.4177,
        "grad_norm": 7.888336181640625,
        "learning_rate": 2.8533210332103323e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.4398,
        "grad_norm": 1.5676109790802002,
        "learning_rate": 2.8505535055350553e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.44967177510261536,
        "eval_accuracy": 0.77768,
        "eval_precision": 0.70391,
        "eval_recall": 0.94559,
        "eval_f1": 0.80705,
        "eval_runtime": 18.1491,
        "eval_samples_per_second": 59.727,
        "eval_steps_per_second": 3.747,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.395,
        "grad_norm": 2.1172587871551514,
        "learning_rate": 2.8477859778597786e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4,
        "grad_norm": 4.183783531188965,
        "learning_rate": 2.845018450184502e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.346,
        "grad_norm": 2.458726167678833,
        "learning_rate": 2.8422509225092252e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.5188,
        "grad_norm": 2.116588830947876,
        "learning_rate": 2.8394833948339482e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.3449,
        "grad_norm": 1.3975889682769775,
        "learning_rate": 2.8367158671586718e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.3894,
        "grad_norm": 1.8516548871994019,
        "learning_rate": 2.8339483394833948e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.4129,
        "grad_norm": 1.8368054628372192,
        "learning_rate": 2.831180811808118e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4605,
        "grad_norm": 2.2829232215881348,
        "learning_rate": 2.8284132841328414e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.4655,
        "grad_norm": 3.609482526779175,
        "learning_rate": 2.8256457564575644e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3453,
        "grad_norm": 3.270350694656372,
        "learning_rate": 2.822878228782288e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.5623,
        "grad_norm": 5.509735107421875,
        "learning_rate": 2.820110701107011e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.3379,
        "grad_norm": 2.338559150695801,
        "learning_rate": 2.8173431734317346e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3609,
        "grad_norm": 2.7437453269958496,
        "learning_rate": 2.8145756457564576e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.4351,
        "grad_norm": 2.335421562194824,
        "learning_rate": 2.811808118081181e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.3949,
        "grad_norm": 9.575324058532715,
        "learning_rate": 2.8090405904059042e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.3273,
        "grad_norm": 3.115246534347534,
        "learning_rate": 2.8062730627306272e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3385,
        "grad_norm": 5.4015069007873535,
        "learning_rate": 2.803505535055351e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.4097,
        "grad_norm": 2.7196578979492188,
        "learning_rate": 2.8007380073800738e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.4356,
        "grad_norm": 1.8445667028427124,
        "learning_rate": 2.797970479704797e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4066,
        "grad_norm": 1.7121913433074951,
        "learning_rate": 2.7952029520295204e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3507,
        "grad_norm": 5.260792255401611,
        "learning_rate": 2.7924354243542437e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4017,
        "grad_norm": 3.242661952972412,
        "learning_rate": 2.7896678966789667e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4384,
        "grad_norm": 1.257570743560791,
        "learning_rate": 2.78690036900369e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.4411,
        "grad_norm": 6.74806547164917,
        "learning_rate": 2.7841328413284133e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.4255,
        "grad_norm": 5.015280723571777,
        "learning_rate": 2.7813653136531366e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3951,
        "grad_norm": 3.063030481338501,
        "learning_rate": 2.77859778597786e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.3815,
        "grad_norm": 1.7935466766357422,
        "learning_rate": 2.775830258302583e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.45960772037506104,
        "eval_accuracy": 0.81181,
        "eval_precision": 0.7728,
        "eval_recall": 0.8743,
        "eval_f1": 0.82042,
        "eval_runtime": 18.1448,
        "eval_samples_per_second": 59.741,
        "eval_steps_per_second": 3.748,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3617,
        "grad_norm": 2.232381820678711,
        "learning_rate": 2.7730627306273065e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3268,
        "grad_norm": 1.9461350440979004,
        "learning_rate": 2.7702952029520295e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.3861,
        "grad_norm": 2.8196916580200195,
        "learning_rate": 2.7675276752767528e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.3863,
        "grad_norm": 5.208291053771973,
        "learning_rate": 2.764760147601476e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.404,
        "grad_norm": 2.3225014209747314,
        "learning_rate": 2.761992619926199e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.3879,
        "grad_norm": 3.077798366546631,
        "learning_rate": 2.7592250922509227e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3759,
        "grad_norm": 2.7375006675720215,
        "learning_rate": 2.7564575645756457e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.2969,
        "grad_norm": 3.8032307624816895,
        "learning_rate": 2.753690036900369e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.4215,
        "grad_norm": 3.810161828994751,
        "learning_rate": 2.7509225092250923e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.372,
        "grad_norm": 5.830765247344971,
        "learning_rate": 2.7481549815498156e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.4468,
        "grad_norm": 4.831562042236328,
        "learning_rate": 2.745387453874539e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.3006,
        "grad_norm": 1.4935863018035889,
        "learning_rate": 2.742619926199262e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.3948,
        "grad_norm": 2.735933303833008,
        "learning_rate": 2.7398523985239852e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.4095,
        "grad_norm": 2.1872751712799072,
        "learning_rate": 2.7370848708487085e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.3636,
        "grad_norm": 1.4014790058135986,
        "learning_rate": 2.734317343173432e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.3317,
        "grad_norm": 3.4273269176483154,
        "learning_rate": 2.731549815498155e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.394,
        "grad_norm": 4.1577935218811035,
        "learning_rate": 2.7287822878228784e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.3537,
        "grad_norm": 6.873368740081787,
        "learning_rate": 2.7260147601476014e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.3991,
        "grad_norm": 3.964355230331421,
        "learning_rate": 2.7232472324723247e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.3576,
        "grad_norm": 2.599184513092041,
        "learning_rate": 2.720479704797048e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.3297,
        "grad_norm": 1.4659749269485474,
        "learning_rate": 2.7177121771217713e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.4195,
        "grad_norm": 4.388431549072266,
        "learning_rate": 2.7149446494464946e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3525,
        "grad_norm": 3.064655065536499,
        "learning_rate": 2.7121771217712176e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.4852,
        "grad_norm": 3.0900943279266357,
        "learning_rate": 2.7094095940959413e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.3876,
        "grad_norm": 2.6527578830718994,
        "learning_rate": 2.7066420664206642e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.4342,
        "grad_norm": 2.160764217376709,
        "learning_rate": 2.7038745387453872e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.3334,
        "grad_norm": 1.698264479637146,
        "learning_rate": 2.701107011070111e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.43326035141944885,
        "eval_accuracy": 0.81919,
        "eval_precision": 0.76704,
        "eval_recall": 0.90807,
        "eval_f1": 0.83162,
        "eval_runtime": 18.1266,
        "eval_samples_per_second": 59.802,
        "eval_steps_per_second": 3.751,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3068,
        "grad_norm": 1.2936969995498657,
        "learning_rate": 2.6983394833948338e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.4199,
        "grad_norm": 1.0494575500488281,
        "learning_rate": 2.6955719557195575e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.3296,
        "grad_norm": 1.6129319667816162,
        "learning_rate": 2.6928044280442804e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3168,
        "grad_norm": 8.248995780944824,
        "learning_rate": 2.6900369003690037e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3976,
        "grad_norm": 1.3466371297836304,
        "learning_rate": 2.687269372693727e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3699,
        "grad_norm": 2.133195400238037,
        "learning_rate": 2.6845018450184504e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3266,
        "grad_norm": 2.0273776054382324,
        "learning_rate": 2.6817343173431737e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.4685,
        "grad_norm": 21.460044860839844,
        "learning_rate": 2.6789667896678966e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.2935,
        "grad_norm": 1.9972976446151733,
        "learning_rate": 2.67619926199262e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.3861,
        "grad_norm": 2.8152518272399902,
        "learning_rate": 2.6734317343173432e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.4227,
        "grad_norm": 3.6590373516082764,
        "learning_rate": 2.6706642066420666e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.4132,
        "grad_norm": 3.2135910987854004,
        "learning_rate": 2.6678966789667895e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.327,
        "grad_norm": 1.6442978382110596,
        "learning_rate": 2.665129151291513e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3362,
        "grad_norm": 3.1071665287017822,
        "learning_rate": 2.662361623616236e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3846,
        "grad_norm": 27.1339168548584,
        "learning_rate": 2.6595940959409594e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3764,
        "grad_norm": 2.1870851516723633,
        "learning_rate": 2.6568265682656828e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3982,
        "grad_norm": 1.1414551734924316,
        "learning_rate": 2.6540590405904057e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.3823,
        "grad_norm": 4.106746673583984,
        "learning_rate": 2.6512915129151294e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3592,
        "grad_norm": 2.5404675006866455,
        "learning_rate": 2.6485239852398523e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.3262,
        "grad_norm": 3.360051393508911,
        "learning_rate": 2.645756457564576e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.4298,
        "grad_norm": 4.664225101470947,
        "learning_rate": 2.642988929889299e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.3553,
        "grad_norm": 7.334924697875977,
        "learning_rate": 2.640221402214022e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.4064,
        "grad_norm": 3.097332000732422,
        "learning_rate": 2.6374538745387456e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.2715,
        "grad_norm": 1.967963457107544,
        "learning_rate": 2.6346863468634685e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.4237,
        "grad_norm": 2.4471685886383057,
        "learning_rate": 2.6319188191881922e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.411,
        "grad_norm": 7.63946533203125,
        "learning_rate": 2.629151291512915e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.378,
        "grad_norm": 1.8703320026397705,
        "learning_rate": 2.6263837638376385e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.42703601717948914,
        "eval_accuracy": 0.82103,
        "eval_precision": 0.75799,
        "eval_recall": 0.93433,
        "eval_f1": 0.83697,
        "eval_runtime": 18.1372,
        "eval_samples_per_second": 59.767,
        "eval_steps_per_second": 3.749,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.2889,
        "grad_norm": 1.4279507398605347,
        "learning_rate": 2.6236162361623618e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.3881,
        "grad_norm": 2.2285635471343994,
        "learning_rate": 2.620848708487085e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.3483,
        "grad_norm": 1.7560555934906006,
        "learning_rate": 2.618081180811808e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.362,
        "grad_norm": 9.470952987670898,
        "learning_rate": 2.6153136531365313e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.3988,
        "grad_norm": 4.573786735534668,
        "learning_rate": 2.6125461254612547e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.3378,
        "grad_norm": 8.586440086364746,
        "learning_rate": 2.609778597785978e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.3453,
        "grad_norm": 3.055187225341797,
        "learning_rate": 2.6070110701107013e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.3305,
        "grad_norm": 2.5594658851623535,
        "learning_rate": 2.6042435424354242e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.4177,
        "grad_norm": 10.241483688354492,
        "learning_rate": 2.601476014760148e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.3077,
        "grad_norm": 1.9006965160369873,
        "learning_rate": 2.598708487084871e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.2722,
        "grad_norm": 2.3746328353881836,
        "learning_rate": 2.595940959409594e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.4014,
        "grad_norm": 39.21760177612305,
        "learning_rate": 2.5931734317343175e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.3691,
        "grad_norm": 2.29282808303833,
        "learning_rate": 2.5904059040590404e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.3655,
        "grad_norm": 1.094687581062317,
        "learning_rate": 2.587638376383764e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.4065,
        "grad_norm": 5.999943256378174,
        "learning_rate": 2.584870848708487e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.3545,
        "grad_norm": 2.748988151550293,
        "learning_rate": 2.5821033210332107e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.3484,
        "grad_norm": 4.961526870727539,
        "learning_rate": 2.5793357933579337e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.3236,
        "grad_norm": 5.399117946624756,
        "learning_rate": 2.5765682656826566e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.3342,
        "grad_norm": 2.9792468547821045,
        "learning_rate": 2.5738007380073803e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.3689,
        "grad_norm": 3.772812843322754,
        "learning_rate": 2.5710332103321032e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.43,
        "grad_norm": 8.996833801269531,
        "learning_rate": 2.5682656826568266e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.3226,
        "grad_norm": 1.5344839096069336,
        "learning_rate": 2.56549815498155e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.3378,
        "grad_norm": 1.0830453634262085,
        "learning_rate": 2.5627306273062732e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.3981,
        "grad_norm": 2.2187366485595703,
        "learning_rate": 2.5599630996309965e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.3373,
        "grad_norm": 2.9786972999572754,
        "learning_rate": 2.5571955719557198e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.3827,
        "grad_norm": 1.8170067071914673,
        "learning_rate": 2.5544280442804428e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.3992,
        "grad_norm": 2.514974594116211,
        "learning_rate": 2.551660516605166e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.4280987083911896,
        "eval_accuracy": 0.83303,
        "eval_precision": 0.78115,
        "eval_recall": 0.91745,
        "eval_f1": 0.84383,
        "eval_runtime": 18.1237,
        "eval_samples_per_second": 59.811,
        "eval_steps_per_second": 3.752,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.3523,
        "grad_norm": 5.585716724395752,
        "learning_rate": 2.5488929889298894e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3019,
        "grad_norm": 11.460514068603516,
        "learning_rate": 2.5461254612546127e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.3699,
        "grad_norm": 3.431809902191162,
        "learning_rate": 2.543357933579336e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.4484,
        "grad_norm": 6.447801113128662,
        "learning_rate": 2.540590405904059e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.4332,
        "grad_norm": 3.0390007495880127,
        "learning_rate": 2.5378228782287826e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.3798,
        "grad_norm": 6.785181522369385,
        "learning_rate": 2.5350553505535056e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.327,
        "grad_norm": 2.6782240867614746,
        "learning_rate": 2.5322878228782285e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.3621,
        "grad_norm": 41.72359848022461,
        "learning_rate": 2.5295202952029522e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3631,
        "grad_norm": 5.556619167327881,
        "learning_rate": 2.526752767527675e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.3296,
        "grad_norm": 2.6907641887664795,
        "learning_rate": 2.5239852398523988e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.3107,
        "grad_norm": 1.8746269941329956,
        "learning_rate": 2.5212177121771218e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.356,
        "grad_norm": 1.9306191205978394,
        "learning_rate": 2.518450184501845e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.3573,
        "grad_norm": 7.613655090332031,
        "learning_rate": 2.5156826568265684e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.2982,
        "grad_norm": 1.1272188425064087,
        "learning_rate": 2.5129151291512914e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3954,
        "grad_norm": 17.27637481689453,
        "learning_rate": 2.510147601476015e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.2849,
        "grad_norm": 1.9966212511062622,
        "learning_rate": 2.507380073800738e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.4534,
        "grad_norm": 2.147904634475708,
        "learning_rate": 2.5046125461254613e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.3106,
        "grad_norm": 2.7833924293518066,
        "learning_rate": 2.5018450184501846e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.2678,
        "grad_norm": 28.29544448852539,
        "learning_rate": 2.499077490774908e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.297,
        "grad_norm": 4.321900367736816,
        "learning_rate": 2.4963099630996312e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3283,
        "grad_norm": 2.4769585132598877,
        "learning_rate": 2.4935424354243545e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3736,
        "grad_norm": 7.344787120819092,
        "learning_rate": 2.4907749077490775e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.4087,
        "grad_norm": 2.752760648727417,
        "learning_rate": 2.4880073800738008e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.3264,
        "grad_norm": 2.934634208679199,
        "learning_rate": 2.485239852398524e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.2741,
        "grad_norm": 0.8923032283782959,
        "learning_rate": 2.482472324723247e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.4,
        "grad_norm": 0.835483193397522,
        "learning_rate": 2.4797047970479707e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3983,
        "grad_norm": 1.0532056093215942,
        "learning_rate": 2.4769372693726937e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.4515569508075714,
        "eval_accuracy": 0.83026,
        "eval_precision": 0.79229,
        "eval_recall": 0.88743,
        "eval_f1": 0.83717,
        "eval_runtime": 18.0969,
        "eval_samples_per_second": 59.9,
        "eval_steps_per_second": 3.758,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.3348,
        "grad_norm": 1.8428411483764648,
        "learning_rate": 2.4741697416974173e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.289,
        "grad_norm": 3.1559066772460938,
        "learning_rate": 2.4714022140221403e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3867,
        "grad_norm": 0.9412944912910461,
        "learning_rate": 2.4686346863468633e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.3043,
        "grad_norm": 1.808297038078308,
        "learning_rate": 2.465867158671587e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.2484,
        "grad_norm": 1.7681926488876343,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3495,
        "grad_norm": 5.001570224761963,
        "learning_rate": 2.4603321033210335e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.4325,
        "grad_norm": 1.1367017030715942,
        "learning_rate": 2.4575645756457565e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.3872,
        "grad_norm": 3.04083251953125,
        "learning_rate": 2.4547970479704798e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.4082,
        "grad_norm": 3.8168601989746094,
        "learning_rate": 2.452029520295203e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.3364,
        "grad_norm": 3.3381760120391846,
        "learning_rate": 2.449261992619926e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.283,
        "grad_norm": 1.494541049003601,
        "learning_rate": 2.4464944649446494e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3981,
        "grad_norm": 4.60196590423584,
        "learning_rate": 2.4437269372693727e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.3492,
        "grad_norm": 3.0811686515808105,
        "learning_rate": 2.440959409594096e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3101,
        "grad_norm": 8.432035446166992,
        "learning_rate": 2.4381918819188193e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.3608,
        "grad_norm": 2.10056471824646,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.3422,
        "grad_norm": 2.7175214290618896,
        "learning_rate": 2.4326568265682656e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.3474,
        "grad_norm": 3.201129198074341,
        "learning_rate": 2.4298892988929892e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.2496,
        "grad_norm": 5.781951904296875,
        "learning_rate": 2.4271217712177122e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.4588,
        "grad_norm": 8.751106262207031,
        "learning_rate": 2.4243542435424355e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.2834,
        "grad_norm": 10.575698852539062,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.2287,
        "grad_norm": 1.314820408821106,
        "learning_rate": 2.4188191881918818e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.4832,
        "grad_norm": 17.149738311767578,
        "learning_rate": 2.4160516605166054e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.482,
        "grad_norm": 1.8341635465621948,
        "learning_rate": 2.4132841328413284e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.2921,
        "grad_norm": 1.5317212343215942,
        "learning_rate": 2.410516605166052e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.4011,
        "grad_norm": 10.065690994262695,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.4333,
        "grad_norm": 13.367444038391113,
        "learning_rate": 2.404981549815498e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.3316,
        "grad_norm": 1.4734632968902588,
        "learning_rate": 2.4022140221402216e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.46504923701286316,
        "eval_accuracy": 0.8155,
        "eval_precision": 0.75113,
        "eval_recall": 0.93433,
        "eval_f1": 0.83278,
        "eval_runtime": 18.1023,
        "eval_samples_per_second": 59.882,
        "eval_steps_per_second": 3.756,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.239,
        "grad_norm": 2.034576892852783,
        "learning_rate": 2.3994464944649446e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3643,
        "grad_norm": 1.3892079591751099,
        "learning_rate": 2.396678966789668e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.2522,
        "grad_norm": 8.609505653381348,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.3135,
        "grad_norm": 0.9753598570823669,
        "learning_rate": 2.3911439114391145e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.37,
        "grad_norm": 2.925671100616455,
        "learning_rate": 2.3883763837638378e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.3579,
        "grad_norm": 2.144237756729126,
        "learning_rate": 2.3856088560885608e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.3774,
        "grad_norm": 28.446949005126953,
        "learning_rate": 2.382841328413284e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.3456,
        "grad_norm": 1.5895510911941528,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.3706,
        "grad_norm": 3.5679073333740234,
        "learning_rate": 2.3773062730627307e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.388,
        "grad_norm": 9.539168357849121,
        "learning_rate": 2.374538745387454e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.3438,
        "grad_norm": 6.08390998840332,
        "learning_rate": 2.3717712177121773e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.2668,
        "grad_norm": 6.335052013397217,
        "learning_rate": 2.3690036900369003e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.3668,
        "grad_norm": 7.0029215812683105,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.2936,
        "grad_norm": 2.3039793968200684,
        "learning_rate": 2.363468634686347e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.3896,
        "grad_norm": 1.483417272567749,
        "learning_rate": 2.3607011070110702e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.3806,
        "grad_norm": 1.8554319143295288,
        "learning_rate": 2.3579335793357935e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.2905,
        "grad_norm": 2.3106577396392822,
        "learning_rate": 2.3551660516605165e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3025,
        "grad_norm": 2.690034866333008,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.3028,
        "grad_norm": 31.635831832885742,
        "learning_rate": 2.349630996309963e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.4225,
        "grad_norm": 6.9073333740234375,
        "learning_rate": 2.3468634686346864e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3066,
        "grad_norm": 6.580255031585693,
        "learning_rate": 2.3440959409594097e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.3559,
        "grad_norm": 2.048922538757324,
        "learning_rate": 2.3413284132841327e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.2818,
        "grad_norm": 1.2401455640792847,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.3531,
        "grad_norm": 4.9370951652526855,
        "learning_rate": 2.3357933579335793e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.3806,
        "grad_norm": 2.622251510620117,
        "learning_rate": 2.3330258302583026e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.4355,
        "grad_norm": 1.8925070762634277,
        "learning_rate": 2.330258302583026e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3036,
        "grad_norm": 2.6506903171539307,
        "learning_rate": 2.3274907749077492e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.4687425494194031,
        "eval_accuracy": 0.8238,
        "eval_precision": 0.8155,
        "eval_recall": 0.82927,
        "eval_f1": 0.82233,
        "eval_runtime": 18.0981,
        "eval_samples_per_second": 59.896,
        "eval_steps_per_second": 3.757,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.2911,
        "grad_norm": 52.52566909790039,
        "learning_rate": 2.3247232472324725e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.2773,
        "grad_norm": 6.835925102233887,
        "learning_rate": 2.3219557195571955e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3554,
        "grad_norm": 8.78110408782959,
        "learning_rate": 2.3191881918819188e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.3534,
        "grad_norm": 4.493319034576416,
        "learning_rate": 2.316420664206642e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.3857,
        "grad_norm": 7.982949733734131,
        "learning_rate": 2.3136531365313654e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.3219,
        "grad_norm": 2.6319692134857178,
        "learning_rate": 2.3108856088560884e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3375,
        "grad_norm": 4.907958507537842,
        "learning_rate": 2.308118081180812e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.2939,
        "grad_norm": 1.5810788869857788,
        "learning_rate": 2.305350553505535e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.2895,
        "grad_norm": 1.3340901136398315,
        "learning_rate": 2.3025830258302583e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.2795,
        "grad_norm": 2.845627784729004,
        "learning_rate": 2.2998154981549816e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.3271,
        "grad_norm": 5.000430583953857,
        "learning_rate": 2.2970479704797046e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.3605,
        "grad_norm": 6.279491901397705,
        "learning_rate": 2.2942804428044282e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.3259,
        "grad_norm": 2.044965982437134,
        "learning_rate": 2.2915129151291512e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.3738,
        "grad_norm": 5.483470916748047,
        "learning_rate": 2.288745387453875e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.2184,
        "grad_norm": 1.5417768955230713,
        "learning_rate": 2.2859778597785978e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.3831,
        "grad_norm": 4.660181522369385,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.3619,
        "grad_norm": 3.618759870529175,
        "learning_rate": 2.2804428044280444e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.4383,
        "grad_norm": 2.45706844329834,
        "learning_rate": 2.2776752767527674e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.3476,
        "grad_norm": 4.7478437423706055,
        "learning_rate": 2.274907749077491e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.3354,
        "grad_norm": 1.248524785041809,
        "learning_rate": 2.272140221402214e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.3212,
        "grad_norm": 7.56988000869751,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.3904,
        "grad_norm": 4.046489238739014,
        "learning_rate": 2.2666051660516606e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3263,
        "grad_norm": 0.957910418510437,
        "learning_rate": 2.263837638376384e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.3549,
        "grad_norm": 3.6652724742889404,
        "learning_rate": 2.261070110701107e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.2681,
        "grad_norm": 1.5244094133377075,
        "learning_rate": 2.2583025830258302e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.3214,
        "grad_norm": 2.060185194015503,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.2723,
        "grad_norm": 1.2594932317733765,
        "learning_rate": 2.252767527675277e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.3339,
        "grad_norm": 3.7096524238586426,
        "learning_rate": 2.25e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.4915456175804138,
        "eval_accuracy": 0.8321,
        "eval_precision": 0.78261,
        "eval_recall": 0.91182,
        "eval_f1": 0.84229,
        "eval_runtime": 18.069,
        "eval_samples_per_second": 59.992,
        "eval_steps_per_second": 3.763,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.2914,
        "grad_norm": 1.8222289085388184,
        "learning_rate": 2.247232472324723e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.3677,
        "grad_norm": 4.093193531036377,
        "learning_rate": 2.2444649446494468e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.3783,
        "grad_norm": 2.6643199920654297,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.3463,
        "grad_norm": 71.79064178466797,
        "learning_rate": 2.238929889298893e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3438,
        "grad_norm": 3.800732135772705,
        "learning_rate": 2.2361623616236163e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.2441,
        "grad_norm": 1.2046939134597778,
        "learning_rate": 2.2333948339483393e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.3572,
        "grad_norm": 5.163764953613281,
        "learning_rate": 2.230627306273063e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.3661,
        "grad_norm": 3.825256586074829,
        "learning_rate": 2.227859778597786e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.3728,
        "grad_norm": 1.7107473611831665,
        "learning_rate": 2.2250922509225092e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.4538,
        "grad_norm": 1.0399384498596191,
        "learning_rate": 2.2223247232472325e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.2849,
        "grad_norm": 2.799989700317383,
        "learning_rate": 2.219557195571956e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.2194,
        "grad_norm": 1.4114629030227661,
        "learning_rate": 2.216789667896679e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.355,
        "grad_norm": 3.775585651397705,
        "learning_rate": 2.214022140221402e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.3073,
        "grad_norm": 7.28484582901001,
        "learning_rate": 2.2112546125461254e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.2783,
        "grad_norm": 1.9446512460708618,
        "learning_rate": 2.2084870848708487e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.2166,
        "grad_norm": 1.3758894205093384,
        "learning_rate": 2.205719557195572e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3063,
        "grad_norm": 0.7341647744178772,
        "learning_rate": 2.2029520295202954e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.2941,
        "grad_norm": 3.2629952430725098,
        "learning_rate": 2.2001845018450187e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2631,
        "grad_norm": 3.0153961181640625,
        "learning_rate": 2.1974169741697416e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.3874,
        "grad_norm": 0.8383445143699646,
        "learning_rate": 2.194649446494465e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.3232,
        "grad_norm": 4.595358371734619,
        "learning_rate": 2.1918819188191882e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.2911,
        "grad_norm": 2.4065420627593994,
        "learning_rate": 2.1891143911439116e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.3088,
        "grad_norm": 3.2038803100585938,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.316,
        "grad_norm": 2.375502109527588,
        "learning_rate": 2.1835793357933578e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.3507,
        "grad_norm": 5.622992038726807,
        "learning_rate": 2.1808118081180815e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.2543,
        "grad_norm": 4.439639091491699,
        "learning_rate": 2.1780442804428044e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.2959,
        "grad_norm": 2.723395347595215,
        "learning_rate": 2.1752767527675274e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.4783097207546234,
        "eval_accuracy": 0.84041,
        "eval_precision": 0.80201,
        "eval_recall": 0.89681,
        "eval_f1": 0.84677,
        "eval_runtime": 18.1268,
        "eval_samples_per_second": 59.801,
        "eval_steps_per_second": 3.751,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.2197,
        "grad_norm": 6.361802577972412,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.4055,
        "grad_norm": 2.6337203979492188,
        "learning_rate": 2.169741697416974e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.2022,
        "grad_norm": 69.71141815185547,
        "learning_rate": 2.1669741697416977e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.2796,
        "grad_norm": 1.5162454843521118,
        "learning_rate": 2.1642066420664206e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.3294,
        "grad_norm": 2.9452919960021973,
        "learning_rate": 2.161439114391144e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.3343,
        "grad_norm": 7.834103107452393,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.3414,
        "grad_norm": 12.580826759338379,
        "learning_rate": 2.1559040590405906e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.3276,
        "grad_norm": 2.1737780570983887,
        "learning_rate": 2.153136531365314e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.3487,
        "grad_norm": 1.7398632764816284,
        "learning_rate": 2.150369003690037e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.3058,
        "grad_norm": 2.087932825088501,
        "learning_rate": 2.14760147601476e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.3057,
        "grad_norm": 1.7126517295837402,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.384,
        "grad_norm": 7.038553237915039,
        "learning_rate": 2.1420664206642068e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.3152,
        "grad_norm": 1.2520642280578613,
        "learning_rate": 2.1392988929889297e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.2903,
        "grad_norm": 2.639406442642212,
        "learning_rate": 2.1365313653136534e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.3151,
        "grad_norm": 2.273134231567383,
        "learning_rate": 2.1337638376383763e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.2576,
        "grad_norm": 0.9143356680870056,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.258,
        "grad_norm": 1.4235591888427734,
        "learning_rate": 2.128228782287823e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.2799,
        "grad_norm": 6.70489501953125,
        "learning_rate": 2.125461254612546e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.4097,
        "grad_norm": 18.16750717163086,
        "learning_rate": 2.1226937269372696e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.3682,
        "grad_norm": 1.7893847227096558,
        "learning_rate": 2.1199261992619925e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2673,
        "grad_norm": 1.71040678024292,
        "learning_rate": 2.1171586715867162e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.2845,
        "grad_norm": 2.0466904640197754,
        "learning_rate": 2.114391143911439e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.2678,
        "grad_norm": 2.4638333320617676,
        "learning_rate": 2.111623616236162e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.3362,
        "grad_norm": 2.269031047821045,
        "learning_rate": 2.1088560885608858e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.2716,
        "grad_norm": 4.539711952209473,
        "learning_rate": 2.1060885608856087e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2773,
        "grad_norm": 3.645289659500122,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.2668,
        "grad_norm": 11.365670204162598,
        "learning_rate": 2.1005535055350554e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.5231918096542358,
        "eval_accuracy": 0.83395,
        "eval_precision": 0.79564,
        "eval_recall": 0.89118,
        "eval_f1": 0.84071,
        "eval_runtime": 18.1122,
        "eval_samples_per_second": 59.849,
        "eval_steps_per_second": 3.754,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.4318,
        "grad_norm": 45.987449645996094,
        "learning_rate": 2.0977859778597787e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.349,
        "grad_norm": 2.270336389541626,
        "learning_rate": 2.095018450184502e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.2324,
        "grad_norm": 2.7492172718048096,
        "learning_rate": 2.0922509225092253e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.2728,
        "grad_norm": 3.677398443222046,
        "learning_rate": 2.0894833948339482e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.3142,
        "grad_norm": 3.1621193885803223,
        "learning_rate": 2.0867158671586716e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.1889,
        "grad_norm": 1.8213403224945068,
        "learning_rate": 2.083948339483395e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.4029,
        "grad_norm": 50.01347732543945,
        "learning_rate": 2.0811808118081182e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.3259,
        "grad_norm": 3.470700740814209,
        "learning_rate": 2.0784132841328415e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.2189,
        "grad_norm": 1.8890266418457031,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.2828,
        "grad_norm": 84.26971435546875,
        "learning_rate": 2.072878228782288e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.3316,
        "grad_norm": 1.0580928325653076,
        "learning_rate": 2.070110701107011e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.3173,
        "grad_norm": 14.836493492126465,
        "learning_rate": 2.0673431734317344e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.3442,
        "grad_norm": 3.853464126586914,
        "learning_rate": 2.0645756457564577e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.3197,
        "grad_norm": 2.857398509979248,
        "learning_rate": 2.0618081180811806e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.2901,
        "grad_norm": 1.946774959564209,
        "learning_rate": 2.0590405904059043e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.2467,
        "grad_norm": 1.4328958988189697,
        "learning_rate": 2.0562730627306273e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.2779,
        "grad_norm": 6.614320278167725,
        "learning_rate": 2.053505535055351e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.2065,
        "grad_norm": 1.9531424045562744,
        "learning_rate": 2.050738007380074e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.2609,
        "grad_norm": 10.662337303161621,
        "learning_rate": 2.047970479704797e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.3828,
        "grad_norm": 1.3641647100448608,
        "learning_rate": 2.0452029520295205e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.3674,
        "grad_norm": 5.762742042541504,
        "learning_rate": 2.0424354243542435e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.3668,
        "grad_norm": 1.7523388862609863,
        "learning_rate": 2.0396678966789668e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.2734,
        "grad_norm": 1.7182196378707886,
        "learning_rate": 2.03690036900369e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.3137,
        "grad_norm": 8.430771827697754,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.2835,
        "grad_norm": 2.857468843460083,
        "learning_rate": 2.0313653136531367e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.393,
        "grad_norm": 8.81481647491455,
        "learning_rate": 2.02859778597786e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.2192,
        "grad_norm": 1.6840672492980957,
        "learning_rate": 2.025830258302583e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.45590367913246155,
        "eval_accuracy": 0.84317,
        "eval_precision": 0.79803,
        "eval_recall": 0.91182,
        "eval_f1": 0.85114,
        "eval_runtime": 18.1456,
        "eval_samples_per_second": 59.739,
        "eval_steps_per_second": 3.747,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.3139,
        "grad_norm": 4.268077850341797,
        "learning_rate": 2.0230627306273063e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.2776,
        "grad_norm": 21.416566848754883,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.2958,
        "grad_norm": 1.3734869956970215,
        "learning_rate": 2.017527675276753e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.2523,
        "grad_norm": 1.7440751791000366,
        "learning_rate": 2.0147601476014762e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.2498,
        "grad_norm": 2.2719714641571045,
        "learning_rate": 2.011992619926199e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.3798,
        "grad_norm": 1.4806382656097412,
        "learning_rate": 2.0092250922509228e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.389,
        "grad_norm": 3.290595531463623,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.2763,
        "grad_norm": 1.9049324989318848,
        "learning_rate": 2.0036900369003687e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.2022,
        "grad_norm": 16.183269500732422,
        "learning_rate": 2.0009225092250924e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.3804,
        "grad_norm": 1.399848222732544,
        "learning_rate": 1.9981549815498154e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.2698,
        "grad_norm": 1.6320903301239014,
        "learning_rate": 1.995387453874539e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.256,
        "grad_norm": 2.910168170928955,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.2639,
        "grad_norm": 0.9151840209960938,
        "learning_rate": 1.9898523985239853e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.3047,
        "grad_norm": 5.089085578918457,
        "learning_rate": 1.9870848708487086e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.2499,
        "grad_norm": 23.582199096679688,
        "learning_rate": 1.9843173431734316e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2715,
        "grad_norm": 3.4051358699798584,
        "learning_rate": 1.9815498154981552e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.278,
        "grad_norm": 1.7222604751586914,
        "learning_rate": 1.9787822878228782e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.4134,
        "grad_norm": 0.6095721125602722,
        "learning_rate": 1.9760147601476015e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.2729,
        "grad_norm": 1.806312084197998,
        "learning_rate": 1.9732472324723248e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.3074,
        "grad_norm": 4.228689670562744,
        "learning_rate": 1.970479704797048e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.3674,
        "grad_norm": 2.2953996658325195,
        "learning_rate": 1.9677121771217714e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.2881,
        "grad_norm": 3.819849967956543,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.2154,
        "grad_norm": 0.8664684891700745,
        "learning_rate": 1.9621771217712177e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.2796,
        "grad_norm": 8.200955390930176,
        "learning_rate": 1.959409594095941e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.3535,
        "grad_norm": 3.8364884853363037,
        "learning_rate": 1.9566420664206643e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.4108,
        "grad_norm": 7.322937965393066,
        "learning_rate": 1.9538745387453873e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.4068,
        "grad_norm": 3.898798704147339,
        "learning_rate": 1.951107011070111e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.43752115964889526,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.80769,
        "eval_recall": 0.90619,
        "eval_f1": 0.85411,
        "eval_runtime": 18.1035,
        "eval_samples_per_second": 59.878,
        "eval_steps_per_second": 3.756,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.2401,
        "grad_norm": 1.4490089416503906,
        "learning_rate": 1.948339483394834e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.2374,
        "grad_norm": 9.478190422058105,
        "learning_rate": 1.9455719557195575e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.3093,
        "grad_norm": 3.166429281234741,
        "learning_rate": 1.9428044280442805e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.3351,
        "grad_norm": 4.181705474853516,
        "learning_rate": 1.9400369003690035e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.2289,
        "grad_norm": 1.2411798238754272,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.3209,
        "grad_norm": 8.84814453125,
        "learning_rate": 1.93450184501845e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.3211,
        "grad_norm": 2.85546612739563,
        "learning_rate": 1.9317343173431737e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.2696,
        "grad_norm": 17.011226654052734,
        "learning_rate": 1.9289667896678967e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2789,
        "grad_norm": 11.512746810913086,
        "learning_rate": 1.92619926199262e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.3175,
        "grad_norm": 3.0809600353240967,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.3971,
        "grad_norm": 11.02750015258789,
        "learning_rate": 1.9206642066420663e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.261,
        "grad_norm": 3.4711577892303467,
        "learning_rate": 1.9178966789667896e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.3346,
        "grad_norm": 5.4108567237854,
        "learning_rate": 1.915129151291513e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.3386,
        "grad_norm": 2.6588456630706787,
        "learning_rate": 1.9123616236162362e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.3046,
        "grad_norm": 2.477924346923828,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.255,
        "grad_norm": 4.675650119781494,
        "learning_rate": 1.9068265682656828e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.2866,
        "grad_norm": 9.638419151306152,
        "learning_rate": 1.9040590405904058e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.253,
        "grad_norm": 2.4116768836975098,
        "learning_rate": 1.901291512915129e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.2724,
        "grad_norm": 3.130387783050537,
        "learning_rate": 1.8985239852398524e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.2491,
        "grad_norm": 6.051774024963379,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.3365,
        "grad_norm": 2.3463025093078613,
        "learning_rate": 1.892988929889299e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.2632,
        "grad_norm": 3.0227198600769043,
        "learning_rate": 1.890221402214022e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.2497,
        "grad_norm": 2.423171281814575,
        "learning_rate": 1.8874538745387456e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.3089,
        "grad_norm": 1.8101272583007812,
        "learning_rate": 1.8846863468634686e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.2527,
        "grad_norm": 2.339749813079834,
        "learning_rate": 1.8819188191881922e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.3276,
        "grad_norm": 9.74313735961914,
        "learning_rate": 1.8791512915129152e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.2634,
        "grad_norm": 6.992303371429443,
        "learning_rate": 1.8763837638376382e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.5071849226951599,
        "eval_accuracy": 0.8155,
        "eval_precision": 0.81836,
        "eval_recall": 0.803,
        "eval_f1": 0.81061,
        "eval_runtime": 18.117,
        "eval_samples_per_second": 59.833,
        "eval_steps_per_second": 3.753,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.2895,
        "grad_norm": 13.903974533081055,
        "learning_rate": 1.8736162361623618e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.1947,
        "grad_norm": 1.0450552701950073,
        "learning_rate": 1.8708487084870848e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.372,
        "grad_norm": 1.080974817276001,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.2403,
        "grad_norm": 3.6344587802886963,
        "learning_rate": 1.8653136531365314e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.2738,
        "grad_norm": 12.801621437072754,
        "learning_rate": 1.8625461254612547e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.3954,
        "grad_norm": 3.3483855724334717,
        "learning_rate": 1.859778597785978e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.3762,
        "grad_norm": 5.26422119140625,
        "learning_rate": 1.857011070110701e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.2672,
        "grad_norm": 2.651384115219116,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.2813,
        "grad_norm": 0.9429416060447693,
        "learning_rate": 1.8514760147601476e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.2884,
        "grad_norm": 2.5408527851104736,
        "learning_rate": 1.848708487084871e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.3288,
        "grad_norm": 3.012155294418335,
        "learning_rate": 1.8459409594095942e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.2777,
        "grad_norm": 1.3134021759033203,
        "learning_rate": 1.8431734317343175e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.2054,
        "grad_norm": 3.559270143508911,
        "learning_rate": 1.8404059040590405e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.2685,
        "grad_norm": 1.0399978160858154,
        "learning_rate": 1.8376383763837638e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.3729,
        "grad_norm": 2.6866440773010254,
        "learning_rate": 1.834870848708487e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.3422,
        "grad_norm": 1.1849212646484375,
        "learning_rate": 1.8321033210332104e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.3524,
        "grad_norm": 3.090698003768921,
        "learning_rate": 1.8293357933579337e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2709,
        "grad_norm": 1.9369193315505981,
        "learning_rate": 1.8265682656826567e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.2559,
        "grad_norm": 9.981063842773438,
        "learning_rate": 1.8238007380073803e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.2088,
        "grad_norm": 2.246692657470703,
        "learning_rate": 1.8210332103321033e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.2801,
        "grad_norm": 1.7236366271972656,
        "learning_rate": 1.8182656826568266e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.3183,
        "grad_norm": 0.8463888168334961,
        "learning_rate": 1.81549815498155e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.3339,
        "grad_norm": 2.010188579559326,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.2742,
        "grad_norm": 2.459193706512451,
        "learning_rate": 1.8099630996309965e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.2242,
        "grad_norm": 0.9894220232963562,
        "learning_rate": 1.8071955719557195e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.3169,
        "grad_norm": 3.4986793994903564,
        "learning_rate": 1.8044280442804428e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.2356,
        "grad_norm": 3.7049591541290283,
        "learning_rate": 1.801660516605166e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.46308258175849915,
        "eval_accuracy": 0.84317,
        "eval_precision": 0.80301,
        "eval_recall": 0.90244,
        "eval_f1": 0.84982,
        "eval_runtime": 18.1665,
        "eval_samples_per_second": 59.67,
        "eval_steps_per_second": 3.743,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.2953,
        "grad_norm": 2.649869441986084,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.2961,
        "grad_norm": 1.534203052520752,
        "learning_rate": 1.7961254612546127e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.1821,
        "grad_norm": 2.895494222640991,
        "learning_rate": 1.7933579335793357e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.2346,
        "grad_norm": 0.8793692588806152,
        "learning_rate": 1.790590405904059e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.4281,
        "grad_norm": 35.72407531738281,
        "learning_rate": 1.7878228782287823e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.2696,
        "grad_norm": 1.744784951210022,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.2375,
        "grad_norm": 1.8722301721572876,
        "learning_rate": 1.7822878228782286e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.2806,
        "grad_norm": 1.9352158308029175,
        "learning_rate": 1.7795202952029522e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.2453,
        "grad_norm": 1.485059142112732,
        "learning_rate": 1.7767527675276752e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.3378,
        "grad_norm": 12.07529067993164,
        "learning_rate": 1.7739852398523985e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.2547,
        "grad_norm": 2.3576831817626953,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.29,
        "grad_norm": 1.2534130811691284,
        "learning_rate": 1.7684501845018448e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.2825,
        "grad_norm": 2.016613245010376,
        "learning_rate": 1.7656826568265684e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.3468,
        "grad_norm": 1.1836223602294922,
        "learning_rate": 1.7629151291512914e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.1596,
        "grad_norm": 1.855090856552124,
        "learning_rate": 1.760147601476015e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.2302,
        "grad_norm": 1.4120436906814575,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.2391,
        "grad_norm": 1.4517574310302734,
        "learning_rate": 1.7546125461254613e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.2514,
        "grad_norm": 9.105637550354004,
        "learning_rate": 1.7518450184501846e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.3581,
        "grad_norm": 1.9683611392974854,
        "learning_rate": 1.7490774907749076e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.3141,
        "grad_norm": 1.4171934127807617,
        "learning_rate": 1.7463099630996313e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.183,
        "grad_norm": 0.872695803642273,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.3204,
        "grad_norm": 13.499940872192383,
        "learning_rate": 1.7407749077490775e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.3192,
        "grad_norm": 3.461498737335205,
        "learning_rate": 1.738007380073801e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.2541,
        "grad_norm": 2.0261082649230957,
        "learning_rate": 1.735239852398524e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.3374,
        "grad_norm": 1.3783421516418457,
        "learning_rate": 1.732472324723247e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.2694,
        "grad_norm": 1.1688919067382812,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.2391,
        "grad_norm": 3.2944893836975098,
        "learning_rate": 1.7269372693726937e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.4958520829677582,
        "eval_accuracy": 0.84502,
        "eval_precision": 0.80066,
        "eval_recall": 0.91182,
        "eval_f1": 0.85263,
        "eval_runtime": 18.1078,
        "eval_samples_per_second": 59.864,
        "eval_steps_per_second": 3.755,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.2511,
        "grad_norm": 1.9537665843963623,
        "learning_rate": 1.724169741697417e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.2625,
        "grad_norm": 2.414438247680664,
        "learning_rate": 1.7214022140221404e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.2118,
        "grad_norm": 4.223170757293701,
        "learning_rate": 1.7186346863468633e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.2085,
        "grad_norm": 1.6835167407989502,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.2387,
        "grad_norm": 1.2588731050491333,
        "learning_rate": 1.71309963099631e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.3187,
        "grad_norm": 2.6445651054382324,
        "learning_rate": 1.7103321033210332e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.2951,
        "grad_norm": 3.5580997467041016,
        "learning_rate": 1.7075645756457566e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.223,
        "grad_norm": 1.7655763626098633,
        "learning_rate": 1.7047970479704795e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2503,
        "grad_norm": 8.944793701171875,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.3615,
        "grad_norm": 14.243118286132812,
        "learning_rate": 1.699261992619926e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.2827,
        "grad_norm": 2.8853025436401367,
        "learning_rate": 1.6964944649446494e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.1823,
        "grad_norm": 2.217954158782959,
        "learning_rate": 1.6937269372693727e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.4084,
        "grad_norm": 1.4967912435531616,
        "learning_rate": 1.690959409594096e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.2747,
        "grad_norm": 5.826542854309082,
        "learning_rate": 1.6881918819188194e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.2472,
        "grad_norm": 3.117429256439209,
        "learning_rate": 1.6854243542435423e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.1932,
        "grad_norm": 4.738637447357178,
        "learning_rate": 1.6826568265682656e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.3381,
        "grad_norm": 4.482412338256836,
        "learning_rate": 1.679889298892989e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.3029,
        "grad_norm": 7.407731533050537,
        "learning_rate": 1.6771217712177123e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.3402,
        "grad_norm": 1.1082130670547485,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.3712,
        "grad_norm": 1.995156168937683,
        "learning_rate": 1.671586715867159e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.3654,
        "grad_norm": 0.8607483506202698,
        "learning_rate": 1.668819188191882e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.2647,
        "grad_norm": 1.2672038078308105,
        "learning_rate": 1.666051660516605e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.2496,
        "grad_norm": 2.8817641735076904,
        "learning_rate": 1.6632841328413285e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.1992,
        "grad_norm": 1.3595396280288696,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.2765,
        "grad_norm": 3.235714912414551,
        "learning_rate": 1.657749077490775e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.2383,
        "grad_norm": 1.544147253036499,
        "learning_rate": 1.654981549815498e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.292,
        "grad_norm": 3.0072309970855713,
        "learning_rate": 1.6522140221402217e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.44072315096855164,
        "eval_accuracy": 0.84225,
        "eval_precision": 0.82321,
        "eval_recall": 0.86492,
        "eval_f1": 0.84355,
        "eval_runtime": 18.093,
        "eval_samples_per_second": 59.913,
        "eval_steps_per_second": 3.758,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.2823,
        "grad_norm": 1.9625065326690674,
        "learning_rate": 1.6494464944649447e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.2529,
        "grad_norm": 1.9257041215896606,
        "learning_rate": 1.6466789667896676e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.3822,
        "grad_norm": 3.81416392326355,
        "learning_rate": 1.6439114391143913e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.2517,
        "grad_norm": 1.2936606407165527,
        "learning_rate": 1.6411439114391142e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2613,
        "grad_norm": 1.3107192516326904,
        "learning_rate": 1.638376383763838e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.2374,
        "grad_norm": 3.6134753227233887,
        "learning_rate": 1.635608856088561e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.3062,
        "grad_norm": 2.9396259784698486,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2465,
        "grad_norm": 4.907322883605957,
        "learning_rate": 1.6300738007380075e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.2815,
        "grad_norm": 1.9614546298980713,
        "learning_rate": 1.6273062730627308e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.2471,
        "grad_norm": 10.448339462280273,
        "learning_rate": 1.624538745387454e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.4179,
        "grad_norm": 4.5612473487854,
        "learning_rate": 1.621771217712177e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.2678,
        "grad_norm": 2.038332223892212,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.2376,
        "grad_norm": 22.989229202270508,
        "learning_rate": 1.6162361623616237e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.283,
        "grad_norm": 1.1624797582626343,
        "learning_rate": 1.613468634686347e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.2566,
        "grad_norm": 7.402616500854492,
        "learning_rate": 1.6107011070110703e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.2442,
        "grad_norm": 1.0845874547958374,
        "learning_rate": 1.6079335793357936e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.3056,
        "grad_norm": 3.4930996894836426,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.2373,
        "grad_norm": 7.28184175491333,
        "learning_rate": 1.60239852398524e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.1709,
        "grad_norm": 1.4008151292800903,
        "learning_rate": 1.5996309963099632e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.302,
        "grad_norm": 0.9638477563858032,
        "learning_rate": 1.596863468634686e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.2202,
        "grad_norm": 48.391510009765625,
        "learning_rate": 1.5940959409594098e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.2323,
        "grad_norm": 3.2630081176757812,
        "learning_rate": 1.5913284132841328e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.387,
        "grad_norm": 4.172947406768799,
        "learning_rate": 1.5885608856088564e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.256,
        "grad_norm": 1.7479028701782227,
        "learning_rate": 1.5857933579335794e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.2686,
        "grad_norm": 4.010439395904541,
        "learning_rate": 1.5830258302583023e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2585,
        "grad_norm": 2.968564748764038,
        "learning_rate": 1.580258302583026e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.256,
        "grad_norm": 12.597965240478516,
        "learning_rate": 1.577490774907749e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.4648749530315399,
        "eval_accuracy": 0.84502,
        "eval_precision": 0.80165,
        "eval_recall": 0.90994,
        "eval_f1": 0.85237,
        "eval_runtime": 18.1232,
        "eval_samples_per_second": 59.813,
        "eval_steps_per_second": 3.752,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.2442,
        "grad_norm": 2.175553560256958,
        "learning_rate": 1.5747232472324726e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.1648,
        "grad_norm": 31.0533447265625,
        "learning_rate": 1.5719557195571956e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.2821,
        "grad_norm": 1.0309395790100098,
        "learning_rate": 1.569188191881919e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.2386,
        "grad_norm": 7.471340179443359,
        "learning_rate": 1.5664206642066422e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.2204,
        "grad_norm": 1.8694347143173218,
        "learning_rate": 1.5636531365313655e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.2422,
        "grad_norm": 3.328120708465576,
        "learning_rate": 1.5608856088560885e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2519,
        "grad_norm": 2.8505024909973145,
        "learning_rate": 1.5581180811808118e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.2057,
        "grad_norm": 1.0917075872421265,
        "learning_rate": 1.555350553505535e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.316,
        "grad_norm": 7.5186543464660645,
        "learning_rate": 1.5525830258302584e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.2134,
        "grad_norm": 1.1786876916885376,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.2773,
        "grad_norm": 1.7384998798370361,
        "learning_rate": 1.5470479704797047e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.2798,
        "grad_norm": 2.800534248352051,
        "learning_rate": 1.5442804428044283e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.2122,
        "grad_norm": 4.783281326293945,
        "learning_rate": 1.5415129151291513e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2939,
        "grad_norm": 1.7198429107666016,
        "learning_rate": 1.5387453874538746e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.1959,
        "grad_norm": 2.042757034301758,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.3125,
        "grad_norm": 3.3088457584381104,
        "learning_rate": 1.533210332103321e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.2642,
        "grad_norm": 13.168417930603027,
        "learning_rate": 1.5304428044280445e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.3339,
        "grad_norm": 7.000926971435547,
        "learning_rate": 1.5276752767527675e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.2247,
        "grad_norm": 1.2811965942382812,
        "learning_rate": 1.524907749077491e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.2193,
        "grad_norm": 3.228423833847046,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.2111,
        "grad_norm": 1.5640400648117065,
        "learning_rate": 1.5193726937269372e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.296,
        "grad_norm": 2.466010570526123,
        "learning_rate": 1.5166051660516607e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.244,
        "grad_norm": 1.102858304977417,
        "learning_rate": 1.5138376383763838e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.4431,
        "grad_norm": 1.8353899717330933,
        "learning_rate": 1.511070110701107e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.2096,
        "grad_norm": 1.6155600547790527,
        "learning_rate": 1.5083025830258303e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.3362,
        "grad_norm": 5.140673637390137,
        "learning_rate": 1.5055350553505534e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.3563,
        "grad_norm": 4.830178737640381,
        "learning_rate": 1.5027675276752769e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.2311,
        "grad_norm": 3.369832754135132,
        "learning_rate": 1.5e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.49252623319625854,
        "eval_accuracy": 0.84502,
        "eval_precision": 0.80985,
        "eval_recall": 0.89493,
        "eval_f1": 0.85027,
        "eval_runtime": 18.09,
        "eval_samples_per_second": 59.923,
        "eval_steps_per_second": 3.759,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.2164,
        "grad_norm": 6.414169788360596,
        "learning_rate": 1.4972324723247233e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.2462,
        "grad_norm": 3.4416191577911377,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2947,
        "grad_norm": 3.5409767627716064,
        "learning_rate": 1.4916974169741698e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.1541,
        "grad_norm": 7.631800174713135,
        "learning_rate": 1.488929889298893e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2285,
        "grad_norm": 5.478541374206543,
        "learning_rate": 1.4861623616236162e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.2871,
        "grad_norm": 1.4402779340744019,
        "learning_rate": 1.4833948339483395e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.189,
        "grad_norm": 4.355867385864258,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.2254,
        "grad_norm": 2.6876015663146973,
        "learning_rate": 1.477859778597786e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.162,
        "grad_norm": 4.849133491516113,
        "learning_rate": 1.4750922509225093e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.3234,
        "grad_norm": 3.073007822036743,
        "learning_rate": 1.4723247232472326e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.2897,
        "grad_norm": 7.765168190002441,
        "learning_rate": 1.4695571955719559e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.2446,
        "grad_norm": 2.523921012878418,
        "learning_rate": 1.4667896678966789e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.1993,
        "grad_norm": 1.2631630897521973,
        "learning_rate": 1.4640221402214022e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.1897,
        "grad_norm": 14.701974868774414,
        "learning_rate": 1.4612546125461255e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.222,
        "grad_norm": 7.269181251525879,
        "learning_rate": 1.4584870848708488e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.1899,
        "grad_norm": 1.6710072755813599,
        "learning_rate": 1.455719557195572e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.2465,
        "grad_norm": 2.789720296859741,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.2318,
        "grad_norm": 3.9612667560577393,
        "learning_rate": 1.4501845018450186e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.2426,
        "grad_norm": 3.112060785293579,
        "learning_rate": 1.4474169741697419e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.231,
        "grad_norm": 4.0370917320251465,
        "learning_rate": 1.4446494464944648e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.2804,
        "grad_norm": 2.4796478748321533,
        "learning_rate": 1.4418819188191881e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.3,
        "grad_norm": 19.93942642211914,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.2531,
        "grad_norm": 1.3310225009918213,
        "learning_rate": 1.4363468634686348e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.3157,
        "grad_norm": 20.39319610595703,
        "learning_rate": 1.433579335793358e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.2082,
        "grad_norm": 10.330392837524414,
        "learning_rate": 1.4308118081180812e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.2533,
        "grad_norm": 5.607283592224121,
        "learning_rate": 1.4280442804428045e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.3518,
        "grad_norm": 2.4653823375701904,
        "learning_rate": 1.4252767527675276e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.49639809131622314,
        "eval_accuracy": 0.84041,
        "eval_precision": 0.81359,
        "eval_recall": 0.87617,
        "eval_f1": 0.84372,
        "eval_runtime": 18.1156,
        "eval_samples_per_second": 59.838,
        "eval_steps_per_second": 3.754,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.3076,
        "grad_norm": 1.259673833847046,
        "learning_rate": 1.422509225092251e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.1827,
        "grad_norm": 1.7267005443572998,
        "learning_rate": 1.4197416974169741e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.2665,
        "grad_norm": 8.07898235321045,
        "learning_rate": 1.4169741697416974e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.2622,
        "grad_norm": 26.883573532104492,
        "learning_rate": 1.4142066420664207e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.1989,
        "grad_norm": 12.415657043457031,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.3144,
        "grad_norm": 1.2022929191589355,
        "learning_rate": 1.4086715867158673e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.231,
        "grad_norm": 4.5405497550964355,
        "learning_rate": 1.4059040590405905e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.2092,
        "grad_norm": 2.5817885398864746,
        "learning_rate": 1.4031365313653136e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.3322,
        "grad_norm": 3.6324262619018555,
        "learning_rate": 1.4003690036900369e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.1887,
        "grad_norm": 3.0462074279785156,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.3095,
        "grad_norm": 4.965890884399414,
        "learning_rate": 1.3948339483394834e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.161,
        "grad_norm": 2.1146676540374756,
        "learning_rate": 1.3920664206642067e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.2203,
        "grad_norm": 15.57236099243164,
        "learning_rate": 1.38929889298893e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.1353,
        "grad_norm": 4.027551174163818,
        "learning_rate": 1.3865313653136533e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.44,
        "grad_norm": 13.000476837158203,
        "learning_rate": 1.3837638376383764e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.2379,
        "grad_norm": 3.3952701091766357,
        "learning_rate": 1.3809963099630995e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.2738,
        "grad_norm": 1.3077237606048584,
        "learning_rate": 1.3782287822878229e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.2914,
        "grad_norm": 1.2258580923080444,
        "learning_rate": 1.3754612546125462e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.2166,
        "grad_norm": 3.591938018798828,
        "learning_rate": 1.3726937269372695e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.358,
        "grad_norm": 1.0711266994476318,
        "learning_rate": 1.3699261992619926e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.1608,
        "grad_norm": 2.593609094619751,
        "learning_rate": 1.367158671586716e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.2781,
        "grad_norm": 0.9742773771286011,
        "learning_rate": 1.3643911439114392e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.2327,
        "grad_norm": 3.8089511394500732,
        "learning_rate": 1.3616236162361624e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.2003,
        "grad_norm": 7.6004414558410645,
        "learning_rate": 1.3588560885608857e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.2625,
        "grad_norm": 24.2636661529541,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.2396,
        "grad_norm": 10.244872093200684,
        "learning_rate": 1.3533210332103321e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.266,
        "grad_norm": 2.0447869300842285,
        "learning_rate": 1.3505535055350554e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.5020681023597717,
        "eval_accuracy": 0.8441,
        "eval_precision": 0.81271,
        "eval_recall": 0.88743,
        "eval_f1": 0.84843,
        "eval_runtime": 18.1147,
        "eval_samples_per_second": 59.841,
        "eval_steps_per_second": 3.754,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.1737,
        "grad_norm": 1.7725623846054077,
        "learning_rate": 1.3477859778597787e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.2629,
        "grad_norm": 0.57211834192276,
        "learning_rate": 1.3450184501845019e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.1509,
        "grad_norm": 0.8185489773750305,
        "learning_rate": 1.3422509225092252e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.2716,
        "grad_norm": 1.5444972515106201,
        "learning_rate": 1.3394833948339483e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.3088,
        "grad_norm": 3.2612125873565674,
        "learning_rate": 1.3367158671586716e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.2891,
        "grad_norm": 1.1772944927215576,
        "learning_rate": 1.3339483394833948e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.2198,
        "grad_norm": 8.892291069030762,
        "learning_rate": 1.331180811808118e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.2598,
        "grad_norm": 1.5916938781738281,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.162,
        "grad_norm": 2.4216392040252686,
        "learning_rate": 1.3256457564575647e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.196,
        "grad_norm": 1.630153775215149,
        "learning_rate": 1.322878228782288e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.3127,
        "grad_norm": 3.605607032775879,
        "learning_rate": 1.320110701107011e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.2022,
        "grad_norm": 0.9703500866889954,
        "learning_rate": 1.3173431734317343e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.2393,
        "grad_norm": 2.5985183715820312,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.2598,
        "grad_norm": 5.117719650268555,
        "learning_rate": 1.3118081180811809e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.2343,
        "grad_norm": 3.5769758224487305,
        "learning_rate": 1.309040590405904e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.2297,
        "grad_norm": 21.470287322998047,
        "learning_rate": 1.3062730627306273e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.2933,
        "grad_norm": 10.779285430908203,
        "learning_rate": 1.3035055350553506e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.3169,
        "grad_norm": 11.907994270324707,
        "learning_rate": 1.300738007380074e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.1986,
        "grad_norm": 2.4980320930480957,
        "learning_rate": 1.297970479704797e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.3167,
        "grad_norm": 1.7469218969345093,
        "learning_rate": 1.2952029520295202e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.2262,
        "grad_norm": 0.6453031301498413,
        "learning_rate": 1.2924354243542435e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.2242,
        "grad_norm": 11.079526901245117,
        "learning_rate": 1.2896678966789668e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.2261,
        "grad_norm": 708.009033203125,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.2011,
        "grad_norm": 1.312385082244873,
        "learning_rate": 1.2841328413284133e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.2142,
        "grad_norm": 0.563524603843689,
        "learning_rate": 1.2813653136531366e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.2191,
        "grad_norm": 7.748455047607422,
        "learning_rate": 1.2785977859778599e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.2929,
        "grad_norm": 3.68045711517334,
        "learning_rate": 1.275830258302583e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.545742928981781,
        "eval_accuracy": 0.84225,
        "eval_precision": 0.811,
        "eval_recall": 0.88555,
        "eval_f1": 0.84664,
        "eval_runtime": 18.1355,
        "eval_samples_per_second": 59.772,
        "eval_steps_per_second": 3.75,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.1812,
        "grad_norm": 4.050914287567139,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.225,
        "grad_norm": 5.323486804962158,
        "learning_rate": 1.2702952029520295e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.1482,
        "grad_norm": 2.4499642848968506,
        "learning_rate": 1.2675276752767528e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.3246,
        "grad_norm": 2.71614408493042,
        "learning_rate": 1.2647601476014761e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.2601,
        "grad_norm": 1.3583675622940063,
        "learning_rate": 1.2619926199261994e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.147,
        "grad_norm": 0.6948838233947754,
        "learning_rate": 1.2592250922509225e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.2517,
        "grad_norm": 4.626856327056885,
        "learning_rate": 1.2564575645756457e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.2128,
        "grad_norm": 0.6086215972900391,
        "learning_rate": 1.253690036900369e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.4585,
        "grad_norm": 1.0993976593017578,
        "learning_rate": 1.2509225092250923e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.2023,
        "grad_norm": 4.744083404541016,
        "learning_rate": 1.2481549815498156e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.1955,
        "grad_norm": 5.878307819366455,
        "learning_rate": 1.2453874538745387e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.1627,
        "grad_norm": 1.4348920583724976,
        "learning_rate": 1.242619926199262e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.1977,
        "grad_norm": 9.91999340057373,
        "learning_rate": 1.2398523985239854e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.2443,
        "grad_norm": 3.435525894165039,
        "learning_rate": 1.2370848708487087e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.2771,
        "grad_norm": 42.1733512878418,
        "learning_rate": 1.2343173431734316e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.4425,
        "grad_norm": 5.220082759857178,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.2305,
        "grad_norm": 13.323352813720703,
        "learning_rate": 1.2287822878228782e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.2272,
        "grad_norm": 13.892407417297363,
        "learning_rate": 1.2260147601476015e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.2518,
        "grad_norm": 6.459617614746094,
        "learning_rate": 1.2232472324723247e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.1776,
        "grad_norm": 3.0117039680480957,
        "learning_rate": 1.220479704797048e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.2017,
        "grad_norm": 168.2470703125,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.2651,
        "grad_norm": 1.1621921062469482,
        "learning_rate": 1.2149446494464946e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.2129,
        "grad_norm": 2.646120309829712,
        "learning_rate": 1.2121771217712177e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.289,
        "grad_norm": 0.7214077711105347,
        "learning_rate": 1.2094095940959409e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.2463,
        "grad_norm": 3.8626067638397217,
        "learning_rate": 1.2066420664206642e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.1805,
        "grad_norm": 0.5786899924278259,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.1941,
        "grad_norm": 0.9990251660346985,
        "learning_rate": 1.2011070110701108e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.5873821973800659,
        "eval_accuracy": 0.84686,
        "eval_precision": 0.81049,
        "eval_recall": 0.89869,
        "eval_f1": 0.85231,
        "eval_runtime": 18.1195,
        "eval_samples_per_second": 59.825,
        "eval_steps_per_second": 3.753,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "train_runtime": 5591.2319,
        "train_samples_per_second": 31.013,
        "train_steps_per_second": 1.939,
        "total_flos": 1.36870370998272e+16,
        "train_loss": 0.3184173664153722,
        "epoch": 24.0,
        "step": 6504
    }
]