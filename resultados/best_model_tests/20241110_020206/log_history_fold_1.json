[
    {
        "loss": 0.653,
        "grad_norm": 6.063819408416748,
        "learning_rate": 2.997232472324723e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.6422,
        "grad_norm": 3.4369399547576904,
        "learning_rate": 2.9944649446494467e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.4395,
        "grad_norm": 5.8664021492004395,
        "learning_rate": 2.9916974169741697e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.5151,
        "grad_norm": 6.191310882568359,
        "learning_rate": 2.9889298892988933e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.4215,
        "grad_norm": 4.516170978546143,
        "learning_rate": 2.9861623616236163e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.4156,
        "grad_norm": 3.9394731521606445,
        "learning_rate": 2.9833948339483396e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.4669,
        "grad_norm": 4.059391498565674,
        "learning_rate": 2.980627306273063e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.4931,
        "grad_norm": 5.651320934295654,
        "learning_rate": 2.977859778597786e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.5303,
        "grad_norm": 4.4533162117004395,
        "learning_rate": 2.975092250922509e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.5346,
        "grad_norm": 2.892172336578369,
        "learning_rate": 2.9723247232472325e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.437,
        "grad_norm": 5.3146467208862305,
        "learning_rate": 2.9695571955719558e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4257,
        "grad_norm": 5.802069664001465,
        "learning_rate": 2.966789667896679e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.5333,
        "grad_norm": 10.256932258605957,
        "learning_rate": 2.9640221402214024e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.453,
        "grad_norm": 3.225203037261963,
        "learning_rate": 2.9612546125461254e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.3612,
        "grad_norm": 2.5007410049438477,
        "learning_rate": 2.958487084870849e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.4509,
        "grad_norm": 3.231165885925293,
        "learning_rate": 2.955719557195572e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.3968,
        "grad_norm": 3.4141347408294678,
        "learning_rate": 2.9529520295202953e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.4296,
        "grad_norm": 3.6662960052490234,
        "learning_rate": 2.9501845018450186e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.5116,
        "grad_norm": 2.8751184940338135,
        "learning_rate": 2.9474169741697416e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4435,
        "grad_norm": 2.6223201751708984,
        "learning_rate": 2.9446494464944652e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.5113,
        "grad_norm": 3.80999493598938,
        "learning_rate": 2.9418819188191882e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4527,
        "grad_norm": 3.597368001937866,
        "learning_rate": 2.9391143911439118e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.5276,
        "grad_norm": 3.016587972640991,
        "learning_rate": 2.9363468634686348e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.5199,
        "grad_norm": 3.3458571434020996,
        "learning_rate": 2.9335793357933578e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.3827,
        "grad_norm": 4.759729385375977,
        "learning_rate": 2.9308118081180814e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.3888,
        "grad_norm": 1.8111928701400757,
        "learning_rate": 2.9280442804428044e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.6025,
        "grad_norm": 10.049942016601562,
        "learning_rate": 2.9252767527675277e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.40331462025642395,
        "eval_accuracy": 0.82103,
        "eval_precision": 0.84431,
        "eval_recall": 0.78479,
        "eval_f1": 0.81346,
        "eval_runtime": 18.1745,
        "eval_samples_per_second": 59.644,
        "eval_steps_per_second": 3.742,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.4547,
        "grad_norm": 5.381372928619385,
        "learning_rate": 2.922509225092251e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4302,
        "grad_norm": 3.1259615421295166,
        "learning_rate": 2.9197416974169743e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.4516,
        "grad_norm": 6.681980133056641,
        "learning_rate": 2.9169741697416976e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.4635,
        "grad_norm": 4.085049629211426,
        "learning_rate": 2.9142066420664206e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.4355,
        "grad_norm": 9.410951614379883,
        "learning_rate": 2.911439114391144e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.5071,
        "grad_norm": 4.521244525909424,
        "learning_rate": 2.9086715867158672e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.4659,
        "grad_norm": 4.8331217765808105,
        "learning_rate": 2.9059040590405905e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4285,
        "grad_norm": 5.141879081726074,
        "learning_rate": 2.9031365313653138e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4607,
        "grad_norm": 2.876976728439331,
        "learning_rate": 2.900369003690037e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.4048,
        "grad_norm": 10.387670516967773,
        "learning_rate": 2.89760147601476e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4398,
        "grad_norm": 3.6794259548187256,
        "learning_rate": 2.8948339483394837e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4572,
        "grad_norm": 3.637324571609497,
        "learning_rate": 2.8920664206642067e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.415,
        "grad_norm": 4.050882339477539,
        "learning_rate": 2.8892988929889297e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.3971,
        "grad_norm": 3.2853193283081055,
        "learning_rate": 2.8865313653136533e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3762,
        "grad_norm": 1.5987250804901123,
        "learning_rate": 2.8837638376383763e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.4614,
        "grad_norm": 5.1756272315979,
        "learning_rate": 2.8809963099631e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.501,
        "grad_norm": 8.833431243896484,
        "learning_rate": 2.878228782287823e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.3856,
        "grad_norm": 4.357643127441406,
        "learning_rate": 2.8754612546125462e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.3911,
        "grad_norm": 4.792054176330566,
        "learning_rate": 2.8726937269372695e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.4738,
        "grad_norm": 2.3552043437957764,
        "learning_rate": 2.8699261992619925e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.3925,
        "grad_norm": 2.1426308155059814,
        "learning_rate": 2.867158671586716e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4234,
        "grad_norm": 5.0852789878845215,
        "learning_rate": 2.864391143911439e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.5065,
        "grad_norm": 6.404050827026367,
        "learning_rate": 2.8616236162361624e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.4094,
        "grad_norm": 3.6154966354370117,
        "learning_rate": 2.8588560885608857e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.3484,
        "grad_norm": 2.9857852458953857,
        "learning_rate": 2.856088560885609e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.44,
        "grad_norm": 3.937769889831543,
        "learning_rate": 2.8533210332103323e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.387,
        "grad_norm": 23.303462982177734,
        "learning_rate": 2.8505535055350553e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.3843395411968231,
        "eval_accuracy": 0.84502,
        "eval_precision": 0.81928,
        "eval_recall": 0.88312,
        "eval_f1": 0.85,
        "eval_runtime": 19.1343,
        "eval_samples_per_second": 56.652,
        "eval_steps_per_second": 3.554,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.4144,
        "grad_norm": 2.5745222568511963,
        "learning_rate": 2.8477859778597786e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.46,
        "grad_norm": 3.8645071983337402,
        "learning_rate": 2.845018450184502e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.3963,
        "grad_norm": 3.3524982929229736,
        "learning_rate": 2.8422509225092252e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.4036,
        "grad_norm": 4.43173885345459,
        "learning_rate": 2.8394833948339482e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.4072,
        "grad_norm": 1.882428526878357,
        "learning_rate": 2.8367158671586718e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.379,
        "grad_norm": 3.4962594509124756,
        "learning_rate": 2.8339483394833948e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.4348,
        "grad_norm": 5.919022560119629,
        "learning_rate": 2.831180811808118e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4891,
        "grad_norm": 2.994036912918091,
        "learning_rate": 2.8284132841328414e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.3903,
        "grad_norm": 4.156067371368408,
        "learning_rate": 2.8256457564575644e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3921,
        "grad_norm": 7.700162887573242,
        "learning_rate": 2.822878228782288e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.4717,
        "grad_norm": 2.711529493331909,
        "learning_rate": 2.820110701107011e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.4693,
        "grad_norm": 2.2467424869537354,
        "learning_rate": 2.8173431734317346e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3366,
        "grad_norm": 2.4572153091430664,
        "learning_rate": 2.8145756457564576e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.4282,
        "grad_norm": 7.458895206451416,
        "learning_rate": 2.811808118081181e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.4057,
        "grad_norm": 3.051802635192871,
        "learning_rate": 2.8090405904059042e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.386,
        "grad_norm": 5.83339262008667,
        "learning_rate": 2.8062730627306272e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3897,
        "grad_norm": 1.1882591247558594,
        "learning_rate": 2.803505535055351e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.2873,
        "grad_norm": 3.3843982219696045,
        "learning_rate": 2.8007380073800738e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3944,
        "grad_norm": 2.8644766807556152,
        "learning_rate": 2.797970479704797e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.3232,
        "grad_norm": 2.103391170501709,
        "learning_rate": 2.7952029520295204e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.4918,
        "grad_norm": 5.512645244598389,
        "learning_rate": 2.7924354243542437e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.3913,
        "grad_norm": 4.3374528884887695,
        "learning_rate": 2.7896678966789667e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4571,
        "grad_norm": 3.3645780086517334,
        "learning_rate": 2.78690036900369e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.4596,
        "grad_norm": 5.970311164855957,
        "learning_rate": 2.7841328413284133e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.4284,
        "grad_norm": 9.573781967163086,
        "learning_rate": 2.7813653136531366e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.4033,
        "grad_norm": 4.266457557678223,
        "learning_rate": 2.77859778597786e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.372,
        "grad_norm": 2.030062198638916,
        "learning_rate": 2.775830258302583e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.3787761926651001,
        "eval_accuracy": 0.82934,
        "eval_precision": 0.76577,
        "eval_recall": 0.9462,
        "eval_f1": 0.84647,
        "eval_runtime": 19.0271,
        "eval_samples_per_second": 56.971,
        "eval_steps_per_second": 3.574,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3925,
        "grad_norm": 4.72367525100708,
        "learning_rate": 2.7730627306273065e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.4331,
        "grad_norm": 11.601330757141113,
        "learning_rate": 2.7702952029520295e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.3907,
        "grad_norm": 2.70689058303833,
        "learning_rate": 2.7675276752767528e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.4665,
        "grad_norm": 2.8827996253967285,
        "learning_rate": 2.764760147601476e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.32,
        "grad_norm": 3.5008273124694824,
        "learning_rate": 2.761992619926199e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.4274,
        "grad_norm": 2.3036611080169678,
        "learning_rate": 2.7592250922509227e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3812,
        "grad_norm": 4.667641639709473,
        "learning_rate": 2.7564575645756457e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3638,
        "grad_norm": 2.2288289070129395,
        "learning_rate": 2.753690036900369e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.4183,
        "grad_norm": 1.4662202596664429,
        "learning_rate": 2.7509225092250923e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3281,
        "grad_norm": 4.260644912719727,
        "learning_rate": 2.7481549815498156e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.4189,
        "grad_norm": 3.9334940910339355,
        "learning_rate": 2.745387453874539e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.5001,
        "grad_norm": 4.757900714874268,
        "learning_rate": 2.742619926199262e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.4163,
        "grad_norm": 2.739454984664917,
        "learning_rate": 2.7398523985239852e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.4028,
        "grad_norm": 6.9683380126953125,
        "learning_rate": 2.7370848708487085e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.3985,
        "grad_norm": 3.1632490158081055,
        "learning_rate": 2.734317343173432e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.4048,
        "grad_norm": 1.737979531288147,
        "learning_rate": 2.731549815498155e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.4516,
        "grad_norm": 7.098090648651123,
        "learning_rate": 2.7287822878228784e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.3415,
        "grad_norm": 1.6960505247116089,
        "learning_rate": 2.7260147601476014e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.4625,
        "grad_norm": 11.6969633102417,
        "learning_rate": 2.7232472324723247e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.3098,
        "grad_norm": 3.0781939029693604,
        "learning_rate": 2.720479704797048e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.4733,
        "grad_norm": 5.930433750152588,
        "learning_rate": 2.7177121771217713e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.3957,
        "grad_norm": 1.9704365730285645,
        "learning_rate": 2.7149446494464946e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3833,
        "grad_norm": 3.716919183731079,
        "learning_rate": 2.7121771217712176e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.2785,
        "grad_norm": 3.6062228679656982,
        "learning_rate": 2.7094095940959413e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.3676,
        "grad_norm": 8.877774238586426,
        "learning_rate": 2.7066420664206642e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.4451,
        "grad_norm": 2.8237102031707764,
        "learning_rate": 2.7038745387453872e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.2962,
        "grad_norm": 2.146106243133545,
        "learning_rate": 2.701107011070111e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.3669418692588806,
        "eval_accuracy": 0.85148,
        "eval_precision": 0.815,
        "eval_recall": 0.90724,
        "eval_f1": 0.85865,
        "eval_runtime": 41.2406,
        "eval_samples_per_second": 26.285,
        "eval_steps_per_second": 1.649,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.4242,
        "grad_norm": 2.597745180130005,
        "learning_rate": 2.6983394833948338e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.3733,
        "grad_norm": 3.453411817550659,
        "learning_rate": 2.6955719557195575e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.3643,
        "grad_norm": 3.233991861343384,
        "learning_rate": 2.6928044280442804e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.4245,
        "grad_norm": 11.09795093536377,
        "learning_rate": 2.6900369003690037e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3446,
        "grad_norm": 2.2565393447875977,
        "learning_rate": 2.687269372693727e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3503,
        "grad_norm": 2.4691083431243896,
        "learning_rate": 2.6845018450184504e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3763,
        "grad_norm": 1.9492688179016113,
        "learning_rate": 2.6817343173431737e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3718,
        "grad_norm": 8.756925582885742,
        "learning_rate": 2.6789667896678966e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.408,
        "grad_norm": 2.2687652111053467,
        "learning_rate": 2.67619926199262e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.4382,
        "grad_norm": 2.3005189895629883,
        "learning_rate": 2.6734317343173432e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.3826,
        "grad_norm": 1.4843569993972778,
        "learning_rate": 2.6706642066420666e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3552,
        "grad_norm": 1.263808012008667,
        "learning_rate": 2.6678966789667895e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.3847,
        "grad_norm": 3.9783003330230713,
        "learning_rate": 2.665129151291513e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3508,
        "grad_norm": 7.3517985343933105,
        "learning_rate": 2.662361623616236e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3744,
        "grad_norm": 1.3788753747940063,
        "learning_rate": 2.6595940959409594e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3447,
        "grad_norm": 1.4363882541656494,
        "learning_rate": 2.6568265682656828e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.4013,
        "grad_norm": 1.8094947338104248,
        "learning_rate": 2.6540590405904057e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.3673,
        "grad_norm": 6.518429756164551,
        "learning_rate": 2.6512915129151294e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3633,
        "grad_norm": 3.132829427719116,
        "learning_rate": 2.6485239852398523e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.3026,
        "grad_norm": 5.1710100173950195,
        "learning_rate": 2.645756457564576e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.379,
        "grad_norm": 5.306674480438232,
        "learning_rate": 2.642988929889299e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.4228,
        "grad_norm": 1.3371710777282715,
        "learning_rate": 2.640221402214022e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.3657,
        "grad_norm": 3.0600192546844482,
        "learning_rate": 2.6374538745387456e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.3911,
        "grad_norm": 2.5629465579986572,
        "learning_rate": 2.6346863468634685e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.3146,
        "grad_norm": 21.432218551635742,
        "learning_rate": 2.6319188191881922e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.4329,
        "grad_norm": 4.670428276062012,
        "learning_rate": 2.629151291512915e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.3031,
        "grad_norm": 1.3631058931350708,
        "learning_rate": 2.6263837638376385e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.37175044417381287,
        "eval_accuracy": 0.85148,
        "eval_precision": 0.79905,
        "eval_recall": 0.93692,
        "eval_f1": 0.86251,
        "eval_runtime": 21.485,
        "eval_samples_per_second": 50.454,
        "eval_steps_per_second": 3.165,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.4046,
        "grad_norm": 2.1251394748687744,
        "learning_rate": 2.6236162361623618e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.3883,
        "grad_norm": 5.04348087310791,
        "learning_rate": 2.620848708487085e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.353,
        "grad_norm": 2.8812568187713623,
        "learning_rate": 2.618081180811808e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.3601,
        "grad_norm": 2.6975269317626953,
        "learning_rate": 2.6153136531365313e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.474,
        "grad_norm": 3.924450635910034,
        "learning_rate": 2.6125461254612547e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.3267,
        "grad_norm": 2.3341004848480225,
        "learning_rate": 2.609778597785978e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.3951,
        "grad_norm": 3.0691797733306885,
        "learning_rate": 2.6070110701107013e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.3361,
        "grad_norm": 11.845488548278809,
        "learning_rate": 2.6042435424354242e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.3625,
        "grad_norm": 7.458971977233887,
        "learning_rate": 2.601476014760148e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.3418,
        "grad_norm": 3.500777244567871,
        "learning_rate": 2.598708487084871e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.3336,
        "grad_norm": 3.8086273670196533,
        "learning_rate": 2.595940959409594e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.4344,
        "grad_norm": 1.8520143032073975,
        "learning_rate": 2.5931734317343175e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.3706,
        "grad_norm": 1.9957761764526367,
        "learning_rate": 2.5904059040590404e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.4829,
        "grad_norm": 18.15840721130371,
        "learning_rate": 2.587638376383764e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.4188,
        "grad_norm": 5.486206531524658,
        "learning_rate": 2.584870848708487e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.341,
        "grad_norm": 1.3405495882034302,
        "learning_rate": 2.5821033210332107e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.332,
        "grad_norm": 1.2865346670150757,
        "learning_rate": 2.5793357933579337e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.2872,
        "grad_norm": 1.4199720621109009,
        "learning_rate": 2.5765682656826566e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.4202,
        "grad_norm": 3.1185309886932373,
        "learning_rate": 2.5738007380073803e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.4782,
        "grad_norm": 3.7149922847747803,
        "learning_rate": 2.5710332103321032e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.4127,
        "grad_norm": 1.2327523231506348,
        "learning_rate": 2.5682656826568266e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.3723,
        "grad_norm": 3.888571262359619,
        "learning_rate": 2.56549815498155e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.3201,
        "grad_norm": 1.3971976041793823,
        "learning_rate": 2.5627306273062732e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.28,
        "grad_norm": 2.2189900875091553,
        "learning_rate": 2.5599630996309965e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.4297,
        "grad_norm": 2.73626708984375,
        "learning_rate": 2.5571955719557198e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.4843,
        "grad_norm": 4.356657981872559,
        "learning_rate": 2.5544280442804428e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.3733,
        "grad_norm": 1.6864962577819824,
        "learning_rate": 2.551660516605166e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.3587307929992676,
        "eval_accuracy": 0.87362,
        "eval_precision": 0.83059,
        "eval_recall": 0.93692,
        "eval_f1": 0.88056,
        "eval_runtime": 34.4095,
        "eval_samples_per_second": 31.503,
        "eval_steps_per_second": 1.976,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.3176,
        "grad_norm": 4.383271217346191,
        "learning_rate": 2.5488929889298894e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3688,
        "grad_norm": 3.065528392791748,
        "learning_rate": 2.5461254612546127e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.3359,
        "grad_norm": 24.318599700927734,
        "learning_rate": 2.543357933579336e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.4409,
        "grad_norm": 4.40269660949707,
        "learning_rate": 2.540590405904059e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.3696,
        "grad_norm": 4.079646110534668,
        "learning_rate": 2.5378228782287826e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.2776,
        "grad_norm": 3.6019554138183594,
        "learning_rate": 2.5350553505535056e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.3234,
        "grad_norm": 2.83758282661438,
        "learning_rate": 2.5322878228782285e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.4274,
        "grad_norm": 14.122034072875977,
        "learning_rate": 2.5295202952029522e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3555,
        "grad_norm": 3.540358781814575,
        "learning_rate": 2.526752767527675e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.4538,
        "grad_norm": 3.2556874752044678,
        "learning_rate": 2.5239852398523988e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.3819,
        "grad_norm": 2.4673187732696533,
        "learning_rate": 2.5212177121771218e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.4862,
        "grad_norm": 23.853750228881836,
        "learning_rate": 2.518450184501845e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.355,
        "grad_norm": 3.1098108291625977,
        "learning_rate": 2.5156826568265684e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.3116,
        "grad_norm": 3.9610862731933594,
        "learning_rate": 2.5129151291512914e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.4321,
        "grad_norm": 3.029189109802246,
        "learning_rate": 2.510147601476015e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.3611,
        "grad_norm": 1.6504533290863037,
        "learning_rate": 2.507380073800738e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.3006,
        "grad_norm": 39.769203186035156,
        "learning_rate": 2.5046125461254613e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.4351,
        "grad_norm": 11.02872085571289,
        "learning_rate": 2.5018450184501846e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.3957,
        "grad_norm": 2.133397340774536,
        "learning_rate": 2.499077490774908e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3433,
        "grad_norm": 1.345356822013855,
        "learning_rate": 2.4963099630996312e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3367,
        "grad_norm": 6.063427448272705,
        "learning_rate": 2.4935424354243545e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3216,
        "grad_norm": 5.325344562530518,
        "learning_rate": 2.4907749077490775e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.4668,
        "grad_norm": 3.0342941284179688,
        "learning_rate": 2.4880073800738008e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.41,
        "grad_norm": 1.4125713109970093,
        "learning_rate": 2.485239852398524e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.3864,
        "grad_norm": 3.2488837242126465,
        "learning_rate": 2.482472324723247e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.315,
        "grad_norm": 7.280588150024414,
        "learning_rate": 2.4797047970479707e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.329,
        "grad_norm": 24.85841941833496,
        "learning_rate": 2.4769372693726937e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.3612213730812073,
        "eval_accuracy": 0.85517,
        "eval_precision": 0.80126,
        "eval_recall": 0.94249,
        "eval_f1": 0.86616,
        "eval_runtime": 34.8133,
        "eval_samples_per_second": 31.137,
        "eval_steps_per_second": 1.953,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.4151,
        "grad_norm": 3.8799941539764404,
        "learning_rate": 2.4741697416974173e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.4046,
        "grad_norm": 3.842299222946167,
        "learning_rate": 2.4714022140221403e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3182,
        "grad_norm": 2.0916900634765625,
        "learning_rate": 2.4686346863468633e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.3267,
        "grad_norm": 1.9276238679885864,
        "learning_rate": 2.465867158671587e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.3027,
        "grad_norm": 3.9800755977630615,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.2856,
        "grad_norm": 2.0172829627990723,
        "learning_rate": 2.4603321033210335e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.3583,
        "grad_norm": 8.854860305786133,
        "learning_rate": 2.4575645756457565e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.3722,
        "grad_norm": 1.6008176803588867,
        "learning_rate": 2.4547970479704798e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.3021,
        "grad_norm": 7.956151485443115,
        "learning_rate": 2.452029520295203e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.2477,
        "grad_norm": 3.135194778442383,
        "learning_rate": 2.449261992619926e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.3435,
        "grad_norm": 7.651029586791992,
        "learning_rate": 2.4464944649446494e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3876,
        "grad_norm": 7.4460296630859375,
        "learning_rate": 2.4437269372693727e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.3055,
        "grad_norm": 2.693891763687134,
        "learning_rate": 2.440959409594096e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3466,
        "grad_norm": 2.410672426223755,
        "learning_rate": 2.4381918819188193e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.3438,
        "grad_norm": 2.7837870121002197,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.3698,
        "grad_norm": 5.044638156890869,
        "learning_rate": 2.4326568265682656e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.2688,
        "grad_norm": 2.2850148677825928,
        "learning_rate": 2.4298892988929892e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.3144,
        "grad_norm": 2.33150577545166,
        "learning_rate": 2.4271217712177122e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.4113,
        "grad_norm": 8.235517501831055,
        "learning_rate": 2.4243542435424355e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.4371,
        "grad_norm": 1.1203012466430664,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.3508,
        "grad_norm": 2.203289031982422,
        "learning_rate": 2.4188191881918818e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.3818,
        "grad_norm": 4.473857879638672,
        "learning_rate": 2.4160516605166054e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.4484,
        "grad_norm": 11.988245964050293,
        "learning_rate": 2.4132841328413284e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.3165,
        "grad_norm": 3.3139302730560303,
        "learning_rate": 2.410516605166052e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.4635,
        "grad_norm": 2.27671217918396,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.4184,
        "grad_norm": 7.130359649658203,
        "learning_rate": 2.404981549815498e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.4056,
        "grad_norm": 1.2478145360946655,
        "learning_rate": 2.4022140221402216e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.3446076512336731,
        "eval_accuracy": 0.869,
        "eval_precision": 0.82594,
        "eval_recall": 0.93321,
        "eval_f1": 0.87631,
        "eval_runtime": 19.6834,
        "eval_samples_per_second": 55.072,
        "eval_steps_per_second": 3.455,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.3411,
        "grad_norm": 4.103149890899658,
        "learning_rate": 2.3994464944649446e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3638,
        "grad_norm": 1.8496358394622803,
        "learning_rate": 2.396678966789668e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.3417,
        "grad_norm": 6.90654993057251,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.4021,
        "grad_norm": 1.6364108324050903,
        "learning_rate": 2.3911439114391145e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.3902,
        "grad_norm": 6.739676475524902,
        "learning_rate": 2.3883763837638378e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.2899,
        "grad_norm": 35.22248458862305,
        "learning_rate": 2.3856088560885608e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.459,
        "grad_norm": 1.8365155458450317,
        "learning_rate": 2.382841328413284e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.4615,
        "grad_norm": 1.40251886844635,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.3084,
        "grad_norm": 1.2941179275512695,
        "learning_rate": 2.3773062730627307e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.3648,
        "grad_norm": 2.1024363040924072,
        "learning_rate": 2.374538745387454e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.3693,
        "grad_norm": 7.8858561515808105,
        "learning_rate": 2.3717712177121773e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.3466,
        "grad_norm": 2.6902005672454834,
        "learning_rate": 2.3690036900369003e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.309,
        "grad_norm": 1.9052308797836304,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.3092,
        "grad_norm": 2.074493885040283,
        "learning_rate": 2.363468634686347e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.3336,
        "grad_norm": 3.7270941734313965,
        "learning_rate": 2.3607011070110702e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.3355,
        "grad_norm": 2.7370243072509766,
        "learning_rate": 2.3579335793357935e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.3679,
        "grad_norm": 5.283762454986572,
        "learning_rate": 2.3551660516605165e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3543,
        "grad_norm": 2.466050863265991,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.4139,
        "grad_norm": 3.279038429260254,
        "learning_rate": 2.349630996309963e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.3904,
        "grad_norm": 54.44160079956055,
        "learning_rate": 2.3468634686346864e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3235,
        "grad_norm": 5.27871561050415,
        "learning_rate": 2.3440959409594097e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.3857,
        "grad_norm": 8.874150276184082,
        "learning_rate": 2.3413284132841327e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.3607,
        "grad_norm": 3.2223715782165527,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.3375,
        "grad_norm": 0.8020045757293701,
        "learning_rate": 2.3357933579335793e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.3992,
        "grad_norm": 10.695552825927734,
        "learning_rate": 2.3330258302583026e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.3485,
        "grad_norm": 3.823744297027588,
        "learning_rate": 2.330258302583026e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3498,
        "grad_norm": 4.967126846313477,
        "learning_rate": 2.3274907749077492e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.39399364590644836,
        "eval_accuracy": 0.85793,
        "eval_precision": 0.85064,
        "eval_recall": 0.86642,
        "eval_f1": 0.85846,
        "eval_runtime": 19.7035,
        "eval_samples_per_second": 55.016,
        "eval_steps_per_second": 3.451,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.3423,
        "grad_norm": 1.995830774307251,
        "learning_rate": 2.3247232472324725e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.3748,
        "grad_norm": 4.1296586990356445,
        "learning_rate": 2.3219557195571955e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3701,
        "grad_norm": 1.3569602966308594,
        "learning_rate": 2.3191881918819188e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.4199,
        "grad_norm": 16.62514305114746,
        "learning_rate": 2.316420664206642e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.4345,
        "grad_norm": 1.112165093421936,
        "learning_rate": 2.3136531365313654e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.4502,
        "grad_norm": 2.261098623275757,
        "learning_rate": 2.3108856088560884e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3677,
        "grad_norm": 9.103621482849121,
        "learning_rate": 2.308118081180812e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.377,
        "grad_norm": 3.4952354431152344,
        "learning_rate": 2.305350553505535e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.363,
        "grad_norm": 37.654476165771484,
        "learning_rate": 2.3025830258302583e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.2597,
        "grad_norm": 1.2529255151748657,
        "learning_rate": 2.2998154981549816e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.4925,
        "grad_norm": 10.958417892456055,
        "learning_rate": 2.2970479704797046e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.3762,
        "grad_norm": 4.402523994445801,
        "learning_rate": 2.2942804428044282e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.3882,
        "grad_norm": 1.6042530536651611,
        "learning_rate": 2.2915129151291512e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.3378,
        "grad_norm": 1.496254563331604,
        "learning_rate": 2.288745387453875e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.4561,
        "grad_norm": 5.212481498718262,
        "learning_rate": 2.2859778597785978e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.443,
        "grad_norm": 2.2643213272094727,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.3707,
        "grad_norm": 2.387878179550171,
        "learning_rate": 2.2804428044280444e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.3792,
        "grad_norm": 1.2516429424285889,
        "learning_rate": 2.2776752767527674e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.3234,
        "grad_norm": 4.6486005783081055,
        "learning_rate": 2.274907749077491e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.3681,
        "grad_norm": 1.8551045656204224,
        "learning_rate": 2.272140221402214e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.3612,
        "grad_norm": 2.017387866973877,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.3383,
        "grad_norm": 3.9744441509246826,
        "learning_rate": 2.2666051660516606e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3867,
        "grad_norm": 8.871037483215332,
        "learning_rate": 2.263837638376384e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.3414,
        "grad_norm": 16.16830825805664,
        "learning_rate": 2.261070110701107e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.4671,
        "grad_norm": 4.495249271392822,
        "learning_rate": 2.2583025830258302e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.3545,
        "grad_norm": 1.654614806175232,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.2905,
        "grad_norm": 4.575961589813232,
        "learning_rate": 2.252767527675277e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.4251,
        "grad_norm": 3.1241724491119385,
        "learning_rate": 2.25e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.37444937229156494,
        "eval_accuracy": 0.86531,
        "eval_precision": 0.82696,
        "eval_recall": 0.92208,
        "eval_f1": 0.87193,
        "eval_runtime": 20.017,
        "eval_samples_per_second": 54.154,
        "eval_steps_per_second": 3.397,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.3215,
        "grad_norm": 3.5252983570098877,
        "learning_rate": 2.247232472324723e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.4025,
        "grad_norm": 2.0248067378997803,
        "learning_rate": 2.2444649446494468e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.4132,
        "grad_norm": 1.0871498584747314,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.4199,
        "grad_norm": 3.7168562412261963,
        "learning_rate": 2.238929889298893e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3186,
        "grad_norm": 5.800395488739014,
        "learning_rate": 2.2361623616236163e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.3328,
        "grad_norm": 4.913208961486816,
        "learning_rate": 2.2333948339483393e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.4256,
        "grad_norm": 3.5770459175109863,
        "learning_rate": 2.230627306273063e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.3267,
        "grad_norm": 6.078311920166016,
        "learning_rate": 2.227859778597786e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.3207,
        "grad_norm": 3.739582061767578,
        "learning_rate": 2.2250922509225092e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3874,
        "grad_norm": 2.9428412914276123,
        "learning_rate": 2.2223247232472325e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.4411,
        "grad_norm": 1.2938226461410522,
        "learning_rate": 2.219557195571956e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.3548,
        "grad_norm": 4.736504554748535,
        "learning_rate": 2.216789667896679e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.3599,
        "grad_norm": 4.365602493286133,
        "learning_rate": 2.214022140221402e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.388,
        "grad_norm": 2.7649946212768555,
        "learning_rate": 2.2112546125461254e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.3778,
        "grad_norm": 17.29608154296875,
        "learning_rate": 2.2084870848708487e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.4007,
        "grad_norm": 2.8169941902160645,
        "learning_rate": 2.205719557195572e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3756,
        "grad_norm": 22.777252197265625,
        "learning_rate": 2.2029520295202954e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.369,
        "grad_norm": 2.4055373668670654,
        "learning_rate": 2.2001845018450187e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.294,
        "grad_norm": 1.2190438508987427,
        "learning_rate": 2.1974169741697416e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.5143,
        "grad_norm": 4.192359447479248,
        "learning_rate": 2.194649446494465e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.4724,
        "grad_norm": 4.252862453460693,
        "learning_rate": 2.1918819188191882e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.3618,
        "grad_norm": 1.9085170030593872,
        "learning_rate": 2.1891143911439116e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.3509,
        "grad_norm": 15.71099853515625,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.3354,
        "grad_norm": 0.68744295835495,
        "learning_rate": 2.1835793357933578e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.4214,
        "grad_norm": 1.058994174003601,
        "learning_rate": 2.1808118081180815e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.3352,
        "grad_norm": 1.1505645513534546,
        "learning_rate": 2.1780442804428044e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.3378,
        "grad_norm": 2.9187333583831787,
        "learning_rate": 2.1752767527675274e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.3627955913543701,
        "eval_accuracy": 0.86439,
        "eval_precision": 0.82667,
        "eval_recall": 0.92022,
        "eval_f1": 0.87094,
        "eval_runtime": 19.6062,
        "eval_samples_per_second": 55.289,
        "eval_steps_per_second": 3.468,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.4091,
        "grad_norm": 1.631487250328064,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.357,
        "grad_norm": 1.1566784381866455,
        "learning_rate": 2.169741697416974e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.3481,
        "grad_norm": 1.879177212715149,
        "learning_rate": 2.1669741697416977e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.3192,
        "grad_norm": 6.272642612457275,
        "learning_rate": 2.1642066420664206e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.4203,
        "grad_norm": 2.0720527172088623,
        "learning_rate": 2.161439114391144e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.3456,
        "grad_norm": 3.515451192855835,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.3356,
        "grad_norm": 2.527576446533203,
        "learning_rate": 2.1559040590405906e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.3496,
        "grad_norm": 22.41218376159668,
        "learning_rate": 2.153136531365314e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.3501,
        "grad_norm": 1.8546665906906128,
        "learning_rate": 2.150369003690037e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.352,
        "grad_norm": 3.7455170154571533,
        "learning_rate": 2.14760147601476e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.3721,
        "grad_norm": 6.309762001037598,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.4138,
        "grad_norm": 4.506591796875,
        "learning_rate": 2.1420664206642068e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.4103,
        "grad_norm": 2.8080661296844482,
        "learning_rate": 2.1392988929889297e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.406,
        "grad_norm": 4.274952411651611,
        "learning_rate": 2.1365313653136534e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.3016,
        "grad_norm": 1.210103154182434,
        "learning_rate": 2.1337638376383763e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.3435,
        "grad_norm": 22.157426834106445,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.3543,
        "grad_norm": 2.057406425476074,
        "learning_rate": 2.128228782287823e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.3191,
        "grad_norm": 3.7256832122802734,
        "learning_rate": 2.125461254612546e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.3417,
        "grad_norm": 1.8940430879592896,
        "learning_rate": 2.1226937269372696e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.3893,
        "grad_norm": 2.1987555027008057,
        "learning_rate": 2.1199261992619925e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2892,
        "grad_norm": 2.2419064044952393,
        "learning_rate": 2.1171586715867162e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.4531,
        "grad_norm": 3.1335926055908203,
        "learning_rate": 2.114391143911439e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.3397,
        "grad_norm": 1.7105923891067505,
        "learning_rate": 2.111623616236162e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.298,
        "grad_norm": 5.9677815437316895,
        "learning_rate": 2.1088560885608858e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.3466,
        "grad_norm": 2.882097005844116,
        "learning_rate": 2.1060885608856087e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2925,
        "grad_norm": 2.9155101776123047,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.3759,
        "grad_norm": 3.2794408798217773,
        "learning_rate": 2.1005535055350554e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.3808049261569977,
        "eval_accuracy": 0.86531,
        "eval_precision": 0.82915,
        "eval_recall": 0.91837,
        "eval_f1": 0.87148,
        "eval_runtime": 19.6552,
        "eval_samples_per_second": 55.151,
        "eval_steps_per_second": 3.46,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.3949,
        "grad_norm": 5.033562660217285,
        "learning_rate": 2.0977859778597787e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.3539,
        "grad_norm": 3.342006206512451,
        "learning_rate": 2.095018450184502e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.4223,
        "grad_norm": 13.545639038085938,
        "learning_rate": 2.0922509225092253e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.3043,
        "grad_norm": 2.2183971405029297,
        "learning_rate": 2.0894833948339482e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.3142,
        "grad_norm": 2.873666524887085,
        "learning_rate": 2.0867158671586716e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.3442,
        "grad_norm": 11.224552154541016,
        "learning_rate": 2.083948339483395e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.3186,
        "grad_norm": 1.9267120361328125,
        "learning_rate": 2.0811808118081182e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.386,
        "grad_norm": 4.150359153747559,
        "learning_rate": 2.0784132841328415e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.4121,
        "grad_norm": 4.016297817230225,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.2581,
        "grad_norm": 2.047760248184204,
        "learning_rate": 2.072878228782288e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.2739,
        "grad_norm": 2.909620523452759,
        "learning_rate": 2.070110701107011e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.3285,
        "grad_norm": 2.109449625015259,
        "learning_rate": 2.0673431734317344e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.2887,
        "grad_norm": 2.322509765625,
        "learning_rate": 2.0645756457564577e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.4527,
        "grad_norm": 13.600796699523926,
        "learning_rate": 2.0618081180811806e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.4078,
        "grad_norm": 3.4732203483581543,
        "learning_rate": 2.0590405904059043e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.4386,
        "grad_norm": 15.913798332214355,
        "learning_rate": 2.0562730627306273e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.3095,
        "grad_norm": 2.9359095096588135,
        "learning_rate": 2.053505535055351e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.3438,
        "grad_norm": 2.2545413970947266,
        "learning_rate": 2.050738007380074e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.3554,
        "grad_norm": 10.57717514038086,
        "learning_rate": 2.047970479704797e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.326,
        "grad_norm": 3.360531806945801,
        "learning_rate": 2.0452029520295205e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.3351,
        "grad_norm": 0.8287478685379028,
        "learning_rate": 2.0424354243542435e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.4434,
        "grad_norm": 1.7462512254714966,
        "learning_rate": 2.0396678966789668e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.428,
        "grad_norm": 2.966792345046997,
        "learning_rate": 2.03690036900369e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.3465,
        "grad_norm": 1.4151839017868042,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.3146,
        "grad_norm": 2.060140609741211,
        "learning_rate": 2.0313653136531367e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.3017,
        "grad_norm": 2.544060230255127,
        "learning_rate": 2.02859778597786e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.3822,
        "grad_norm": 3.277247905731201,
        "learning_rate": 2.025830258302583e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.37551891803741455,
        "eval_accuracy": 0.86162,
        "eval_precision": 0.80062,
        "eval_recall": 0.96104,
        "eval_f1": 0.87352,
        "eval_runtime": 20.204,
        "eval_samples_per_second": 53.653,
        "eval_steps_per_second": 3.366,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.3716,
        "grad_norm": 5.992965221405029,
        "learning_rate": 2.0230627306273063e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.2653,
        "grad_norm": 2.2589120864868164,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.3856,
        "grad_norm": 2.247392177581787,
        "learning_rate": 2.017527675276753e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.4656,
        "grad_norm": 2.044795513153076,
        "learning_rate": 2.0147601476014762e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.2812,
        "grad_norm": 8.555816650390625,
        "learning_rate": 2.011992619926199e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.3536,
        "grad_norm": 1.1142734289169312,
        "learning_rate": 2.0092250922509228e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.3403,
        "grad_norm": 4.926789283752441,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.3676,
        "grad_norm": 2.097667694091797,
        "learning_rate": 2.0036900369003687e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.3341,
        "grad_norm": 2.768321990966797,
        "learning_rate": 2.0009225092250924e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.4074,
        "grad_norm": 78.41957092285156,
        "learning_rate": 1.9981549815498154e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.2803,
        "grad_norm": 0.8111069798469543,
        "learning_rate": 1.995387453874539e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.3421,
        "grad_norm": 14.188529014587402,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.3438,
        "grad_norm": 0.6857059001922607,
        "learning_rate": 1.9898523985239853e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.3327,
        "grad_norm": 2.1049561500549316,
        "learning_rate": 1.9870848708487086e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.5032,
        "grad_norm": 3.536712408065796,
        "learning_rate": 1.9843173431734316e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.3121,
        "grad_norm": 1.0261974334716797,
        "learning_rate": 1.9815498154981552e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2778,
        "grad_norm": 5.801016807556152,
        "learning_rate": 1.9787822878228782e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.497,
        "grad_norm": 3.4203131198883057,
        "learning_rate": 1.9760147601476015e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.3009,
        "grad_norm": 3.2022016048431396,
        "learning_rate": 1.9732472324723248e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.2855,
        "grad_norm": 3.225066661834717,
        "learning_rate": 1.970479704797048e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.3816,
        "grad_norm": 10.317183494567871,
        "learning_rate": 1.9677121771217714e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.3837,
        "grad_norm": 2.354747772216797,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.4172,
        "grad_norm": 1.693376064300537,
        "learning_rate": 1.9621771217712177e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.3665,
        "grad_norm": 3.3271572589874268,
        "learning_rate": 1.959409594095941e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.3473,
        "grad_norm": 21.963354110717773,
        "learning_rate": 1.9566420664206643e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.3458,
        "grad_norm": 3.0492637157440186,
        "learning_rate": 1.9538745387453873e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.3386,
        "grad_norm": 6.307071685791016,
        "learning_rate": 1.951107011070111e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.3625617027282715,
        "eval_accuracy": 0.87915,
        "eval_precision": 0.85052,
        "eval_recall": 0.91837,
        "eval_f1": 0.88314,
        "eval_runtime": 19.6507,
        "eval_samples_per_second": 55.163,
        "eval_steps_per_second": 3.46,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.4074,
        "grad_norm": 3.172401189804077,
        "learning_rate": 1.948339483394834e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.4193,
        "grad_norm": 23.877912521362305,
        "learning_rate": 1.9455719557195575e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.282,
        "grad_norm": 4.757190704345703,
        "learning_rate": 1.9428044280442805e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.3702,
        "grad_norm": 51.42610168457031,
        "learning_rate": 1.9400369003690035e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.3307,
        "grad_norm": 2.955198287963867,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.3703,
        "grad_norm": 15.411298751831055,
        "learning_rate": 1.93450184501845e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.3797,
        "grad_norm": 6.026682376861572,
        "learning_rate": 1.9317343173431737e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.3548,
        "grad_norm": 1.8482493162155151,
        "learning_rate": 1.9289667896678967e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2869,
        "grad_norm": 1.3276665210723877,
        "learning_rate": 1.92619926199262e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.347,
        "grad_norm": 1.932674765586853,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.3692,
        "grad_norm": 2.414276123046875,
        "learning_rate": 1.9206642066420663e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.3488,
        "grad_norm": 17.91992950439453,
        "learning_rate": 1.9178966789667896e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.369,
        "grad_norm": 3.3327622413635254,
        "learning_rate": 1.915129151291513e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.3752,
        "grad_norm": 1.5479921102523804,
        "learning_rate": 1.9123616236162362e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.3745,
        "grad_norm": 4.245405673980713,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.3553,
        "grad_norm": 0.8132333159446716,
        "learning_rate": 1.9068265682656828e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.4457,
        "grad_norm": 3.8485240936279297,
        "learning_rate": 1.9040590405904058e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.4328,
        "grad_norm": 5.892379283905029,
        "learning_rate": 1.901291512915129e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.306,
        "grad_norm": 3.8162240982055664,
        "learning_rate": 1.8985239852398524e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.3264,
        "grad_norm": 2.274646043777466,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.2531,
        "grad_norm": 2.0236318111419678,
        "learning_rate": 1.892988929889299e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.4511,
        "grad_norm": 2.020357131958008,
        "learning_rate": 1.890221402214022e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.3982,
        "grad_norm": 21.07646369934082,
        "learning_rate": 1.8874538745387456e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.3278,
        "grad_norm": 9.542899131774902,
        "learning_rate": 1.8846863468634686e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.2503,
        "grad_norm": 2.77030086517334,
        "learning_rate": 1.8819188191881922e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.2445,
        "grad_norm": 1.8882083892822266,
        "learning_rate": 1.8791512915129152e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.4283,
        "grad_norm": 7.876401424407959,
        "learning_rate": 1.8763837638376382e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.3726465404033661,
        "eval_accuracy": 0.87177,
        "eval_precision": 0.81949,
        "eval_recall": 0.95176,
        "eval_f1": 0.88069,
        "eval_runtime": 19.6159,
        "eval_samples_per_second": 55.261,
        "eval_steps_per_second": 3.467,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.3201,
        "grad_norm": 5.520711898803711,
        "learning_rate": 1.8736162361623618e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.4086,
        "grad_norm": 4.9816999435424805,
        "learning_rate": 1.8708487084870848e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.2749,
        "grad_norm": 2.1925415992736816,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.335,
        "grad_norm": 2.491926431655884,
        "learning_rate": 1.8653136531365314e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.3159,
        "grad_norm": 1.845279574394226,
        "learning_rate": 1.8625461254612547e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.3907,
        "grad_norm": 1.3425666093826294,
        "learning_rate": 1.859778597785978e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.3828,
        "grad_norm": 5.236363410949707,
        "learning_rate": 1.857011070110701e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.3097,
        "grad_norm": 1.7387213706970215,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.4146,
        "grad_norm": 3.4302587509155273,
        "learning_rate": 1.8514760147601476e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.3376,
        "grad_norm": 4.503767967224121,
        "learning_rate": 1.848708487084871e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.2983,
        "grad_norm": 7.6054534912109375,
        "learning_rate": 1.8459409594095942e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.3007,
        "grad_norm": 1.0789185762405396,
        "learning_rate": 1.8431734317343175e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.28,
        "grad_norm": 1.8009216785430908,
        "learning_rate": 1.8404059040590405e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.3575,
        "grad_norm": 95.08045196533203,
        "learning_rate": 1.8376383763837638e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.3892,
        "grad_norm": 1.3819986581802368,
        "learning_rate": 1.834870848708487e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.4096,
        "grad_norm": 7.482360363006592,
        "learning_rate": 1.8321033210332104e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.3948,
        "grad_norm": 2.9689652919769287,
        "learning_rate": 1.8293357933579337e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.285,
        "grad_norm": 2.8969790935516357,
        "learning_rate": 1.8265682656826567e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.324,
        "grad_norm": 2.110978603363037,
        "learning_rate": 1.8238007380073803e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.3833,
        "grad_norm": 3.7286951541900635,
        "learning_rate": 1.8210332103321033e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.3803,
        "grad_norm": 5.0561604499816895,
        "learning_rate": 1.8182656826568266e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.316,
        "grad_norm": 10.906756401062012,
        "learning_rate": 1.81549815498155e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.3491,
        "grad_norm": 3.624993085861206,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.3738,
        "grad_norm": 1.8904961347579956,
        "learning_rate": 1.8099630996309965e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.3822,
        "grad_norm": 1.546080231666565,
        "learning_rate": 1.8071955719557195e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.3424,
        "grad_norm": 1.4537866115570068,
        "learning_rate": 1.8044280442804428e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.3073,
        "grad_norm": 0.9774147272109985,
        "learning_rate": 1.801660516605166e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.42343318462371826,
        "eval_accuracy": 0.84963,
        "eval_precision": 0.84307,
        "eval_recall": 0.85714,
        "eval_f1": 0.85005,
        "eval_runtime": 19.6809,
        "eval_samples_per_second": 55.079,
        "eval_steps_per_second": 3.455,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.4341,
        "grad_norm": 119.0849380493164,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.4184,
        "grad_norm": 0.7723937034606934,
        "learning_rate": 1.7961254612546127e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.375,
        "grad_norm": 1.941343903541565,
        "learning_rate": 1.7933579335793357e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.2496,
        "grad_norm": 1.3599828481674194,
        "learning_rate": 1.790590405904059e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.3605,
        "grad_norm": 3.2497637271881104,
        "learning_rate": 1.7878228782287823e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.4074,
        "grad_norm": 2.0344955921173096,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.4201,
        "grad_norm": 2.002702236175537,
        "learning_rate": 1.7822878228782286e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.3977,
        "grad_norm": 14.655051231384277,
        "learning_rate": 1.7795202952029522e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.3345,
        "grad_norm": 4.280600547790527,
        "learning_rate": 1.7767527675276752e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.3255,
        "grad_norm": 1.0264244079589844,
        "learning_rate": 1.7739852398523985e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.319,
        "grad_norm": 2.4521284103393555,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.3501,
        "grad_norm": 1.9807883501052856,
        "learning_rate": 1.7684501845018448e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.4056,
        "grad_norm": 32.62099075317383,
        "learning_rate": 1.7656826568265684e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.3002,
        "grad_norm": 1.0690399408340454,
        "learning_rate": 1.7629151291512914e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.4225,
        "grad_norm": 1.7597535848617554,
        "learning_rate": 1.760147601476015e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.3,
        "grad_norm": 4.998770713806152,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.4248,
        "grad_norm": 11.184842109680176,
        "learning_rate": 1.7546125461254613e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.3617,
        "grad_norm": 1.8920459747314453,
        "learning_rate": 1.7518450184501846e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.2793,
        "grad_norm": 22.38207244873047,
        "learning_rate": 1.7490774907749076e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.352,
        "grad_norm": 11.81229305267334,
        "learning_rate": 1.7463099630996313e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.378,
        "grad_norm": 2.1255271434783936,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.381,
        "grad_norm": 5.245622634887695,
        "learning_rate": 1.7407749077490775e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.3545,
        "grad_norm": 1.2341948747634888,
        "learning_rate": 1.738007380073801e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.3044,
        "grad_norm": 3.2572827339172363,
        "learning_rate": 1.735239852398524e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.2901,
        "grad_norm": 2.471128225326538,
        "learning_rate": 1.732472324723247e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.3778,
        "grad_norm": 3.6706631183624268,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.2807,
        "grad_norm": 3.088541269302368,
        "learning_rate": 1.7269372693726937e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.4312553405761719,
        "eval_accuracy": 0.8607,
        "eval_precision": 0.83681,
        "eval_recall": 0.89425,
        "eval_f1": 0.86457,
        "eval_runtime": 19.7585,
        "eval_samples_per_second": 54.863,
        "eval_steps_per_second": 3.442,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.3946,
        "grad_norm": 1.7480168342590332,
        "learning_rate": 1.724169741697417e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.3108,
        "grad_norm": 2.6176414489746094,
        "learning_rate": 1.7214022140221404e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.3198,
        "grad_norm": 2.1802093982696533,
        "learning_rate": 1.7186346863468633e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.2483,
        "grad_norm": 8.110021591186523,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.3261,
        "grad_norm": 89.58758544921875,
        "learning_rate": 1.71309963099631e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.423,
        "grad_norm": 3.6449601650238037,
        "learning_rate": 1.7103321033210332e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.4348,
        "grad_norm": 3.287492513656616,
        "learning_rate": 1.7075645756457566e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.3899,
        "grad_norm": 3.660865068435669,
        "learning_rate": 1.7047970479704795e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2497,
        "grad_norm": 2.2506933212280273,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.4091,
        "grad_norm": 4.794617652893066,
        "learning_rate": 1.699261992619926e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.3211,
        "grad_norm": 4.715555667877197,
        "learning_rate": 1.6964944649446494e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.3656,
        "grad_norm": 4.095335483551025,
        "learning_rate": 1.6937269372693727e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.4023,
        "grad_norm": 1.5408413410186768,
        "learning_rate": 1.690959409594096e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.3258,
        "grad_norm": 4.855563640594482,
        "learning_rate": 1.6881918819188194e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.3531,
        "grad_norm": 2.297306776046753,
        "learning_rate": 1.6854243542435423e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.2997,
        "grad_norm": 7.8763885498046875,
        "learning_rate": 1.6826568265682656e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.3451,
        "grad_norm": 2.4135820865631104,
        "learning_rate": 1.679889298892989e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.2776,
        "grad_norm": 2.2678639888763428,
        "learning_rate": 1.6771217712177123e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.3083,
        "grad_norm": 7.429826259613037,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.3455,
        "grad_norm": 2.687650442123413,
        "learning_rate": 1.671586715867159e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.3689,
        "grad_norm": 1.5758990049362183,
        "learning_rate": 1.668819188191882e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.3137,
        "grad_norm": 1.0524784326553345,
        "learning_rate": 1.666051660516605e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.3079,
        "grad_norm": 9.561402320861816,
        "learning_rate": 1.6632841328413285e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.3097,
        "grad_norm": 0.7736802697181702,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.3917,
        "grad_norm": 0.6898639798164368,
        "learning_rate": 1.657749077490775e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.3747,
        "grad_norm": 2.207692861557007,
        "learning_rate": 1.654981549815498e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.3868,
        "grad_norm": 1.8493281602859497,
        "learning_rate": 1.6522140221402217e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.38081327080726624,
        "eval_accuracy": 0.86993,
        "eval_precision": 0.82947,
        "eval_recall": 0.9295,
        "eval_f1": 0.87664,
        "eval_runtime": 19.5709,
        "eval_samples_per_second": 55.388,
        "eval_steps_per_second": 3.475,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.3593,
        "grad_norm": 2.5982415676116943,
        "learning_rate": 1.6494464944649447e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.3184,
        "grad_norm": 2.11016583442688,
        "learning_rate": 1.6466789667896676e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.2884,
        "grad_norm": 22.312171936035156,
        "learning_rate": 1.6439114391143913e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.3548,
        "grad_norm": 14.244414329528809,
        "learning_rate": 1.6411439114391142e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2953,
        "grad_norm": 8.40617847442627,
        "learning_rate": 1.638376383763838e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.3831,
        "grad_norm": 1.9167660474777222,
        "learning_rate": 1.635608856088561e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.3184,
        "grad_norm": 2.2013018131256104,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2609,
        "grad_norm": 0.6753044128417969,
        "learning_rate": 1.6300738007380075e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.4589,
        "grad_norm": 1.589805245399475,
        "learning_rate": 1.6273062730627308e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.3297,
        "grad_norm": 2.947641372680664,
        "learning_rate": 1.624538745387454e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.3111,
        "grad_norm": 2.775012254714966,
        "learning_rate": 1.621771217712177e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.3183,
        "grad_norm": 2.6019606590270996,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.206,
        "grad_norm": 1.095611572265625,
        "learning_rate": 1.6162361623616237e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.3158,
        "grad_norm": 4.761330604553223,
        "learning_rate": 1.613468634686347e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.4407,
        "grad_norm": 22.204374313354492,
        "learning_rate": 1.6107011070110703e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.2952,
        "grad_norm": 1.0519020557403564,
        "learning_rate": 1.6079335793357936e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.3234,
        "grad_norm": 8.569648742675781,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.374,
        "grad_norm": 1.5067137479782104,
        "learning_rate": 1.60239852398524e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.366,
        "grad_norm": 1.2789350748062134,
        "learning_rate": 1.5996309963099632e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.3709,
        "grad_norm": 5.128697872161865,
        "learning_rate": 1.596863468634686e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.4141,
        "grad_norm": 2.8186099529266357,
        "learning_rate": 1.5940959409594098e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.3473,
        "grad_norm": 4.606523036956787,
        "learning_rate": 1.5913284132841328e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.3236,
        "grad_norm": 2.438424587249756,
        "learning_rate": 1.5885608856088564e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2675,
        "grad_norm": 3.260516881942749,
        "learning_rate": 1.5857933579335794e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.265,
        "grad_norm": 1.289196252822876,
        "learning_rate": 1.5830258302583023e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2716,
        "grad_norm": 3.5339038372039795,
        "learning_rate": 1.580258302583026e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.3802,
        "grad_norm": 303.34442138671875,
        "learning_rate": 1.577490774907749e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.3766997456550598,
        "eval_accuracy": 0.87085,
        "eval_precision": 0.82022,
        "eval_recall": 0.94805,
        "eval_f1": 0.87952,
        "eval_runtime": 20.0417,
        "eval_samples_per_second": 54.087,
        "eval_steps_per_second": 3.393,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.3339,
        "grad_norm": 2.969449281692505,
        "learning_rate": 1.5747232472324726e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.3398,
        "grad_norm": 6.323782444000244,
        "learning_rate": 1.5719557195571956e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.3591,
        "grad_norm": 4.075181484222412,
        "learning_rate": 1.569188191881919e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.2492,
        "grad_norm": 1.9705009460449219,
        "learning_rate": 1.5664206642066422e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.3368,
        "grad_norm": 1.2274338006973267,
        "learning_rate": 1.5636531365313655e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.3076,
        "grad_norm": 2.2546768188476562,
        "learning_rate": 1.5608856088560885e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2965,
        "grad_norm": 1.0135060548782349,
        "learning_rate": 1.5581180811808118e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.2574,
        "grad_norm": 2.159559488296509,
        "learning_rate": 1.555350553505535e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.3264,
        "grad_norm": 1.2663209438323975,
        "learning_rate": 1.5525830258302584e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.3185,
        "grad_norm": 2.17411470413208,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.4344,
        "grad_norm": 6.8868794441223145,
        "learning_rate": 1.5470479704797047e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.3307,
        "grad_norm": 5.724356651306152,
        "learning_rate": 1.5442804428044283e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.3035,
        "grad_norm": 1.687238335609436,
        "learning_rate": 1.5415129151291513e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.3408,
        "grad_norm": 1.6958798170089722,
        "learning_rate": 1.5387453874538746e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.2874,
        "grad_norm": 15.493278503417969,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.3373,
        "grad_norm": 1.6133012771606445,
        "learning_rate": 1.533210332103321e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.3604,
        "grad_norm": 1.8568187952041626,
        "learning_rate": 1.5304428044280445e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.299,
        "grad_norm": 1.626447319984436,
        "learning_rate": 1.5276752767527675e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.3892,
        "grad_norm": 6.669703006744385,
        "learning_rate": 1.524907749077491e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.3189,
        "grad_norm": 6.715670108795166,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.31,
        "grad_norm": 3.895991086959839,
        "learning_rate": 1.5193726937269372e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.3018,
        "grad_norm": 2.662091016769409,
        "learning_rate": 1.5166051660516607e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.3744,
        "grad_norm": 7.202201843261719,
        "learning_rate": 1.5138376383763838e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.3401,
        "grad_norm": 5.405104637145996,
        "learning_rate": 1.511070110701107e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.349,
        "grad_norm": 3.9595556259155273,
        "learning_rate": 1.5083025830258303e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.2782,
        "grad_norm": 2.2976911067962646,
        "learning_rate": 1.5055350553505534e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.3068,
        "grad_norm": 2.6206674575805664,
        "learning_rate": 1.5027675276752769e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.2826,
        "grad_norm": 0.833702802658081,
        "learning_rate": 1.5e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.3571013808250427,
        "eval_accuracy": 0.87269,
        "eval_precision": 0.8325,
        "eval_recall": 0.93135,
        "eval_f1": 0.87916,
        "eval_runtime": 19.6233,
        "eval_samples_per_second": 55.24,
        "eval_steps_per_second": 3.465,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.3442,
        "grad_norm": 1.7485218048095703,
        "learning_rate": 1.4972324723247233e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.3647,
        "grad_norm": 1.0099148750305176,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2876,
        "grad_norm": 1.8022047281265259,
        "learning_rate": 1.4916974169741698e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.3121,
        "grad_norm": 1.4175474643707275,
        "learning_rate": 1.488929889298893e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.3825,
        "grad_norm": 4.256837844848633,
        "learning_rate": 1.4861623616236162e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.3282,
        "grad_norm": 1.843907117843628,
        "learning_rate": 1.4833948339483395e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.228,
        "grad_norm": 2.88322114944458,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.2643,
        "grad_norm": 5.762725830078125,
        "learning_rate": 1.477859778597786e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.3316,
        "grad_norm": 1.8931217193603516,
        "learning_rate": 1.4750922509225093e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.284,
        "grad_norm": 1.930015206336975,
        "learning_rate": 1.4723247232472326e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.3898,
        "grad_norm": 1.3770655393600464,
        "learning_rate": 1.4695571955719559e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.2759,
        "grad_norm": 2.455054998397827,
        "learning_rate": 1.4667896678966789e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.3292,
        "grad_norm": 1.4465522766113281,
        "learning_rate": 1.4640221402214022e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.3004,
        "grad_norm": 2.112334728240967,
        "learning_rate": 1.4612546125461255e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.3269,
        "grad_norm": 4.181772232055664,
        "learning_rate": 1.4584870848708488e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.2687,
        "grad_norm": 1.2287489175796509,
        "learning_rate": 1.455719557195572e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.344,
        "grad_norm": 1.9605178833007812,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.3469,
        "grad_norm": 13.595296859741211,
        "learning_rate": 1.4501845018450186e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.3612,
        "grad_norm": 4.133015155792236,
        "learning_rate": 1.4474169741697419e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.3517,
        "grad_norm": 0.9869608879089355,
        "learning_rate": 1.4446494464944648e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.2775,
        "grad_norm": 5.774104595184326,
        "learning_rate": 1.4418819188191881e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.3446,
        "grad_norm": 5.556114196777344,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.3502,
        "grad_norm": 8.3486909866333,
        "learning_rate": 1.4363468634686348e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.3382,
        "grad_norm": 57.60734176635742,
        "learning_rate": 1.433579335793358e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.2905,
        "grad_norm": 30.40727424621582,
        "learning_rate": 1.4308118081180812e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.3087,
        "grad_norm": 0.9919569492340088,
        "learning_rate": 1.4280442804428045e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.2346,
        "grad_norm": 3.2986652851104736,
        "learning_rate": 1.4252767527675276e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.38072147965431213,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.83893,
        "eval_recall": 0.92764,
        "eval_f1": 0.88106,
        "eval_runtime": 19.6849,
        "eval_samples_per_second": 55.068,
        "eval_steps_per_second": 3.454,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.3859,
        "grad_norm": 5.633527755737305,
        "learning_rate": 1.422509225092251e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.2474,
        "grad_norm": 0.9014101028442383,
        "learning_rate": 1.4197416974169741e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.2764,
        "grad_norm": 5.350720405578613,
        "learning_rate": 1.4169741697416974e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.3976,
        "grad_norm": 5.772829532623291,
        "learning_rate": 1.4142066420664207e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.3738,
        "grad_norm": 15.335965156555176,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.2958,
        "grad_norm": 3.6723642349243164,
        "learning_rate": 1.4086715867158673e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.285,
        "grad_norm": 1.7225219011306763,
        "learning_rate": 1.4059040590405905e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.3212,
        "grad_norm": 2.9116268157958984,
        "learning_rate": 1.4031365313653136e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.3878,
        "grad_norm": 3.3792614936828613,
        "learning_rate": 1.4003690036900369e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.2964,
        "grad_norm": 3.8280444145202637,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.3259,
        "grad_norm": 2.8881940841674805,
        "learning_rate": 1.3948339483394834e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.1748,
        "grad_norm": 1.937659740447998,
        "learning_rate": 1.3920664206642067e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.4562,
        "grad_norm": 63.20217514038086,
        "learning_rate": 1.38929889298893e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.322,
        "grad_norm": 31.816341400146484,
        "learning_rate": 1.3865313653136533e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.306,
        "grad_norm": 4.110074996948242,
        "learning_rate": 1.3837638376383764e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.2495,
        "grad_norm": 1.1649647951126099,
        "learning_rate": 1.3809963099630995e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.2973,
        "grad_norm": 2.5144710540771484,
        "learning_rate": 1.3782287822878229e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.3717,
        "grad_norm": 3.4298958778381348,
        "learning_rate": 1.3754612546125462e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.2351,
        "grad_norm": 8.849148750305176,
        "learning_rate": 1.3726937269372695e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.3101,
        "grad_norm": 1.8777797222137451,
        "learning_rate": 1.3699261992619926e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.1862,
        "grad_norm": 2.6157844066619873,
        "learning_rate": 1.367158671586716e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.3222,
        "grad_norm": 1.5625907182693481,
        "learning_rate": 1.3643911439114392e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.3092,
        "grad_norm": 2.7388482093811035,
        "learning_rate": 1.3616236162361624e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.2483,
        "grad_norm": 0.8255239129066467,
        "learning_rate": 1.3588560885608857e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.3637,
        "grad_norm": 0.9185400605201721,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.4951,
        "grad_norm": 3.905109167098999,
        "learning_rate": 1.3533210332103321e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.3208,
        "grad_norm": 26.9383487701416,
        "learning_rate": 1.3505535055350554e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.36527106165885925,
        "eval_accuracy": 0.86347,
        "eval_precision": 0.8118,
        "eval_recall": 0.94434,
        "eval_f1": 0.87307,
        "eval_runtime": 20.1164,
        "eval_samples_per_second": 53.886,
        "eval_steps_per_second": 3.38,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.3559,
        "grad_norm": 2.552370309829712,
        "learning_rate": 1.3477859778597787e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.2919,
        "grad_norm": 2.2087574005126953,
        "learning_rate": 1.3450184501845019e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.3627,
        "grad_norm": 16.185623168945312,
        "learning_rate": 1.3422509225092252e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.3466,
        "grad_norm": 10.797673225402832,
        "learning_rate": 1.3394833948339483e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.3016,
        "grad_norm": 2.3604376316070557,
        "learning_rate": 1.3367158671586716e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.2929,
        "grad_norm": 2.1520001888275146,
        "learning_rate": 1.3339483394833948e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.294,
        "grad_norm": 2.4358434677124023,
        "learning_rate": 1.331180811808118e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.2966,
        "grad_norm": 2.838010549545288,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.3229,
        "grad_norm": 7.36992883682251,
        "learning_rate": 1.3256457564575647e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.2917,
        "grad_norm": 5.839430332183838,
        "learning_rate": 1.322878228782288e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.2996,
        "grad_norm": 2.1628787517547607,
        "learning_rate": 1.320110701107011e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.1929,
        "grad_norm": 2.5316550731658936,
        "learning_rate": 1.3173431734317343e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.3553,
        "grad_norm": 5.871840476989746,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.2599,
        "grad_norm": 40.433773040771484,
        "learning_rate": 1.3118081180811809e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.2816,
        "grad_norm": 1.6903820037841797,
        "learning_rate": 1.309040590405904e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.3281,
        "grad_norm": 1.0352189540863037,
        "learning_rate": 1.3062730627306273e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.2878,
        "grad_norm": 1.6558376550674438,
        "learning_rate": 1.3035055350553506e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.252,
        "grad_norm": 2.341123104095459,
        "learning_rate": 1.300738007380074e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.3094,
        "grad_norm": 2.7564709186553955,
        "learning_rate": 1.297970479704797e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.3137,
        "grad_norm": 5.90565824508667,
        "learning_rate": 1.2952029520295202e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.298,
        "grad_norm": 0.7878069877624512,
        "learning_rate": 1.2924354243542435e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.4249,
        "grad_norm": 1.9054155349731445,
        "learning_rate": 1.2896678966789668e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.3762,
        "grad_norm": 0.9244458675384521,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.3077,
        "grad_norm": 1.4431580305099487,
        "learning_rate": 1.2841328413284133e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.4518,
        "grad_norm": 5.970641136169434,
        "learning_rate": 1.2813653136531366e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.3415,
        "grad_norm": 6.675187110900879,
        "learning_rate": 1.2785977859778599e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.3085,
        "grad_norm": 1.2306571006774902,
        "learning_rate": 1.275830258302583e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.36004820466041565,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.84354,
        "eval_recall": 0.92022,
        "eval_f1": 0.88021,
        "eval_runtime": 19.6509,
        "eval_samples_per_second": 55.163,
        "eval_steps_per_second": 3.46,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.2744,
        "grad_norm": 0.6816261410713196,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.3023,
        "grad_norm": 0.8245008587837219,
        "learning_rate": 1.2702952029520295e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.2275,
        "grad_norm": 1.5851590633392334,
        "learning_rate": 1.2675276752767528e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.2627,
        "grad_norm": 2.440107822418213,
        "learning_rate": 1.2647601476014761e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.299,
        "grad_norm": 18.4805908203125,
        "learning_rate": 1.2619926199261994e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.4194,
        "grad_norm": 3.0088565349578857,
        "learning_rate": 1.2592250922509225e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.2411,
        "grad_norm": 2.011429786682129,
        "learning_rate": 1.2564575645756457e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.2699,
        "grad_norm": 1.5306795835494995,
        "learning_rate": 1.253690036900369e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.389,
        "grad_norm": 17.6292667388916,
        "learning_rate": 1.2509225092250923e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.2771,
        "grad_norm": 2.1759233474731445,
        "learning_rate": 1.2481549815498156e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.2738,
        "grad_norm": 3.841806173324585,
        "learning_rate": 1.2453874538745387e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.3414,
        "grad_norm": 1.6161495447158813,
        "learning_rate": 1.242619926199262e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.3112,
        "grad_norm": 3.145956516265869,
        "learning_rate": 1.2398523985239854e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.3608,
        "grad_norm": 1.517854928970337,
        "learning_rate": 1.2370848708487087e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.2157,
        "grad_norm": 1.3894484043121338,
        "learning_rate": 1.2343173431734316e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.3566,
        "grad_norm": 28.987510681152344,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.2763,
        "grad_norm": 2.5920095443725586,
        "learning_rate": 1.2287822878228782e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.3905,
        "grad_norm": 1.3830206394195557,
        "learning_rate": 1.2260147601476015e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.352,
        "grad_norm": 0.7086893320083618,
        "learning_rate": 1.2232472324723247e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.2628,
        "grad_norm": 3.329134941101074,
        "learning_rate": 1.220479704797048e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.25,
        "grad_norm": 3.1170718669891357,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.268,
        "grad_norm": 3.420492172241211,
        "learning_rate": 1.2149446494464946e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.313,
        "grad_norm": 5.449703216552734,
        "learning_rate": 1.2121771217712177e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.2753,
        "grad_norm": 3.180156707763672,
        "learning_rate": 1.2094095940959409e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.3688,
        "grad_norm": 34.52009582519531,
        "learning_rate": 1.2066420664206642e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.3954,
        "grad_norm": 1.8654744625091553,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.2499,
        "grad_norm": 4.310066223144531,
        "learning_rate": 1.2011070110701108e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.37019577622413635,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.83779,
        "eval_recall": 0.9295,
        "eval_f1": 0.88127,
        "eval_runtime": 19.6934,
        "eval_samples_per_second": 55.044,
        "eval_steps_per_second": 3.453,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "train_runtime": 6302.7478,
        "train_samples_per_second": 27.512,
        "train_steps_per_second": 1.72,
        "total_flos": 1.36870370998272e+16,
        "train_loss": 0.36263818637471357,
        "epoch": 24.0,
        "step": 6504
    }
]