[
    {
        "loss": 0.6029,
        "grad_norm": 17.810588836669922,
        "learning_rate": 2.997232472324723e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.4766,
        "grad_norm": 5.036632537841797,
        "learning_rate": 2.9944649446494467e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.4959,
        "grad_norm": 2.989450454711914,
        "learning_rate": 2.9916974169741697e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.4953,
        "grad_norm": 8.236306190490723,
        "learning_rate": 2.9889298892988933e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.5233,
        "grad_norm": 3.7053654193878174,
        "learning_rate": 2.9861623616236163e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.5636,
        "grad_norm": 7.374506950378418,
        "learning_rate": 2.9833948339483396e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.3804,
        "grad_norm": 4.803990840911865,
        "learning_rate": 2.980627306273063e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.4652,
        "grad_norm": 7.518715858459473,
        "learning_rate": 2.977859778597786e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.4672,
        "grad_norm": 2.7707931995391846,
        "learning_rate": 2.975092250922509e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.4794,
        "grad_norm": 11.314554214477539,
        "learning_rate": 2.9723247232472325e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.5081,
        "grad_norm": 2.8058106899261475,
        "learning_rate": 2.9695571955719558e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.5372,
        "grad_norm": 4.112560749053955,
        "learning_rate": 2.966789667896679e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4638,
        "grad_norm": 3.1963953971862793,
        "learning_rate": 2.9640221402214024e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4727,
        "grad_norm": 8.870346069335938,
        "learning_rate": 2.9612546125461254e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4414,
        "grad_norm": 3.378742218017578,
        "learning_rate": 2.958487084870849e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.5618,
        "grad_norm": 3.1019210815429688,
        "learning_rate": 2.955719557195572e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.4644,
        "grad_norm": 7.480664253234863,
        "learning_rate": 2.9529520295202953e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.6008,
        "grad_norm": 9.678544998168945,
        "learning_rate": 2.9501845018450186e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4443,
        "grad_norm": 2.4273345470428467,
        "learning_rate": 2.9474169741697416e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.419,
        "grad_norm": 4.777332782745361,
        "learning_rate": 2.9446494464944652e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.5056,
        "grad_norm": 2.877722978591919,
        "learning_rate": 2.9418819188191882e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4785,
        "grad_norm": 4.51572322845459,
        "learning_rate": 2.9391143911439118e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.4294,
        "grad_norm": 2.1217048168182373,
        "learning_rate": 2.9363468634686348e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.425,
        "grad_norm": 1.9330921173095703,
        "learning_rate": 2.9335793357933578e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.5037,
        "grad_norm": 5.371467113494873,
        "learning_rate": 2.9308118081180814e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4891,
        "grad_norm": 3.893463373184204,
        "learning_rate": 2.9280442804428044e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4416,
        "grad_norm": 2.169703960418701,
        "learning_rate": 2.9252767527675277e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.43340468406677246,
        "eval_accuracy": 0.82749,
        "eval_precision": 0.7769,
        "eval_recall": 0.91434,
        "eval_f1": 0.84003,
        "eval_runtime": 18.8441,
        "eval_samples_per_second": 57.525,
        "eval_steps_per_second": 3.609,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.3622,
        "grad_norm": 2.5830330848693848,
        "learning_rate": 2.922509225092251e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4456,
        "grad_norm": 4.206839084625244,
        "learning_rate": 2.9197416974169743e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.4987,
        "grad_norm": 5.61771821975708,
        "learning_rate": 2.9169741697416976e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.3538,
        "grad_norm": 14.828376770019531,
        "learning_rate": 2.9142066420664206e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.4767,
        "grad_norm": 2.7111454010009766,
        "learning_rate": 2.911439114391144e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4909,
        "grad_norm": 5.654956817626953,
        "learning_rate": 2.9086715867158672e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.448,
        "grad_norm": 3.3410255908966064,
        "learning_rate": 2.9059040590405905e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.5017,
        "grad_norm": 2.4895873069763184,
        "learning_rate": 2.9031365313653138e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4624,
        "grad_norm": 8.424383163452148,
        "learning_rate": 2.900369003690037e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.4175,
        "grad_norm": 2.526005983352661,
        "learning_rate": 2.89760147601476e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4512,
        "grad_norm": 2.9541807174682617,
        "learning_rate": 2.8948339483394837e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4125,
        "grad_norm": 1.3971539735794067,
        "learning_rate": 2.8920664206642067e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.4844,
        "grad_norm": 1.9542415142059326,
        "learning_rate": 2.8892988929889297e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.4395,
        "grad_norm": 2.8247828483581543,
        "learning_rate": 2.8865313653136533e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3234,
        "grad_norm": 3.164546251296997,
        "learning_rate": 2.8837638376383763e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.5804,
        "grad_norm": 7.302767753601074,
        "learning_rate": 2.8809963099631e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.436,
        "grad_norm": 2.3870086669921875,
        "learning_rate": 2.878228782287823e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.4846,
        "grad_norm": 1.4771311283111572,
        "learning_rate": 2.8754612546125462e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.4662,
        "grad_norm": 2.239032506942749,
        "learning_rate": 2.8726937269372695e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.4051,
        "grad_norm": 4.889848709106445,
        "learning_rate": 2.8699261992619925e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.5719,
        "grad_norm": 2.5021777153015137,
        "learning_rate": 2.867158671586716e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4422,
        "grad_norm": 3.4554593563079834,
        "learning_rate": 2.864391143911439e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.3733,
        "grad_norm": 5.031985759735107,
        "learning_rate": 2.8616236162361624e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.4359,
        "grad_norm": 5.027651786804199,
        "learning_rate": 2.8588560885608857e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.377,
        "grad_norm": 2.133530378341675,
        "learning_rate": 2.856088560885609e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.3506,
        "grad_norm": 3.7167000770568848,
        "learning_rate": 2.8533210332103323e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.4466,
        "grad_norm": 1.4443941116333008,
        "learning_rate": 2.8505535055350553e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.4223853349685669,
        "eval_accuracy": 0.81365,
        "eval_precision": 0.74963,
        "eval_recall": 0.93669,
        "eval_f1": 0.83278,
        "eval_runtime": 19.0084,
        "eval_samples_per_second": 57.027,
        "eval_steps_per_second": 3.577,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.4134,
        "grad_norm": 3.6646251678466797,
        "learning_rate": 2.8477859778597786e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4183,
        "grad_norm": 2.5712220668792725,
        "learning_rate": 2.845018450184502e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.3154,
        "grad_norm": 3.0522823333740234,
        "learning_rate": 2.8422509225092252e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3681,
        "grad_norm": 2.277909278869629,
        "learning_rate": 2.8394833948339482e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.474,
        "grad_norm": 2.539252758026123,
        "learning_rate": 2.8367158671586718e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.4145,
        "grad_norm": 2.3824779987335205,
        "learning_rate": 2.8339483394833948e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.4449,
        "grad_norm": 6.139922142028809,
        "learning_rate": 2.831180811808118e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4392,
        "grad_norm": 1.7360440492630005,
        "learning_rate": 2.8284132841328414e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.3308,
        "grad_norm": 2.744422197341919,
        "learning_rate": 2.8256457564575644e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.5526,
        "grad_norm": 6.294919967651367,
        "learning_rate": 2.822878228782288e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.3433,
        "grad_norm": 2.779564142227173,
        "learning_rate": 2.820110701107011e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.3361,
        "grad_norm": 2.3759255409240723,
        "learning_rate": 2.8173431734317346e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.4259,
        "grad_norm": 1.654173493385315,
        "learning_rate": 2.8145756457564576e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.3927,
        "grad_norm": 1.8863933086395264,
        "learning_rate": 2.811808118081181e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.404,
        "grad_norm": 2.298722743988037,
        "learning_rate": 2.8090405904059042e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.4184,
        "grad_norm": 2.578462600708008,
        "learning_rate": 2.8062730627306272e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3654,
        "grad_norm": 1.3687412738800049,
        "learning_rate": 2.803505535055351e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.4067,
        "grad_norm": 3.5892958641052246,
        "learning_rate": 2.8007380073800738e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3743,
        "grad_norm": 1.0996721982955933,
        "learning_rate": 2.797970479704797e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4913,
        "grad_norm": 2.7923197746276855,
        "learning_rate": 2.7952029520295204e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.4868,
        "grad_norm": 9.611235618591309,
        "learning_rate": 2.7924354243542437e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4621,
        "grad_norm": 5.064711570739746,
        "learning_rate": 2.7896678966789667e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.3442,
        "grad_norm": 3.522136926651001,
        "learning_rate": 2.78690036900369e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.3807,
        "grad_norm": 44.82373809814453,
        "learning_rate": 2.7841328413284133e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.6424,
        "grad_norm": 4.957503318786621,
        "learning_rate": 2.7813653136531366e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3811,
        "grad_norm": 3.753695487976074,
        "learning_rate": 2.77859778597786e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.4878,
        "grad_norm": 4.0420918464660645,
        "learning_rate": 2.775830258302583e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.4172520339488983,
        "eval_accuracy": 0.82841,
        "eval_precision": 0.78537,
        "eval_recall": 0.89944,
        "eval_f1": 0.83854,
        "eval_runtime": 18.9618,
        "eval_samples_per_second": 57.168,
        "eval_steps_per_second": 3.586,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3677,
        "grad_norm": 2.901219367980957,
        "learning_rate": 2.7730627306273065e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3648,
        "grad_norm": 1.8101481199264526,
        "learning_rate": 2.7702952029520295e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.4153,
        "grad_norm": 3.0698907375335693,
        "learning_rate": 2.7675276752767528e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.4248,
        "grad_norm": 5.9033989906311035,
        "learning_rate": 2.764760147601476e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.3871,
        "grad_norm": 2.249232769012451,
        "learning_rate": 2.761992619926199e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.4128,
        "grad_norm": 4.230837345123291,
        "learning_rate": 2.7592250922509227e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3622,
        "grad_norm": 8.218223571777344,
        "learning_rate": 2.7564575645756457e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.4295,
        "grad_norm": 8.566610336303711,
        "learning_rate": 2.753690036900369e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.3869,
        "grad_norm": 1.9880917072296143,
        "learning_rate": 2.7509225092250923e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.4329,
        "grad_norm": 6.626732349395752,
        "learning_rate": 2.7481549815498156e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.4364,
        "grad_norm": 4.074692726135254,
        "learning_rate": 2.745387453874539e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.4515,
        "grad_norm": 3.7972166538238525,
        "learning_rate": 2.742619926199262e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.4075,
        "grad_norm": 6.547538757324219,
        "learning_rate": 2.7398523985239852e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.3513,
        "grad_norm": 13.787576675415039,
        "learning_rate": 2.7370848708487085e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.5147,
        "grad_norm": 3.479750394821167,
        "learning_rate": 2.734317343173432e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.387,
        "grad_norm": 9.984313011169434,
        "learning_rate": 2.731549815498155e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3976,
        "grad_norm": 3.2292301654815674,
        "learning_rate": 2.7287822878228784e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.4196,
        "grad_norm": 2.6740317344665527,
        "learning_rate": 2.7260147601476014e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.4129,
        "grad_norm": 2.6200830936431885,
        "learning_rate": 2.7232472324723247e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.4073,
        "grad_norm": 1.753222107887268,
        "learning_rate": 2.720479704797048e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.3177,
        "grad_norm": 2.3010618686676025,
        "learning_rate": 2.7177121771217713e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.384,
        "grad_norm": 1.8026574850082397,
        "learning_rate": 2.7149446494464946e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3264,
        "grad_norm": 1.6575003862380981,
        "learning_rate": 2.7121771217712176e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3991,
        "grad_norm": 1.5451695919036865,
        "learning_rate": 2.7094095940959413e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.4677,
        "grad_norm": 6.494409561157227,
        "learning_rate": 2.7066420664206642e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.4497,
        "grad_norm": 2.3831658363342285,
        "learning_rate": 2.7038745387453872e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.3235,
        "grad_norm": 2.269655466079712,
        "learning_rate": 2.701107011070111e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.4372095763683319,
        "eval_accuracy": 0.83487,
        "eval_precision": 0.79538,
        "eval_recall": 0.89758,
        "eval_f1": 0.84339,
        "eval_runtime": 18.9764,
        "eval_samples_per_second": 57.124,
        "eval_steps_per_second": 3.583,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3896,
        "grad_norm": 3.417541027069092,
        "learning_rate": 2.6983394833948338e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.439,
        "grad_norm": 3.6545588970184326,
        "learning_rate": 2.6955719557195575e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.3275,
        "grad_norm": 3.517426013946533,
        "learning_rate": 2.6928044280442804e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.4042,
        "grad_norm": 5.056300163269043,
        "learning_rate": 2.6900369003690037e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.512,
        "grad_norm": 2.7246296405792236,
        "learning_rate": 2.687269372693727e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.4735,
        "grad_norm": 1.6220026016235352,
        "learning_rate": 2.6845018450184504e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3876,
        "grad_norm": 4.197608470916748,
        "learning_rate": 2.6817343173431737e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3172,
        "grad_norm": 2.324347734451294,
        "learning_rate": 2.6789667896678966e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.366,
        "grad_norm": 3.5674502849578857,
        "learning_rate": 2.67619926199262e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.4151,
        "grad_norm": 2.0899715423583984,
        "learning_rate": 2.6734317343173432e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.43,
        "grad_norm": 6.1125874519348145,
        "learning_rate": 2.6706642066420666e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3619,
        "grad_norm": 1.4175435304641724,
        "learning_rate": 2.6678966789667895e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.345,
        "grad_norm": 1.1315759420394897,
        "learning_rate": 2.665129151291513e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3638,
        "grad_norm": 2.361693859100342,
        "learning_rate": 2.662361623616236e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.4802,
        "grad_norm": 6.283597469329834,
        "learning_rate": 2.6595940959409594e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3287,
        "grad_norm": 2.055183172225952,
        "learning_rate": 2.6568265682656828e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3494,
        "grad_norm": 2.5719687938690186,
        "learning_rate": 2.6540590405904057e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.3144,
        "grad_norm": 6.3031721115112305,
        "learning_rate": 2.6512915129151294e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3913,
        "grad_norm": 3.351597785949707,
        "learning_rate": 2.6485239852398523e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.3781,
        "grad_norm": 1.7350096702575684,
        "learning_rate": 2.645756457564576e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.3836,
        "grad_norm": 2.103450059890747,
        "learning_rate": 2.642988929889299e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.472,
        "grad_norm": 5.457194805145264,
        "learning_rate": 2.640221402214022e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.3648,
        "grad_norm": 2.778959274291992,
        "learning_rate": 2.6374538745387456e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.4566,
        "grad_norm": 6.645160675048828,
        "learning_rate": 2.6346863468634685e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.325,
        "grad_norm": 6.0842413902282715,
        "learning_rate": 2.6319188191881922e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.4966,
        "grad_norm": 1.854293704032898,
        "learning_rate": 2.629151291512915e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.3631,
        "grad_norm": 3.7543716430664062,
        "learning_rate": 2.6263837638376385e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.42424270510673523,
        "eval_accuracy": 0.8238,
        "eval_precision": 0.75668,
        "eval_recall": 0.94972,
        "eval_f1": 0.84228,
        "eval_runtime": 18.8093,
        "eval_samples_per_second": 57.631,
        "eval_steps_per_second": 3.615,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.4568,
        "grad_norm": 3.73710036277771,
        "learning_rate": 2.6236162361623618e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.4498,
        "grad_norm": 2.0438597202301025,
        "learning_rate": 2.620848708487085e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.3123,
        "grad_norm": 1.6707621812820435,
        "learning_rate": 2.618081180811808e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.4328,
        "grad_norm": 1.6383188962936401,
        "learning_rate": 2.6153136531365313e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.2959,
        "grad_norm": 3.5011236667633057,
        "learning_rate": 2.6125461254612547e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.389,
        "grad_norm": 0.8317691087722778,
        "learning_rate": 2.609778597785978e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.4412,
        "grad_norm": 2.1664397716522217,
        "learning_rate": 2.6070110701107013e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.3914,
        "grad_norm": 0.9258899688720703,
        "learning_rate": 2.6042435424354242e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.3784,
        "grad_norm": 1.0201373100280762,
        "learning_rate": 2.601476014760148e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.3566,
        "grad_norm": 1.616437315940857,
        "learning_rate": 2.598708487084871e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.3778,
        "grad_norm": 1.1591850519180298,
        "learning_rate": 2.595940959409594e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.4059,
        "grad_norm": 7.156895637512207,
        "learning_rate": 2.5931734317343175e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.2734,
        "grad_norm": 1.5378212928771973,
        "learning_rate": 2.5904059040590404e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.3407,
        "grad_norm": 8.393484115600586,
        "learning_rate": 2.587638376383764e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.3635,
        "grad_norm": 3.617398500442505,
        "learning_rate": 2.584870848708487e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.4659,
        "grad_norm": 2.7417948246002197,
        "learning_rate": 2.5821033210332107e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.3169,
        "grad_norm": 1.238415002822876,
        "learning_rate": 2.5793357933579337e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.4185,
        "grad_norm": 5.408350944519043,
        "learning_rate": 2.5765682656826566e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.4207,
        "grad_norm": 2.8834095001220703,
        "learning_rate": 2.5738007380073803e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.3273,
        "grad_norm": 5.646585941314697,
        "learning_rate": 2.5710332103321032e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.43,
        "grad_norm": 9.088579177856445,
        "learning_rate": 2.5682656826568266e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.313,
        "grad_norm": 1.4664897918701172,
        "learning_rate": 2.56549815498155e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.3391,
        "grad_norm": 1.0027674436569214,
        "learning_rate": 2.5627306273062732e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.5042,
        "grad_norm": 3.706731081008911,
        "learning_rate": 2.5599630996309965e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.4037,
        "grad_norm": 1.446839451789856,
        "learning_rate": 2.5571955719557198e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.3782,
        "grad_norm": 2.417497396469116,
        "learning_rate": 2.5544280442804428e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.3564,
        "grad_norm": 1.302075982093811,
        "learning_rate": 2.551660516605166e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.40347620844841003,
        "eval_accuracy": 0.83856,
        "eval_precision": 0.80167,
        "eval_recall": 0.89572,
        "eval_f1": 0.84609,
        "eval_runtime": 18.7821,
        "eval_samples_per_second": 57.715,
        "eval_steps_per_second": 3.62,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.4078,
        "grad_norm": 5.592131614685059,
        "learning_rate": 2.5488929889298894e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3646,
        "grad_norm": 1.309273600578308,
        "learning_rate": 2.5461254612546127e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.3032,
        "grad_norm": 2.8253207206726074,
        "learning_rate": 2.543357933579336e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.3923,
        "grad_norm": 5.903370380401611,
        "learning_rate": 2.540590405904059e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.4677,
        "grad_norm": 14.257733345031738,
        "learning_rate": 2.5378228782287826e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.3216,
        "grad_norm": 2.652529001235962,
        "learning_rate": 2.5350553505535056e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.3953,
        "grad_norm": 8.133503913879395,
        "learning_rate": 2.5322878228782285e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.3339,
        "grad_norm": 5.84971284866333,
        "learning_rate": 2.5295202952029522e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.434,
        "grad_norm": 15.281270980834961,
        "learning_rate": 2.526752767527675e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.3554,
        "grad_norm": 2.294750213623047,
        "learning_rate": 2.5239852398523988e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.4222,
        "grad_norm": 3.354562282562256,
        "learning_rate": 2.5212177121771218e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.2615,
        "grad_norm": 2.2833433151245117,
        "learning_rate": 2.518450184501845e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.2819,
        "grad_norm": 2.072143077850342,
        "learning_rate": 2.5156826568265684e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.4327,
        "grad_norm": 1.0658140182495117,
        "learning_rate": 2.5129151291512914e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3896,
        "grad_norm": 3.570798873901367,
        "learning_rate": 2.510147601476015e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.2872,
        "grad_norm": 13.412202835083008,
        "learning_rate": 2.507380073800738e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.4215,
        "grad_norm": 2.8665521144866943,
        "learning_rate": 2.5046125461254613e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.2518,
        "grad_norm": 1.1483436822891235,
        "learning_rate": 2.5018450184501846e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.3548,
        "grad_norm": 4.506441593170166,
        "learning_rate": 2.499077490774908e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3256,
        "grad_norm": 4.326079368591309,
        "learning_rate": 2.4963099630996312e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3858,
        "grad_norm": 1.4900307655334473,
        "learning_rate": 2.4935424354243545e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.4017,
        "grad_norm": 8.765863418579102,
        "learning_rate": 2.4907749077490775e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.3716,
        "grad_norm": 5.478677749633789,
        "learning_rate": 2.4880073800738008e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.391,
        "grad_norm": 2.847322702407837,
        "learning_rate": 2.485239852398524e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.3512,
        "grad_norm": 1.6888281106948853,
        "learning_rate": 2.482472324723247e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.3883,
        "grad_norm": 1.170158863067627,
        "learning_rate": 2.4797047970479707e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.353,
        "grad_norm": 2.395803213119507,
        "learning_rate": 2.4769372693726937e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.41175565123558044,
        "eval_accuracy": 0.84041,
        "eval_precision": 0.80435,
        "eval_recall": 0.89572,
        "eval_f1": 0.84758,
        "eval_runtime": 18.7895,
        "eval_samples_per_second": 57.692,
        "eval_steps_per_second": 3.619,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.3421,
        "grad_norm": 1.0539706945419312,
        "learning_rate": 2.4741697416974173e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.4901,
        "grad_norm": 5.135354518890381,
        "learning_rate": 2.4714022140221403e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3563,
        "grad_norm": 4.263775825500488,
        "learning_rate": 2.4686346863468633e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.3351,
        "grad_norm": 2.1981940269470215,
        "learning_rate": 2.465867158671587e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.2857,
        "grad_norm": 1.8478235006332397,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3666,
        "grad_norm": 1.574064016342163,
        "learning_rate": 2.4603321033210335e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.42,
        "grad_norm": 3.3476202487945557,
        "learning_rate": 2.4575645756457565e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.4207,
        "grad_norm": 1.614974856376648,
        "learning_rate": 2.4547970479704798e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.3586,
        "grad_norm": 4.171999931335449,
        "learning_rate": 2.452029520295203e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.3239,
        "grad_norm": 2.084728717803955,
        "learning_rate": 2.449261992619926e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.3523,
        "grad_norm": 1.500476598739624,
        "learning_rate": 2.4464944649446494e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3272,
        "grad_norm": 2.827792167663574,
        "learning_rate": 2.4437269372693727e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.3958,
        "grad_norm": 3.6265556812286377,
        "learning_rate": 2.440959409594096e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3921,
        "grad_norm": 3.060948133468628,
        "learning_rate": 2.4381918819188193e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.3714,
        "grad_norm": 2.4350459575653076,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.3581,
        "grad_norm": 2.3202602863311768,
        "learning_rate": 2.4326568265682656e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.2669,
        "grad_norm": 1.603737235069275,
        "learning_rate": 2.4298892988929892e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.3169,
        "grad_norm": 2.601705551147461,
        "learning_rate": 2.4271217712177122e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.332,
        "grad_norm": 1.4121190309524536,
        "learning_rate": 2.4243542435424355e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.3407,
        "grad_norm": 5.532303810119629,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.4556,
        "grad_norm": 2.965240240097046,
        "learning_rate": 2.4188191881918818e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.3354,
        "grad_norm": 1.8887128829956055,
        "learning_rate": 2.4160516605166054e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.3951,
        "grad_norm": 6.237536430358887,
        "learning_rate": 2.4132841328413284e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.3734,
        "grad_norm": 1.7367265224456787,
        "learning_rate": 2.410516605166052e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.3263,
        "grad_norm": 0.8789992332458496,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.3474,
        "grad_norm": 4.831303596496582,
        "learning_rate": 2.404981549815498e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.3711,
        "grad_norm": 24.79281997680664,
        "learning_rate": 2.4022140221402216e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.3909899890422821,
        "eval_accuracy": 0.8524,
        "eval_precision": 0.81157,
        "eval_recall": 0.91434,
        "eval_f1": 0.85989,
        "eval_runtime": 19.261,
        "eval_samples_per_second": 56.28,
        "eval_steps_per_second": 3.53,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.3095,
        "grad_norm": 1.9018421173095703,
        "learning_rate": 2.3994464944649446e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3734,
        "grad_norm": 2.684140682220459,
        "learning_rate": 2.396678966789668e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.3072,
        "grad_norm": 2.3835721015930176,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.2685,
        "grad_norm": 4.112637519836426,
        "learning_rate": 2.3911439114391145e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.3917,
        "grad_norm": 4.034666061401367,
        "learning_rate": 2.3883763837638378e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.3147,
        "grad_norm": 9.91657543182373,
        "learning_rate": 2.3856088560885608e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.3883,
        "grad_norm": 4.408146858215332,
        "learning_rate": 2.382841328413284e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.3292,
        "grad_norm": 3.6175408363342285,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.3653,
        "grad_norm": 9.880833625793457,
        "learning_rate": 2.3773062730627307e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.4417,
        "grad_norm": 1.1215471029281616,
        "learning_rate": 2.374538745387454e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.4128,
        "grad_norm": 1.3673774003982544,
        "learning_rate": 2.3717712177121773e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.3008,
        "grad_norm": 3.6091158390045166,
        "learning_rate": 2.3690036900369003e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.3062,
        "grad_norm": 2.5064470767974854,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.4785,
        "grad_norm": 3.4622724056243896,
        "learning_rate": 2.363468634686347e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.3727,
        "grad_norm": 2.1397013664245605,
        "learning_rate": 2.3607011070110702e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.294,
        "grad_norm": 1.1593786478042603,
        "learning_rate": 2.3579335793357935e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.3814,
        "grad_norm": 2.8280272483825684,
        "learning_rate": 2.3551660516605165e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3358,
        "grad_norm": 0.6540192365646362,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.3116,
        "grad_norm": 1.4646679162979126,
        "learning_rate": 2.349630996309963e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.403,
        "grad_norm": 1.306453824043274,
        "learning_rate": 2.3468634686346864e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3327,
        "grad_norm": 2.7425966262817383,
        "learning_rate": 2.3440959409594097e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.3778,
        "grad_norm": 4.664613723754883,
        "learning_rate": 2.3413284132841327e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.3957,
        "grad_norm": 3.171605110168457,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.2882,
        "grad_norm": 2.518850326538086,
        "learning_rate": 2.3357933579335793e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.4475,
        "grad_norm": 18.93201446533203,
        "learning_rate": 2.3330258302583026e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.3102,
        "grad_norm": 7.163301944732666,
        "learning_rate": 2.330258302583026e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.4068,
        "grad_norm": 10.829438209533691,
        "learning_rate": 2.3274907749077492e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.37544578313827515,
        "eval_accuracy": 0.85517,
        "eval_precision": 0.81148,
        "eval_recall": 0.92179,
        "eval_f1": 0.86312,
        "eval_runtime": 18.7898,
        "eval_samples_per_second": 57.691,
        "eval_steps_per_second": 3.619,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.357,
        "grad_norm": 2.576138973236084,
        "learning_rate": 2.3247232472324725e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.2766,
        "grad_norm": 1.6813910007476807,
        "learning_rate": 2.3219557195571955e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3875,
        "grad_norm": 8.060397148132324,
        "learning_rate": 2.3191881918819188e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.3064,
        "grad_norm": 6.501482963562012,
        "learning_rate": 2.316420664206642e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.3623,
        "grad_norm": 2.020702600479126,
        "learning_rate": 2.3136531365313654e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.3796,
        "grad_norm": 2.3962230682373047,
        "learning_rate": 2.3108856088560884e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3975,
        "grad_norm": 2.835312843322754,
        "learning_rate": 2.308118081180812e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.4044,
        "grad_norm": 3.5037288665771484,
        "learning_rate": 2.305350553505535e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.2766,
        "grad_norm": 3.5240230560302734,
        "learning_rate": 2.3025830258302583e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.3597,
        "grad_norm": 7.415501594543457,
        "learning_rate": 2.2998154981549816e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.3611,
        "grad_norm": 8.925466537475586,
        "learning_rate": 2.2970479704797046e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.4015,
        "grad_norm": 2.4740140438079834,
        "learning_rate": 2.2942804428044282e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.3589,
        "grad_norm": 2.3219449520111084,
        "learning_rate": 2.2915129151291512e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.3466,
        "grad_norm": 3.2274434566497803,
        "learning_rate": 2.288745387453875e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.3041,
        "grad_norm": 5.34296989440918,
        "learning_rate": 2.2859778597785978e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.2955,
        "grad_norm": 4.524832725524902,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.3142,
        "grad_norm": 3.498455047607422,
        "learning_rate": 2.2804428044280444e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.4572,
        "grad_norm": 4.026516437530518,
        "learning_rate": 2.2776752767527674e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.2537,
        "grad_norm": 2.9758691787719727,
        "learning_rate": 2.274907749077491e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.3166,
        "grad_norm": 2.0351130962371826,
        "learning_rate": 2.272140221402214e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.3359,
        "grad_norm": 1.9766842126846313,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.2727,
        "grad_norm": 3.394115686416626,
        "learning_rate": 2.2666051660516606e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3242,
        "grad_norm": 1.7047268152236938,
        "learning_rate": 2.263837638376384e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.3927,
        "grad_norm": 1.0195997953414917,
        "learning_rate": 2.261070110701107e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.2775,
        "grad_norm": 5.759815216064453,
        "learning_rate": 2.2583025830258302e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.3292,
        "grad_norm": 0.6677325963973999,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.4358,
        "grad_norm": 1.3493198156356812,
        "learning_rate": 2.252767527675277e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.3515,
        "grad_norm": 2.7250304222106934,
        "learning_rate": 2.25e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.38425111770629883,
        "eval_accuracy": 0.85424,
        "eval_precision": 0.80713,
        "eval_recall": 0.92737,
        "eval_f1": 0.86308,
        "eval_runtime": 18.7125,
        "eval_samples_per_second": 57.929,
        "eval_steps_per_second": 3.634,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.3113,
        "grad_norm": 1.137189269065857,
        "learning_rate": 2.247232472324723e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.3252,
        "grad_norm": 2.42665958404541,
        "learning_rate": 2.2444649446494468e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.216,
        "grad_norm": 19.721933364868164,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.4082,
        "grad_norm": 38.274658203125,
        "learning_rate": 2.238929889298893e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3238,
        "grad_norm": 3.0444815158843994,
        "learning_rate": 2.2361623616236163e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.2798,
        "grad_norm": 0.8841883540153503,
        "learning_rate": 2.2333948339483393e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.3238,
        "grad_norm": 8.73836898803711,
        "learning_rate": 2.230627306273063e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.3324,
        "grad_norm": 2.614797592163086,
        "learning_rate": 2.227859778597786e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.4119,
        "grad_norm": 1.4854278564453125,
        "learning_rate": 2.2250922509225092e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3935,
        "grad_norm": 2.683598041534424,
        "learning_rate": 2.2223247232472325e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.3963,
        "grad_norm": 2.1520698070526123,
        "learning_rate": 2.219557195571956e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.3454,
        "grad_norm": 1.7617378234863281,
        "learning_rate": 2.216789667896679e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.3723,
        "grad_norm": 3.1443002223968506,
        "learning_rate": 2.214022140221402e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.4398,
        "grad_norm": 4.898059368133545,
        "learning_rate": 2.2112546125461254e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.3838,
        "grad_norm": 0.9362784028053284,
        "learning_rate": 2.2084870848708487e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.2848,
        "grad_norm": 2.8148269653320312,
        "learning_rate": 2.205719557195572e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3076,
        "grad_norm": 2.0332250595092773,
        "learning_rate": 2.2029520295202954e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.3484,
        "grad_norm": 1.7465784549713135,
        "learning_rate": 2.2001845018450187e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2312,
        "grad_norm": 6.050868988037109,
        "learning_rate": 2.1974169741697416e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.4101,
        "grad_norm": 14.497750282287598,
        "learning_rate": 2.194649446494465e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.4067,
        "grad_norm": 14.7941312789917,
        "learning_rate": 2.1918819188191882e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.3443,
        "grad_norm": 3.0454623699188232,
        "learning_rate": 2.1891143911439116e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.4051,
        "grad_norm": 5.284335136413574,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.3751,
        "grad_norm": 60.872291564941406,
        "learning_rate": 2.1835793357933578e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.4222,
        "grad_norm": 2.0734903812408447,
        "learning_rate": 2.1808118081180815e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.332,
        "grad_norm": 2.094322919845581,
        "learning_rate": 2.1780442804428044e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.3608,
        "grad_norm": 4.421166896820068,
        "learning_rate": 2.1752767527675274e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.4097716808319092,
        "eval_accuracy": 0.84502,
        "eval_precision": 0.78964,
        "eval_recall": 0.93669,
        "eval_f1": 0.8569,
        "eval_runtime": 18.8069,
        "eval_samples_per_second": 57.639,
        "eval_steps_per_second": 3.616,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.3365,
        "grad_norm": 2.509002208709717,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.422,
        "grad_norm": 3.3143928050994873,
        "learning_rate": 2.169741697416974e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.4057,
        "grad_norm": 4.878128528594971,
        "learning_rate": 2.1669741697416977e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.4641,
        "grad_norm": 2.2275233268737793,
        "learning_rate": 2.1642066420664206e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.3416,
        "grad_norm": 2.8300375938415527,
        "learning_rate": 2.161439114391144e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.284,
        "grad_norm": 2.7748777866363525,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.2838,
        "grad_norm": 1.2909204959869385,
        "learning_rate": 2.1559040590405906e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.2865,
        "grad_norm": 2.029417037963867,
        "learning_rate": 2.153136531365314e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.4054,
        "grad_norm": 1.3768385648727417,
        "learning_rate": 2.150369003690037e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.4324,
        "grad_norm": 3.0482101440429688,
        "learning_rate": 2.14760147601476e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.3252,
        "grad_norm": 11.889062881469727,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.2917,
        "grad_norm": 1.7738083600997925,
        "learning_rate": 2.1420664206642068e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.3609,
        "grad_norm": 61.264888763427734,
        "learning_rate": 2.1392988929889297e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.3708,
        "grad_norm": 3.3544297218322754,
        "learning_rate": 2.1365313653136534e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.2993,
        "grad_norm": 1.4574998617172241,
        "learning_rate": 2.1337638376383763e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.3518,
        "grad_norm": 2.039048194885254,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.3036,
        "grad_norm": 2.0348222255706787,
        "learning_rate": 2.128228782287823e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.3501,
        "grad_norm": 2.943702220916748,
        "learning_rate": 2.125461254612546e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.3336,
        "grad_norm": 3.6246566772460938,
        "learning_rate": 2.1226937269372696e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.3457,
        "grad_norm": 3.395501136779785,
        "learning_rate": 2.1199261992619925e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2914,
        "grad_norm": 2.4606375694274902,
        "learning_rate": 2.1171586715867162e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.3397,
        "grad_norm": 1.0500500202178955,
        "learning_rate": 2.114391143911439e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.3881,
        "grad_norm": 5.052217960357666,
        "learning_rate": 2.111623616236162e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.4352,
        "grad_norm": 9.22000789642334,
        "learning_rate": 2.1088560885608858e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.274,
        "grad_norm": 4.559703826904297,
        "learning_rate": 2.1060885608856087e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2856,
        "grad_norm": 3.4478166103363037,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.3835,
        "grad_norm": 3.290621519088745,
        "learning_rate": 2.1005535055350554e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.41978827118873596,
        "eval_accuracy": 0.85148,
        "eval_precision": 0.79102,
        "eval_recall": 0.95158,
        "eval_f1": 0.86391,
        "eval_runtime": 18.7993,
        "eval_samples_per_second": 57.662,
        "eval_steps_per_second": 3.617,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.4316,
        "grad_norm": 33.951942443847656,
        "learning_rate": 2.0977859778597787e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.3441,
        "grad_norm": 5.600779056549072,
        "learning_rate": 2.095018450184502e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.3558,
        "grad_norm": 1.927927851676941,
        "learning_rate": 2.0922509225092253e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.3556,
        "grad_norm": 0.9052586555480957,
        "learning_rate": 2.0894833948339482e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2991,
        "grad_norm": 3.0579986572265625,
        "learning_rate": 2.0867158671586716e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.3754,
        "grad_norm": 1.472377896308899,
        "learning_rate": 2.083948339483395e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.3815,
        "grad_norm": 4.343798637390137,
        "learning_rate": 2.0811808118081182e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.344,
        "grad_norm": 4.854202747344971,
        "learning_rate": 2.0784132841328415e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.4213,
        "grad_norm": 13.300334930419922,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.3536,
        "grad_norm": 128.68484497070312,
        "learning_rate": 2.072878228782288e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.337,
        "grad_norm": 11.323797225952148,
        "learning_rate": 2.070110701107011e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.4101,
        "grad_norm": 19.661714553833008,
        "learning_rate": 2.0673431734317344e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.3876,
        "grad_norm": 3.0512847900390625,
        "learning_rate": 2.0645756457564577e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.3059,
        "grad_norm": 0.9329705834388733,
        "learning_rate": 2.0618081180811806e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.3193,
        "grad_norm": 1.505866527557373,
        "learning_rate": 2.0590405904059043e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.3043,
        "grad_norm": 1.2923734188079834,
        "learning_rate": 2.0562730627306273e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.4048,
        "grad_norm": 2.114849328994751,
        "learning_rate": 2.053505535055351e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.3857,
        "grad_norm": 1.628783941268921,
        "learning_rate": 2.050738007380074e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.3336,
        "grad_norm": 1.4391783475875854,
        "learning_rate": 2.047970479704797e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.345,
        "grad_norm": 6.127629280090332,
        "learning_rate": 2.0452029520295205e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.3389,
        "grad_norm": 0.6422023773193359,
        "learning_rate": 2.0424354243542435e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.3491,
        "grad_norm": 1.3118438720703125,
        "learning_rate": 2.0396678966789668e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.3626,
        "grad_norm": 3.018212080001831,
        "learning_rate": 2.03690036900369e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.3725,
        "grad_norm": 16.83941078186035,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.3255,
        "grad_norm": 2.559720754623413,
        "learning_rate": 2.0313653136531367e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.364,
        "grad_norm": 3.939138889312744,
        "learning_rate": 2.02859778597786e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.3804,
        "grad_norm": 3.717235803604126,
        "learning_rate": 2.025830258302583e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.4344978332519531,
        "eval_accuracy": 0.84133,
        "eval_precision": 0.80776,
        "eval_recall": 0.89199,
        "eval_f1": 0.84779,
        "eval_runtime": 18.7961,
        "eval_samples_per_second": 57.672,
        "eval_steps_per_second": 3.618,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.381,
        "grad_norm": 3.347667932510376,
        "learning_rate": 2.0230627306273063e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.4238,
        "grad_norm": 3.8256959915161133,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.3211,
        "grad_norm": 4.376001834869385,
        "learning_rate": 2.017527675276753e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.2962,
        "grad_norm": 6.590695381164551,
        "learning_rate": 2.0147601476014762e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.2783,
        "grad_norm": 0.5709701776504517,
        "learning_rate": 2.011992619926199e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.3929,
        "grad_norm": 13.463882446289062,
        "learning_rate": 2.0092250922509228e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.4479,
        "grad_norm": 2.2716338634490967,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.3119,
        "grad_norm": 1.5307672023773193,
        "learning_rate": 2.0036900369003687e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.3952,
        "grad_norm": 6.809060573577881,
        "learning_rate": 2.0009225092250924e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.4176,
        "grad_norm": 2.3709864616394043,
        "learning_rate": 1.9981549815498154e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.3762,
        "grad_norm": 2.1240861415863037,
        "learning_rate": 1.995387453874539e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.2716,
        "grad_norm": 68.06183624267578,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.3094,
        "grad_norm": 1.4933971166610718,
        "learning_rate": 1.9898523985239853e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.33,
        "grad_norm": 1.1480581760406494,
        "learning_rate": 1.9870848708487086e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.3014,
        "grad_norm": 12.88959789276123,
        "learning_rate": 1.9843173431734316e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.3395,
        "grad_norm": 14.011805534362793,
        "learning_rate": 1.9815498154981552e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.3224,
        "grad_norm": 23.47857666015625,
        "learning_rate": 1.9787822878228782e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.2288,
        "grad_norm": 0.823837161064148,
        "learning_rate": 1.9760147601476015e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.4976,
        "grad_norm": 5.765155792236328,
        "learning_rate": 1.9732472324723248e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.3489,
        "grad_norm": 2.082550048828125,
        "learning_rate": 1.970479704797048e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.3959,
        "grad_norm": 2.9201362133026123,
        "learning_rate": 1.9677121771217714e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.4042,
        "grad_norm": 2.9255332946777344,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.2969,
        "grad_norm": 8.271029472351074,
        "learning_rate": 1.9621771217712177e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.3201,
        "grad_norm": 12.003325462341309,
        "learning_rate": 1.959409594095941e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.3451,
        "grad_norm": 1.838702917098999,
        "learning_rate": 1.9566420664206643e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.3636,
        "grad_norm": 16.839618682861328,
        "learning_rate": 1.9538745387453873e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.3193,
        "grad_norm": 8.276256561279297,
        "learning_rate": 1.951107011070111e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.3888438045978546,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.79811,
        "eval_recall": 0.94227,
        "eval_f1": 0.86422,
        "eval_runtime": 18.7677,
        "eval_samples_per_second": 57.759,
        "eval_steps_per_second": 3.623,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.2951,
        "grad_norm": 5.012938499450684,
        "learning_rate": 1.948339483394834e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.3887,
        "grad_norm": 1.3363832235336304,
        "learning_rate": 1.9455719557195575e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.2863,
        "grad_norm": 2.507425546646118,
        "learning_rate": 1.9428044280442805e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.2176,
        "grad_norm": 1.270237922668457,
        "learning_rate": 1.9400369003690035e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.3407,
        "grad_norm": 1.6859947443008423,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.2941,
        "grad_norm": 2.9313464164733887,
        "learning_rate": 1.93450184501845e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.4766,
        "grad_norm": 15.660062789916992,
        "learning_rate": 1.9317343173431737e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.3535,
        "grad_norm": 16.122547149658203,
        "learning_rate": 1.9289667896678967e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.286,
        "grad_norm": 0.6987468004226685,
        "learning_rate": 1.92619926199262e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.2996,
        "grad_norm": 1.6883245706558228,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.2752,
        "grad_norm": 1.7238761186599731,
        "learning_rate": 1.9206642066420663e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.2922,
        "grad_norm": 3.245406150817871,
        "learning_rate": 1.9178966789667896e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.3255,
        "grad_norm": 1.8400362730026245,
        "learning_rate": 1.915129151291513e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.3198,
        "grad_norm": 1.6360589265823364,
        "learning_rate": 1.9123616236162362e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.2671,
        "grad_norm": 2.0282037258148193,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.3366,
        "grad_norm": 1.3123918771743774,
        "learning_rate": 1.9068265682656828e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.2986,
        "grad_norm": 1.5326285362243652,
        "learning_rate": 1.9040590405904058e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.2804,
        "grad_norm": 13.250617027282715,
        "learning_rate": 1.901291512915129e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.3889,
        "grad_norm": 5.53541898727417,
        "learning_rate": 1.8985239852398524e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.2663,
        "grad_norm": 2.461705446243286,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.4135,
        "grad_norm": 3.382816791534424,
        "learning_rate": 1.892988929889299e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.3436,
        "grad_norm": 2.0448055267333984,
        "learning_rate": 1.890221402214022e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.3093,
        "grad_norm": 6.576246738433838,
        "learning_rate": 1.8874538745387456e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.3408,
        "grad_norm": 6.965133190155029,
        "learning_rate": 1.8846863468634686e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.4296,
        "grad_norm": 3.9343342781066895,
        "learning_rate": 1.8819188191881922e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.3211,
        "grad_norm": 4.302042484283447,
        "learning_rate": 1.8791512915129152e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.3334,
        "grad_norm": 1.5811543464660645,
        "learning_rate": 1.8763837638376382e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.38909438252449036,
        "eval_accuracy": 0.85886,
        "eval_precision": 0.82432,
        "eval_recall": 0.90875,
        "eval_f1": 0.86448,
        "eval_runtime": 18.7777,
        "eval_samples_per_second": 57.728,
        "eval_steps_per_second": 3.621,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.304,
        "grad_norm": 4.757859706878662,
        "learning_rate": 1.8736162361623618e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.3213,
        "grad_norm": 2.402888774871826,
        "learning_rate": 1.8708487084870848e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.2763,
        "grad_norm": 2.6930744647979736,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.2776,
        "grad_norm": 1.857816457748413,
        "learning_rate": 1.8653136531365314e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.3363,
        "grad_norm": 2.792476177215576,
        "learning_rate": 1.8625461254612547e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.2485,
        "grad_norm": 0.7825570702552795,
        "learning_rate": 1.859778597785978e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.2475,
        "grad_norm": 0.9567354321479797,
        "learning_rate": 1.857011070110701e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.3656,
        "grad_norm": 3.402165174484253,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.4448,
        "grad_norm": 3.6288063526153564,
        "learning_rate": 1.8514760147601476e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.3189,
        "grad_norm": 1.1056077480316162,
        "learning_rate": 1.848708487084871e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.3611,
        "grad_norm": 2.822622776031494,
        "learning_rate": 1.8459409594095942e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.3452,
        "grad_norm": 1.9484448432922363,
        "learning_rate": 1.8431734317343175e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.2918,
        "grad_norm": 2.6329052448272705,
        "learning_rate": 1.8404059040590405e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.2924,
        "grad_norm": 2.253720760345459,
        "learning_rate": 1.8376383763837638e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.4107,
        "grad_norm": 3.8745551109313965,
        "learning_rate": 1.834870848708487e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.2967,
        "grad_norm": 31.352102279663086,
        "learning_rate": 1.8321033210332104e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.3357,
        "grad_norm": 5.18865442276001,
        "learning_rate": 1.8293357933579337e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2904,
        "grad_norm": 5.601133823394775,
        "learning_rate": 1.8265682656826567e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.3521,
        "grad_norm": 2.4481747150421143,
        "learning_rate": 1.8238007380073803e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.2905,
        "grad_norm": 2.262268304824829,
        "learning_rate": 1.8210332103321033e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.3473,
        "grad_norm": 2.9708943367004395,
        "learning_rate": 1.8182656826568266e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.3234,
        "grad_norm": 5.322345733642578,
        "learning_rate": 1.81549815498155e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.3014,
        "grad_norm": 8.08459186553955,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.3777,
        "grad_norm": 1.0284574031829834,
        "learning_rate": 1.8099630996309965e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.2875,
        "grad_norm": 3.365229606628418,
        "learning_rate": 1.8071955719557195e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.4068,
        "grad_norm": 1.7313251495361328,
        "learning_rate": 1.8044280442804428e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.4186,
        "grad_norm": 5.18381404876709,
        "learning_rate": 1.801660516605166e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.3622717559337616,
        "eval_accuracy": 0.86255,
        "eval_precision": 0.8266,
        "eval_recall": 0.91434,
        "eval_f1": 0.86826,
        "eval_runtime": 18.7576,
        "eval_samples_per_second": 57.79,
        "eval_steps_per_second": 3.625,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.3181,
        "grad_norm": 1.4971097707748413,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.2995,
        "grad_norm": 2.5892837047576904,
        "learning_rate": 1.7961254612546127e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.3016,
        "grad_norm": 1.6356370449066162,
        "learning_rate": 1.7933579335793357e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.2751,
        "grad_norm": 4.876714706420898,
        "learning_rate": 1.790590405904059e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.3765,
        "grad_norm": 5.04373025894165,
        "learning_rate": 1.7878228782287823e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.2746,
        "grad_norm": 4.383419513702393,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.2346,
        "grad_norm": 7.249710559844971,
        "learning_rate": 1.7822878228782286e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.3419,
        "grad_norm": 7.714144706726074,
        "learning_rate": 1.7795202952029522e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.3148,
        "grad_norm": 9.562713623046875,
        "learning_rate": 1.7767527675276752e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.2399,
        "grad_norm": 2.6287641525268555,
        "learning_rate": 1.7739852398523985e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.4048,
        "grad_norm": 9.620586395263672,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.3575,
        "grad_norm": 7.1836347579956055,
        "learning_rate": 1.7684501845018448e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.2956,
        "grad_norm": 3.066749334335327,
        "learning_rate": 1.7656826568265684e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.299,
        "grad_norm": 7.906862735748291,
        "learning_rate": 1.7629151291512914e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.3079,
        "grad_norm": 2.165341377258301,
        "learning_rate": 1.760147601476015e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.2584,
        "grad_norm": 1.3923568725585938,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.3095,
        "grad_norm": 3.438668966293335,
        "learning_rate": 1.7546125461254613e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.4031,
        "grad_norm": 5.566425800323486,
        "learning_rate": 1.7518450184501846e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.213,
        "grad_norm": 4.015777587890625,
        "learning_rate": 1.7490774907749076e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.2874,
        "grad_norm": 0.47713157534599304,
        "learning_rate": 1.7463099630996313e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.2711,
        "grad_norm": 29.27676010131836,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.387,
        "grad_norm": 1.5711418390274048,
        "learning_rate": 1.7407749077490775e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.2733,
        "grad_norm": 10.879556655883789,
        "learning_rate": 1.738007380073801e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.264,
        "grad_norm": 3.1102800369262695,
        "learning_rate": 1.735239852398524e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.2883,
        "grad_norm": 1.7405099868774414,
        "learning_rate": 1.732472324723247e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.3893,
        "grad_norm": 1.711177945137024,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.3055,
        "grad_norm": 2.7145721912384033,
        "learning_rate": 1.7269372693726937e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.3773176968097687,
        "eval_accuracy": 0.87085,
        "eval_precision": 0.82594,
        "eval_recall": 0.93669,
        "eval_f1": 0.87784,
        "eval_runtime": 18.7684,
        "eval_samples_per_second": 57.757,
        "eval_steps_per_second": 3.623,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.3534,
        "grad_norm": 2.9198131561279297,
        "learning_rate": 1.724169741697417e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.3047,
        "grad_norm": 0.8934934735298157,
        "learning_rate": 1.7214022140221404e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.2761,
        "grad_norm": 1.1409231424331665,
        "learning_rate": 1.7186346863468633e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.3154,
        "grad_norm": 7.619491100311279,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.2676,
        "grad_norm": 17.989837646484375,
        "learning_rate": 1.71309963099631e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.3845,
        "grad_norm": 4.484813213348389,
        "learning_rate": 1.7103321033210332e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.2515,
        "grad_norm": 1.289429783821106,
        "learning_rate": 1.7075645756457566e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.3251,
        "grad_norm": 0.9001436829566956,
        "learning_rate": 1.7047970479704795e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2505,
        "grad_norm": 0.8793818950653076,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.2581,
        "grad_norm": 3.274986505508423,
        "learning_rate": 1.699261992619926e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.4238,
        "grad_norm": 16.361663818359375,
        "learning_rate": 1.6964944649446494e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.3608,
        "grad_norm": 1.6214231252670288,
        "learning_rate": 1.6937269372693727e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.3496,
        "grad_norm": 1.7849270105361938,
        "learning_rate": 1.690959409594096e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.1893,
        "grad_norm": 0.747342050075531,
        "learning_rate": 1.6881918819188194e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.4099,
        "grad_norm": 27.065513610839844,
        "learning_rate": 1.6854243542435423e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.3089,
        "grad_norm": 2.979269027709961,
        "learning_rate": 1.6826568265682656e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.2518,
        "grad_norm": 2.4977526664733887,
        "learning_rate": 1.679889298892989e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.3117,
        "grad_norm": 5.362060070037842,
        "learning_rate": 1.6771217712177123e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.1692,
        "grad_norm": 1.633731722831726,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.2927,
        "grad_norm": 1.6495890617370605,
        "learning_rate": 1.671586715867159e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.3095,
        "grad_norm": 1.5267120599746704,
        "learning_rate": 1.668819188191882e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.2619,
        "grad_norm": 16.31435775756836,
        "learning_rate": 1.666051660516605e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.337,
        "grad_norm": 4.964962959289551,
        "learning_rate": 1.6632841328413285e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.2222,
        "grad_norm": 2.170588254928589,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.3128,
        "grad_norm": 3.4129109382629395,
        "learning_rate": 1.657749077490775e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.3012,
        "grad_norm": 2.4125864505767822,
        "learning_rate": 1.654981549815498e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.3467,
        "grad_norm": 2.4282920360565186,
        "learning_rate": 1.6522140221402217e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.3922916352748871,
        "eval_accuracy": 0.86255,
        "eval_precision": 0.81596,
        "eval_recall": 0.93296,
        "eval_f1": 0.87055,
        "eval_runtime": 18.7568,
        "eval_samples_per_second": 57.792,
        "eval_steps_per_second": 3.625,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.2941,
        "grad_norm": 1.053921103477478,
        "learning_rate": 1.6494464944649447e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.4353,
        "grad_norm": 4.963919162750244,
        "learning_rate": 1.6466789667896676e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.3211,
        "grad_norm": 5.909135818481445,
        "learning_rate": 1.6439114391143913e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.2943,
        "grad_norm": 0.8743127584457397,
        "learning_rate": 1.6411439114391142e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2868,
        "grad_norm": 2.0964324474334717,
        "learning_rate": 1.638376383763838e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.4009,
        "grad_norm": 4.767509460449219,
        "learning_rate": 1.635608856088561e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.3062,
        "grad_norm": 1.7882139682769775,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2938,
        "grad_norm": 2.175173044204712,
        "learning_rate": 1.6300738007380075e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.282,
        "grad_norm": 5.512359619140625,
        "learning_rate": 1.6273062730627308e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.2559,
        "grad_norm": 1.6041581630706787,
        "learning_rate": 1.624538745387454e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.36,
        "grad_norm": 20.804214477539062,
        "learning_rate": 1.621771217712177e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.3153,
        "grad_norm": 2.0129892826080322,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.2757,
        "grad_norm": 4.894339561462402,
        "learning_rate": 1.6162361623616237e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.2941,
        "grad_norm": 7.3959808349609375,
        "learning_rate": 1.613468634686347e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.2893,
        "grad_norm": 1.3057925701141357,
        "learning_rate": 1.6107011070110703e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.3336,
        "grad_norm": 0.658703088760376,
        "learning_rate": 1.6079335793357936e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.3621,
        "grad_norm": 5.117066860198975,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.2792,
        "grad_norm": 5.377016067504883,
        "learning_rate": 1.60239852398524e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.3158,
        "grad_norm": 1.5035078525543213,
        "learning_rate": 1.5996309963099632e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.2495,
        "grad_norm": 39.47745132446289,
        "learning_rate": 1.596863468634686e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.215,
        "grad_norm": 2.4101176261901855,
        "learning_rate": 1.5940959409594098e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.3206,
        "grad_norm": 45.23712921142578,
        "learning_rate": 1.5913284132841328e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.3964,
        "grad_norm": 2.077298164367676,
        "learning_rate": 1.5885608856088564e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2897,
        "grad_norm": 7.240540027618408,
        "learning_rate": 1.5857933579335794e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.2501,
        "grad_norm": 2.5179333686828613,
        "learning_rate": 1.5830258302583023e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2847,
        "grad_norm": 6.206228733062744,
        "learning_rate": 1.580258302583026e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.2925,
        "grad_norm": 2.9780659675598145,
        "learning_rate": 1.577490774907749e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.4255808889865875,
        "eval_accuracy": 0.85978,
        "eval_precision": 0.80899,
        "eval_recall": 0.93855,
        "eval_f1": 0.86897,
        "eval_runtime": 18.7623,
        "eval_samples_per_second": 57.776,
        "eval_steps_per_second": 3.624,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.2129,
        "grad_norm": 1.0526350736618042,
        "learning_rate": 1.5747232472324726e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.3092,
        "grad_norm": 1.5057541131973267,
        "learning_rate": 1.5719557195571956e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.2525,
        "grad_norm": 1.2274187803268433,
        "learning_rate": 1.569188191881919e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.2854,
        "grad_norm": 6.992311477661133,
        "learning_rate": 1.5664206642066422e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.2764,
        "grad_norm": 1.4800992012023926,
        "learning_rate": 1.5636531365313655e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.3117,
        "grad_norm": 3.609311103820801,
        "learning_rate": 1.5608856088560885e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2694,
        "grad_norm": 2.2129688262939453,
        "learning_rate": 1.5581180811808118e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.3613,
        "grad_norm": 5.264146327972412,
        "learning_rate": 1.555350553505535e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.3395,
        "grad_norm": 0.8623986840248108,
        "learning_rate": 1.5525830258302584e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.207,
        "grad_norm": 1.4587820768356323,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.3248,
        "grad_norm": 2.667966842651367,
        "learning_rate": 1.5470479704797047e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.3109,
        "grad_norm": 3.599379062652588,
        "learning_rate": 1.5442804428044283e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.2894,
        "grad_norm": 11.55986213684082,
        "learning_rate": 1.5415129151291513e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2418,
        "grad_norm": 1.1088175773620605,
        "learning_rate": 1.5387453874538746e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.2595,
        "grad_norm": 4.564812660217285,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.2314,
        "grad_norm": 13.72191333770752,
        "learning_rate": 1.533210332103321e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.1452,
        "grad_norm": 2.232034921646118,
        "learning_rate": 1.5304428044280445e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.3164,
        "grad_norm": 3.731229782104492,
        "learning_rate": 1.5276752767527675e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.3072,
        "grad_norm": 2.012907028198242,
        "learning_rate": 1.524907749077491e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.3114,
        "grad_norm": 1.3022481203079224,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.3611,
        "grad_norm": 26.05748176574707,
        "learning_rate": 1.5193726937269372e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.3513,
        "grad_norm": 1.2482646703720093,
        "learning_rate": 1.5166051660516607e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.3709,
        "grad_norm": 9.557633399963379,
        "learning_rate": 1.5138376383763838e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.2793,
        "grad_norm": 1.3756723403930664,
        "learning_rate": 1.511070110701107e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.37,
        "grad_norm": 5.740914821624756,
        "learning_rate": 1.5083025830258303e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.2874,
        "grad_norm": 0.6190536022186279,
        "learning_rate": 1.5055350553505534e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.3245,
        "grad_norm": 5.0182600021362305,
        "learning_rate": 1.5027675276752769e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.2244,
        "grad_norm": 2.9364795684814453,
        "learning_rate": 1.5e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.4022290110588074,
        "eval_accuracy": 0.86347,
        "eval_precision": 0.81422,
        "eval_recall": 0.93855,
        "eval_f1": 0.87197,
        "eval_runtime": 18.6545,
        "eval_samples_per_second": 58.109,
        "eval_steps_per_second": 3.645,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.3685,
        "grad_norm": 1.996315836906433,
        "learning_rate": 1.4972324723247233e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.3084,
        "grad_norm": 7.09781551361084,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.3107,
        "grad_norm": 5.286782264709473,
        "learning_rate": 1.4916974169741698e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.3371,
        "grad_norm": 4.550482749938965,
        "learning_rate": 1.488929889298893e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2921,
        "grad_norm": 0.835933268070221,
        "learning_rate": 1.4861623616236162e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.2632,
        "grad_norm": 1.8656010627746582,
        "learning_rate": 1.4833948339483395e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.2681,
        "grad_norm": 0.7157765030860901,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.2252,
        "grad_norm": 7.402814865112305,
        "learning_rate": 1.477859778597786e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.2307,
        "grad_norm": 14.188135147094727,
        "learning_rate": 1.4750922509225093e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.3306,
        "grad_norm": 2.850018262863159,
        "learning_rate": 1.4723247232472326e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.2674,
        "grad_norm": 7.379563808441162,
        "learning_rate": 1.4695571955719559e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.2558,
        "grad_norm": 2.595275640487671,
        "learning_rate": 1.4667896678966789e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.2916,
        "grad_norm": 1.4929896593093872,
        "learning_rate": 1.4640221402214022e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.3738,
        "grad_norm": 1.4935446977615356,
        "learning_rate": 1.4612546125461255e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.1942,
        "grad_norm": 12.461865425109863,
        "learning_rate": 1.4584870848708488e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.2844,
        "grad_norm": 4.194702625274658,
        "learning_rate": 1.455719557195572e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.3121,
        "grad_norm": 3.423157215118408,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.3084,
        "grad_norm": 6.792301654815674,
        "learning_rate": 1.4501845018450186e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.2731,
        "grad_norm": 1.3338979482650757,
        "learning_rate": 1.4474169741697419e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.2767,
        "grad_norm": 21.49372673034668,
        "learning_rate": 1.4446494464944648e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.4052,
        "grad_norm": 4.928877353668213,
        "learning_rate": 1.4418819188191881e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.3257,
        "grad_norm": 1.404231071472168,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.4305,
        "grad_norm": 0.9447356462478638,
        "learning_rate": 1.4363468634686348e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.3019,
        "grad_norm": 3.5407609939575195,
        "learning_rate": 1.433579335793358e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.2883,
        "grad_norm": 4.071877956390381,
        "learning_rate": 1.4308118081180812e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.2438,
        "grad_norm": 0.5912383198738098,
        "learning_rate": 1.4280442804428045e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.2551,
        "grad_norm": 5.141870498657227,
        "learning_rate": 1.4252767527675276e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.4056941568851471,
        "eval_accuracy": 0.85978,
        "eval_precision": 0.81924,
        "eval_recall": 0.91993,
        "eval_f1": 0.86667,
        "eval_runtime": 18.7568,
        "eval_samples_per_second": 57.792,
        "eval_steps_per_second": 3.625,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.3022,
        "grad_norm": 25.15767478942871,
        "learning_rate": 1.422509225092251e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.3029,
        "grad_norm": 8.004412651062012,
        "learning_rate": 1.4197416974169741e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.3336,
        "grad_norm": 8.011452674865723,
        "learning_rate": 1.4169741697416974e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.3583,
        "grad_norm": 2.2260050773620605,
        "learning_rate": 1.4142066420664207e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.2951,
        "grad_norm": 5.11679744720459,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.267,
        "grad_norm": 2.7994496822357178,
        "learning_rate": 1.4086715867158673e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.2911,
        "grad_norm": 3.8881492614746094,
        "learning_rate": 1.4059040590405905e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.215,
        "grad_norm": 5.674932479858398,
        "learning_rate": 1.4031365313653136e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.2321,
        "grad_norm": 0.8860130906105042,
        "learning_rate": 1.4003690036900369e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.2466,
        "grad_norm": 1.61739182472229,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.233,
        "grad_norm": 1.9938546419143677,
        "learning_rate": 1.3948339483394834e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.305,
        "grad_norm": 7.7026567459106445,
        "learning_rate": 1.3920664206642067e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.199,
        "grad_norm": 10.31737995147705,
        "learning_rate": 1.38929889298893e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.2709,
        "grad_norm": 1.125141978263855,
        "learning_rate": 1.3865313653136533e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.2135,
        "grad_norm": 19.776294708251953,
        "learning_rate": 1.3837638376383764e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.2743,
        "grad_norm": 4.512045383453369,
        "learning_rate": 1.3809963099630995e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.2736,
        "grad_norm": 3.6591830253601074,
        "learning_rate": 1.3782287822878229e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.2714,
        "grad_norm": 12.006535530090332,
        "learning_rate": 1.3754612546125462e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.4512,
        "grad_norm": 1.6514314413070679,
        "learning_rate": 1.3726937269372695e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.2913,
        "grad_norm": 9.482474327087402,
        "learning_rate": 1.3699261992619926e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.3831,
        "grad_norm": 6.848212242126465,
        "learning_rate": 1.367158671586716e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.3187,
        "grad_norm": 1.520401954650879,
        "learning_rate": 1.3643911439114392e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.2752,
        "grad_norm": 1.1529486179351807,
        "learning_rate": 1.3616236162361624e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.2775,
        "grad_norm": 7.898179054260254,
        "learning_rate": 1.3588560885608857e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.3288,
        "grad_norm": 1.1773439645767212,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.2735,
        "grad_norm": 3.181441307067871,
        "learning_rate": 1.3533210332103321e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.3073,
        "grad_norm": 2.9096884727478027,
        "learning_rate": 1.3505535055350554e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.3921658992767334,
        "eval_accuracy": 0.86162,
        "eval_precision": 0.8126,
        "eval_recall": 0.93669,
        "eval_f1": 0.87024,
        "eval_runtime": 18.7857,
        "eval_samples_per_second": 57.703,
        "eval_steps_per_second": 3.62,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.3469,
        "grad_norm": 2.8503329753875732,
        "learning_rate": 1.3477859778597787e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.3076,
        "grad_norm": 0.8982266187667847,
        "learning_rate": 1.3450184501845019e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.2032,
        "grad_norm": 4.196138858795166,
        "learning_rate": 1.3422509225092252e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.3413,
        "grad_norm": 3.0308444499969482,
        "learning_rate": 1.3394833948339483e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.2527,
        "grad_norm": 4.071331977844238,
        "learning_rate": 1.3367158671586716e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.2999,
        "grad_norm": 2.007355213165283,
        "learning_rate": 1.3339483394833948e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.3602,
        "grad_norm": 0.5112881660461426,
        "learning_rate": 1.331180811808118e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.3078,
        "grad_norm": 1.034481406211853,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.3246,
        "grad_norm": 2.5824856758117676,
        "learning_rate": 1.3256457564575647e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.3008,
        "grad_norm": 1.2849161624908447,
        "learning_rate": 1.322878228782288e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.1807,
        "grad_norm": 2.4324920177459717,
        "learning_rate": 1.320110701107011e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.1464,
        "grad_norm": 1.1971325874328613,
        "learning_rate": 1.3173431734317343e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.3054,
        "grad_norm": 12.910124778747559,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.3148,
        "grad_norm": 1.7568128108978271,
        "learning_rate": 1.3118081180811809e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.3998,
        "grad_norm": 4.203787803649902,
        "learning_rate": 1.309040590405904e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.3869,
        "grad_norm": 4.593122482299805,
        "learning_rate": 1.3062730627306273e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.2695,
        "grad_norm": 1.8066835403442383,
        "learning_rate": 1.3035055350553506e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.2175,
        "grad_norm": 6.424169063568115,
        "learning_rate": 1.300738007380074e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.3483,
        "grad_norm": 2.264409065246582,
        "learning_rate": 1.297970479704797e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.3126,
        "grad_norm": 0.4027196168899536,
        "learning_rate": 1.2952029520295202e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.2952,
        "grad_norm": 12.386098861694336,
        "learning_rate": 1.2924354243542435e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.318,
        "grad_norm": 4.5609450340271,
        "learning_rate": 1.2896678966789668e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.222,
        "grad_norm": 2.239344596862793,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.3011,
        "grad_norm": 2.786363124847412,
        "learning_rate": 1.2841328413284133e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.2997,
        "grad_norm": 1.2004984617233276,
        "learning_rate": 1.2813653136531366e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.353,
        "grad_norm": 1.5193003416061401,
        "learning_rate": 1.2785977859778599e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.3705,
        "grad_norm": 0.8407829403877258,
        "learning_rate": 1.275830258302583e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.3896135091781616,
        "eval_accuracy": 0.85793,
        "eval_precision": 0.79782,
        "eval_recall": 0.95531,
        "eval_f1": 0.86949,
        "eval_runtime": 18.8719,
        "eval_samples_per_second": 57.44,
        "eval_steps_per_second": 3.603,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.2713,
        "grad_norm": 1.3030263185501099,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.3003,
        "grad_norm": 3.621673345565796,
        "learning_rate": 1.2702952029520295e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.2798,
        "grad_norm": 1.8620320558547974,
        "learning_rate": 1.2675276752767528e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.2572,
        "grad_norm": 1.7559916973114014,
        "learning_rate": 1.2647601476014761e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.2021,
        "grad_norm": 1.1993757486343384,
        "learning_rate": 1.2619926199261994e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.2754,
        "grad_norm": 1.3185837268829346,
        "learning_rate": 1.2592250922509225e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.2058,
        "grad_norm": 1.0854982137680054,
        "learning_rate": 1.2564575645756457e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.343,
        "grad_norm": 1.6803514957427979,
        "learning_rate": 1.253690036900369e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.3297,
        "grad_norm": 3.760331392288208,
        "learning_rate": 1.2509225092250923e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.2736,
        "grad_norm": 2.5298404693603516,
        "learning_rate": 1.2481549815498156e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.4037,
        "grad_norm": 2.0410165786743164,
        "learning_rate": 1.2453874538745387e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.3252,
        "grad_norm": 2.3137028217315674,
        "learning_rate": 1.242619926199262e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.2442,
        "grad_norm": 1.2190439701080322,
        "learning_rate": 1.2398523985239854e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.2441,
        "grad_norm": 2.4417152404785156,
        "learning_rate": 1.2370848708487087e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.2836,
        "grad_norm": 10.060297966003418,
        "learning_rate": 1.2343173431734316e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.3452,
        "grad_norm": 7.425616264343262,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.3342,
        "grad_norm": 0.6958854794502258,
        "learning_rate": 1.2287822878228782e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.3369,
        "grad_norm": 1.995911955833435,
        "learning_rate": 1.2260147601476015e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.3128,
        "grad_norm": 1.188725471496582,
        "learning_rate": 1.2232472324723247e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.2199,
        "grad_norm": 5.387650012969971,
        "learning_rate": 1.220479704797048e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.3324,
        "grad_norm": 1.602428913116455,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.3159,
        "grad_norm": 0.7556313872337341,
        "learning_rate": 1.2149446494464946e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.1965,
        "grad_norm": 2.498657703399658,
        "learning_rate": 1.2121771217712177e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.3641,
        "grad_norm": 5.853977680206299,
        "learning_rate": 1.2094095940959409e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.257,
        "grad_norm": 2.0135421752929688,
        "learning_rate": 1.2066420664206642e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.3196,
        "grad_norm": 2.4864625930786133,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.1885,
        "grad_norm": 0.8644094467163086,
        "learning_rate": 1.2011070110701108e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.4291602075099945,
        "eval_accuracy": 0.86347,
        "eval_precision": 0.82149,
        "eval_recall": 0.92551,
        "eval_f1": 0.8704,
        "eval_runtime": 18.7548,
        "eval_samples_per_second": 57.799,
        "eval_steps_per_second": 3.626,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "loss": 0.1897,
        "grad_norm": 2.728722333908081,
        "learning_rate": 1.198339483394834e-05,
        "epoch": 24.022140221402214,
        "step": 6510
    },
    {
        "loss": 0.298,
        "grad_norm": 5.1503190994262695,
        "learning_rate": 1.1955719557195573e-05,
        "epoch": 24.059040590405903,
        "step": 6520
    },
    {
        "loss": 0.4483,
        "grad_norm": 0.5797061324119568,
        "learning_rate": 1.1928044280442804e-05,
        "epoch": 24.095940959409592,
        "step": 6530
    },
    {
        "loss": 0.344,
        "grad_norm": 5.492834568023682,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 24.132841328413285,
        "step": 6540
    },
    {
        "loss": 0.28,
        "grad_norm": 2.149284839630127,
        "learning_rate": 1.187269372693727e-05,
        "epoch": 24.169741697416974,
        "step": 6550
    },
    {
        "loss": 0.2916,
        "grad_norm": 1.3142611980438232,
        "learning_rate": 1.1845018450184501e-05,
        "epoch": 24.206642066420663,
        "step": 6560
    },
    {
        "loss": 0.2586,
        "grad_norm": 2.2045438289642334,
        "learning_rate": 1.1817343173431735e-05,
        "epoch": 24.243542435424356,
        "step": 6570
    },
    {
        "loss": 0.1944,
        "grad_norm": 3.3337979316711426,
        "learning_rate": 1.1789667896678968e-05,
        "epoch": 24.280442804428045,
        "step": 6580
    },
    {
        "loss": 0.2667,
        "grad_norm": 3.1045587062835693,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 24.317343173431734,
        "step": 6590
    },
    {
        "loss": 0.3084,
        "grad_norm": 12.275186538696289,
        "learning_rate": 1.1734317343173432e-05,
        "epoch": 24.354243542435423,
        "step": 6600
    },
    {
        "loss": 0.2159,
        "grad_norm": 8.384957313537598,
        "learning_rate": 1.1706642066420663e-05,
        "epoch": 24.391143911439116,
        "step": 6610
    },
    {
        "loss": 0.3172,
        "grad_norm": 1.1137924194335938,
        "learning_rate": 1.1678966789667897e-05,
        "epoch": 24.428044280442805,
        "step": 6620
    },
    {
        "loss": 0.3114,
        "grad_norm": 0.6950532793998718,
        "learning_rate": 1.165129151291513e-05,
        "epoch": 24.464944649446494,
        "step": 6630
    },
    {
        "loss": 0.3158,
        "grad_norm": 1.8797967433929443,
        "learning_rate": 1.1623616236162363e-05,
        "epoch": 24.501845018450183,
        "step": 6640
    },
    {
        "loss": 0.2857,
        "grad_norm": 2.163268804550171,
        "learning_rate": 1.1595940959409594e-05,
        "epoch": 24.538745387453876,
        "step": 6650
    },
    {
        "loss": 0.3299,
        "grad_norm": 8.310746192932129,
        "learning_rate": 1.1568265682656827e-05,
        "epoch": 24.575645756457565,
        "step": 6660
    },
    {
        "loss": 0.244,
        "grad_norm": 0.9180229306221008,
        "learning_rate": 1.154059040590406e-05,
        "epoch": 24.612546125461254,
        "step": 6670
    },
    {
        "loss": 0.2031,
        "grad_norm": 1.5191787481307983,
        "learning_rate": 1.1512915129151292e-05,
        "epoch": 24.649446494464943,
        "step": 6680
    },
    {
        "loss": 0.27,
        "grad_norm": 24.393348693847656,
        "learning_rate": 1.1485239852398523e-05,
        "epoch": 24.686346863468636,
        "step": 6690
    },
    {
        "loss": 0.1743,
        "grad_norm": 53.68841552734375,
        "learning_rate": 1.1457564575645756e-05,
        "epoch": 24.723247232472325,
        "step": 6700
    },
    {
        "loss": 0.2945,
        "grad_norm": 0.5421151518821716,
        "learning_rate": 1.1429889298892989e-05,
        "epoch": 24.760147601476014,
        "step": 6710
    },
    {
        "loss": 0.3933,
        "grad_norm": 15.6610107421875,
        "learning_rate": 1.1402214022140222e-05,
        "epoch": 24.797047970479706,
        "step": 6720
    },
    {
        "loss": 0.2916,
        "grad_norm": 1.7009915113449097,
        "learning_rate": 1.1374538745387455e-05,
        "epoch": 24.833948339483396,
        "step": 6730
    },
    {
        "loss": 0.2431,
        "grad_norm": 5.582066059112549,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 24.870848708487085,
        "step": 6740
    },
    {
        "loss": 0.2102,
        "grad_norm": 3.342247247695923,
        "learning_rate": 1.131918819188192e-05,
        "epoch": 24.907749077490774,
        "step": 6750
    },
    {
        "loss": 0.2311,
        "grad_norm": 4.9134111404418945,
        "learning_rate": 1.1291512915129151e-05,
        "epoch": 24.944649446494466,
        "step": 6760
    },
    {
        "loss": 0.3082,
        "grad_norm": 8.56214714050293,
        "learning_rate": 1.1263837638376384e-05,
        "epoch": 24.981549815498155,
        "step": 6770
    },
    {
        "eval_loss": 0.39655959606170654,
        "eval_accuracy": 0.869,
        "eval_precision": 0.82324,
        "eval_recall": 0.93669,
        "eval_f1": 0.87631,
        "eval_runtime": 18.7096,
        "eval_samples_per_second": 57.938,
        "eval_steps_per_second": 3.635,
        "epoch": 25.0,
        "step": 6775
    },
    {
        "loss": 0.2501,
        "grad_norm": 1.0156512260437012,
        "learning_rate": 1.1236162361623616e-05,
        "epoch": 25.018450184501845,
        "step": 6780
    },
    {
        "loss": 0.2674,
        "grad_norm": 0.8406242728233337,
        "learning_rate": 1.1208487084870849e-05,
        "epoch": 25.055350553505534,
        "step": 6790
    },
    {
        "loss": 0.2018,
        "grad_norm": 1.4558669328689575,
        "learning_rate": 1.1180811808118082e-05,
        "epoch": 25.092250922509226,
        "step": 6800
    },
    {
        "loss": 0.216,
        "grad_norm": 2.7256805896759033,
        "learning_rate": 1.1153136531365315e-05,
        "epoch": 25.129151291512915,
        "step": 6810
    },
    {
        "loss": 0.2876,
        "grad_norm": 0.3051183223724365,
        "learning_rate": 1.1125461254612546e-05,
        "epoch": 25.166051660516604,
        "step": 6820
    },
    {
        "loss": 0.348,
        "grad_norm": 11.119142532348633,
        "learning_rate": 1.109778597785978e-05,
        "epoch": 25.202952029520294,
        "step": 6830
    },
    {
        "loss": 0.273,
        "grad_norm": 2.5962610244750977,
        "learning_rate": 1.107011070110701e-05,
        "epoch": 25.239852398523986,
        "step": 6840
    },
    {
        "loss": 0.2422,
        "grad_norm": 8.26537799835205,
        "learning_rate": 1.1042435424354244e-05,
        "epoch": 25.276752767527675,
        "step": 6850
    },
    {
        "loss": 0.3987,
        "grad_norm": 1.3142446279525757,
        "learning_rate": 1.1014760147601477e-05,
        "epoch": 25.313653136531364,
        "step": 6860
    },
    {
        "loss": 0.2638,
        "grad_norm": 1.15690279006958,
        "learning_rate": 1.0987084870848708e-05,
        "epoch": 25.350553505535057,
        "step": 6870
    },
    {
        "loss": 0.4005,
        "grad_norm": 2.758171558380127,
        "learning_rate": 1.0959409594095941e-05,
        "epoch": 25.387453874538746,
        "step": 6880
    },
    {
        "loss": 0.2153,
        "grad_norm": 3.8067822456359863,
        "learning_rate": 1.0931734317343174e-05,
        "epoch": 25.424354243542435,
        "step": 6890
    },
    {
        "loss": 0.2348,
        "grad_norm": 3.9257254600524902,
        "learning_rate": 1.0904059040590407e-05,
        "epoch": 25.461254612546124,
        "step": 6900
    },
    {
        "loss": 0.2297,
        "grad_norm": 25.065244674682617,
        "learning_rate": 1.0876383763837637e-05,
        "epoch": 25.498154981549817,
        "step": 6910
    },
    {
        "loss": 0.1489,
        "grad_norm": 2.8112587928771973,
        "learning_rate": 1.084870848708487e-05,
        "epoch": 25.535055350553506,
        "step": 6920
    },
    {
        "loss": 0.2411,
        "grad_norm": 1.590267300605774,
        "learning_rate": 1.0821033210332103e-05,
        "epoch": 25.571955719557195,
        "step": 6930
    },
    {
        "loss": 0.3335,
        "grad_norm": 66.61868286132812,
        "learning_rate": 1.0793357933579336e-05,
        "epoch": 25.608856088560884,
        "step": 6940
    },
    {
        "loss": 0.3001,
        "grad_norm": 5.311956405639648,
        "learning_rate": 1.076568265682657e-05,
        "epoch": 25.645756457564577,
        "step": 6950
    },
    {
        "loss": 0.2996,
        "grad_norm": 0.9569886922836304,
        "learning_rate": 1.07380073800738e-05,
        "epoch": 25.682656826568266,
        "step": 6960
    },
    {
        "loss": 0.2313,
        "grad_norm": 1.28579580783844,
        "learning_rate": 1.0710332103321034e-05,
        "epoch": 25.719557195571955,
        "step": 6970
    },
    {
        "loss": 0.2578,
        "grad_norm": 2.8205184936523438,
        "learning_rate": 1.0682656826568267e-05,
        "epoch": 25.756457564575644,
        "step": 6980
    },
    {
        "loss": 0.3341,
        "grad_norm": 5.799572944641113,
        "learning_rate": 1.0654981549815498e-05,
        "epoch": 25.793357933579337,
        "step": 6990
    },
    {
        "loss": 0.2607,
        "grad_norm": 13.509452819824219,
        "learning_rate": 1.062730627306273e-05,
        "epoch": 25.830258302583026,
        "step": 7000
    },
    {
        "loss": 0.3557,
        "grad_norm": 11.357054710388184,
        "learning_rate": 1.0599630996309963e-05,
        "epoch": 25.867158671586715,
        "step": 7010
    },
    {
        "loss": 0.2346,
        "grad_norm": 19.37615203857422,
        "learning_rate": 1.0571955719557196e-05,
        "epoch": 25.904059040590404,
        "step": 7020
    },
    {
        "loss": 0.2422,
        "grad_norm": 11.615395545959473,
        "learning_rate": 1.0544280442804429e-05,
        "epoch": 25.940959409594097,
        "step": 7030
    },
    {
        "loss": 0.2932,
        "grad_norm": 1.8707294464111328,
        "learning_rate": 1.0516605166051662e-05,
        "epoch": 25.977859778597786,
        "step": 7040
    },
    {
        "eval_loss": 0.3835280239582062,
        "eval_accuracy": 0.86347,
        "eval_precision": 0.81524,
        "eval_recall": 0.93669,
        "eval_f1": 0.87175,
        "eval_runtime": 18.7057,
        "eval_samples_per_second": 57.95,
        "eval_steps_per_second": 3.635,
        "epoch": 26.0,
        "step": 7046
    },
    {
        "loss": 0.3618,
        "grad_norm": 10.276524543762207,
        "learning_rate": 1.0488929889298893e-05,
        "epoch": 26.014760147601475,
        "step": 7050
    },
    {
        "loss": 0.2647,
        "grad_norm": 0.8856700658798218,
        "learning_rate": 1.0461254612546126e-05,
        "epoch": 26.051660516605168,
        "step": 7060
    },
    {
        "loss": 0.2406,
        "grad_norm": 3.122180223464966,
        "learning_rate": 1.0433579335793358e-05,
        "epoch": 26.088560885608857,
        "step": 7070
    },
    {
        "loss": 0.2646,
        "grad_norm": 1.2458893060684204,
        "learning_rate": 1.0405904059040591e-05,
        "epoch": 26.125461254612546,
        "step": 7080
    },
    {
        "loss": 0.2722,
        "grad_norm": 2.527545690536499,
        "learning_rate": 1.0378228782287822e-05,
        "epoch": 26.162361623616235,
        "step": 7090
    },
    {
        "loss": 0.2148,
        "grad_norm": 2.441941976547241,
        "learning_rate": 1.0350553505535055e-05,
        "epoch": 26.199261992619927,
        "step": 7100
    },
    {
        "loss": 0.2784,
        "grad_norm": 7.05795955657959,
        "learning_rate": 1.0322878228782288e-05,
        "epoch": 26.236162361623617,
        "step": 7110
    },
    {
        "loss": 0.3138,
        "grad_norm": 4.333937644958496,
        "learning_rate": 1.0295202952029521e-05,
        "epoch": 26.273062730627306,
        "step": 7120
    },
    {
        "loss": 0.1952,
        "grad_norm": 30.12543296813965,
        "learning_rate": 1.0267527675276755e-05,
        "epoch": 26.309963099630995,
        "step": 7130
    },
    {
        "loss": 0.2236,
        "grad_norm": 1.2119616270065308,
        "learning_rate": 1.0239852398523984e-05,
        "epoch": 26.346863468634687,
        "step": 7140
    },
    {
        "loss": 0.2884,
        "grad_norm": 18.918664932250977,
        "learning_rate": 1.0212177121771217e-05,
        "epoch": 26.383763837638377,
        "step": 7150
    },
    {
        "loss": 0.2267,
        "grad_norm": 10.95050048828125,
        "learning_rate": 1.018450184501845e-05,
        "epoch": 26.420664206642066,
        "step": 7160
    },
    {
        "loss": 0.2294,
        "grad_norm": 1.824110746383667,
        "learning_rate": 1.0156826568265683e-05,
        "epoch": 26.457564575645755,
        "step": 7170
    },
    {
        "loss": 0.3244,
        "grad_norm": 43.40498733520508,
        "learning_rate": 1.0129151291512915e-05,
        "epoch": 26.494464944649447,
        "step": 7180
    },
    {
        "loss": 0.3748,
        "grad_norm": 12.188989639282227,
        "learning_rate": 1.0101476014760148e-05,
        "epoch": 26.531365313653136,
        "step": 7190
    },
    {
        "loss": 0.2602,
        "grad_norm": 2.970980405807495,
        "learning_rate": 1.0073800738007381e-05,
        "epoch": 26.568265682656826,
        "step": 7200
    },
    {
        "loss": 0.2769,
        "grad_norm": 1.57420015335083,
        "learning_rate": 1.0046125461254614e-05,
        "epoch": 26.605166051660518,
        "step": 7210
    },
    {
        "loss": 0.3035,
        "grad_norm": 1.0105665922164917,
        "learning_rate": 1.0018450184501844e-05,
        "epoch": 26.642066420664207,
        "step": 7220
    },
    {
        "loss": 0.3239,
        "grad_norm": 1.415094256401062,
        "learning_rate": 9.990774907749077e-06,
        "epoch": 26.678966789667896,
        "step": 7230
    },
    {
        "loss": 0.2215,
        "grad_norm": 2.747823715209961,
        "learning_rate": 9.96309963099631e-06,
        "epoch": 26.715867158671585,
        "step": 7240
    },
    {
        "loss": 0.2434,
        "grad_norm": 3.1391069889068604,
        "learning_rate": 9.935424354243543e-06,
        "epoch": 26.752767527675278,
        "step": 7250
    },
    {
        "loss": 0.3807,
        "grad_norm": 2.281740427017212,
        "learning_rate": 9.907749077490776e-06,
        "epoch": 26.789667896678967,
        "step": 7260
    },
    {
        "loss": 0.2853,
        "grad_norm": 2.087564468383789,
        "learning_rate": 9.880073800738007e-06,
        "epoch": 26.826568265682656,
        "step": 7270
    },
    {
        "loss": 0.3127,
        "grad_norm": 3.6756551265716553,
        "learning_rate": 9.85239852398524e-06,
        "epoch": 26.863468634686345,
        "step": 7280
    },
    {
        "loss": 0.1947,
        "grad_norm": 1.5064151287078857,
        "learning_rate": 9.824723247232474e-06,
        "epoch": 26.900369003690038,
        "step": 7290
    },
    {
        "loss": 0.3336,
        "grad_norm": 1.2079886198043823,
        "learning_rate": 9.797047970479705e-06,
        "epoch": 26.937269372693727,
        "step": 7300
    },
    {
        "loss": 0.2366,
        "grad_norm": 1.0687025785446167,
        "learning_rate": 9.769372693726936e-06,
        "epoch": 26.974169741697416,
        "step": 7310
    },
    {
        "eval_loss": 0.41192182898521423,
        "eval_accuracy": 0.86439,
        "eval_precision": 0.80952,
        "eval_recall": 0.94972,
        "eval_f1": 0.87404,
        "eval_runtime": 18.7587,
        "eval_samples_per_second": 57.787,
        "eval_steps_per_second": 3.625,
        "epoch": 27.0,
        "step": 7317
    },
    {
        "train_runtime": 6415.1858,
        "train_samples_per_second": 27.03,
        "train_steps_per_second": 1.69,
        "total_flos": 1.53979167373056e+16,
        "train_loss": 0.3414551969172118,
        "epoch": 27.0,
        "step": 7317
    }
]