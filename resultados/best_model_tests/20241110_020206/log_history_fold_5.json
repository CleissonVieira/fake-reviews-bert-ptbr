[
    {
        "loss": 0.6721,
        "grad_norm": 4.52374267578125,
        "learning_rate": 2.997232472324723e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.5642,
        "grad_norm": 7.790989398956299,
        "learning_rate": 2.9944649446494467e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.4615,
        "grad_norm": 3.7836458683013916,
        "learning_rate": 2.9916974169741697e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.4094,
        "grad_norm": 4.555257320404053,
        "learning_rate": 2.9889298892988933e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.526,
        "grad_norm": 3.592888116836548,
        "learning_rate": 2.9861623616236163e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.5657,
        "grad_norm": 4.0742011070251465,
        "learning_rate": 2.9833948339483396e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.5113,
        "grad_norm": 3.490900754928589,
        "learning_rate": 2.980627306273063e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.3936,
        "grad_norm": 3.5998435020446777,
        "learning_rate": 2.977859778597786e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.4575,
        "grad_norm": 2.96172833442688,
        "learning_rate": 2.975092250922509e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.4905,
        "grad_norm": 2.138275146484375,
        "learning_rate": 2.9723247232472325e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.5006,
        "grad_norm": 2.8986754417419434,
        "learning_rate": 2.9695571955719558e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4754,
        "grad_norm": 5.383829116821289,
        "learning_rate": 2.966789667896679e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.485,
        "grad_norm": 3.9994142055511475,
        "learning_rate": 2.9640221402214024e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4418,
        "grad_norm": 3.4759676456451416,
        "learning_rate": 2.9612546125461254e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4452,
        "grad_norm": 2.6763529777526855,
        "learning_rate": 2.958487084870849e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.3942,
        "grad_norm": 2.9934637546539307,
        "learning_rate": 2.955719557195572e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.4437,
        "grad_norm": 2.539395809173584,
        "learning_rate": 2.9529520295202953e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.4668,
        "grad_norm": 1.2846821546554565,
        "learning_rate": 2.9501845018450186e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4988,
        "grad_norm": 2.25032377243042,
        "learning_rate": 2.9474169741697416e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4542,
        "grad_norm": 2.512178421020508,
        "learning_rate": 2.9446494464944652e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.4165,
        "grad_norm": 2.9231276512145996,
        "learning_rate": 2.9418819188191882e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4156,
        "grad_norm": 4.067076206207275,
        "learning_rate": 2.9391143911439118e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.4024,
        "grad_norm": 2.405437707901001,
        "learning_rate": 2.9363468634686348e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.4231,
        "grad_norm": 2.236697196960449,
        "learning_rate": 2.9335793357933578e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.3605,
        "grad_norm": 3.157529592514038,
        "learning_rate": 2.9308118081180814e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4323,
        "grad_norm": 3.076469659805298,
        "learning_rate": 2.9280442804428044e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4434,
        "grad_norm": 4.074828624725342,
        "learning_rate": 2.9252767527675277e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.4425778388977051,
        "eval_accuracy": 0.80332,
        "eval_precision": 0.84979,
        "eval_recall": 0.74684,
        "eval_f1": 0.795,
        "eval_runtime": 18.1354,
        "eval_samples_per_second": 59.718,
        "eval_steps_per_second": 3.75,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.4127,
        "grad_norm": 1.7037923336029053,
        "learning_rate": 2.922509225092251e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.401,
        "grad_norm": 1.6049909591674805,
        "learning_rate": 2.9197416974169743e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.5008,
        "grad_norm": 5.113902568817139,
        "learning_rate": 2.9169741697416976e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.4764,
        "grad_norm": 3.4386019706726074,
        "learning_rate": 2.9142066420664206e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.3659,
        "grad_norm": 5.5428009033203125,
        "learning_rate": 2.911439114391144e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4118,
        "grad_norm": 3.8431921005249023,
        "learning_rate": 2.9086715867158672e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.3654,
        "grad_norm": 2.888737916946411,
        "learning_rate": 2.9059040590405905e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4596,
        "grad_norm": 2.346226215362549,
        "learning_rate": 2.9031365313653138e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.3025,
        "grad_norm": 4.296987533569336,
        "learning_rate": 2.900369003690037e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.5476,
        "grad_norm": 2.974553346633911,
        "learning_rate": 2.89760147601476e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.3993,
        "grad_norm": 2.6705901622772217,
        "learning_rate": 2.8948339483394837e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4673,
        "grad_norm": 4.08268404006958,
        "learning_rate": 2.8920664206642067e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.381,
        "grad_norm": 3.437990188598633,
        "learning_rate": 2.8892988929889297e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.4102,
        "grad_norm": 2.0028042793273926,
        "learning_rate": 2.8865313653136533e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3713,
        "grad_norm": 2.0773398876190186,
        "learning_rate": 2.8837638376383763e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.3928,
        "grad_norm": 1.9315087795257568,
        "learning_rate": 2.8809963099631e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.4409,
        "grad_norm": 4.015288829803467,
        "learning_rate": 2.878228782287823e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.5163,
        "grad_norm": 2.671912670135498,
        "learning_rate": 2.8754612546125462e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.4157,
        "grad_norm": 2.845463275909424,
        "learning_rate": 2.8726937269372695e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.4874,
        "grad_norm": 4.060578346252441,
        "learning_rate": 2.8699261992619925e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.3063,
        "grad_norm": 3.6159861087799072,
        "learning_rate": 2.867158671586716e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.368,
        "grad_norm": 4.647232532501221,
        "learning_rate": 2.864391143911439e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.3165,
        "grad_norm": 2.8061470985412598,
        "learning_rate": 2.8616236162361624e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.2984,
        "grad_norm": 1.609493613243103,
        "learning_rate": 2.8588560885608857e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.4732,
        "grad_norm": 2.2044918537139893,
        "learning_rate": 2.856088560885609e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.4595,
        "grad_norm": 2.6255812644958496,
        "learning_rate": 2.8533210332103323e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.4124,
        "grad_norm": 2.4050498008728027,
        "learning_rate": 2.8505535055350553e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.37382686138153076,
        "eval_accuracy": 0.85411,
        "eval_precision": 0.83646,
        "eval_recall": 0.88788,
        "eval_f1": 0.8614,
        "eval_runtime": 18.1558,
        "eval_samples_per_second": 59.65,
        "eval_steps_per_second": 3.745,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.3494,
        "grad_norm": 2.9507594108581543,
        "learning_rate": 2.8477859778597786e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4353,
        "grad_norm": 3.823080539703369,
        "learning_rate": 2.845018450184502e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.3829,
        "grad_norm": 1.652268409729004,
        "learning_rate": 2.8422509225092252e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3429,
        "grad_norm": 3.2585911750793457,
        "learning_rate": 2.8394833948339482e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.3609,
        "grad_norm": 1.915569543838501,
        "learning_rate": 2.8367158671586718e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.422,
        "grad_norm": 1.7738451957702637,
        "learning_rate": 2.8339483394833948e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.3897,
        "grad_norm": 3.8200111389160156,
        "learning_rate": 2.831180811808118e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4547,
        "grad_norm": 2.5275890827178955,
        "learning_rate": 2.8284132841328414e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.3504,
        "grad_norm": 2.9306893348693848,
        "learning_rate": 2.8256457564575644e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3519,
        "grad_norm": 2.2321908473968506,
        "learning_rate": 2.822878228782288e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.3579,
        "grad_norm": 1.0189634561538696,
        "learning_rate": 2.820110701107011e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.4126,
        "grad_norm": 7.622488021850586,
        "learning_rate": 2.8173431734317346e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.4121,
        "grad_norm": 3.490541458129883,
        "learning_rate": 2.8145756457564576e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.3881,
        "grad_norm": 5.132927894592285,
        "learning_rate": 2.811808118081181e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.3635,
        "grad_norm": 5.00125789642334,
        "learning_rate": 2.8090405904059042e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.3687,
        "grad_norm": 2.4392406940460205,
        "learning_rate": 2.8062730627306272e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.4474,
        "grad_norm": 3.905942440032959,
        "learning_rate": 2.803505535055351e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.342,
        "grad_norm": 2.1679487228393555,
        "learning_rate": 2.8007380073800738e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3655,
        "grad_norm": 1.9647938013076782,
        "learning_rate": 2.797970479704797e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4781,
        "grad_norm": 3.7546117305755615,
        "learning_rate": 2.7952029520295204e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3871,
        "grad_norm": 1.6044470071792603,
        "learning_rate": 2.7924354243542437e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.3454,
        "grad_norm": 1.1389533281326294,
        "learning_rate": 2.7896678966789667e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.3209,
        "grad_norm": 0.7752988934516907,
        "learning_rate": 2.78690036900369e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.3433,
        "grad_norm": 0.9335472583770752,
        "learning_rate": 2.7841328413284133e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.3498,
        "grad_norm": 2.2994534969329834,
        "learning_rate": 2.7813653136531366e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.5387,
        "grad_norm": 3.1750900745391846,
        "learning_rate": 2.77859778597786e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.3834,
        "grad_norm": 1.523941993713379,
        "learning_rate": 2.775830258302583e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.38328489661216736,
        "eval_accuracy": 0.85411,
        "eval_precision": 0.80526,
        "eval_recall": 0.94213,
        "eval_f1": 0.86833,
        "eval_runtime": 18.1593,
        "eval_samples_per_second": 59.639,
        "eval_steps_per_second": 3.745,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3773,
        "grad_norm": 3.2335379123687744,
        "learning_rate": 2.7730627306273065e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3577,
        "grad_norm": 5.347175598144531,
        "learning_rate": 2.7702952029520295e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.333,
        "grad_norm": 0.9243844151496887,
        "learning_rate": 2.7675276752767528e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.408,
        "grad_norm": 9.040679931640625,
        "learning_rate": 2.764760147601476e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.4191,
        "grad_norm": 1.4544885158538818,
        "learning_rate": 2.761992619926199e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.4138,
        "grad_norm": 2.208158493041992,
        "learning_rate": 2.7592250922509227e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3421,
        "grad_norm": 2.008514165878296,
        "learning_rate": 2.7564575645756457e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3723,
        "grad_norm": 2.642258882522583,
        "learning_rate": 2.753690036900369e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.3426,
        "grad_norm": 3.280019521713257,
        "learning_rate": 2.7509225092250923e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3859,
        "grad_norm": 1.5091761350631714,
        "learning_rate": 2.7481549815498156e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.3347,
        "grad_norm": 5.681694507598877,
        "learning_rate": 2.745387453874539e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.3586,
        "grad_norm": 1.3403528928756714,
        "learning_rate": 2.742619926199262e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.3475,
        "grad_norm": 2.0341434478759766,
        "learning_rate": 2.7398523985239852e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.356,
        "grad_norm": 4.700520038604736,
        "learning_rate": 2.7370848708487085e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.3961,
        "grad_norm": 6.076221942901611,
        "learning_rate": 2.734317343173432e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.4428,
        "grad_norm": 2.0809619426727295,
        "learning_rate": 2.731549815498155e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3494,
        "grad_norm": 2.4306890964508057,
        "learning_rate": 2.7287822878228784e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.313,
        "grad_norm": 6.239560604095459,
        "learning_rate": 2.7260147601476014e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.3474,
        "grad_norm": 15.960816383361816,
        "learning_rate": 2.7232472324723247e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.2706,
        "grad_norm": 1.6188641786575317,
        "learning_rate": 2.720479704797048e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.2516,
        "grad_norm": 2.7124674320220947,
        "learning_rate": 2.7177121771217713e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.454,
        "grad_norm": 3.065139055252075,
        "learning_rate": 2.7149446494464946e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.4363,
        "grad_norm": 1.9006507396697998,
        "learning_rate": 2.7121771217712176e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3164,
        "grad_norm": 2.3614630699157715,
        "learning_rate": 2.7094095940959413e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.2438,
        "grad_norm": 1.0305004119873047,
        "learning_rate": 2.7066420664206642e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.3838,
        "grad_norm": 13.68113899230957,
        "learning_rate": 2.7038745387453872e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.2994,
        "grad_norm": 4.800247669219971,
        "learning_rate": 2.701107011070111e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.3824467957019806,
        "eval_accuracy": 0.86981,
        "eval_precision": 0.83226,
        "eval_recall": 0.93309,
        "eval_f1": 0.8798,
        "eval_runtime": 18.1863,
        "eval_samples_per_second": 59.55,
        "eval_steps_per_second": 3.739,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3394,
        "grad_norm": 5.411591529846191,
        "learning_rate": 2.6983394833948338e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.443,
        "grad_norm": 6.846158504486084,
        "learning_rate": 2.6955719557195575e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.3124,
        "grad_norm": 10.795552253723145,
        "learning_rate": 2.6928044280442804e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3508,
        "grad_norm": 1.086995005607605,
        "learning_rate": 2.6900369003690037e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3436,
        "grad_norm": 6.50501823425293,
        "learning_rate": 2.687269372693727e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3203,
        "grad_norm": 16.692548751831055,
        "learning_rate": 2.6845018450184504e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3175,
        "grad_norm": 3.0886354446411133,
        "learning_rate": 2.6817343173431737e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3767,
        "grad_norm": 20.23941421508789,
        "learning_rate": 2.6789667896678966e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.4464,
        "grad_norm": 3.6330175399780273,
        "learning_rate": 2.67619926199262e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.4314,
        "grad_norm": 1.8372135162353516,
        "learning_rate": 2.6734317343173432e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.312,
        "grad_norm": 1.8767504692077637,
        "learning_rate": 2.6706642066420666e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3593,
        "grad_norm": 1.9885793924331665,
        "learning_rate": 2.6678966789667895e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.3379,
        "grad_norm": 0.8677645921707153,
        "learning_rate": 2.665129151291513e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3427,
        "grad_norm": 5.390510559082031,
        "learning_rate": 2.662361623616236e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.242,
        "grad_norm": 2.3674795627593994,
        "learning_rate": 2.6595940959409594e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.2918,
        "grad_norm": 1.5236389636993408,
        "learning_rate": 2.6568265682656828e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3115,
        "grad_norm": 1.5147943496704102,
        "learning_rate": 2.6540590405904057e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.32,
        "grad_norm": 1.9218194484710693,
        "learning_rate": 2.6512915129151294e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3913,
        "grad_norm": 18.87592887878418,
        "learning_rate": 2.6485239852398523e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.4105,
        "grad_norm": 3.6886801719665527,
        "learning_rate": 2.645756457564576e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.378,
        "grad_norm": 3.251030683517456,
        "learning_rate": 2.642988929889299e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.3507,
        "grad_norm": 3.0545880794525146,
        "learning_rate": 2.640221402214022e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.2505,
        "grad_norm": 3.8103699684143066,
        "learning_rate": 2.6374538745387456e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.312,
        "grad_norm": 8.282651901245117,
        "learning_rate": 2.6346863468634685e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.4551,
        "grad_norm": 1.2412058115005493,
        "learning_rate": 2.6319188191881922e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.3479,
        "grad_norm": 6.538786888122559,
        "learning_rate": 2.629151291512915e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.2762,
        "grad_norm": 4.687804222106934,
        "learning_rate": 2.6263837638376385e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.34933921694755554,
        "eval_accuracy": 0.8735,
        "eval_precision": 0.83333,
        "eval_recall": 0.94033,
        "eval_f1": 0.8836,
        "eval_runtime": 18.1507,
        "eval_samples_per_second": 59.667,
        "eval_steps_per_second": 3.746,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.3989,
        "grad_norm": 2.028665065765381,
        "learning_rate": 2.6236162361623618e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.2268,
        "grad_norm": 1.1077724695205688,
        "learning_rate": 2.620848708487085e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.3927,
        "grad_norm": 1.2305784225463867,
        "learning_rate": 2.618081180811808e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.3542,
        "grad_norm": 1.3731458187103271,
        "learning_rate": 2.6153136531365313e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.2644,
        "grad_norm": 5.65448522567749,
        "learning_rate": 2.6125461254612547e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.3774,
        "grad_norm": 2.836911201477051,
        "learning_rate": 2.609778597785978e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.3556,
        "grad_norm": 1.4663082361221313,
        "learning_rate": 2.6070110701107013e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.344,
        "grad_norm": 3.0187575817108154,
        "learning_rate": 2.6042435424354242e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.2783,
        "grad_norm": 1.497252345085144,
        "learning_rate": 2.601476014760148e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.3389,
        "grad_norm": 1.272957682609558,
        "learning_rate": 2.598708487084871e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.2546,
        "grad_norm": 3.314328908920288,
        "learning_rate": 2.595940959409594e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.3799,
        "grad_norm": 12.093399047851562,
        "learning_rate": 2.5931734317343175e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.3779,
        "grad_norm": 1.9976294040679932,
        "learning_rate": 2.5904059040590404e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.3051,
        "grad_norm": 7.1549248695373535,
        "learning_rate": 2.587638376383764e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.2766,
        "grad_norm": 1.4842653274536133,
        "learning_rate": 2.584870848708487e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.297,
        "grad_norm": 2.835160970687866,
        "learning_rate": 2.5821033210332107e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.2699,
        "grad_norm": 23.215595245361328,
        "learning_rate": 2.5793357933579337e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.354,
        "grad_norm": 3.470790386199951,
        "learning_rate": 2.5765682656826566e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.3874,
        "grad_norm": 5.024897575378418,
        "learning_rate": 2.5738007380073803e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.3113,
        "grad_norm": 2.8061070442199707,
        "learning_rate": 2.5710332103321032e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.3249,
        "grad_norm": 2.797727584838867,
        "learning_rate": 2.5682656826568266e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.3304,
        "grad_norm": 2.761394739151001,
        "learning_rate": 2.56549815498155e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.3347,
        "grad_norm": 1.7636412382125854,
        "learning_rate": 2.5627306273062732e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.3395,
        "grad_norm": 3.3974881172180176,
        "learning_rate": 2.5599630996309965e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.337,
        "grad_norm": 4.196862697601318,
        "learning_rate": 2.5571955719557198e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.352,
        "grad_norm": 2.6827309131622314,
        "learning_rate": 2.5544280442804428e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.3811,
        "grad_norm": 12.691329002380371,
        "learning_rate": 2.551660516605166e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.33210301399230957,
        "eval_accuracy": 0.86981,
        "eval_precision": 0.82907,
        "eval_recall": 0.93852,
        "eval_f1": 0.88041,
        "eval_runtime": 18.1917,
        "eval_samples_per_second": 59.532,
        "eval_steps_per_second": 3.738,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.312,
        "grad_norm": 1.3261386156082153,
        "learning_rate": 2.5488929889298894e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.2931,
        "grad_norm": 5.504898548126221,
        "learning_rate": 2.5461254612546127e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.3113,
        "grad_norm": 6.277438163757324,
        "learning_rate": 2.543357933579336e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.3026,
        "grad_norm": 1.8923847675323486,
        "learning_rate": 2.540590405904059e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.227,
        "grad_norm": 14.797831535339355,
        "learning_rate": 2.5378228782287826e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.2758,
        "grad_norm": 1.59032142162323,
        "learning_rate": 2.5350553505535056e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.4124,
        "grad_norm": 3.4701716899871826,
        "learning_rate": 2.5322878228782285e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.3466,
        "grad_norm": 1.6689625978469849,
        "learning_rate": 2.5295202952029522e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3404,
        "grad_norm": 3.857842445373535,
        "learning_rate": 2.526752767527675e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.3567,
        "grad_norm": 8.239547729492188,
        "learning_rate": 2.5239852398523988e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.2884,
        "grad_norm": 1.6102098226547241,
        "learning_rate": 2.5212177121771218e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.3337,
        "grad_norm": 1.8452260494232178,
        "learning_rate": 2.518450184501845e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.3317,
        "grad_norm": 3.4730935096740723,
        "learning_rate": 2.5156826568265684e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.2503,
        "grad_norm": 1.303758144378662,
        "learning_rate": 2.5129151291512914e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3015,
        "grad_norm": 3.506739616394043,
        "learning_rate": 2.510147601476015e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.2991,
        "grad_norm": 5.954000473022461,
        "learning_rate": 2.507380073800738e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.3896,
        "grad_norm": 4.37215518951416,
        "learning_rate": 2.5046125461254613e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.3806,
        "grad_norm": 1.3803054094314575,
        "learning_rate": 2.5018450184501846e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.2647,
        "grad_norm": 2.2956466674804688,
        "learning_rate": 2.499077490774908e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3282,
        "grad_norm": 1.392623782157898,
        "learning_rate": 2.4963099630996312e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.2292,
        "grad_norm": 8.379222869873047,
        "learning_rate": 2.4935424354243545e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3237,
        "grad_norm": 1.2401272058486938,
        "learning_rate": 2.4907749077490775e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.3161,
        "grad_norm": 5.1755499839782715,
        "learning_rate": 2.4880073800738008e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.3964,
        "grad_norm": 2.156130790710449,
        "learning_rate": 2.485239852398524e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.3243,
        "grad_norm": 2.1874747276306152,
        "learning_rate": 2.482472324723247e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.3568,
        "grad_norm": 11.612887382507324,
        "learning_rate": 2.4797047970479707e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3198,
        "grad_norm": 1.2227178812026978,
        "learning_rate": 2.4769372693726937e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.3573070764541626,
        "eval_accuracy": 0.87073,
        "eval_precision": 0.82418,
        "eval_recall": 0.94937,
        "eval_f1": 0.88235,
        "eval_runtime": 18.2002,
        "eval_samples_per_second": 59.505,
        "eval_steps_per_second": 3.736,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.3326,
        "grad_norm": 1.686517596244812,
        "learning_rate": 2.4741697416974173e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.3415,
        "grad_norm": 5.512940406799316,
        "learning_rate": 2.4714022140221403e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.2895,
        "grad_norm": 3.4828550815582275,
        "learning_rate": 2.4686346863468633e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.223,
        "grad_norm": 3.2468979358673096,
        "learning_rate": 2.465867158671587e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.3573,
        "grad_norm": 1.3611276149749756,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3132,
        "grad_norm": 1.7767421007156372,
        "learning_rate": 2.4603321033210335e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.1743,
        "grad_norm": 15.345104217529297,
        "learning_rate": 2.4575645756457565e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.2688,
        "grad_norm": 0.9623515605926514,
        "learning_rate": 2.4547970479704798e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.4336,
        "grad_norm": 4.724416255950928,
        "learning_rate": 2.452029520295203e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.2734,
        "grad_norm": 2.907435417175293,
        "learning_rate": 2.449261992619926e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.3204,
        "grad_norm": 2.9111809730529785,
        "learning_rate": 2.4464944649446494e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.2687,
        "grad_norm": 2.6114609241485596,
        "learning_rate": 2.4437269372693727e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.2515,
        "grad_norm": 10.818279266357422,
        "learning_rate": 2.440959409594096e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3885,
        "grad_norm": 6.501590728759766,
        "learning_rate": 2.4381918819188193e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.2494,
        "grad_norm": 3.4383039474487305,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.3056,
        "grad_norm": 1.986654281616211,
        "learning_rate": 2.4326568265682656e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.3935,
        "grad_norm": 15.14600658416748,
        "learning_rate": 2.4298892988929892e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.2926,
        "grad_norm": 16.343782424926758,
        "learning_rate": 2.4271217712177122e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.3172,
        "grad_norm": 2.7211568355560303,
        "learning_rate": 2.4243542435424355e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.246,
        "grad_norm": 7.38940954208374,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.3515,
        "grad_norm": 4.604212760925293,
        "learning_rate": 2.4188191881918818e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.3205,
        "grad_norm": 3.3549020290374756,
        "learning_rate": 2.4160516605166054e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.3027,
        "grad_norm": 1.702610969543457,
        "learning_rate": 2.4132841328413284e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.4276,
        "grad_norm": 17.608898162841797,
        "learning_rate": 2.410516605166052e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.3258,
        "grad_norm": 1.8601064682006836,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.2639,
        "grad_norm": 4.702117443084717,
        "learning_rate": 2.404981549815498e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.379,
        "grad_norm": 6.215113639831543,
        "learning_rate": 2.4022140221402216e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.3537652790546417,
        "eval_accuracy": 0.87258,
        "eval_precision": 0.84072,
        "eval_recall": 0.92586,
        "eval_f1": 0.88124,
        "eval_runtime": 18.1932,
        "eval_samples_per_second": 59.528,
        "eval_steps_per_second": 3.738,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.2702,
        "grad_norm": 3.2697012424468994,
        "learning_rate": 2.3994464944649446e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3392,
        "grad_norm": 8.014420509338379,
        "learning_rate": 2.396678966789668e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.2771,
        "grad_norm": 3.111311197280884,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.3024,
        "grad_norm": 2.32492733001709,
        "learning_rate": 2.3911439114391145e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.3474,
        "grad_norm": 1.3491134643554688,
        "learning_rate": 2.3883763837638378e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.2432,
        "grad_norm": 4.136703968048096,
        "learning_rate": 2.3856088560885608e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.3701,
        "grad_norm": 2.788910388946533,
        "learning_rate": 2.382841328413284e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.3291,
        "grad_norm": 1.8515421152114868,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.2004,
        "grad_norm": 1.5178773403167725,
        "learning_rate": 2.3773062730627307e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.327,
        "grad_norm": 5.277375221252441,
        "learning_rate": 2.374538745387454e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.2419,
        "grad_norm": 1.8102662563323975,
        "learning_rate": 2.3717712177121773e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.3334,
        "grad_norm": 4.732275009155273,
        "learning_rate": 2.3690036900369003e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.2231,
        "grad_norm": 0.8748528957366943,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.2662,
        "grad_norm": 5.799459457397461,
        "learning_rate": 2.363468634686347e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.3657,
        "grad_norm": 1.7315298318862915,
        "learning_rate": 2.3607011070110702e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.2398,
        "grad_norm": 0.997424304485321,
        "learning_rate": 2.3579335793357935e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.3149,
        "grad_norm": 4.5011162757873535,
        "learning_rate": 2.3551660516605165e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3825,
        "grad_norm": 4.363218307495117,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.3029,
        "grad_norm": 1.865257740020752,
        "learning_rate": 2.349630996309963e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.3356,
        "grad_norm": 2.4139881134033203,
        "learning_rate": 2.3468634686346864e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3354,
        "grad_norm": 3.53204345703125,
        "learning_rate": 2.3440959409594097e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.2576,
        "grad_norm": 7.430867671966553,
        "learning_rate": 2.3413284132841327e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.422,
        "grad_norm": 5.800909996032715,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.3196,
        "grad_norm": 9.18730354309082,
        "learning_rate": 2.3357933579335793e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.2435,
        "grad_norm": 0.9984444975852966,
        "learning_rate": 2.3330258302583026e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.2449,
        "grad_norm": 4.093051433563232,
        "learning_rate": 2.330258302583026e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.2446,
        "grad_norm": 2.3358614444732666,
        "learning_rate": 2.3274907749077492e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.3690403699874878,
        "eval_accuracy": 0.87812,
        "eval_precision": 0.86106,
        "eval_recall": 0.90778,
        "eval_f1": 0.8838,
        "eval_runtime": 18.1681,
        "eval_samples_per_second": 59.61,
        "eval_steps_per_second": 3.743,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.322,
        "grad_norm": 9.67263412475586,
        "learning_rate": 2.3247232472324725e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.3739,
        "grad_norm": 1.0639162063598633,
        "learning_rate": 2.3219557195571955e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3817,
        "grad_norm": 2.1604018211364746,
        "learning_rate": 2.3191881918819188e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.2317,
        "grad_norm": 1.4477695226669312,
        "learning_rate": 2.316420664206642e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.2453,
        "grad_norm": 1.7775641679763794,
        "learning_rate": 2.3136531365313654e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.2838,
        "grad_norm": 13.735395431518555,
        "learning_rate": 2.3108856088560884e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3668,
        "grad_norm": 3.245532751083374,
        "learning_rate": 2.308118081180812e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.3141,
        "grad_norm": 3.7742059230804443,
        "learning_rate": 2.305350553505535e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.317,
        "grad_norm": 3.1715660095214844,
        "learning_rate": 2.3025830258302583e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.216,
        "grad_norm": 4.053919315338135,
        "learning_rate": 2.2998154981549816e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.2266,
        "grad_norm": 0.6707038879394531,
        "learning_rate": 2.2970479704797046e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.43,
        "grad_norm": 4.264744758605957,
        "learning_rate": 2.2942804428044282e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.2942,
        "grad_norm": 1.5844029188156128,
        "learning_rate": 2.2915129151291512e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.2611,
        "grad_norm": 1.1499252319335938,
        "learning_rate": 2.288745387453875e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.2412,
        "grad_norm": 6.962387561798096,
        "learning_rate": 2.2859778597785978e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.2014,
        "grad_norm": 2.4637069702148438,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.3037,
        "grad_norm": 1.0702998638153076,
        "learning_rate": 2.2804428044280444e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.3376,
        "grad_norm": 3.2557666301727295,
        "learning_rate": 2.2776752767527674e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.3124,
        "grad_norm": 4.055500507354736,
        "learning_rate": 2.274907749077491e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.2714,
        "grad_norm": 5.6250834465026855,
        "learning_rate": 2.272140221402214e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.2532,
        "grad_norm": 3.5386102199554443,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.2962,
        "grad_norm": 2.112457036972046,
        "learning_rate": 2.2666051660516606e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3181,
        "grad_norm": 8.227458000183105,
        "learning_rate": 2.263837638376384e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.3425,
        "grad_norm": 0.9007002711296082,
        "learning_rate": 2.261070110701107e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.2206,
        "grad_norm": 1.9065134525299072,
        "learning_rate": 2.2583025830258302e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.3185,
        "grad_norm": 1.367978811264038,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.2454,
        "grad_norm": 1.722487449645996,
        "learning_rate": 2.252767527675277e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.4369,
        "grad_norm": 2.2254741191864014,
        "learning_rate": 2.25e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.39955756068229675,
        "eval_accuracy": 0.86888,
        "eval_precision": 0.85128,
        "eval_recall": 0.90054,
        "eval_f1": 0.87522,
        "eval_runtime": 18.1594,
        "eval_samples_per_second": 59.638,
        "eval_steps_per_second": 3.745,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.2548,
        "grad_norm": 1.1261154413223267,
        "learning_rate": 2.247232472324723e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.3921,
        "grad_norm": 8.693737030029297,
        "learning_rate": 2.2444649446494468e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.2581,
        "grad_norm": 1.0957481861114502,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.2943,
        "grad_norm": 6.273369312286377,
        "learning_rate": 2.238929889298893e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3227,
        "grad_norm": 5.0758795738220215,
        "learning_rate": 2.2361623616236163e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.2904,
        "grad_norm": 4.815678119659424,
        "learning_rate": 2.2333948339483393e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.2335,
        "grad_norm": 10.279714584350586,
        "learning_rate": 2.230627306273063e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.2642,
        "grad_norm": 14.832449913024902,
        "learning_rate": 2.227859778597786e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.2017,
        "grad_norm": 7.8405046463012695,
        "learning_rate": 2.2250922509225092e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.2797,
        "grad_norm": 1.222022533416748,
        "learning_rate": 2.2223247232472325e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.2412,
        "grad_norm": 2.9890358448028564,
        "learning_rate": 2.219557195571956e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.2267,
        "grad_norm": 0.7057422399520874,
        "learning_rate": 2.216789667896679e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.3038,
        "grad_norm": 7.016386032104492,
        "learning_rate": 2.214022140221402e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.2722,
        "grad_norm": 10.392537117004395,
        "learning_rate": 2.2112546125461254e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.318,
        "grad_norm": 5.08735990524292,
        "learning_rate": 2.2084870848708487e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.2711,
        "grad_norm": 4.536290168762207,
        "learning_rate": 2.205719557195572e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.2796,
        "grad_norm": 1.5975606441497803,
        "learning_rate": 2.2029520295202954e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.299,
        "grad_norm": 1.0269896984100342,
        "learning_rate": 2.2001845018450187e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2486,
        "grad_norm": 6.649929046630859,
        "learning_rate": 2.1974169741697416e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.2782,
        "grad_norm": 1.3962223529815674,
        "learning_rate": 2.194649446494465e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.3075,
        "grad_norm": 1.2926397323608398,
        "learning_rate": 2.1918819188191882e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.4148,
        "grad_norm": 0.6192538738250732,
        "learning_rate": 2.1891143911439116e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.2963,
        "grad_norm": 4.996471881866455,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.2856,
        "grad_norm": 3.286036968231201,
        "learning_rate": 2.1835793357933578e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.3592,
        "grad_norm": 2.0220603942871094,
        "learning_rate": 2.1808118081180815e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.2802,
        "grad_norm": 2.1709558963775635,
        "learning_rate": 2.1780442804428044e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.2759,
        "grad_norm": 1.0977367162704468,
        "learning_rate": 2.1752767527675274e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.35452699661254883,
        "eval_accuracy": 0.87812,
        "eval_precision": 0.85618,
        "eval_recall": 0.91501,
        "eval_f1": 0.88462,
        "eval_runtime": 18.2002,
        "eval_samples_per_second": 59.505,
        "eval_steps_per_second": 3.736,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.2431,
        "grad_norm": 2.2261290550231934,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.3406,
        "grad_norm": 3.5681674480438232,
        "learning_rate": 2.169741697416974e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.2786,
        "grad_norm": 1.4878382682800293,
        "learning_rate": 2.1669741697416977e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.2696,
        "grad_norm": 1.8133809566497803,
        "learning_rate": 2.1642066420664206e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.3048,
        "grad_norm": 2.9080936908721924,
        "learning_rate": 2.161439114391144e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.3636,
        "grad_norm": 3.6028997898101807,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.3562,
        "grad_norm": 1.3784271478652954,
        "learning_rate": 2.1559040590405906e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.1963,
        "grad_norm": 8.256796836853027,
        "learning_rate": 2.153136531365314e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.3129,
        "grad_norm": 5.146406173706055,
        "learning_rate": 2.150369003690037e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.2617,
        "grad_norm": 3.5256035327911377,
        "learning_rate": 2.14760147601476e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.1738,
        "grad_norm": 1.9191468954086304,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.3009,
        "grad_norm": 16.244483947753906,
        "learning_rate": 2.1420664206642068e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.209,
        "grad_norm": 0.7338749170303345,
        "learning_rate": 2.1392988929889297e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.2669,
        "grad_norm": 1.3052064180374146,
        "learning_rate": 2.1365313653136534e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.2477,
        "grad_norm": 2.5363359451293945,
        "learning_rate": 2.1337638376383763e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.2335,
        "grad_norm": 14.106856346130371,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.301,
        "grad_norm": 1.8246779441833496,
        "learning_rate": 2.128228782287823e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.304,
        "grad_norm": 2.3731658458709717,
        "learning_rate": 2.125461254612546e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.2572,
        "grad_norm": 0.8919517397880554,
        "learning_rate": 2.1226937269372696e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.3798,
        "grad_norm": 12.407687187194824,
        "learning_rate": 2.1199261992619925e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.3036,
        "grad_norm": 12.592385292053223,
        "learning_rate": 2.1171586715867162e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.2889,
        "grad_norm": 7.817718029022217,
        "learning_rate": 2.114391143911439e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.2252,
        "grad_norm": 1.6153923273086548,
        "learning_rate": 2.111623616236162e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.3585,
        "grad_norm": 11.669110298156738,
        "learning_rate": 2.1088560885608858e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.3136,
        "grad_norm": 1.7670446634292603,
        "learning_rate": 2.1060885608856087e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2241,
        "grad_norm": 2.7170603275299072,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.191,
        "grad_norm": 1.8491986989974976,
        "learning_rate": 2.1005535055350554e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.38252338767051697,
        "eval_accuracy": 0.87996,
        "eval_precision": 0.86403,
        "eval_recall": 0.90778,
        "eval_f1": 0.88536,
        "eval_runtime": 18.1963,
        "eval_samples_per_second": 59.518,
        "eval_steps_per_second": 3.737,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.3222,
        "grad_norm": 13.17476749420166,
        "learning_rate": 2.0977859778597787e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.2917,
        "grad_norm": 8.843855857849121,
        "learning_rate": 2.095018450184502e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.3048,
        "grad_norm": 3.5241196155548096,
        "learning_rate": 2.0922509225092253e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.2052,
        "grad_norm": 2.2847678661346436,
        "learning_rate": 2.0894833948339482e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2425,
        "grad_norm": 1.5213648080825806,
        "learning_rate": 2.0867158671586716e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.1719,
        "grad_norm": 4.751677989959717,
        "learning_rate": 2.083948339483395e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.1972,
        "grad_norm": 4.615911483764648,
        "learning_rate": 2.0811808118081182e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.3214,
        "grad_norm": 3.892118215560913,
        "learning_rate": 2.0784132841328415e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.3054,
        "grad_norm": 1.2103954553604126,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.3599,
        "grad_norm": 1.7145493030548096,
        "learning_rate": 2.072878228782288e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.2121,
        "grad_norm": 2.2902886867523193,
        "learning_rate": 2.070110701107011e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.3239,
        "grad_norm": 3.437314987182617,
        "learning_rate": 2.0673431734317344e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.2189,
        "grad_norm": 3.6726109981536865,
        "learning_rate": 2.0645756457564577e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.2567,
        "grad_norm": 14.80420207977295,
        "learning_rate": 2.0618081180811806e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.2535,
        "grad_norm": 4.314529895782471,
        "learning_rate": 2.0590405904059043e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.3081,
        "grad_norm": 6.088430881500244,
        "learning_rate": 2.0562730627306273e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.239,
        "grad_norm": 2.864464521408081,
        "learning_rate": 2.053505535055351e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.2936,
        "grad_norm": 2.5941474437713623,
        "learning_rate": 2.050738007380074e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.2659,
        "grad_norm": 7.31838846206665,
        "learning_rate": 2.047970479704797e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.2638,
        "grad_norm": 16.473230361938477,
        "learning_rate": 2.0452029520295205e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.3103,
        "grad_norm": 2.139587879180908,
        "learning_rate": 2.0424354243542435e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.2615,
        "grad_norm": 4.551403999328613,
        "learning_rate": 2.0396678966789668e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.3353,
        "grad_norm": 8.973029136657715,
        "learning_rate": 2.03690036900369e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.226,
        "grad_norm": 0.8814162015914917,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.2076,
        "grad_norm": 3.700139045715332,
        "learning_rate": 2.0313653136531367e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.2568,
        "grad_norm": 7.465571880340576,
        "learning_rate": 2.02859778597786e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.2392,
        "grad_norm": 1.6760404109954834,
        "learning_rate": 2.025830258302583e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.39585986733436584,
        "eval_accuracy": 0.8735,
        "eval_precision": 0.825,
        "eval_recall": 0.95479,
        "eval_f1": 0.88516,
        "eval_runtime": 18.1924,
        "eval_samples_per_second": 59.53,
        "eval_steps_per_second": 3.738,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.1773,
        "grad_norm": 2.171659469604492,
        "learning_rate": 2.0230627306273063e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.222,
        "grad_norm": 1.5077104568481445,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.2107,
        "grad_norm": 1.3284552097320557,
        "learning_rate": 2.017527675276753e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.2731,
        "grad_norm": 0.5371651649475098,
        "learning_rate": 2.0147601476014762e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.3099,
        "grad_norm": 16.927404403686523,
        "learning_rate": 2.011992619926199e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.2982,
        "grad_norm": 1.0446184873580933,
        "learning_rate": 2.0092250922509228e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.2406,
        "grad_norm": 1.4112823009490967,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.209,
        "grad_norm": 18.962182998657227,
        "learning_rate": 2.0036900369003687e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.207,
        "grad_norm": 10.92432975769043,
        "learning_rate": 2.0009225092250924e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.3405,
        "grad_norm": 14.161505699157715,
        "learning_rate": 1.9981549815498154e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.2428,
        "grad_norm": 2.780672550201416,
        "learning_rate": 1.995387453874539e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.2242,
        "grad_norm": 2.198943614959717,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.2375,
        "grad_norm": 1.5255906581878662,
        "learning_rate": 1.9898523985239853e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.26,
        "grad_norm": 26.246065139770508,
        "learning_rate": 1.9870848708487086e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.26,
        "grad_norm": 12.558906555175781,
        "learning_rate": 1.9843173431734316e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2019,
        "grad_norm": 1.1338486671447754,
        "learning_rate": 1.9815498154981552e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2628,
        "grad_norm": 14.810070991516113,
        "learning_rate": 1.9787822878228782e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.3079,
        "grad_norm": 21.275407791137695,
        "learning_rate": 1.9760147601476015e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.2502,
        "grad_norm": 3.0941543579101562,
        "learning_rate": 1.9732472324723248e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.354,
        "grad_norm": 6.904670238494873,
        "learning_rate": 1.970479704797048e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.2686,
        "grad_norm": 2.749981641769409,
        "learning_rate": 1.9677121771217714e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.1898,
        "grad_norm": 3.926396608352661,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.2508,
        "grad_norm": 4.944167613983154,
        "learning_rate": 1.9621771217712177e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.2171,
        "grad_norm": 1.0302140712738037,
        "learning_rate": 1.959409594095941e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.1966,
        "grad_norm": 1.265163779258728,
        "learning_rate": 1.9566420664206643e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.3158,
        "grad_norm": 2.7956347465515137,
        "learning_rate": 1.9538745387453873e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.292,
        "grad_norm": 3.9430758953094482,
        "learning_rate": 1.951107011070111e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.3482612371444702,
        "eval_accuracy": 0.87812,
        "eval_precision": 0.8526,
        "eval_recall": 0.92043,
        "eval_f1": 0.88522,
        "eval_runtime": 18.1845,
        "eval_samples_per_second": 59.556,
        "eval_steps_per_second": 3.739,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.3111,
        "grad_norm": 2.000753879547119,
        "learning_rate": 1.948339483394834e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.3134,
        "grad_norm": 3.804086446762085,
        "learning_rate": 1.9455719557195575e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.2445,
        "grad_norm": 1.7351099252700806,
        "learning_rate": 1.9428044280442805e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.2632,
        "grad_norm": 1.0510703325271606,
        "learning_rate": 1.9400369003690035e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.1951,
        "grad_norm": 5.3383355140686035,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.2624,
        "grad_norm": 19.988750457763672,
        "learning_rate": 1.93450184501845e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.2829,
        "grad_norm": 23.299345016479492,
        "learning_rate": 1.9317343173431737e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.1317,
        "grad_norm": 8.711518287658691,
        "learning_rate": 1.9289667896678967e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2239,
        "grad_norm": 18.784507751464844,
        "learning_rate": 1.92619926199262e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.221,
        "grad_norm": 5.232605457305908,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.2498,
        "grad_norm": 4.202415466308594,
        "learning_rate": 1.9206642066420663e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.3289,
        "grad_norm": 1.2887831926345825,
        "learning_rate": 1.9178966789667896e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.2421,
        "grad_norm": 2.030930519104004,
        "learning_rate": 1.915129151291513e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.238,
        "grad_norm": 2.029201030731201,
        "learning_rate": 1.9123616236162362e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.2786,
        "grad_norm": 1.9637255668640137,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.2162,
        "grad_norm": 6.363801956176758,
        "learning_rate": 1.9068265682656828e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.1764,
        "grad_norm": 1.0216740369796753,
        "learning_rate": 1.9040590405904058e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.2566,
        "grad_norm": 4.487436771392822,
        "learning_rate": 1.901291512915129e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.2475,
        "grad_norm": 6.3543853759765625,
        "learning_rate": 1.8985239852398524e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.2602,
        "grad_norm": 4.291229248046875,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.2384,
        "grad_norm": 1.4533129930496216,
        "learning_rate": 1.892988929889299e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.3251,
        "grad_norm": 12.999327659606934,
        "learning_rate": 1.890221402214022e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.2067,
        "grad_norm": 4.518825531005859,
        "learning_rate": 1.8874538745387456e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.3057,
        "grad_norm": 1.8535383939743042,
        "learning_rate": 1.8846863468634686e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.1701,
        "grad_norm": 6.166013240814209,
        "learning_rate": 1.8819188191881922e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.3468,
        "grad_norm": 5.677933692932129,
        "learning_rate": 1.8791512915129152e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.2483,
        "grad_norm": 1.3676809072494507,
        "learning_rate": 1.8763837638376382e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.3766449987888336,
        "eval_accuracy": 0.87258,
        "eval_precision": 0.84298,
        "eval_recall": 0.92224,
        "eval_f1": 0.88083,
        "eval_runtime": 18.3745,
        "eval_samples_per_second": 58.94,
        "eval_steps_per_second": 3.701,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.2037,
        "grad_norm": 1.920466423034668,
        "learning_rate": 1.8736162361623618e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.2246,
        "grad_norm": 3.5881967544555664,
        "learning_rate": 1.8708487084870848e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.0893,
        "grad_norm": 4.288325786590576,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.427,
        "grad_norm": 5.696232795715332,
        "learning_rate": 1.8653136531365314e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.2839,
        "grad_norm": 4.754034996032715,
        "learning_rate": 1.8625461254612547e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.2287,
        "grad_norm": 1.3448357582092285,
        "learning_rate": 1.859778597785978e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.2728,
        "grad_norm": 19.631454467773438,
        "learning_rate": 1.857011070110701e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.2582,
        "grad_norm": 4.612514495849609,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.141,
        "grad_norm": 8.628032684326172,
        "learning_rate": 1.8514760147601476e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.2599,
        "grad_norm": 1.0325313806533813,
        "learning_rate": 1.848708487084871e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.2741,
        "grad_norm": 0.9866481423377991,
        "learning_rate": 1.8459409594095942e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.2065,
        "grad_norm": 7.715199947357178,
        "learning_rate": 1.8431734317343175e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.1057,
        "grad_norm": 3.5277414321899414,
        "learning_rate": 1.8404059040590405e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.2795,
        "grad_norm": 23.50020980834961,
        "learning_rate": 1.8376383763837638e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.1725,
        "grad_norm": 3.8874926567077637,
        "learning_rate": 1.834870848708487e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.3413,
        "grad_norm": 9.171198844909668,
        "learning_rate": 1.8321033210332104e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.2798,
        "grad_norm": 2.39564847946167,
        "learning_rate": 1.8293357933579337e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.1778,
        "grad_norm": 2.315018653869629,
        "learning_rate": 1.8265682656826567e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.2602,
        "grad_norm": 2.120060682296753,
        "learning_rate": 1.8238007380073803e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.1803,
        "grad_norm": 1.5922077894210815,
        "learning_rate": 1.8210332103321033e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.3077,
        "grad_norm": 25.21571922302246,
        "learning_rate": 1.8182656826568266e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.2871,
        "grad_norm": 6.286450386047363,
        "learning_rate": 1.81549815498155e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.2803,
        "grad_norm": 4.710939407348633,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.2896,
        "grad_norm": 2.32210111618042,
        "learning_rate": 1.8099630996309965e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.165,
        "grad_norm": 1.2502009868621826,
        "learning_rate": 1.8071955719557195e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.2188,
        "grad_norm": 1.9822911024093628,
        "learning_rate": 1.8044280442804428e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.2008,
        "grad_norm": 2.6936609745025635,
        "learning_rate": 1.801660516605166e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.4585629105567932,
        "eval_accuracy": 0.87719,
        "eval_precision": 0.85836,
        "eval_recall": 0.90958,
        "eval_f1": 0.88323,
        "eval_runtime": 18.374,
        "eval_samples_per_second": 58.942,
        "eval_steps_per_second": 3.701,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.2008,
        "grad_norm": 0.23415550589561462,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.2979,
        "grad_norm": 0.7800855040550232,
        "learning_rate": 1.7961254612546127e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.33,
        "grad_norm": 0.825896680355072,
        "learning_rate": 1.7933579335793357e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.2213,
        "grad_norm": 4.858773708343506,
        "learning_rate": 1.790590405904059e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.222,
        "grad_norm": 2.365748882293701,
        "learning_rate": 1.7878228782287823e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.2146,
        "grad_norm": 8.748481750488281,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.2426,
        "grad_norm": 2.402434825897217,
        "learning_rate": 1.7822878228782286e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.2805,
        "grad_norm": 0.7921406626701355,
        "learning_rate": 1.7795202952029522e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.1613,
        "grad_norm": 1.003230094909668,
        "learning_rate": 1.7767527675276752e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.3285,
        "grad_norm": 2.2207248210906982,
        "learning_rate": 1.7739852398523985e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.2508,
        "grad_norm": 3.2559430599212646,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.2346,
        "grad_norm": 14.664559364318848,
        "learning_rate": 1.7684501845018448e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.1691,
        "grad_norm": 1.6639349460601807,
        "learning_rate": 1.7656826568265684e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.2677,
        "grad_norm": 1.4240624904632568,
        "learning_rate": 1.7629151291512914e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.2428,
        "grad_norm": 0.8508139848709106,
        "learning_rate": 1.760147601476015e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.2452,
        "grad_norm": 25.045108795166016,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.2321,
        "grad_norm": 4.649934768676758,
        "learning_rate": 1.7546125461254613e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.2201,
        "grad_norm": 4.619705677032471,
        "learning_rate": 1.7518450184501846e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.286,
        "grad_norm": 53.09452819824219,
        "learning_rate": 1.7490774907749076e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.1802,
        "grad_norm": 11.514110565185547,
        "learning_rate": 1.7463099630996313e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.219,
        "grad_norm": 1.7207715511322021,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.2627,
        "grad_norm": 1.5129992961883545,
        "learning_rate": 1.7407749077490775e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.2787,
        "grad_norm": 2.0000827312469482,
        "learning_rate": 1.738007380073801e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.1886,
        "grad_norm": 3.9147603511810303,
        "learning_rate": 1.735239852398524e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.293,
        "grad_norm": 0.4186578094959259,
        "learning_rate": 1.732472324723247e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.1269,
        "grad_norm": 1.5012532472610474,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.2027,
        "grad_norm": 14.391884803771973,
        "learning_rate": 1.7269372693726937e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.4200981557369232,
        "eval_accuracy": 0.88181,
        "eval_precision": 0.86078,
        "eval_recall": 0.91682,
        "eval_f1": 0.88792,
        "eval_runtime": 18.3733,
        "eval_samples_per_second": 58.944,
        "eval_steps_per_second": 3.701,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.1734,
        "grad_norm": 1.1337627172470093,
        "learning_rate": 1.724169741697417e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.2038,
        "grad_norm": 2.8722124099731445,
        "learning_rate": 1.7214022140221404e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.2398,
        "grad_norm": 1.1161181926727295,
        "learning_rate": 1.7186346863468633e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.1936,
        "grad_norm": 1.5976738929748535,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.3776,
        "grad_norm": 13.104183197021484,
        "learning_rate": 1.71309963099631e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.2526,
        "grad_norm": 0.6529772877693176,
        "learning_rate": 1.7103321033210332e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.1678,
        "grad_norm": 3.1478681564331055,
        "learning_rate": 1.7075645756457566e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.0796,
        "grad_norm": 1.0860251188278198,
        "learning_rate": 1.7047970479704795e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2666,
        "grad_norm": 0.3604345917701721,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.2638,
        "grad_norm": 3.332083225250244,
        "learning_rate": 1.699261992619926e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.2307,
        "grad_norm": 7.202600002288818,
        "learning_rate": 1.6964944649446494e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.3205,
        "grad_norm": 7.53733491897583,
        "learning_rate": 1.6937269372693727e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.2599,
        "grad_norm": 5.215360164642334,
        "learning_rate": 1.690959409594096e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.2421,
        "grad_norm": 8.897248268127441,
        "learning_rate": 1.6881918819188194e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.168,
        "grad_norm": 1.7770031690597534,
        "learning_rate": 1.6854243542435423e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.1759,
        "grad_norm": 1.2156325578689575,
        "learning_rate": 1.6826568265682656e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.2743,
        "grad_norm": 1.39322030544281,
        "learning_rate": 1.679889298892989e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.1835,
        "grad_norm": 1.4839340448379517,
        "learning_rate": 1.6771217712177123e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.3613,
        "grad_norm": 5.971835613250732,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.172,
        "grad_norm": 3.373640537261963,
        "learning_rate": 1.671586715867159e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.2742,
        "grad_norm": 1.3628782033920288,
        "learning_rate": 1.668819188191882e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.1918,
        "grad_norm": 3.0048983097076416,
        "learning_rate": 1.666051660516605e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.2051,
        "grad_norm": 3.4968535900115967,
        "learning_rate": 1.6632841328413285e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.2701,
        "grad_norm": 20.20094871520996,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.2311,
        "grad_norm": 4.973133563995361,
        "learning_rate": 1.657749077490775e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.2641,
        "grad_norm": 2.653663396835327,
        "learning_rate": 1.654981549815498e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.1116,
        "grad_norm": 3.6225695610046387,
        "learning_rate": 1.6522140221402217e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.4129147529602051,
        "eval_accuracy": 0.8855,
        "eval_precision": 0.84992,
        "eval_recall": 0.94213,
        "eval_f1": 0.89365,
        "eval_runtime": 18.3614,
        "eval_samples_per_second": 58.982,
        "eval_steps_per_second": 3.703,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.249,
        "grad_norm": 2.5859642028808594,
        "learning_rate": 1.6494464944649447e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.2037,
        "grad_norm": 1.7673484086990356,
        "learning_rate": 1.6466789667896676e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.2583,
        "grad_norm": 6.292783260345459,
        "learning_rate": 1.6439114391143913e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.1309,
        "grad_norm": 1.0995521545410156,
        "learning_rate": 1.6411439114391142e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2113,
        "grad_norm": 0.9298223257064819,
        "learning_rate": 1.638376383763838e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.1433,
        "grad_norm": 1.4833636283874512,
        "learning_rate": 1.635608856088561e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.2599,
        "grad_norm": 8.039532661437988,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.1941,
        "grad_norm": 1.1902172565460205,
        "learning_rate": 1.6300738007380075e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.1805,
        "grad_norm": 2.4021127223968506,
        "learning_rate": 1.6273062730627308e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.2729,
        "grad_norm": 3.7449734210968018,
        "learning_rate": 1.624538745387454e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.1957,
        "grad_norm": 9.681398391723633,
        "learning_rate": 1.621771217712177e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.2814,
        "grad_norm": 9.659897804260254,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.1882,
        "grad_norm": 3.0159823894500732,
        "learning_rate": 1.6162361623616237e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.2422,
        "grad_norm": 4.00116491317749,
        "learning_rate": 1.613468634686347e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.2103,
        "grad_norm": 1.7166781425476074,
        "learning_rate": 1.6107011070110703e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.2557,
        "grad_norm": 4.580594062805176,
        "learning_rate": 1.6079335793357936e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.2175,
        "grad_norm": 16.44117546081543,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.2975,
        "grad_norm": 1.8008760213851929,
        "learning_rate": 1.60239852398524e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.2279,
        "grad_norm": 3.402376890182495,
        "learning_rate": 1.5996309963099632e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.1514,
        "grad_norm": 1.666744351387024,
        "learning_rate": 1.596863468634686e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.1502,
        "grad_norm": 0.45014989376068115,
        "learning_rate": 1.5940959409594098e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.3114,
        "grad_norm": 9.556089401245117,
        "learning_rate": 1.5913284132841328e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.1942,
        "grad_norm": 0.8953871726989746,
        "learning_rate": 1.5885608856088564e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2544,
        "grad_norm": 20.44641876220703,
        "learning_rate": 1.5857933579335794e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.2069,
        "grad_norm": 39.05978775024414,
        "learning_rate": 1.5830258302583023e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2466,
        "grad_norm": 1.3008936643600464,
        "learning_rate": 1.580258302583026e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.2657,
        "grad_norm": 4.186346530914307,
        "learning_rate": 1.577490774907749e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.40639907121658325,
        "eval_accuracy": 0.87812,
        "eval_precision": 0.86995,
        "eval_recall": 0.89512,
        "eval_f1": 0.88235,
        "eval_runtime": 18.1334,
        "eval_samples_per_second": 59.724,
        "eval_steps_per_second": 3.75,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.2907,
        "grad_norm": 18.913631439208984,
        "learning_rate": 1.5747232472324726e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.1379,
        "grad_norm": 1.0696324110031128,
        "learning_rate": 1.5719557195571956e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.1537,
        "grad_norm": 0.6390066742897034,
        "learning_rate": 1.569188191881919e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.1272,
        "grad_norm": 8.54207706451416,
        "learning_rate": 1.5664206642066422e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.4324,
        "grad_norm": 10.913060188293457,
        "learning_rate": 1.5636531365313655e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.2968,
        "grad_norm": 4.276906490325928,
        "learning_rate": 1.5608856088560885e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2219,
        "grad_norm": 22.82061004638672,
        "learning_rate": 1.5581180811808118e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.1988,
        "grad_norm": 2.597848415374756,
        "learning_rate": 1.555350553505535e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.2385,
        "grad_norm": 1.6850311756134033,
        "learning_rate": 1.5525830258302584e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.1302,
        "grad_norm": 6.942528247833252,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.2069,
        "grad_norm": 11.755378723144531,
        "learning_rate": 1.5470479704797047e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.1349,
        "grad_norm": 0.7779541611671448,
        "learning_rate": 1.5442804428044283e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.2067,
        "grad_norm": 3.4882423877716064,
        "learning_rate": 1.5415129151291513e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2726,
        "grad_norm": 9.118802070617676,
        "learning_rate": 1.5387453874538746e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.1538,
        "grad_norm": 2.2222375869750977,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.2495,
        "grad_norm": 1.285217523574829,
        "learning_rate": 1.533210332103321e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.1564,
        "grad_norm": 2.4147961139678955,
        "learning_rate": 1.5304428044280445e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.1763,
        "grad_norm": 6.1971330642700195,
        "learning_rate": 1.5276752767527675e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.2713,
        "grad_norm": 38.8311882019043,
        "learning_rate": 1.524907749077491e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.2392,
        "grad_norm": 1.1773474216461182,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.2888,
        "grad_norm": 5.259782314300537,
        "learning_rate": 1.5193726937269372e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.3692,
        "grad_norm": 0.8914377093315125,
        "learning_rate": 1.5166051660516607e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.0802,
        "grad_norm": 0.7014486789703369,
        "learning_rate": 1.5138376383763838e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.2326,
        "grad_norm": 6.11865234375,
        "learning_rate": 1.511070110701107e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.1812,
        "grad_norm": 3.4188127517700195,
        "learning_rate": 1.5083025830258303e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.1937,
        "grad_norm": 5.7259907722473145,
        "learning_rate": 1.5055350553505534e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.3275,
        "grad_norm": 17.986431121826172,
        "learning_rate": 1.5027675276752769e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.1308,
        "grad_norm": 1.4106818437576294,
        "learning_rate": 1.5e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.449006050825119,
        "eval_accuracy": 0.87719,
        "eval_precision": 0.85235,
        "eval_recall": 0.91863,
        "eval_f1": 0.88425,
        "eval_runtime": 18.126,
        "eval_samples_per_second": 59.748,
        "eval_steps_per_second": 3.752,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.2137,
        "grad_norm": 1.4136823415756226,
        "learning_rate": 1.4972324723247233e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.316,
        "grad_norm": 2.789412498474121,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.1822,
        "grad_norm": 3.641427993774414,
        "learning_rate": 1.4916974169741698e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.24,
        "grad_norm": 17.91988182067871,
        "learning_rate": 1.488929889298893e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.1659,
        "grad_norm": 16.502172470092773,
        "learning_rate": 1.4861623616236162e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.3036,
        "grad_norm": 1.0762311220169067,
        "learning_rate": 1.4833948339483395e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.1798,
        "grad_norm": 1.5714715719223022,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.2119,
        "grad_norm": 43.1226806640625,
        "learning_rate": 1.477859778597786e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.2061,
        "grad_norm": 2.957794666290283,
        "learning_rate": 1.4750922509225093e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.1775,
        "grad_norm": 7.601559638977051,
        "learning_rate": 1.4723247232472326e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.1661,
        "grad_norm": 4.664719104766846,
        "learning_rate": 1.4695571955719559e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.1913,
        "grad_norm": 4.6576762199401855,
        "learning_rate": 1.4667896678966789e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.1402,
        "grad_norm": 5.720860481262207,
        "learning_rate": 1.4640221402214022e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.22,
        "grad_norm": 8.747577667236328,
        "learning_rate": 1.4612546125461255e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.3007,
        "grad_norm": 2.500811815261841,
        "learning_rate": 1.4584870848708488e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.1965,
        "grad_norm": 6.805240631103516,
        "learning_rate": 1.455719557195572e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.3124,
        "grad_norm": 2.3551156520843506,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.2026,
        "grad_norm": 5.716683864593506,
        "learning_rate": 1.4501845018450186e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.2006,
        "grad_norm": 56.062339782714844,
        "learning_rate": 1.4474169741697419e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.1426,
        "grad_norm": 1.2868465185165405,
        "learning_rate": 1.4446494464944648e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.1709,
        "grad_norm": 1.4205012321472168,
        "learning_rate": 1.4418819188191881e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.147,
        "grad_norm": 0.888098418712616,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.2427,
        "grad_norm": 43.78263473510742,
        "learning_rate": 1.4363468634686348e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.1983,
        "grad_norm": 1.6735687255859375,
        "learning_rate": 1.433579335793358e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.2432,
        "grad_norm": 3.4037599563598633,
        "learning_rate": 1.4308118081180812e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.1614,
        "grad_norm": 5.675127983093262,
        "learning_rate": 1.4280442804428045e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.2371,
        "grad_norm": 0.3140963912010193,
        "learning_rate": 1.4252767527675276e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.4665669798851013,
        "eval_accuracy": 0.87627,
        "eval_precision": 0.8708,
        "eval_recall": 0.88969,
        "eval_f1": 0.88014,
        "eval_runtime": 18.1546,
        "eval_samples_per_second": 59.654,
        "eval_steps_per_second": 3.746,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.1892,
        "grad_norm": 1.1929038763046265,
        "learning_rate": 1.422509225092251e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.1898,
        "grad_norm": 1.2602816820144653,
        "learning_rate": 1.4197416974169741e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.2274,
        "grad_norm": 1.350119948387146,
        "learning_rate": 1.4169741697416974e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.13,
        "grad_norm": 6.169693946838379,
        "learning_rate": 1.4142066420664207e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.2538,
        "grad_norm": 40.336875915527344,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.1933,
        "grad_norm": 7.079987525939941,
        "learning_rate": 1.4086715867158673e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.2144,
        "grad_norm": 21.565269470214844,
        "learning_rate": 1.4059040590405905e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.1445,
        "grad_norm": 2.4175868034362793,
        "learning_rate": 1.4031365313653136e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.1719,
        "grad_norm": 1.3376656770706177,
        "learning_rate": 1.4003690036900369e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.2348,
        "grad_norm": 3.157470464706421,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.1524,
        "grad_norm": 0.42394712567329407,
        "learning_rate": 1.3948339483394834e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.222,
        "grad_norm": 5.9541096687316895,
        "learning_rate": 1.3920664206642067e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.2665,
        "grad_norm": 6.845029354095459,
        "learning_rate": 1.38929889298893e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.2255,
        "grad_norm": 38.715972900390625,
        "learning_rate": 1.3865313653136533e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.1593,
        "grad_norm": 0.6899175643920898,
        "learning_rate": 1.3837638376383764e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.1254,
        "grad_norm": 5.023512840270996,
        "learning_rate": 1.3809963099630995e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.216,
        "grad_norm": 3.1533679962158203,
        "learning_rate": 1.3782287822878229e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.3616,
        "grad_norm": 3.7139337062835693,
        "learning_rate": 1.3754612546125462e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.2298,
        "grad_norm": 1.4365804195404053,
        "learning_rate": 1.3726937269372695e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.2412,
        "grad_norm": 20.44230079650879,
        "learning_rate": 1.3699261992619926e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.2009,
        "grad_norm": 1.1831387281417847,
        "learning_rate": 1.367158671586716e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.1903,
        "grad_norm": 2.285792589187622,
        "learning_rate": 1.3643911439114392e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.1994,
        "grad_norm": 0.642038106918335,
        "learning_rate": 1.3616236162361624e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.2856,
        "grad_norm": 2.964247703552246,
        "learning_rate": 1.3588560885608857e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.2117,
        "grad_norm": 20.07579803466797,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.1962,
        "grad_norm": 1.3058042526245117,
        "learning_rate": 1.3533210332103321e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.2445,
        "grad_norm": 14.529607772827148,
        "learning_rate": 1.3505535055350554e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.5034136772155762,
        "eval_accuracy": 0.88089,
        "eval_precision": 0.86678,
        "eval_recall": 0.90597,
        "eval_f1": 0.88594,
        "eval_runtime": 18.2136,
        "eval_samples_per_second": 59.461,
        "eval_steps_per_second": 3.733,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.1683,
        "grad_norm": 1.0734349489212036,
        "learning_rate": 1.3477859778597787e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.1575,
        "grad_norm": 1.0197969675064087,
        "learning_rate": 1.3450184501845019e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.1839,
        "grad_norm": 1.8692225217819214,
        "learning_rate": 1.3422509225092252e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.1504,
        "grad_norm": 2.295830488204956,
        "learning_rate": 1.3394833948339483e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.2259,
        "grad_norm": 0.6251819729804993,
        "learning_rate": 1.3367158671586716e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.1736,
        "grad_norm": 2.404660224914551,
        "learning_rate": 1.3339483394833948e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.1786,
        "grad_norm": 1.5230457782745361,
        "learning_rate": 1.331180811808118e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.2083,
        "grad_norm": 2.3968048095703125,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.2648,
        "grad_norm": 82.41349029541016,
        "learning_rate": 1.3256457564575647e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.2123,
        "grad_norm": 12.394070625305176,
        "learning_rate": 1.322878228782288e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.2223,
        "grad_norm": 0.8644281625747681,
        "learning_rate": 1.320110701107011e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.2301,
        "grad_norm": 2.9406020641326904,
        "learning_rate": 1.3173431734317343e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.1773,
        "grad_norm": 0.7407160401344299,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.3231,
        "grad_norm": 16.943754196166992,
        "learning_rate": 1.3118081180811809e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.2026,
        "grad_norm": 2.085177421569824,
        "learning_rate": 1.309040590405904e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.1845,
        "grad_norm": 10.795065879821777,
        "learning_rate": 1.3062730627306273e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.1622,
        "grad_norm": 2.8108365535736084,
        "learning_rate": 1.3035055350553506e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.1966,
        "grad_norm": 7.871556758880615,
        "learning_rate": 1.300738007380074e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.1362,
        "grad_norm": 0.8551661372184753,
        "learning_rate": 1.297970479704797e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.2755,
        "grad_norm": 3.0628581047058105,
        "learning_rate": 1.2952029520295202e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.2532,
        "grad_norm": 3.4873249530792236,
        "learning_rate": 1.2924354243542435e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.1428,
        "grad_norm": 1.023595929145813,
        "learning_rate": 1.2896678966789668e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.204,
        "grad_norm": 2.733433485031128,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.1968,
        "grad_norm": 6.75441837310791,
        "learning_rate": 1.2841328413284133e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.392,
        "grad_norm": 23.37181282043457,
        "learning_rate": 1.2813653136531366e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.1579,
        "grad_norm": 1.5332223176956177,
        "learning_rate": 1.2785977859778599e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.2379,
        "grad_norm": 1.4080458879470825,
        "learning_rate": 1.275830258302583e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.4669205844402313,
        "eval_accuracy": 0.87165,
        "eval_precision": 0.86063,
        "eval_recall": 0.89331,
        "eval_f1": 0.87666,
        "eval_runtime": 18.1476,
        "eval_samples_per_second": 59.677,
        "eval_steps_per_second": 3.747,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.183,
        "grad_norm": 2.6829257011413574,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.153,
        "grad_norm": 1.1069386005401611,
        "learning_rate": 1.2702952029520295e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.2483,
        "grad_norm": 3.762601375579834,
        "learning_rate": 1.2675276752767528e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.213,
        "grad_norm": 6.790403366088867,
        "learning_rate": 1.2647601476014761e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.1026,
        "grad_norm": 9.645598411560059,
        "learning_rate": 1.2619926199261994e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.2062,
        "grad_norm": 16.697734832763672,
        "learning_rate": 1.2592250922509225e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.2663,
        "grad_norm": 1.1482112407684326,
        "learning_rate": 1.2564575645756457e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.3137,
        "grad_norm": 37.28030776977539,
        "learning_rate": 1.253690036900369e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.2632,
        "grad_norm": 1.8524364233016968,
        "learning_rate": 1.2509225092250923e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.1916,
        "grad_norm": 3.151916742324829,
        "learning_rate": 1.2481549815498156e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.1628,
        "grad_norm": 1.3888787031173706,
        "learning_rate": 1.2453874538745387e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.2186,
        "grad_norm": 0.9136897325515747,
        "learning_rate": 1.242619926199262e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.1288,
        "grad_norm": 0.7550109624862671,
        "learning_rate": 1.2398523985239854e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.1658,
        "grad_norm": 0.9048355221748352,
        "learning_rate": 1.2370848708487087e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.1793,
        "grad_norm": 10.256502151489258,
        "learning_rate": 1.2343173431734316e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.1893,
        "grad_norm": 6.396910667419434,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.2107,
        "grad_norm": 0.4341691732406616,
        "learning_rate": 1.2287822878228782e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.1787,
        "grad_norm": 0.6179641485214233,
        "learning_rate": 1.2260147601476015e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.2182,
        "grad_norm": 2.6923911571502686,
        "learning_rate": 1.2232472324723247e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.2644,
        "grad_norm": 2.2789762020111084,
        "learning_rate": 1.220479704797048e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.2413,
        "grad_norm": 2.374194860458374,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.1785,
        "grad_norm": 15.938034057617188,
        "learning_rate": 1.2149446494464946e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.2025,
        "grad_norm": 25.86090087890625,
        "learning_rate": 1.2121771217712177e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.1761,
        "grad_norm": 0.8710336089134216,
        "learning_rate": 1.2094095940959409e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.2169,
        "grad_norm": 15.892435073852539,
        "learning_rate": 1.2066420664206642e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.2075,
        "grad_norm": 3.686285972595215,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.1571,
        "grad_norm": 0.74626225233078,
        "learning_rate": 1.2011070110701108e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.5209974646568298,
        "eval_accuracy": 0.87719,
        "eval_precision": 0.86082,
        "eval_recall": 0.90597,
        "eval_f1": 0.88282,
        "eval_runtime": 18.1719,
        "eval_samples_per_second": 59.598,
        "eval_steps_per_second": 3.742,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "loss": 0.2152,
        "grad_norm": 2.4085562229156494,
        "learning_rate": 1.198339483394834e-05,
        "epoch": 24.022140221402214,
        "step": 6510
    },
    {
        "loss": 0.115,
        "grad_norm": 7.7416768074035645,
        "learning_rate": 1.1955719557195573e-05,
        "epoch": 24.059040590405903,
        "step": 6520
    },
    {
        "loss": 0.155,
        "grad_norm": 3.4034931659698486,
        "learning_rate": 1.1928044280442804e-05,
        "epoch": 24.095940959409592,
        "step": 6530
    },
    {
        "loss": 0.1968,
        "grad_norm": 4.718996047973633,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 24.132841328413285,
        "step": 6540
    },
    {
        "loss": 0.1017,
        "grad_norm": 1.0833261013031006,
        "learning_rate": 1.187269372693727e-05,
        "epoch": 24.169741697416974,
        "step": 6550
    },
    {
        "loss": 0.1839,
        "grad_norm": 2.145822286605835,
        "learning_rate": 1.1845018450184501e-05,
        "epoch": 24.206642066420663,
        "step": 6560
    },
    {
        "loss": 0.1939,
        "grad_norm": 0.4363548755645752,
        "learning_rate": 1.1817343173431735e-05,
        "epoch": 24.243542435424356,
        "step": 6570
    },
    {
        "loss": 0.204,
        "grad_norm": 2.9233784675598145,
        "learning_rate": 1.1789667896678968e-05,
        "epoch": 24.280442804428045,
        "step": 6580
    },
    {
        "loss": 0.1605,
        "grad_norm": 2.114363670349121,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 24.317343173431734,
        "step": 6590
    },
    {
        "loss": 0.1799,
        "grad_norm": 8.275362968444824,
        "learning_rate": 1.1734317343173432e-05,
        "epoch": 24.354243542435423,
        "step": 6600
    },
    {
        "loss": 0.1927,
        "grad_norm": 1.410248041152954,
        "learning_rate": 1.1706642066420663e-05,
        "epoch": 24.391143911439116,
        "step": 6610
    },
    {
        "loss": 0.1997,
        "grad_norm": 12.33001708984375,
        "learning_rate": 1.1678966789667897e-05,
        "epoch": 24.428044280442805,
        "step": 6620
    },
    {
        "loss": 0.2033,
        "grad_norm": 59.10812759399414,
        "learning_rate": 1.165129151291513e-05,
        "epoch": 24.464944649446494,
        "step": 6630
    },
    {
        "loss": 0.16,
        "grad_norm": 3.9314897060394287,
        "learning_rate": 1.1623616236162363e-05,
        "epoch": 24.501845018450183,
        "step": 6640
    },
    {
        "loss": 0.1404,
        "grad_norm": 0.5950173139572144,
        "learning_rate": 1.1595940959409594e-05,
        "epoch": 24.538745387453876,
        "step": 6650
    },
    {
        "loss": 0.2107,
        "grad_norm": 9.493247985839844,
        "learning_rate": 1.1568265682656827e-05,
        "epoch": 24.575645756457565,
        "step": 6660
    },
    {
        "loss": 0.331,
        "grad_norm": 1.5816518068313599,
        "learning_rate": 1.154059040590406e-05,
        "epoch": 24.612546125461254,
        "step": 6670
    },
    {
        "loss": 0.191,
        "grad_norm": 1.373347282409668,
        "learning_rate": 1.1512915129151292e-05,
        "epoch": 24.649446494464943,
        "step": 6680
    },
    {
        "loss": 0.1659,
        "grad_norm": 0.6914066076278687,
        "learning_rate": 1.1485239852398523e-05,
        "epoch": 24.686346863468636,
        "step": 6690
    },
    {
        "loss": 0.1029,
        "grad_norm": 16.734460830688477,
        "learning_rate": 1.1457564575645756e-05,
        "epoch": 24.723247232472325,
        "step": 6700
    },
    {
        "loss": 0.2435,
        "grad_norm": 45.38624572753906,
        "learning_rate": 1.1429889298892989e-05,
        "epoch": 24.760147601476014,
        "step": 6710
    },
    {
        "loss": 0.2228,
        "grad_norm": 1.857120156288147,
        "learning_rate": 1.1402214022140222e-05,
        "epoch": 24.797047970479706,
        "step": 6720
    },
    {
        "loss": 0.2299,
        "grad_norm": 0.615537703037262,
        "learning_rate": 1.1374538745387455e-05,
        "epoch": 24.833948339483396,
        "step": 6730
    },
    {
        "loss": 0.2198,
        "grad_norm": 1.404950737953186,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 24.870848708487085,
        "step": 6740
    },
    {
        "loss": 0.1997,
        "grad_norm": 1.0900871753692627,
        "learning_rate": 1.131918819188192e-05,
        "epoch": 24.907749077490774,
        "step": 6750
    },
    {
        "loss": 0.2669,
        "grad_norm": 8.188475608825684,
        "learning_rate": 1.1291512915129151e-05,
        "epoch": 24.944649446494466,
        "step": 6760
    },
    {
        "loss": 0.1467,
        "grad_norm": 15.3514404296875,
        "learning_rate": 1.1263837638376384e-05,
        "epoch": 24.981549815498155,
        "step": 6770
    },
    {
        "eval_loss": 0.5002817511558533,
        "eval_accuracy": 0.88089,
        "eval_precision": 0.86552,
        "eval_recall": 0.90778,
        "eval_f1": 0.88614,
        "eval_runtime": 18.1421,
        "eval_samples_per_second": 59.695,
        "eval_steps_per_second": 3.748,
        "epoch": 25.0,
        "step": 6775
    },
    {
        "loss": 0.3381,
        "grad_norm": 5.663588523864746,
        "learning_rate": 1.1236162361623616e-05,
        "epoch": 25.018450184501845,
        "step": 6780
    },
    {
        "loss": 0.1517,
        "grad_norm": 1.857222080230713,
        "learning_rate": 1.1208487084870849e-05,
        "epoch": 25.055350553505534,
        "step": 6790
    },
    {
        "loss": 0.154,
        "grad_norm": 0.8767886161804199,
        "learning_rate": 1.1180811808118082e-05,
        "epoch": 25.092250922509226,
        "step": 6800
    },
    {
        "loss": 0.1611,
        "grad_norm": 0.8642728328704834,
        "learning_rate": 1.1153136531365315e-05,
        "epoch": 25.129151291512915,
        "step": 6810
    },
    {
        "loss": 0.2185,
        "grad_norm": 1.6733031272888184,
        "learning_rate": 1.1125461254612546e-05,
        "epoch": 25.166051660516604,
        "step": 6820
    },
    {
        "loss": 0.1983,
        "grad_norm": 4.387386322021484,
        "learning_rate": 1.109778597785978e-05,
        "epoch": 25.202952029520294,
        "step": 6830
    },
    {
        "loss": 0.179,
        "grad_norm": 0.8825311660766602,
        "learning_rate": 1.107011070110701e-05,
        "epoch": 25.239852398523986,
        "step": 6840
    },
    {
        "loss": 0.207,
        "grad_norm": 11.692341804504395,
        "learning_rate": 1.1042435424354244e-05,
        "epoch": 25.276752767527675,
        "step": 6850
    },
    {
        "loss": 0.2628,
        "grad_norm": 17.69922637939453,
        "learning_rate": 1.1014760147601477e-05,
        "epoch": 25.313653136531364,
        "step": 6860
    },
    {
        "loss": 0.2476,
        "grad_norm": 1.9928491115570068,
        "learning_rate": 1.0987084870848708e-05,
        "epoch": 25.350553505535057,
        "step": 6870
    },
    {
        "loss": 0.0994,
        "grad_norm": 16.376195907592773,
        "learning_rate": 1.0959409594095941e-05,
        "epoch": 25.387453874538746,
        "step": 6880
    },
    {
        "loss": 0.1077,
        "grad_norm": 0.2119242250919342,
        "learning_rate": 1.0931734317343174e-05,
        "epoch": 25.424354243542435,
        "step": 6890
    },
    {
        "loss": 0.1404,
        "grad_norm": 3.8927037715911865,
        "learning_rate": 1.0904059040590407e-05,
        "epoch": 25.461254612546124,
        "step": 6900
    },
    {
        "loss": 0.3049,
        "grad_norm": 5.8357319831848145,
        "learning_rate": 1.0876383763837637e-05,
        "epoch": 25.498154981549817,
        "step": 6910
    },
    {
        "loss": 0.1467,
        "grad_norm": 8.808650970458984,
        "learning_rate": 1.084870848708487e-05,
        "epoch": 25.535055350553506,
        "step": 6920
    },
    {
        "loss": 0.1621,
        "grad_norm": 1.3497127294540405,
        "learning_rate": 1.0821033210332103e-05,
        "epoch": 25.571955719557195,
        "step": 6930
    },
    {
        "loss": 0.2361,
        "grad_norm": 1.2182952165603638,
        "learning_rate": 1.0793357933579336e-05,
        "epoch": 25.608856088560884,
        "step": 6940
    },
    {
        "loss": 0.1525,
        "grad_norm": 1.7726596593856812,
        "learning_rate": 1.076568265682657e-05,
        "epoch": 25.645756457564577,
        "step": 6950
    },
    {
        "loss": 0.1542,
        "grad_norm": 2.1446173191070557,
        "learning_rate": 1.07380073800738e-05,
        "epoch": 25.682656826568266,
        "step": 6960
    },
    {
        "loss": 0.2477,
        "grad_norm": 11.048700332641602,
        "learning_rate": 1.0710332103321034e-05,
        "epoch": 25.719557195571955,
        "step": 6970
    },
    {
        "loss": 0.1132,
        "grad_norm": 6.808810710906982,
        "learning_rate": 1.0682656826568267e-05,
        "epoch": 25.756457564575644,
        "step": 6980
    },
    {
        "loss": 0.2097,
        "grad_norm": 1.136579990386963,
        "learning_rate": 1.0654981549815498e-05,
        "epoch": 25.793357933579337,
        "step": 6990
    },
    {
        "loss": 0.1515,
        "grad_norm": 1.3311824798583984,
        "learning_rate": 1.062730627306273e-05,
        "epoch": 25.830258302583026,
        "step": 7000
    },
    {
        "loss": 0.2819,
        "grad_norm": 1.844319224357605,
        "learning_rate": 1.0599630996309963e-05,
        "epoch": 25.867158671586715,
        "step": 7010
    },
    {
        "loss": 0.2896,
        "grad_norm": 0.7093396782875061,
        "learning_rate": 1.0571955719557196e-05,
        "epoch": 25.904059040590404,
        "step": 7020
    },
    {
        "loss": 0.1587,
        "grad_norm": 46.199371337890625,
        "learning_rate": 1.0544280442804429e-05,
        "epoch": 25.940959409594097,
        "step": 7030
    },
    {
        "loss": 0.195,
        "grad_norm": 5.293177604675293,
        "learning_rate": 1.0516605166051662e-05,
        "epoch": 25.977859778597786,
        "step": 7040
    },
    {
        "eval_loss": 0.5184770226478577,
        "eval_accuracy": 0.86888,
        "eval_precision": 0.86116,
        "eval_recall": 0.88608,
        "eval_f1": 0.87344,
        "eval_runtime": 18.1367,
        "eval_samples_per_second": 59.713,
        "eval_steps_per_second": 3.749,
        "epoch": 26.0,
        "step": 7046
    },
    {
        "loss": 0.2711,
        "grad_norm": 1.745205044746399,
        "learning_rate": 1.0488929889298893e-05,
        "epoch": 26.014760147601475,
        "step": 7050
    },
    {
        "loss": 0.1097,
        "grad_norm": 2.3727962970733643,
        "learning_rate": 1.0461254612546126e-05,
        "epoch": 26.051660516605168,
        "step": 7060
    },
    {
        "loss": 0.1536,
        "grad_norm": 4.60044002532959,
        "learning_rate": 1.0433579335793358e-05,
        "epoch": 26.088560885608857,
        "step": 7070
    },
    {
        "loss": 0.1839,
        "grad_norm": 6.046728610992432,
        "learning_rate": 1.0405904059040591e-05,
        "epoch": 26.125461254612546,
        "step": 7080
    },
    {
        "loss": 0.2636,
        "grad_norm": 2.3556134700775146,
        "learning_rate": 1.0378228782287822e-05,
        "epoch": 26.162361623616235,
        "step": 7090
    },
    {
        "loss": 0.1643,
        "grad_norm": 5.026673316955566,
        "learning_rate": 1.0350553505535055e-05,
        "epoch": 26.199261992619927,
        "step": 7100
    },
    {
        "loss": 0.2182,
        "grad_norm": 1.04521906375885,
        "learning_rate": 1.0322878228782288e-05,
        "epoch": 26.236162361623617,
        "step": 7110
    },
    {
        "loss": 0.1768,
        "grad_norm": 2.626519203186035,
        "learning_rate": 1.0295202952029521e-05,
        "epoch": 26.273062730627306,
        "step": 7120
    },
    {
        "loss": 0.1671,
        "grad_norm": 0.8397164344787598,
        "learning_rate": 1.0267527675276755e-05,
        "epoch": 26.309963099630995,
        "step": 7130
    },
    {
        "loss": 0.1336,
        "grad_norm": 0.8389466404914856,
        "learning_rate": 1.0239852398523984e-05,
        "epoch": 26.346863468634687,
        "step": 7140
    },
    {
        "loss": 0.1152,
        "grad_norm": 0.6550336480140686,
        "learning_rate": 1.0212177121771217e-05,
        "epoch": 26.383763837638377,
        "step": 7150
    },
    {
        "loss": 0.2871,
        "grad_norm": 2.351067066192627,
        "learning_rate": 1.018450184501845e-05,
        "epoch": 26.420664206642066,
        "step": 7160
    },
    {
        "loss": 0.1705,
        "grad_norm": 4.1139936447143555,
        "learning_rate": 1.0156826568265683e-05,
        "epoch": 26.457564575645755,
        "step": 7170
    },
    {
        "loss": 0.18,
        "grad_norm": 0.9729860424995422,
        "learning_rate": 1.0129151291512915e-05,
        "epoch": 26.494464944649447,
        "step": 7180
    },
    {
        "loss": 0.1336,
        "grad_norm": 0.7140766382217407,
        "learning_rate": 1.0101476014760148e-05,
        "epoch": 26.531365313653136,
        "step": 7190
    },
    {
        "loss": 0.1638,
        "grad_norm": 0.536218523979187,
        "learning_rate": 1.0073800738007381e-05,
        "epoch": 26.568265682656826,
        "step": 7200
    },
    {
        "loss": 0.2244,
        "grad_norm": 18.186683654785156,
        "learning_rate": 1.0046125461254614e-05,
        "epoch": 26.605166051660518,
        "step": 7210
    },
    {
        "loss": 0.1977,
        "grad_norm": 1.9503798484802246,
        "learning_rate": 1.0018450184501844e-05,
        "epoch": 26.642066420664207,
        "step": 7220
    },
    {
        "loss": 0.1992,
        "grad_norm": 8.347463607788086,
        "learning_rate": 9.990774907749077e-06,
        "epoch": 26.678966789667896,
        "step": 7230
    },
    {
        "loss": 0.1785,
        "grad_norm": 1.2288484573364258,
        "learning_rate": 9.96309963099631e-06,
        "epoch": 26.715867158671585,
        "step": 7240
    },
    {
        "loss": 0.1617,
        "grad_norm": 2.727126359939575,
        "learning_rate": 9.935424354243543e-06,
        "epoch": 26.752767527675278,
        "step": 7250
    },
    {
        "loss": 0.12,
        "grad_norm": 0.4974634349346161,
        "learning_rate": 9.907749077490776e-06,
        "epoch": 26.789667896678967,
        "step": 7260
    },
    {
        "loss": 0.1472,
        "grad_norm": 0.6418587565422058,
        "learning_rate": 9.880073800738007e-06,
        "epoch": 26.826568265682656,
        "step": 7270
    },
    {
        "loss": 0.1792,
        "grad_norm": 2.4620494842529297,
        "learning_rate": 9.85239852398524e-06,
        "epoch": 26.863468634686345,
        "step": 7280
    },
    {
        "loss": 0.1804,
        "grad_norm": 1.7312090396881104,
        "learning_rate": 9.824723247232474e-06,
        "epoch": 26.900369003690038,
        "step": 7290
    },
    {
        "loss": 0.344,
        "grad_norm": 3.0052883625030518,
        "learning_rate": 9.797047970479705e-06,
        "epoch": 26.937269372693727,
        "step": 7300
    },
    {
        "loss": 0.2041,
        "grad_norm": 1.4192901849746704,
        "learning_rate": 9.769372693726936e-06,
        "epoch": 26.974169741697416,
        "step": 7310
    },
    {
        "eval_loss": 0.5267235636711121,
        "eval_accuracy": 0.87627,
        "eval_precision": 0.86562,
        "eval_recall": 0.89693,
        "eval_f1": 0.88099,
        "eval_runtime": 18.191,
        "eval_samples_per_second": 59.535,
        "eval_steps_per_second": 3.738,
        "epoch": 27.0,
        "step": 7317
    },
    {
        "loss": 0.1233,
        "grad_norm": 5.605360507965088,
        "learning_rate": 9.74169741697417e-06,
        "epoch": 27.011070110701105,
        "step": 7320
    },
    {
        "loss": 0.1448,
        "grad_norm": 2.791351079940796,
        "learning_rate": 9.714022140221402e-06,
        "epoch": 27.047970479704798,
        "step": 7330
    },
    {
        "loss": 0.0991,
        "grad_norm": 1.2854962348937988,
        "learning_rate": 9.686346863468636e-06,
        "epoch": 27.084870848708487,
        "step": 7340
    },
    {
        "loss": 0.3068,
        "grad_norm": 4.546250820159912,
        "learning_rate": 9.658671586715869e-06,
        "epoch": 27.121771217712176,
        "step": 7350
    },
    {
        "loss": 0.1728,
        "grad_norm": 1.1140577793121338,
        "learning_rate": 9.6309963099631e-06,
        "epoch": 27.15867158671587,
        "step": 7360
    },
    {
        "loss": 0.1708,
        "grad_norm": 6.895722389221191,
        "learning_rate": 9.603321033210331e-06,
        "epoch": 27.195571955719558,
        "step": 7370
    },
    {
        "loss": 0.1169,
        "grad_norm": 7.3938307762146,
        "learning_rate": 9.575645756457564e-06,
        "epoch": 27.232472324723247,
        "step": 7380
    },
    {
        "loss": 0.2312,
        "grad_norm": 16.482192993164062,
        "learning_rate": 9.547970479704798e-06,
        "epoch": 27.269372693726936,
        "step": 7390
    },
    {
        "loss": 0.2172,
        "grad_norm": 6.881591320037842,
        "learning_rate": 9.520295202952029e-06,
        "epoch": 27.30627306273063,
        "step": 7400
    },
    {
        "loss": 0.1381,
        "grad_norm": 3.061925172805786,
        "learning_rate": 9.492619926199262e-06,
        "epoch": 27.343173431734318,
        "step": 7410
    },
    {
        "loss": 0.1946,
        "grad_norm": 2.482541084289551,
        "learning_rate": 9.464944649446495e-06,
        "epoch": 27.380073800738007,
        "step": 7420
    },
    {
        "loss": 0.1035,
        "grad_norm": 1.0869907140731812,
        "learning_rate": 9.437269372693728e-06,
        "epoch": 27.416974169741696,
        "step": 7430
    },
    {
        "loss": 0.1302,
        "grad_norm": 1.3590270280838013,
        "learning_rate": 9.409594095940961e-06,
        "epoch": 27.45387453874539,
        "step": 7440
    },
    {
        "loss": 0.1506,
        "grad_norm": 0.5225532650947571,
        "learning_rate": 9.381918819188191e-06,
        "epoch": 27.490774907749078,
        "step": 7450
    },
    {
        "loss": 0.1772,
        "grad_norm": 1.6658928394317627,
        "learning_rate": 9.354243542435424e-06,
        "epoch": 27.527675276752767,
        "step": 7460
    },
    {
        "loss": 0.1434,
        "grad_norm": 24.384593963623047,
        "learning_rate": 9.326568265682657e-06,
        "epoch": 27.564575645756456,
        "step": 7470
    },
    {
        "loss": 0.2067,
        "grad_norm": 0.3288620412349701,
        "learning_rate": 9.29889298892989e-06,
        "epoch": 27.60147601476015,
        "step": 7480
    },
    {
        "loss": 0.2124,
        "grad_norm": 9.42970085144043,
        "learning_rate": 9.271217712177122e-06,
        "epoch": 27.638376383763838,
        "step": 7490
    },
    {
        "loss": 0.1955,
        "grad_norm": 1.1288676261901855,
        "learning_rate": 9.243542435424355e-06,
        "epoch": 27.675276752767527,
        "step": 7500
    },
    {
        "loss": 0.2361,
        "grad_norm": 4.108041286468506,
        "learning_rate": 9.215867158671588e-06,
        "epoch": 27.71217712177122,
        "step": 7510
    },
    {
        "loss": 0.1562,
        "grad_norm": 6.450983047485352,
        "learning_rate": 9.188191881918819e-06,
        "epoch": 27.74907749077491,
        "step": 7520
    },
    {
        "loss": 0.2954,
        "grad_norm": 1.7924450635910034,
        "learning_rate": 9.160516605166052e-06,
        "epoch": 27.785977859778598,
        "step": 7530
    },
    {
        "loss": 0.1849,
        "grad_norm": 8.087520599365234,
        "learning_rate": 9.132841328413284e-06,
        "epoch": 27.822878228782287,
        "step": 7540
    },
    {
        "loss": 0.2335,
        "grad_norm": 17.9820556640625,
        "learning_rate": 9.105166051660517e-06,
        "epoch": 27.85977859778598,
        "step": 7550
    },
    {
        "loss": 0.1335,
        "grad_norm": 0.9541551470756531,
        "learning_rate": 9.07749077490775e-06,
        "epoch": 27.89667896678967,
        "step": 7560
    },
    {
        "loss": 0.1235,
        "grad_norm": 6.764195919036865,
        "learning_rate": 9.049815498154983e-06,
        "epoch": 27.933579335793358,
        "step": 7570
    },
    {
        "loss": 0.2025,
        "grad_norm": 1.6861481666564941,
        "learning_rate": 9.022140221402214e-06,
        "epoch": 27.970479704797047,
        "step": 7580
    },
    {
        "eval_loss": 0.543237566947937,
        "eval_accuracy": 0.87719,
        "eval_precision": 0.86207,
        "eval_recall": 0.90416,
        "eval_f1": 0.88261,
        "eval_runtime": 18.1813,
        "eval_samples_per_second": 59.567,
        "eval_steps_per_second": 3.74,
        "epoch": 28.0,
        "step": 7588
    },
    {
        "train_runtime": 6550.0359,
        "train_samples_per_second": 26.479,
        "train_steps_per_second": 1.655,
        "total_flos": 1.597189350457344e+16,
        "train_loss": 0.27089084794820456,
        "epoch": 28.0,
        "step": 7588
    }
]