[
    {
        "loss": 0.6328,
        "grad_norm": 4.1455559730529785,
        "learning_rate": 2.997232472324723e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.5483,
        "grad_norm": 12.015608787536621,
        "learning_rate": 2.9944649446494467e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.474,
        "grad_norm": 8.503592491149902,
        "learning_rate": 2.9916974169741697e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.4945,
        "grad_norm": 8.402212142944336,
        "learning_rate": 2.9889298892988933e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.5349,
        "grad_norm": 8.194154739379883,
        "learning_rate": 2.9861623616236163e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.412,
        "grad_norm": 2.3790760040283203,
        "learning_rate": 2.9833948339483396e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.5027,
        "grad_norm": 4.961184501647949,
        "learning_rate": 2.980627306273063e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.3817,
        "grad_norm": 4.721670627593994,
        "learning_rate": 2.977859778597786e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.4355,
        "grad_norm": 2.8381690979003906,
        "learning_rate": 2.975092250922509e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.5273,
        "grad_norm": 3.043626308441162,
        "learning_rate": 2.9723247232472325e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.4346,
        "grad_norm": 2.3867762088775635,
        "learning_rate": 2.9695571955719558e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4947,
        "grad_norm": 1.8070131540298462,
        "learning_rate": 2.966789667896679e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.5174,
        "grad_norm": 5.4355340003967285,
        "learning_rate": 2.9640221402214024e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4983,
        "grad_norm": 6.0530924797058105,
        "learning_rate": 2.9612546125461254e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4146,
        "grad_norm": 3.3759522438049316,
        "learning_rate": 2.958487084870849e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.4109,
        "grad_norm": 4.19359016418457,
        "learning_rate": 2.955719557195572e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.3115,
        "grad_norm": 4.979308128356934,
        "learning_rate": 2.9529520295202953e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.518,
        "grad_norm": 5.82654333114624,
        "learning_rate": 2.9501845018450186e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4419,
        "grad_norm": 2.796133279800415,
        "learning_rate": 2.9474169741697416e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4595,
        "grad_norm": 1.5849404335021973,
        "learning_rate": 2.9446494464944652e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.477,
        "grad_norm": 4.523159980773926,
        "learning_rate": 2.9418819188191882e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4487,
        "grad_norm": 3.6463868618011475,
        "learning_rate": 2.9391143911439118e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.4201,
        "grad_norm": 2.46638560295105,
        "learning_rate": 2.9363468634686348e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.4262,
        "grad_norm": 2.738175868988037,
        "learning_rate": 2.9335793357933578e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.4632,
        "grad_norm": 2.370316505432129,
        "learning_rate": 2.9308118081180814e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4842,
        "grad_norm": 2.5700273513793945,
        "learning_rate": 2.9280442804428044e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4063,
        "grad_norm": 3.113006353378296,
        "learning_rate": 2.9252767527675277e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.433037132024765,
        "eval_accuracy": 0.81273,
        "eval_precision": 0.77541,
        "eval_recall": 0.87755,
        "eval_f1": 0.82332,
        "eval_runtime": 18.1995,
        "eval_samples_per_second": 59.562,
        "eval_steps_per_second": 3.736,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.5387,
        "grad_norm": 2.7633368968963623,
        "learning_rate": 2.922509225092251e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4534,
        "grad_norm": 3.5021674633026123,
        "learning_rate": 2.9197416974169743e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.3943,
        "grad_norm": 1.7532070875167847,
        "learning_rate": 2.9169741697416976e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.4096,
        "grad_norm": 4.808969020843506,
        "learning_rate": 2.9142066420664206e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.3727,
        "grad_norm": 2.3354310989379883,
        "learning_rate": 2.911439114391144e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4668,
        "grad_norm": 7.662729263305664,
        "learning_rate": 2.9086715867158672e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.4466,
        "grad_norm": 3.1888482570648193,
        "learning_rate": 2.9059040590405905e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4276,
        "grad_norm": 3.729707717895508,
        "learning_rate": 2.9031365313653138e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4214,
        "grad_norm": 5.204050540924072,
        "learning_rate": 2.900369003690037e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.5512,
        "grad_norm": 2.7668139934539795,
        "learning_rate": 2.89760147601476e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4105,
        "grad_norm": 3.3625028133392334,
        "learning_rate": 2.8948339483394837e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.3911,
        "grad_norm": 3.6968066692352295,
        "learning_rate": 2.8920664206642067e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.3979,
        "grad_norm": 4.6705169677734375,
        "learning_rate": 2.8892988929889297e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.3638,
        "grad_norm": 2.056269407272339,
        "learning_rate": 2.8865313653136533e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.4178,
        "grad_norm": 2.575284242630005,
        "learning_rate": 2.8837638376383763e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.3786,
        "grad_norm": 3.7582454681396484,
        "learning_rate": 2.8809963099631e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.4437,
        "grad_norm": 2.2198286056518555,
        "learning_rate": 2.878228782287823e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.3976,
        "grad_norm": 2.0695247650146484,
        "learning_rate": 2.8754612546125462e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.4217,
        "grad_norm": 4.252983570098877,
        "learning_rate": 2.8726937269372695e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.3904,
        "grad_norm": 2.141289234161377,
        "learning_rate": 2.8699261992619925e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.3816,
        "grad_norm": 1.6242674589157104,
        "learning_rate": 2.867158671586716e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.493,
        "grad_norm": 2.0286571979522705,
        "learning_rate": 2.864391143911439e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.4103,
        "grad_norm": 3.2369773387908936,
        "learning_rate": 2.8616236162361624e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.3887,
        "grad_norm": 3.559636116027832,
        "learning_rate": 2.8588560885608857e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.3305,
        "grad_norm": 1.2085999250411987,
        "learning_rate": 2.856088560885609e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.3333,
        "grad_norm": 2.2069473266601562,
        "learning_rate": 2.8533210332103323e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.2835,
        "grad_norm": 5.1482253074646,
        "learning_rate": 2.8505535055350553e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.46208125352859497,
        "eval_accuracy": 0.82011,
        "eval_precision": 0.78197,
        "eval_recall": 0.88497,
        "eval_f1": 0.83029,
        "eval_runtime": 18.1727,
        "eval_samples_per_second": 59.65,
        "eval_steps_per_second": 3.742,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.3149,
        "grad_norm": 4.043838024139404,
        "learning_rate": 2.8477859778597786e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.3417,
        "grad_norm": 2.254591703414917,
        "learning_rate": 2.845018450184502e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.3094,
        "grad_norm": 26.644771575927734,
        "learning_rate": 2.8422509225092252e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3105,
        "grad_norm": 1.6206567287445068,
        "learning_rate": 2.8394833948339482e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.3733,
        "grad_norm": 2.1503872871398926,
        "learning_rate": 2.8367158671586718e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.4057,
        "grad_norm": 4.866835594177246,
        "learning_rate": 2.8339483394833948e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.3908,
        "grad_norm": 1.5680125951766968,
        "learning_rate": 2.831180811808118e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.3988,
        "grad_norm": 2.200826644897461,
        "learning_rate": 2.8284132841328414e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.4446,
        "grad_norm": 2.7427334785461426,
        "learning_rate": 2.8256457564575644e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3446,
        "grad_norm": 1.9690563678741455,
        "learning_rate": 2.822878228782288e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.5128,
        "grad_norm": 2.050140857696533,
        "learning_rate": 2.820110701107011e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.3722,
        "grad_norm": 1.9764528274536133,
        "learning_rate": 2.8173431734317346e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3562,
        "grad_norm": 5.506792068481445,
        "learning_rate": 2.8145756457564576e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.3239,
        "grad_norm": 9.143298149108887,
        "learning_rate": 2.811808118081181e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.4512,
        "grad_norm": 3.9260709285736084,
        "learning_rate": 2.8090405904059042e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.4085,
        "grad_norm": 1.9462738037109375,
        "learning_rate": 2.8062730627306272e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3238,
        "grad_norm": 1.737866997718811,
        "learning_rate": 2.803505535055351e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.3626,
        "grad_norm": 6.066840648651123,
        "learning_rate": 2.8007380073800738e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3097,
        "grad_norm": 2.7388460636138916,
        "learning_rate": 2.797970479704797e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.3715,
        "grad_norm": 1.5002777576446533,
        "learning_rate": 2.7952029520295204e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3573,
        "grad_norm": 1.5112035274505615,
        "learning_rate": 2.7924354243542437e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4308,
        "grad_norm": 4.922558784484863,
        "learning_rate": 2.7896678966789667e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4292,
        "grad_norm": 2.2720634937286377,
        "learning_rate": 2.78690036900369e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.4116,
        "grad_norm": 1.746806263923645,
        "learning_rate": 2.7841328413284133e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.3649,
        "grad_norm": 1.5771710872650146,
        "learning_rate": 2.7813653136531366e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3661,
        "grad_norm": 3.1779019832611084,
        "learning_rate": 2.77859778597786e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.4517,
        "grad_norm": 3.518258810043335,
        "learning_rate": 2.775830258302583e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.39025214314460754,
        "eval_accuracy": 0.83764,
        "eval_precision": 0.79417,
        "eval_recall": 0.90909,
        "eval_f1": 0.84775,
        "eval_runtime": 18.1669,
        "eval_samples_per_second": 59.669,
        "eval_steps_per_second": 3.743,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.4091,
        "grad_norm": 2.141045093536377,
        "learning_rate": 2.7730627306273065e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.355,
        "grad_norm": 5.039862632751465,
        "learning_rate": 2.7702952029520295e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.3303,
        "grad_norm": 5.820464134216309,
        "learning_rate": 2.7675276752767528e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.3406,
        "grad_norm": 7.4891767501831055,
        "learning_rate": 2.764760147601476e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.4442,
        "grad_norm": 4.702464580535889,
        "learning_rate": 2.761992619926199e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.4183,
        "grad_norm": 1.534471869468689,
        "learning_rate": 2.7592250922509227e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3572,
        "grad_norm": 4.136606216430664,
        "learning_rate": 2.7564575645756457e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.321,
        "grad_norm": 2.1153318881988525,
        "learning_rate": 2.753690036900369e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.4262,
        "grad_norm": 3.377707004547119,
        "learning_rate": 2.7509225092250923e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3107,
        "grad_norm": 2.3996031284332275,
        "learning_rate": 2.7481549815498156e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.297,
        "grad_norm": 4.325633525848389,
        "learning_rate": 2.745387453874539e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.3709,
        "grad_norm": 1.488118052482605,
        "learning_rate": 2.742619926199262e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.3721,
        "grad_norm": 2.2404556274414062,
        "learning_rate": 2.7398523985239852e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.3088,
        "grad_norm": 1.3967881202697754,
        "learning_rate": 2.7370848708487085e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.3136,
        "grad_norm": 1.1421409845352173,
        "learning_rate": 2.734317343173432e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.3589,
        "grad_norm": 3.0273020267486572,
        "learning_rate": 2.731549815498155e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3645,
        "grad_norm": 1.9148565530776978,
        "learning_rate": 2.7287822878228784e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.2847,
        "grad_norm": 3.8024961948394775,
        "learning_rate": 2.7260147601476014e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.3879,
        "grad_norm": 2.777648448944092,
        "learning_rate": 2.7232472324723247e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.4576,
        "grad_norm": 2.8211846351623535,
        "learning_rate": 2.720479704797048e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.3902,
        "grad_norm": 5.391212463378906,
        "learning_rate": 2.7177121771217713e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.4219,
        "grad_norm": 2.7845983505249023,
        "learning_rate": 2.7149446494464946e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3181,
        "grad_norm": 1.0429919958114624,
        "learning_rate": 2.7121771217712176e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3535,
        "grad_norm": 4.149434566497803,
        "learning_rate": 2.7094095940959413e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.447,
        "grad_norm": 4.359703540802002,
        "learning_rate": 2.7066420664206642e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.3222,
        "grad_norm": 1.381819248199463,
        "learning_rate": 2.7038745387453872e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.2965,
        "grad_norm": 3.3701655864715576,
        "learning_rate": 2.701107011070111e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.4501517713069916,
        "eval_accuracy": 0.83764,
        "eval_precision": 0.77966,
        "eval_recall": 0.93878,
        "eval_f1": 0.85185,
        "eval_runtime": 18.1632,
        "eval_samples_per_second": 59.681,
        "eval_steps_per_second": 3.744,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3421,
        "grad_norm": 1.1416438817977905,
        "learning_rate": 2.6983394833948338e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.3253,
        "grad_norm": 3.4291505813598633,
        "learning_rate": 2.6955719557195575e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.363,
        "grad_norm": 1.4644564390182495,
        "learning_rate": 2.6928044280442804e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3326,
        "grad_norm": 1.6754239797592163,
        "learning_rate": 2.6900369003690037e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3135,
        "grad_norm": 5.506091594696045,
        "learning_rate": 2.687269372693727e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.4123,
        "grad_norm": 2.4476521015167236,
        "learning_rate": 2.6845018450184504e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3228,
        "grad_norm": 3.6802778244018555,
        "learning_rate": 2.6817343173431737e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.344,
        "grad_norm": 1.3186064958572388,
        "learning_rate": 2.6789667896678966e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.3621,
        "grad_norm": 4.047479152679443,
        "learning_rate": 2.67619926199262e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.3529,
        "grad_norm": 1.687985897064209,
        "learning_rate": 2.6734317343173432e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.3205,
        "grad_norm": 3.209737777709961,
        "learning_rate": 2.6706642066420666e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3774,
        "grad_norm": 7.752160549163818,
        "learning_rate": 2.6678966789667895e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.3163,
        "grad_norm": 4.252804279327393,
        "learning_rate": 2.665129151291513e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.295,
        "grad_norm": 1.9522559642791748,
        "learning_rate": 2.662361623616236e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3242,
        "grad_norm": 2.0084571838378906,
        "learning_rate": 2.6595940959409594e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.2878,
        "grad_norm": 1.0618263483047485,
        "learning_rate": 2.6568265682656828e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3986,
        "grad_norm": 4.637627124786377,
        "learning_rate": 2.6540590405904057e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.2667,
        "grad_norm": 4.7942986488342285,
        "learning_rate": 2.6512915129151294e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3343,
        "grad_norm": 1.5048344135284424,
        "learning_rate": 2.6485239852398523e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.2549,
        "grad_norm": 5.451541423797607,
        "learning_rate": 2.645756457564576e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.3382,
        "grad_norm": 0.9336617588996887,
        "learning_rate": 2.642988929889299e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.4326,
        "grad_norm": 3.332688570022583,
        "learning_rate": 2.640221402214022e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.3749,
        "grad_norm": 2.530395030975342,
        "learning_rate": 2.6374538745387456e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.4208,
        "grad_norm": 3.4283664226531982,
        "learning_rate": 2.6346863468634685e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.3862,
        "grad_norm": 1.48197603225708,
        "learning_rate": 2.6319188191881922e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.3905,
        "grad_norm": 4.424309730529785,
        "learning_rate": 2.629151291512915e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.3849,
        "grad_norm": 3.956214666366577,
        "learning_rate": 2.6263837638376385e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.39323312044143677,
        "eval_accuracy": 0.84225,
        "eval_precision": 0.80976,
        "eval_recall": 0.89239,
        "eval_f1": 0.84907,
        "eval_runtime": 18.2074,
        "eval_samples_per_second": 59.536,
        "eval_steps_per_second": 3.735,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.3044,
        "grad_norm": 5.22444486618042,
        "learning_rate": 2.6236162361623618e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.4028,
        "grad_norm": 4.355584144592285,
        "learning_rate": 2.620848708487085e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.3338,
        "grad_norm": 1.4915715456008911,
        "learning_rate": 2.618081180811808e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.3513,
        "grad_norm": 3.939255714416504,
        "learning_rate": 2.6153136531365313e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.3353,
        "grad_norm": 1.0903664827346802,
        "learning_rate": 2.6125461254612547e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.3562,
        "grad_norm": 3.7750954627990723,
        "learning_rate": 2.609778597785978e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.2812,
        "grad_norm": 2.2467281818389893,
        "learning_rate": 2.6070110701107013e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.3138,
        "grad_norm": 7.459804058074951,
        "learning_rate": 2.6042435424354242e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.3395,
        "grad_norm": 3.541663646697998,
        "learning_rate": 2.601476014760148e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.367,
        "grad_norm": 3.1488192081451416,
        "learning_rate": 2.598708487084871e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.4099,
        "grad_norm": 2.945905923843384,
        "learning_rate": 2.595940959409594e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.2864,
        "grad_norm": 1.7078485488891602,
        "learning_rate": 2.5931734317343175e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.289,
        "grad_norm": 4.9725165367126465,
        "learning_rate": 2.5904059040590404e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.3837,
        "grad_norm": 4.060091495513916,
        "learning_rate": 2.587638376383764e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.3901,
        "grad_norm": 4.687983512878418,
        "learning_rate": 2.584870848708487e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.2258,
        "grad_norm": 2.18072247505188,
        "learning_rate": 2.5821033210332107e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.451,
        "grad_norm": 1.262904167175293,
        "learning_rate": 2.5793357933579337e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.3579,
        "grad_norm": 3.7703444957733154,
        "learning_rate": 2.5765682656826566e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.2928,
        "grad_norm": 2.2694170475006104,
        "learning_rate": 2.5738007380073803e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.3872,
        "grad_norm": 3.8882551193237305,
        "learning_rate": 2.5710332103321032e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.3832,
        "grad_norm": 3.0932488441467285,
        "learning_rate": 2.5682656826568266e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.2554,
        "grad_norm": 3.221935987472534,
        "learning_rate": 2.56549815498155e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.2963,
        "grad_norm": 0.7572112083435059,
        "learning_rate": 2.5627306273062732e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.445,
        "grad_norm": 9.053337097167969,
        "learning_rate": 2.5599630996309965e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.3301,
        "grad_norm": 1.4679607152938843,
        "learning_rate": 2.5571955719557198e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.4275,
        "grad_norm": 1.862554669380188,
        "learning_rate": 2.5544280442804428e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.3207,
        "grad_norm": 2.1391801834106445,
        "learning_rate": 2.551660516605166e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.3993975520133972,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.79968,
        "eval_recall": 0.92579,
        "eval_f1": 0.85813,
        "eval_runtime": 18.1985,
        "eval_samples_per_second": 59.565,
        "eval_steps_per_second": 3.737,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.2631,
        "grad_norm": 3.288928747177124,
        "learning_rate": 2.5488929889298894e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3076,
        "grad_norm": 1.9431979656219482,
        "learning_rate": 2.5461254612546127e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.286,
        "grad_norm": 3.3077993392944336,
        "learning_rate": 2.543357933579336e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.3297,
        "grad_norm": 6.418483257293701,
        "learning_rate": 2.540590405904059e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.3284,
        "grad_norm": 1.465744972229004,
        "learning_rate": 2.5378228782287826e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.2941,
        "grad_norm": 1.009210467338562,
        "learning_rate": 2.5350553505535056e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.3543,
        "grad_norm": 4.674093723297119,
        "learning_rate": 2.5322878228782285e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.3513,
        "grad_norm": 1.6397688388824463,
        "learning_rate": 2.5295202952029522e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.2551,
        "grad_norm": 5.619370937347412,
        "learning_rate": 2.526752767527675e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.3391,
        "grad_norm": 5.429955005645752,
        "learning_rate": 2.5239852398523988e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.3046,
        "grad_norm": 6.298069953918457,
        "learning_rate": 2.5212177121771218e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.2766,
        "grad_norm": 1.8657424449920654,
        "learning_rate": 2.518450184501845e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.3881,
        "grad_norm": 1.45686936378479,
        "learning_rate": 2.5156826568265684e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.3451,
        "grad_norm": 11.461234092712402,
        "learning_rate": 2.5129151291512914e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.2881,
        "grad_norm": 8.015358924865723,
        "learning_rate": 2.510147601476015e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.3361,
        "grad_norm": 3.3444628715515137,
        "learning_rate": 2.507380073800738e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.3357,
        "grad_norm": 1.1656163930892944,
        "learning_rate": 2.5046125461254613e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.3549,
        "grad_norm": 1.468622088432312,
        "learning_rate": 2.5018450184501846e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.2957,
        "grad_norm": 2.2127296924591064,
        "learning_rate": 2.499077490774908e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3669,
        "grad_norm": 2.911641836166382,
        "learning_rate": 2.4963099630996312e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3003,
        "grad_norm": 8.40746021270752,
        "learning_rate": 2.4935424354243545e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3407,
        "grad_norm": 2.6066553592681885,
        "learning_rate": 2.4907749077490775e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.3169,
        "grad_norm": 1.2722432613372803,
        "learning_rate": 2.4880073800738008e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.2711,
        "grad_norm": 2.351728677749634,
        "learning_rate": 2.485239852398524e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.4191,
        "grad_norm": 2.161567449569702,
        "learning_rate": 2.482472324723247e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.3007,
        "grad_norm": 2.9909145832061768,
        "learning_rate": 2.4797047970479707e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3526,
        "grad_norm": 0.8141732811927795,
        "learning_rate": 2.4769372693726937e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.4091610610485077,
        "eval_accuracy": 0.84963,
        "eval_precision": 0.80032,
        "eval_recall": 0.9295,
        "eval_f1": 0.86009,
        "eval_runtime": 18.1736,
        "eval_samples_per_second": 59.647,
        "eval_steps_per_second": 3.742,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.3779,
        "grad_norm": 2.7755701541900635,
        "learning_rate": 2.4741697416974173e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.3131,
        "grad_norm": 2.3449654579162598,
        "learning_rate": 2.4714022140221403e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3608,
        "grad_norm": 9.344202995300293,
        "learning_rate": 2.4686346863468633e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.2425,
        "grad_norm": 2.5524230003356934,
        "learning_rate": 2.465867158671587e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.3756,
        "grad_norm": 9.313216209411621,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3364,
        "grad_norm": 4.118436813354492,
        "learning_rate": 2.4603321033210335e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.2989,
        "grad_norm": 6.83403205871582,
        "learning_rate": 2.4575645756457565e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.2828,
        "grad_norm": 5.268277168273926,
        "learning_rate": 2.4547970479704798e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.2607,
        "grad_norm": 1.7118418216705322,
        "learning_rate": 2.452029520295203e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.442,
        "grad_norm": 5.803650379180908,
        "learning_rate": 2.449261992619926e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.2691,
        "grad_norm": 1.3390636444091797,
        "learning_rate": 2.4464944649446494e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3003,
        "grad_norm": 1.4384359121322632,
        "learning_rate": 2.4437269372693727e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.2483,
        "grad_norm": 2.4251344203948975,
        "learning_rate": 2.440959409594096e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3348,
        "grad_norm": 2.50434947013855,
        "learning_rate": 2.4381918819188193e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.2324,
        "grad_norm": 2.0851168632507324,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.311,
        "grad_norm": 1.448857307434082,
        "learning_rate": 2.4326568265682656e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.338,
        "grad_norm": 1.737471342086792,
        "learning_rate": 2.4298892988929892e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.2581,
        "grad_norm": 2.3278045654296875,
        "learning_rate": 2.4271217712177122e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.3393,
        "grad_norm": 9.040238380432129,
        "learning_rate": 2.4243542435424355e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.3485,
        "grad_norm": 5.078901767730713,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.275,
        "grad_norm": 1.6668760776519775,
        "learning_rate": 2.4188191881918818e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.256,
        "grad_norm": 2.1689467430114746,
        "learning_rate": 2.4160516605166054e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.336,
        "grad_norm": 11.52987003326416,
        "learning_rate": 2.4132841328413284e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.3344,
        "grad_norm": 2.4578869342803955,
        "learning_rate": 2.410516605166052e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.2988,
        "grad_norm": 3.1389081478118896,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.2966,
        "grad_norm": 7.515549182891846,
        "learning_rate": 2.404981549815498e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.3753,
        "grad_norm": 8.8396577835083,
        "learning_rate": 2.4022140221402216e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.3859013020992279,
        "eval_accuracy": 0.8607,
        "eval_precision": 0.82013,
        "eval_recall": 0.92208,
        "eval_f1": 0.86812,
        "eval_runtime": 18.1702,
        "eval_samples_per_second": 59.658,
        "eval_steps_per_second": 3.742,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.2986,
        "grad_norm": 2.4452691078186035,
        "learning_rate": 2.3994464944649446e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3473,
        "grad_norm": 2.624450206756592,
        "learning_rate": 2.396678966789668e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.2499,
        "grad_norm": 9.939939498901367,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.2458,
        "grad_norm": 19.856168746948242,
        "learning_rate": 2.3911439114391145e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.2717,
        "grad_norm": 3.110234498977661,
        "learning_rate": 2.3883763837638378e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.3762,
        "grad_norm": 5.689622402191162,
        "learning_rate": 2.3856088560885608e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.3068,
        "grad_norm": 2.789064645767212,
        "learning_rate": 2.382841328413284e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.2852,
        "grad_norm": 4.643261909484863,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.2598,
        "grad_norm": 2.3217952251434326,
        "learning_rate": 2.3773062730627307e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.3384,
        "grad_norm": 8.716117858886719,
        "learning_rate": 2.374538745387454e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.2289,
        "grad_norm": 1.2765357494354248,
        "learning_rate": 2.3717712177121773e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.2552,
        "grad_norm": 6.611877918243408,
        "learning_rate": 2.3690036900369003e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.2258,
        "grad_norm": 1.416018009185791,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.2667,
        "grad_norm": 11.258731842041016,
        "learning_rate": 2.363468634686347e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.444,
        "grad_norm": 8.607918739318848,
        "learning_rate": 2.3607011070110702e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.3296,
        "grad_norm": 2.601163387298584,
        "learning_rate": 2.3579335793357935e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.2973,
        "grad_norm": 2.972477674484253,
        "learning_rate": 2.3551660516605165e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.273,
        "grad_norm": 8.502341270446777,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.28,
        "grad_norm": 3.3398678302764893,
        "learning_rate": 2.349630996309963e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.3246,
        "grad_norm": 1.7190747261047363,
        "learning_rate": 2.3468634686346864e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3568,
        "grad_norm": 2.985942840576172,
        "learning_rate": 2.3440959409594097e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.2827,
        "grad_norm": 1.4955273866653442,
        "learning_rate": 2.3413284132841327e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.2733,
        "grad_norm": 2.4649012088775635,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.3124,
        "grad_norm": 4.4510955810546875,
        "learning_rate": 2.3357933579335793e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.2616,
        "grad_norm": 1.678128957748413,
        "learning_rate": 2.3330258302583026e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.3333,
        "grad_norm": 8.391535758972168,
        "learning_rate": 2.330258302583026e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3562,
        "grad_norm": 4.049249649047852,
        "learning_rate": 2.3274907749077492e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.40523937344551086,
        "eval_accuracy": 0.8441,
        "eval_precision": 0.79459,
        "eval_recall": 0.92579,
        "eval_f1": 0.85518,
        "eval_runtime": 18.1765,
        "eval_samples_per_second": 59.637,
        "eval_steps_per_second": 3.741,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.3424,
        "grad_norm": 2.2693073749542236,
        "learning_rate": 2.3247232472324725e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.3756,
        "grad_norm": 12.588123321533203,
        "learning_rate": 2.3219557195571955e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3306,
        "grad_norm": 4.185188293457031,
        "learning_rate": 2.3191881918819188e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.3013,
        "grad_norm": 6.806925296783447,
        "learning_rate": 2.316420664206642e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.2771,
        "grad_norm": 0.9712611436843872,
        "learning_rate": 2.3136531365313654e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.2695,
        "grad_norm": 2.0354719161987305,
        "learning_rate": 2.3108856088560884e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3262,
        "grad_norm": 12.817840576171875,
        "learning_rate": 2.308118081180812e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.3547,
        "grad_norm": 7.880792617797852,
        "learning_rate": 2.305350553505535e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.285,
        "grad_norm": 2.636291027069092,
        "learning_rate": 2.3025830258302583e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.2548,
        "grad_norm": 1.7319488525390625,
        "learning_rate": 2.2998154981549816e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.2508,
        "grad_norm": 4.075901031494141,
        "learning_rate": 2.2970479704797046e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.3017,
        "grad_norm": 2.266460657119751,
        "learning_rate": 2.2942804428044282e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.2718,
        "grad_norm": 2.1010777950286865,
        "learning_rate": 2.2915129151291512e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.2787,
        "grad_norm": 4.930769443511963,
        "learning_rate": 2.288745387453875e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.3096,
        "grad_norm": 5.441627502441406,
        "learning_rate": 2.2859778597785978e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.2682,
        "grad_norm": 1.5200953483581543,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.2145,
        "grad_norm": 2.1583633422851562,
        "learning_rate": 2.2804428044280444e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.3854,
        "grad_norm": 2.693770170211792,
        "learning_rate": 2.2776752767527674e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.2294,
        "grad_norm": 1.0619289875030518,
        "learning_rate": 2.274907749077491e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.2554,
        "grad_norm": 3.364792585372925,
        "learning_rate": 2.272140221402214e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.2928,
        "grad_norm": 3.2191362380981445,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.2631,
        "grad_norm": 1.9417258501052856,
        "learning_rate": 2.2666051660516606e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3099,
        "grad_norm": 5.9096574783325195,
        "learning_rate": 2.263837638376384e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.3368,
        "grad_norm": 4.840371608734131,
        "learning_rate": 2.261070110701107e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.3324,
        "grad_norm": 1.603149652481079,
        "learning_rate": 2.2583025830258302e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.2748,
        "grad_norm": 1.9527900218963623,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.1942,
        "grad_norm": 2.399369955062866,
        "learning_rate": 2.252767527675277e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.2524,
        "grad_norm": 1.091488003730774,
        "learning_rate": 2.25e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.4651487469673157,
        "eval_accuracy": 0.85978,
        "eval_precision": 0.81983,
        "eval_recall": 0.92022,
        "eval_f1": 0.86713,
        "eval_runtime": 18.1265,
        "eval_samples_per_second": 59.802,
        "eval_steps_per_second": 3.751,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.3261,
        "grad_norm": 1.898983359336853,
        "learning_rate": 2.247232472324723e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.2329,
        "grad_norm": 2.146920919418335,
        "learning_rate": 2.2444649446494468e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.2075,
        "grad_norm": 1.887856125831604,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.2099,
        "grad_norm": 8.418927192687988,
        "learning_rate": 2.238929889298893e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3897,
        "grad_norm": 2.5188181400299072,
        "learning_rate": 2.2361623616236163e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.2957,
        "grad_norm": 12.640857696533203,
        "learning_rate": 2.2333948339483393e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.2892,
        "grad_norm": 1.9391711950302124,
        "learning_rate": 2.230627306273063e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.28,
        "grad_norm": 14.858293533325195,
        "learning_rate": 2.227859778597786e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.2284,
        "grad_norm": 1.6126827001571655,
        "learning_rate": 2.2250922509225092e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3248,
        "grad_norm": 5.2715325355529785,
        "learning_rate": 2.2223247232472325e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.3807,
        "grad_norm": 5.816046714782715,
        "learning_rate": 2.219557195571956e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.3568,
        "grad_norm": 3.6613433361053467,
        "learning_rate": 2.216789667896679e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.2063,
        "grad_norm": 1.408481240272522,
        "learning_rate": 2.214022140221402e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.3094,
        "grad_norm": 3.028057098388672,
        "learning_rate": 2.2112546125461254e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.2603,
        "grad_norm": 1.291779637336731,
        "learning_rate": 2.2084870848708487e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.2521,
        "grad_norm": 1.7016047239303589,
        "learning_rate": 2.205719557195572e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3062,
        "grad_norm": 1.001652479171753,
        "learning_rate": 2.2029520295202954e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.2415,
        "grad_norm": 1.3614028692245483,
        "learning_rate": 2.2001845018450187e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2045,
        "grad_norm": 3.3627636432647705,
        "learning_rate": 2.1974169741697416e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.265,
        "grad_norm": 3.430107831954956,
        "learning_rate": 2.194649446494465e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.4153,
        "grad_norm": 2.213568925857544,
        "learning_rate": 2.1918819188191882e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.3984,
        "grad_norm": 3.1905441284179688,
        "learning_rate": 2.1891143911439116e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.2178,
        "grad_norm": 4.665060997009277,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.3691,
        "grad_norm": 1.776137113571167,
        "learning_rate": 2.1835793357933578e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.1782,
        "grad_norm": 1.325242042541504,
        "learning_rate": 2.1808118081180815e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.3023,
        "grad_norm": 7.0603437423706055,
        "learning_rate": 2.1780442804428044e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.3063,
        "grad_norm": 2.7052383422851562,
        "learning_rate": 2.1752767527675274e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.4726042151451111,
        "eval_accuracy": 0.85517,
        "eval_precision": 0.82264,
        "eval_recall": 0.90353,
        "eval_f1": 0.86118,
        "eval_runtime": 18.2254,
        "eval_samples_per_second": 59.477,
        "eval_steps_per_second": 3.731,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.2823,
        "grad_norm": 1.635867714881897,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.2595,
        "grad_norm": 1.4920789003372192,
        "learning_rate": 2.169741697416974e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.2895,
        "grad_norm": 2.8619656562805176,
        "learning_rate": 2.1669741697416977e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.192,
        "grad_norm": 1.9815380573272705,
        "learning_rate": 2.1642066420664206e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.2309,
        "grad_norm": 0.6325991749763489,
        "learning_rate": 2.161439114391144e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.187,
        "grad_norm": 8.902277946472168,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.3376,
        "grad_norm": 1.7396267652511597,
        "learning_rate": 2.1559040590405906e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.2812,
        "grad_norm": 1.179643988609314,
        "learning_rate": 2.153136531365314e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.2865,
        "grad_norm": 1.2036678791046143,
        "learning_rate": 2.150369003690037e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.2882,
        "grad_norm": 6.21687650680542,
        "learning_rate": 2.14760147601476e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.3002,
        "grad_norm": 1.922964334487915,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.2709,
        "grad_norm": 3.8946609497070312,
        "learning_rate": 2.1420664206642068e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.2282,
        "grad_norm": 8.189543724060059,
        "learning_rate": 2.1392988929889297e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.2384,
        "grad_norm": 2.6319618225097656,
        "learning_rate": 2.1365313653136534e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.1986,
        "grad_norm": 1.6715494394302368,
        "learning_rate": 2.1337638376383763e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.3056,
        "grad_norm": 3.91054368019104,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.2634,
        "grad_norm": 1.2890281677246094,
        "learning_rate": 2.128228782287823e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.3175,
        "grad_norm": 3.4393813610076904,
        "learning_rate": 2.125461254612546e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.2626,
        "grad_norm": 3.6751902103424072,
        "learning_rate": 2.1226937269372696e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.3251,
        "grad_norm": 2.7933690547943115,
        "learning_rate": 2.1199261992619925e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2174,
        "grad_norm": 4.843684673309326,
        "learning_rate": 2.1171586715867162e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.2801,
        "grad_norm": 1.7838401794433594,
        "learning_rate": 2.114391143911439e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.2761,
        "grad_norm": 4.887365818023682,
        "learning_rate": 2.111623616236162e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.2792,
        "grad_norm": 3.048635482788086,
        "learning_rate": 2.1088560885608858e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.2908,
        "grad_norm": 1.0168347358703613,
        "learning_rate": 2.1060885608856087e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2596,
        "grad_norm": 1.866127848625183,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.2772,
        "grad_norm": 1.3978756666183472,
        "learning_rate": 2.1005535055350554e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.4750157296657562,
        "eval_accuracy": 0.86624,
        "eval_precision": 0.82616,
        "eval_recall": 0.92579,
        "eval_f1": 0.87314,
        "eval_runtime": 18.1595,
        "eval_samples_per_second": 59.693,
        "eval_steps_per_second": 3.745,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.2081,
        "grad_norm": 7.39203405380249,
        "learning_rate": 2.0977859778597787e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.2833,
        "grad_norm": 3.5964088439941406,
        "learning_rate": 2.095018450184502e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.1871,
        "grad_norm": 2.11098051071167,
        "learning_rate": 2.0922509225092253e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.1777,
        "grad_norm": 1.3636071681976318,
        "learning_rate": 2.0894833948339482e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2495,
        "grad_norm": 0.4614957273006439,
        "learning_rate": 2.0867158671586716e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.2353,
        "grad_norm": 3.3601722717285156,
        "learning_rate": 2.083948339483395e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.2733,
        "grad_norm": 10.667129516601562,
        "learning_rate": 2.0811808118081182e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.2715,
        "grad_norm": 2.625410795211792,
        "learning_rate": 2.0784132841328415e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.2086,
        "grad_norm": 2.3285257816314697,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.3855,
        "grad_norm": 2.60539174079895,
        "learning_rate": 2.072878228782288e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.174,
        "grad_norm": 3.3935024738311768,
        "learning_rate": 2.070110701107011e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.2273,
        "grad_norm": 1.452750325202942,
        "learning_rate": 2.0673431734317344e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.3649,
        "grad_norm": 23.84032440185547,
        "learning_rate": 2.0645756457564577e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.2233,
        "grad_norm": 4.65159273147583,
        "learning_rate": 2.0618081180811806e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.2452,
        "grad_norm": 4.839836597442627,
        "learning_rate": 2.0590405904059043e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.2219,
        "grad_norm": 0.7240193486213684,
        "learning_rate": 2.0562730627306273e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.3493,
        "grad_norm": 7.420537948608398,
        "learning_rate": 2.053505535055351e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.2763,
        "grad_norm": 9.665274620056152,
        "learning_rate": 2.050738007380074e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.3105,
        "grad_norm": 9.53769588470459,
        "learning_rate": 2.047970479704797e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.2271,
        "grad_norm": 12.1156005859375,
        "learning_rate": 2.0452029520295205e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.3108,
        "grad_norm": 0.8103010058403015,
        "learning_rate": 2.0424354243542435e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.337,
        "grad_norm": 9.269758224487305,
        "learning_rate": 2.0396678966789668e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.2839,
        "grad_norm": 8.221081733703613,
        "learning_rate": 2.03690036900369e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.2366,
        "grad_norm": 3.2778427600860596,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.3149,
        "grad_norm": 8.279769897460938,
        "learning_rate": 2.0313653136531367e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.3644,
        "grad_norm": 1.2998727560043335,
        "learning_rate": 2.02859778597786e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.2857,
        "grad_norm": 10.584452629089355,
        "learning_rate": 2.025830258302583e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.4500671625137329,
        "eval_accuracy": 0.86347,
        "eval_precision": 0.8118,
        "eval_recall": 0.94434,
        "eval_f1": 0.87307,
        "eval_runtime": 18.1683,
        "eval_samples_per_second": 59.664,
        "eval_steps_per_second": 3.743,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.3,
        "grad_norm": 0.7203750014305115,
        "learning_rate": 2.0230627306273063e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.2177,
        "grad_norm": 2.734447956085205,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.2276,
        "grad_norm": 0.6144223809242249,
        "learning_rate": 2.017527675276753e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.2878,
        "grad_norm": 4.202133655548096,
        "learning_rate": 2.0147601476014762e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.2333,
        "grad_norm": 4.589268207550049,
        "learning_rate": 2.011992619926199e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.2094,
        "grad_norm": 5.730677127838135,
        "learning_rate": 2.0092250922509228e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.3678,
        "grad_norm": 22.247451782226562,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.2014,
        "grad_norm": 6.294736862182617,
        "learning_rate": 2.0036900369003687e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.2696,
        "grad_norm": 1.3435837030410767,
        "learning_rate": 2.0009225092250924e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.2571,
        "grad_norm": 5.404002666473389,
        "learning_rate": 1.9981549815498154e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.2977,
        "grad_norm": 2.927044630050659,
        "learning_rate": 1.995387453874539e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.3176,
        "grad_norm": 1.7122595310211182,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.2422,
        "grad_norm": 8.577821731567383,
        "learning_rate": 1.9898523985239853e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.2301,
        "grad_norm": 5.495785713195801,
        "learning_rate": 1.9870848708487086e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.2186,
        "grad_norm": 1.268850326538086,
        "learning_rate": 1.9843173431734316e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2256,
        "grad_norm": 1.8995965719223022,
        "learning_rate": 1.9815498154981552e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2285,
        "grad_norm": 1.103684902191162,
        "learning_rate": 1.9787822878228782e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.217,
        "grad_norm": 2.3155503273010254,
        "learning_rate": 1.9760147601476015e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.388,
        "grad_norm": 12.967294692993164,
        "learning_rate": 1.9732472324723248e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.2234,
        "grad_norm": 1.7508577108383179,
        "learning_rate": 1.970479704797048e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.2472,
        "grad_norm": 1.7324055433273315,
        "learning_rate": 1.9677121771217714e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.3067,
        "grad_norm": 3.624135971069336,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.2387,
        "grad_norm": 5.480549335479736,
        "learning_rate": 1.9621771217712177e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.1854,
        "grad_norm": 1.354310393333435,
        "learning_rate": 1.959409594095941e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.2476,
        "grad_norm": 1.5257810354232788,
        "learning_rate": 1.9566420664206643e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.2151,
        "grad_norm": 0.5091063976287842,
        "learning_rate": 1.9538745387453873e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.2896,
        "grad_norm": 0.6015862822532654,
        "learning_rate": 1.951107011070111e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.5089777112007141,
        "eval_accuracy": 0.85701,
        "eval_precision": 0.81788,
        "eval_recall": 0.91651,
        "eval_f1": 0.86439,
        "eval_runtime": 18.1731,
        "eval_samples_per_second": 59.648,
        "eval_steps_per_second": 3.742,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.2821,
        "grad_norm": 1.272741675376892,
        "learning_rate": 1.948339483394834e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.1675,
        "grad_norm": 2.4571774005889893,
        "learning_rate": 1.9455719557195575e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.2595,
        "grad_norm": 1.824005365371704,
        "learning_rate": 1.9428044280442805e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.288,
        "grad_norm": 3.17911434173584,
        "learning_rate": 1.9400369003690035e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.2134,
        "grad_norm": 10.141373634338379,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.3115,
        "grad_norm": 6.328453063964844,
        "learning_rate": 1.93450184501845e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.1822,
        "grad_norm": 3.015704393386841,
        "learning_rate": 1.9317343173431737e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.2275,
        "grad_norm": 0.9755555391311646,
        "learning_rate": 1.9289667896678967e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2373,
        "grad_norm": 1.02384614944458,
        "learning_rate": 1.92619926199262e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.2301,
        "grad_norm": 0.8384682536125183,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.3378,
        "grad_norm": 6.713461875915527,
        "learning_rate": 1.9206642066420663e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.3082,
        "grad_norm": 1.0021564960479736,
        "learning_rate": 1.9178966789667896e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.3124,
        "grad_norm": 1.2442415952682495,
        "learning_rate": 1.915129151291513e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.2494,
        "grad_norm": 1.7222051620483398,
        "learning_rate": 1.9123616236162362e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.3812,
        "grad_norm": 7.169760227203369,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.2192,
        "grad_norm": 4.343343257904053,
        "learning_rate": 1.9068265682656828e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.2024,
        "grad_norm": 6.643985748291016,
        "learning_rate": 1.9040590405904058e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.196,
        "grad_norm": 9.768265724182129,
        "learning_rate": 1.901291512915129e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.1991,
        "grad_norm": 6.348132610321045,
        "learning_rate": 1.8985239852398524e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.3462,
        "grad_norm": 14.821806907653809,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.1989,
        "grad_norm": 11.846284866333008,
        "learning_rate": 1.892988929889299e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.2624,
        "grad_norm": 1.6462581157684326,
        "learning_rate": 1.890221402214022e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.2587,
        "grad_norm": 1.4804167747497559,
        "learning_rate": 1.8874538745387456e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.3076,
        "grad_norm": 1.8140203952789307,
        "learning_rate": 1.8846863468634686e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.2152,
        "grad_norm": 7.807764530181885,
        "learning_rate": 1.8819188191881922e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.2436,
        "grad_norm": 4.535635471343994,
        "learning_rate": 1.8791512915129152e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.2164,
        "grad_norm": 8.358292579650879,
        "learning_rate": 1.8763837638376382e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.5037792921066284,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.80656,
        "eval_recall": 0.9128,
        "eval_f1": 0.8564,
        "eval_runtime": 18.172,
        "eval_samples_per_second": 59.652,
        "eval_steps_per_second": 3.742,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.3115,
        "grad_norm": 1.1429060697555542,
        "learning_rate": 1.8736162361623618e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.2501,
        "grad_norm": 1.416121482849121,
        "learning_rate": 1.8708487084870848e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.1559,
        "grad_norm": 2.8600213527679443,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.2295,
        "grad_norm": 16.529224395751953,
        "learning_rate": 1.8653136531365314e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.2148,
        "grad_norm": 6.679436206817627,
        "learning_rate": 1.8625461254612547e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.1737,
        "grad_norm": 15.594441413879395,
        "learning_rate": 1.859778597785978e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.3009,
        "grad_norm": 1.3075529336929321,
        "learning_rate": 1.857011070110701e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.2786,
        "grad_norm": 5.499883651733398,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.287,
        "grad_norm": 2.6918418407440186,
        "learning_rate": 1.8514760147601476e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.3212,
        "grad_norm": 12.543292999267578,
        "learning_rate": 1.848708487084871e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.2065,
        "grad_norm": 1.1544841527938843,
        "learning_rate": 1.8459409594095942e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.2571,
        "grad_norm": 2.192399024963379,
        "learning_rate": 1.8431734317343175e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.24,
        "grad_norm": 1.7115975618362427,
        "learning_rate": 1.8404059040590405e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.24,
        "grad_norm": 2.092860698699951,
        "learning_rate": 1.8376383763837638e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.2775,
        "grad_norm": 3.383852958679199,
        "learning_rate": 1.834870848708487e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.2277,
        "grad_norm": 6.39716911315918,
        "learning_rate": 1.8321033210332104e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.2097,
        "grad_norm": 0.7435025572776794,
        "learning_rate": 1.8293357933579337e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2372,
        "grad_norm": 2.6514430046081543,
        "learning_rate": 1.8265682656826567e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.2669,
        "grad_norm": 2.447216272354126,
        "learning_rate": 1.8238007380073803e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.1928,
        "grad_norm": 7.489110469818115,
        "learning_rate": 1.8210332103321033e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.3158,
        "grad_norm": 70.84150695800781,
        "learning_rate": 1.8182656826568266e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.1703,
        "grad_norm": 3.9441025257110596,
        "learning_rate": 1.81549815498155e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.3231,
        "grad_norm": 12.344390869140625,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.22,
        "grad_norm": 12.705254554748535,
        "learning_rate": 1.8099630996309965e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.254,
        "grad_norm": 40.38232421875,
        "learning_rate": 1.8071955719557195e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.2026,
        "grad_norm": 2.179868698120117,
        "learning_rate": 1.8044280442804428e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.2549,
        "grad_norm": 3.5711705684661865,
        "learning_rate": 1.801660516605166e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.5040356516838074,
        "eval_accuracy": 0.86347,
        "eval_precision": 0.82747,
        "eval_recall": 0.91651,
        "eval_f1": 0.86972,
        "eval_runtime": 18.2123,
        "eval_samples_per_second": 59.52,
        "eval_steps_per_second": 3.734,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.1257,
        "grad_norm": 3.121994733810425,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.3346,
        "grad_norm": 2.334542751312256,
        "learning_rate": 1.7961254612546127e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.2248,
        "grad_norm": 3.331289291381836,
        "learning_rate": 1.7933579335793357e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.1921,
        "grad_norm": 1.3290132284164429,
        "learning_rate": 1.790590405904059e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.1748,
        "grad_norm": 10.457064628601074,
        "learning_rate": 1.7878228782287823e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.176,
        "grad_norm": 3.0372209548950195,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.1814,
        "grad_norm": 2.8597381114959717,
        "learning_rate": 1.7822878228782286e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.3741,
        "grad_norm": 8.270280838012695,
        "learning_rate": 1.7795202952029522e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.2267,
        "grad_norm": 3.3327836990356445,
        "learning_rate": 1.7767527675276752e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.3034,
        "grad_norm": 10.597417831420898,
        "learning_rate": 1.7739852398523985e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.2505,
        "grad_norm": 0.6883874535560608,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.2288,
        "grad_norm": 1.7767401933670044,
        "learning_rate": 1.7684501845018448e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.2705,
        "grad_norm": 2.2091290950775146,
        "learning_rate": 1.7656826568265684e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.2384,
        "grad_norm": 5.204725742340088,
        "learning_rate": 1.7629151291512914e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.278,
        "grad_norm": 1.549204707145691,
        "learning_rate": 1.760147601476015e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.1848,
        "grad_norm": 3.782470941543579,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.2273,
        "grad_norm": 2.6905558109283447,
        "learning_rate": 1.7546125461254613e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.2024,
        "grad_norm": 3.59818959236145,
        "learning_rate": 1.7518450184501846e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.2314,
        "grad_norm": 10.762181282043457,
        "learning_rate": 1.7490774907749076e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.2243,
        "grad_norm": 0.6830035448074341,
        "learning_rate": 1.7463099630996313e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.2411,
        "grad_norm": 3.3021721839904785,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.2787,
        "grad_norm": 8.45927619934082,
        "learning_rate": 1.7407749077490775e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.2947,
        "grad_norm": 6.10329008102417,
        "learning_rate": 1.738007380073801e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.2113,
        "grad_norm": 2.173194169998169,
        "learning_rate": 1.735239852398524e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.2702,
        "grad_norm": 5.773020267486572,
        "learning_rate": 1.732472324723247e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.2019,
        "grad_norm": 1.0762964487075806,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.1713,
        "grad_norm": 2.449218988418579,
        "learning_rate": 1.7269372693726937e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.5663406848907471,
        "eval_accuracy": 0.8607,
        "eval_precision": 0.83916,
        "eval_recall": 0.89054,
        "eval_f1": 0.86409,
        "eval_runtime": 18.2405,
        "eval_samples_per_second": 59.428,
        "eval_steps_per_second": 3.728,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.2462,
        "grad_norm": 8.155010223388672,
        "learning_rate": 1.724169741697417e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.1858,
        "grad_norm": 4.9028778076171875,
        "learning_rate": 1.7214022140221404e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.19,
        "grad_norm": 17.436159133911133,
        "learning_rate": 1.7186346863468633e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.1984,
        "grad_norm": 1.4929450750350952,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.219,
        "grad_norm": 0.7836324572563171,
        "learning_rate": 1.71309963099631e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.2707,
        "grad_norm": 1.8370862007141113,
        "learning_rate": 1.7103321033210332e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.2601,
        "grad_norm": 1.1535972356796265,
        "learning_rate": 1.7075645756457566e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.1615,
        "grad_norm": 5.341141700744629,
        "learning_rate": 1.7047970479704795e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2618,
        "grad_norm": 3.723327159881592,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.2986,
        "grad_norm": 9.79095458984375,
        "learning_rate": 1.699261992619926e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.1584,
        "grad_norm": 1.3052388429641724,
        "learning_rate": 1.6964944649446494e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.235,
        "grad_norm": 1.9215391874313354,
        "learning_rate": 1.6937269372693727e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.2094,
        "grad_norm": 27.150117874145508,
        "learning_rate": 1.690959409594096e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.2471,
        "grad_norm": 1.6509019136428833,
        "learning_rate": 1.6881918819188194e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.2489,
        "grad_norm": 1.344146728515625,
        "learning_rate": 1.6854243542435423e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.1903,
        "grad_norm": 1.5402884483337402,
        "learning_rate": 1.6826568265682656e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.154,
        "grad_norm": 3.946526050567627,
        "learning_rate": 1.679889298892989e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.3248,
        "grad_norm": 8.248265266418457,
        "learning_rate": 1.6771217712177123e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.2514,
        "grad_norm": 3.108027935028076,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.2084,
        "grad_norm": 1.5292294025421143,
        "learning_rate": 1.671586715867159e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.2498,
        "grad_norm": 11.061382293701172,
        "learning_rate": 1.668819188191882e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.1969,
        "grad_norm": 3.8289520740509033,
        "learning_rate": 1.666051660516605e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.1454,
        "grad_norm": 5.330443382263184,
        "learning_rate": 1.6632841328413285e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.2236,
        "grad_norm": 16.31702423095703,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.3005,
        "grad_norm": 2.3116796016693115,
        "learning_rate": 1.657749077490775e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.2233,
        "grad_norm": 10.816922187805176,
        "learning_rate": 1.654981549815498e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.276,
        "grad_norm": 1.3247532844543457,
        "learning_rate": 1.6522140221402217e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.49886855483055115,
        "eval_accuracy": 0.86808,
        "eval_precision": 0.83,
        "eval_recall": 0.92393,
        "eval_f1": 0.87445,
        "eval_runtime": 18.1998,
        "eval_samples_per_second": 59.561,
        "eval_steps_per_second": 3.736,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.2322,
        "grad_norm": 2.312906265258789,
        "learning_rate": 1.6494464944649447e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.1898,
        "grad_norm": 4.453392505645752,
        "learning_rate": 1.6466789667896676e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.2113,
        "grad_norm": 1.9827691316604614,
        "learning_rate": 1.6439114391143913e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.1896,
        "grad_norm": 1.0253297090530396,
        "learning_rate": 1.6411439114391142e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.229,
        "grad_norm": 0.9389504194259644,
        "learning_rate": 1.638376383763838e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.1977,
        "grad_norm": 40.145057678222656,
        "learning_rate": 1.635608856088561e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.2945,
        "grad_norm": 84.73507690429688,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2413,
        "grad_norm": 0.8797691464424133,
        "learning_rate": 1.6300738007380075e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.1508,
        "grad_norm": 3.0602431297302246,
        "learning_rate": 1.6273062730627308e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.1244,
        "grad_norm": 2.420452356338501,
        "learning_rate": 1.624538745387454e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.2119,
        "grad_norm": 0.9334281086921692,
        "learning_rate": 1.621771217712177e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.1921,
        "grad_norm": 1.3708906173706055,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.1507,
        "grad_norm": 2.2225184440612793,
        "learning_rate": 1.6162361623616237e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.2011,
        "grad_norm": 5.108001232147217,
        "learning_rate": 1.613468634686347e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.2277,
        "grad_norm": 2.120257616043091,
        "learning_rate": 1.6107011070110703e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.2111,
        "grad_norm": 4.7116007804870605,
        "learning_rate": 1.6079335793357936e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.2291,
        "grad_norm": 8.926437377929688,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.3164,
        "grad_norm": 3.369319200515747,
        "learning_rate": 1.60239852398524e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.2116,
        "grad_norm": 2.387544870376587,
        "learning_rate": 1.5996309963099632e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.2445,
        "grad_norm": 4.478021621704102,
        "learning_rate": 1.596863468634686e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.2514,
        "grad_norm": 2.525412082672119,
        "learning_rate": 1.5940959409594098e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.199,
        "grad_norm": 42.72466278076172,
        "learning_rate": 1.5913284132841328e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.2803,
        "grad_norm": 0.9812997579574585,
        "learning_rate": 1.5885608856088564e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2026,
        "grad_norm": 38.49885559082031,
        "learning_rate": 1.5857933579335794e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.3171,
        "grad_norm": 8.962234497070312,
        "learning_rate": 1.5830258302583023e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2195,
        "grad_norm": 1.6844797134399414,
        "learning_rate": 1.580258302583026e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.172,
        "grad_norm": 1.901448369026184,
        "learning_rate": 1.577490774907749e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.6323168873786926,
        "eval_accuracy": 0.85055,
        "eval_precision": 0.83363,
        "eval_recall": 0.87384,
        "eval_f1": 0.85326,
        "eval_runtime": 18.2167,
        "eval_samples_per_second": 59.506,
        "eval_steps_per_second": 3.733,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.2418,
        "grad_norm": 0.714468777179718,
        "learning_rate": 1.5747232472324726e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.1812,
        "grad_norm": 49.6081428527832,
        "learning_rate": 1.5719557195571956e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.2166,
        "grad_norm": 9.638249397277832,
        "learning_rate": 1.569188191881919e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.1163,
        "grad_norm": 0.6487756967544556,
        "learning_rate": 1.5664206642066422e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.2682,
        "grad_norm": 4.220464706420898,
        "learning_rate": 1.5636531365313655e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.2415,
        "grad_norm": 14.186070442199707,
        "learning_rate": 1.5608856088560885e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2417,
        "grad_norm": 3.8365845680236816,
        "learning_rate": 1.5581180811808118e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.1798,
        "grad_norm": 11.794220924377441,
        "learning_rate": 1.555350553505535e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.2796,
        "grad_norm": 8.184500694274902,
        "learning_rate": 1.5525830258302584e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.237,
        "grad_norm": 2.9787445068359375,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.1713,
        "grad_norm": 1.5537850856781006,
        "learning_rate": 1.5470479704797047e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.1795,
        "grad_norm": 2.8744919300079346,
        "learning_rate": 1.5442804428044283e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.2776,
        "grad_norm": 6.765928268432617,
        "learning_rate": 1.5415129151291513e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.231,
        "grad_norm": 13.326889991760254,
        "learning_rate": 1.5387453874538746e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.1737,
        "grad_norm": 7.815138339996338,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.1366,
        "grad_norm": 1.9579845666885376,
        "learning_rate": 1.533210332103321e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.3126,
        "grad_norm": 12.822836875915527,
        "learning_rate": 1.5304428044280445e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.2957,
        "grad_norm": 8.24951457977295,
        "learning_rate": 1.5276752767527675e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.2324,
        "grad_norm": 9.671161651611328,
        "learning_rate": 1.524907749077491e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.163,
        "grad_norm": 1.2225421667099,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.1671,
        "grad_norm": 3.249711275100708,
        "learning_rate": 1.5193726937269372e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.2392,
        "grad_norm": 51.58546447753906,
        "learning_rate": 1.5166051660516607e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.2655,
        "grad_norm": 4.1743245124816895,
        "learning_rate": 1.5138376383763838e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.1655,
        "grad_norm": 1.5613933801651,
        "learning_rate": 1.511070110701107e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.2372,
        "grad_norm": 3.1896681785583496,
        "learning_rate": 1.5083025830258303e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.1905,
        "grad_norm": 9.284906387329102,
        "learning_rate": 1.5055350553505534e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.3005,
        "grad_norm": 3.2114028930664062,
        "learning_rate": 1.5027675276752769e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.2037,
        "grad_norm": 1.3315448760986328,
        "learning_rate": 1.5e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.5352663993835449,
        "eval_accuracy": 0.85055,
        "eval_precision": 0.81788,
        "eval_recall": 0.89981,
        "eval_f1": 0.85689,
        "eval_runtime": 18.186,
        "eval_samples_per_second": 59.606,
        "eval_steps_per_second": 3.739,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.1833,
        "grad_norm": 1.2112089395523071,
        "learning_rate": 1.4972324723247233e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.2072,
        "grad_norm": 5.238758087158203,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2419,
        "grad_norm": 9.675317764282227,
        "learning_rate": 1.4916974169741698e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.1019,
        "grad_norm": 10.884011268615723,
        "learning_rate": 1.488929889298893e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2646,
        "grad_norm": 1.4511351585388184,
        "learning_rate": 1.4861623616236162e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.182,
        "grad_norm": 5.541290283203125,
        "learning_rate": 1.4833948339483395e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.1624,
        "grad_norm": 143.83035278320312,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.2372,
        "grad_norm": 28.209667205810547,
        "learning_rate": 1.477859778597786e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.2517,
        "grad_norm": 8.992276191711426,
        "learning_rate": 1.4750922509225093e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.2414,
        "grad_norm": 1.6277278661727905,
        "learning_rate": 1.4723247232472326e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.2167,
        "grad_norm": 7.339791774749756,
        "learning_rate": 1.4695571955719559e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.2182,
        "grad_norm": 6.174863815307617,
        "learning_rate": 1.4667896678966789e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.2051,
        "grad_norm": 3.94197678565979,
        "learning_rate": 1.4640221402214022e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.2166,
        "grad_norm": 1.5713521242141724,
        "learning_rate": 1.4612546125461255e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.2442,
        "grad_norm": 3.521746873855591,
        "learning_rate": 1.4584870848708488e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.1722,
        "grad_norm": 2.893742322921753,
        "learning_rate": 1.455719557195572e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.2129,
        "grad_norm": 4.717182636260986,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.1555,
        "grad_norm": 4.245517730712891,
        "learning_rate": 1.4501845018450186e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.1146,
        "grad_norm": 7.912182807922363,
        "learning_rate": 1.4474169741697419e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.4025,
        "grad_norm": 10.819164276123047,
        "learning_rate": 1.4446494464944648e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.2296,
        "grad_norm": 1.2152665853500366,
        "learning_rate": 1.4418819188191881e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.2186,
        "grad_norm": 1.1606953144073486,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.3005,
        "grad_norm": 16.637859344482422,
        "learning_rate": 1.4363468634686348e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.1757,
        "grad_norm": 2.1463379859924316,
        "learning_rate": 1.433579335793358e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.1625,
        "grad_norm": 2.9227182865142822,
        "learning_rate": 1.4308118081180812e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.3082,
        "grad_norm": 0.860278844833374,
        "learning_rate": 1.4280442804428045e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.1355,
        "grad_norm": 2.2464141845703125,
        "learning_rate": 1.4252767527675276e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.5562676191329956,
        "eval_accuracy": 0.85886,
        "eval_precision": 0.83162,
        "eval_recall": 0.89796,
        "eval_f1": 0.86351,
        "eval_runtime": 18.1979,
        "eval_samples_per_second": 59.567,
        "eval_steps_per_second": 3.737,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.21,
        "grad_norm": 161.985595703125,
        "learning_rate": 1.422509225092251e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.1559,
        "grad_norm": 6.93464994430542,
        "learning_rate": 1.4197416974169741e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.2203,
        "grad_norm": 3.325995445251465,
        "learning_rate": 1.4169741697416974e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.2755,
        "grad_norm": 1.5551091432571411,
        "learning_rate": 1.4142066420664207e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.2805,
        "grad_norm": 12.095083236694336,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.1482,
        "grad_norm": 22.19981575012207,
        "learning_rate": 1.4086715867158673e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.2131,
        "grad_norm": 3.919283866882324,
        "learning_rate": 1.4059040590405905e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.1209,
        "grad_norm": 8.75870132446289,
        "learning_rate": 1.4031365313653136e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.3189,
        "grad_norm": 8.209638595581055,
        "learning_rate": 1.4003690036900369e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.1835,
        "grad_norm": 28.12687110900879,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.094,
        "grad_norm": 0.7059605717658997,
        "learning_rate": 1.3948339483394834e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.2749,
        "grad_norm": 7.176096439361572,
        "learning_rate": 1.3920664206642067e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.0895,
        "grad_norm": 9.711506843566895,
        "learning_rate": 1.38929889298893e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.2433,
        "grad_norm": 2.722292184829712,
        "learning_rate": 1.3865313653136533e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.2323,
        "grad_norm": 0.5692064166069031,
        "learning_rate": 1.3837638376383764e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.2995,
        "grad_norm": 0.5514811873435974,
        "learning_rate": 1.3809963099630995e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.12,
        "grad_norm": 23.88880729675293,
        "learning_rate": 1.3782287822878229e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.223,
        "grad_norm": 10.29345417022705,
        "learning_rate": 1.3754612546125462e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.4308,
        "grad_norm": 7.03131628036499,
        "learning_rate": 1.3726937269372695e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.2789,
        "grad_norm": 4.187948703765869,
        "learning_rate": 1.3699261992619926e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.2002,
        "grad_norm": 12.919846534729004,
        "learning_rate": 1.367158671586716e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.1618,
        "grad_norm": 2.431624412536621,
        "learning_rate": 1.3643911439114392e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.2234,
        "grad_norm": 21.905532836914062,
        "learning_rate": 1.3616236162361624e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.1699,
        "grad_norm": 3.4867520332336426,
        "learning_rate": 1.3588560885608857e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.2354,
        "grad_norm": 2.135924816131592,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.2443,
        "grad_norm": 16.03529930114746,
        "learning_rate": 1.3533210332103321e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.2694,
        "grad_norm": 5.058593273162842,
        "learning_rate": 1.3505535055350554e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.5778595805168152,
        "eval_accuracy": 0.86624,
        "eval_precision": 0.83849,
        "eval_recall": 0.90538,
        "eval_f1": 0.87065,
        "eval_runtime": 18.1802,
        "eval_samples_per_second": 59.625,
        "eval_steps_per_second": 3.74,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.1644,
        "grad_norm": 3.175571918487549,
        "learning_rate": 1.3477859778597787e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.1896,
        "grad_norm": 33.296302795410156,
        "learning_rate": 1.3450184501845019e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.2432,
        "grad_norm": 8.802642822265625,
        "learning_rate": 1.3422509225092252e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.1947,
        "grad_norm": 2.4139139652252197,
        "learning_rate": 1.3394833948339483e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.1394,
        "grad_norm": 1.0448660850524902,
        "learning_rate": 1.3367158671586716e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.2359,
        "grad_norm": 2.1785686016082764,
        "learning_rate": 1.3339483394833948e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.2319,
        "grad_norm": 1.7646018266677856,
        "learning_rate": 1.331180811808118e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.1321,
        "grad_norm": 1.4392861127853394,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.2735,
        "grad_norm": 8.029657363891602,
        "learning_rate": 1.3256457564575647e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.1104,
        "grad_norm": 1.9722660779953003,
        "learning_rate": 1.322878228782288e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.2137,
        "grad_norm": 9.826414108276367,
        "learning_rate": 1.320110701107011e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.1193,
        "grad_norm": 25.548583984375,
        "learning_rate": 1.3173431734317343e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.1308,
        "grad_norm": 0.6355085968971252,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.3081,
        "grad_norm": 0.6773098707199097,
        "learning_rate": 1.3118081180811809e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.2724,
        "grad_norm": 10.006448745727539,
        "learning_rate": 1.309040590405904e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.2345,
        "grad_norm": 3.261406660079956,
        "learning_rate": 1.3062730627306273e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.2259,
        "grad_norm": 1.694246530532837,
        "learning_rate": 1.3035055350553506e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.2026,
        "grad_norm": 0.6724967956542969,
        "learning_rate": 1.300738007380074e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.1868,
        "grad_norm": 2.6845624446868896,
        "learning_rate": 1.297970479704797e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.1917,
        "grad_norm": 5.967291831970215,
        "learning_rate": 1.2952029520295202e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.3218,
        "grad_norm": 2.9399795532226562,
        "learning_rate": 1.2924354243542435e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.1753,
        "grad_norm": 1.6409028768539429,
        "learning_rate": 1.2896678966789668e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.2236,
        "grad_norm": 1.0623011589050293,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.2431,
        "grad_norm": 7.4543280601501465,
        "learning_rate": 1.2841328413284133e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.1688,
        "grad_norm": 31.80036163330078,
        "learning_rate": 1.2813653136531366e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.196,
        "grad_norm": 1.9198330640792847,
        "learning_rate": 1.2785977859778599e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.275,
        "grad_norm": 0.5289472341537476,
        "learning_rate": 1.275830258302583e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.5671429634094238,
        "eval_accuracy": 0.86716,
        "eval_precision": 0.84111,
        "eval_recall": 0.90353,
        "eval_f1": 0.8712,
        "eval_runtime": 18.178,
        "eval_samples_per_second": 59.632,
        "eval_steps_per_second": 3.741,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.1444,
        "grad_norm": 0.9848661422729492,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.2724,
        "grad_norm": 8.264620780944824,
        "learning_rate": 1.2702952029520295e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.1675,
        "grad_norm": 4.014472484588623,
        "learning_rate": 1.2675276752767528e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.2036,
        "grad_norm": 8.646921157836914,
        "learning_rate": 1.2647601476014761e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.1235,
        "grad_norm": 25.685556411743164,
        "learning_rate": 1.2619926199261994e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.3439,
        "grad_norm": 20.233150482177734,
        "learning_rate": 1.2592250922509225e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.1672,
        "grad_norm": 1.3271536827087402,
        "learning_rate": 1.2564575645756457e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.2926,
        "grad_norm": 1.216649055480957,
        "learning_rate": 1.253690036900369e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.2125,
        "grad_norm": 12.11614990234375,
        "learning_rate": 1.2509225092250923e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.1535,
        "grad_norm": 0.7877753973007202,
        "learning_rate": 1.2481549815498156e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.1656,
        "grad_norm": 0.6025156378746033,
        "learning_rate": 1.2453874538745387e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.1986,
        "grad_norm": 29.095727920532227,
        "learning_rate": 1.242619926199262e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.1138,
        "grad_norm": 4.750482082366943,
        "learning_rate": 1.2398523985239854e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.2102,
        "grad_norm": 0.31218039989471436,
        "learning_rate": 1.2370848708487087e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.1623,
        "grad_norm": 0.49581485986709595,
        "learning_rate": 1.2343173431734316e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.2005,
        "grad_norm": 5.691254615783691,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.2716,
        "grad_norm": 1.757393717765808,
        "learning_rate": 1.2287822878228782e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.1556,
        "grad_norm": 1.6746963262557983,
        "learning_rate": 1.2260147601476015e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.163,
        "grad_norm": 0.613208532333374,
        "learning_rate": 1.2232472324723247e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.2739,
        "grad_norm": 1.037363052368164,
        "learning_rate": 1.220479704797048e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.2984,
        "grad_norm": 2.4603264331817627,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.0799,
        "grad_norm": 54.419769287109375,
        "learning_rate": 1.2149446494464946e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.2342,
        "grad_norm": 0.9522631764411926,
        "learning_rate": 1.2121771217712177e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.1486,
        "grad_norm": 1.6693644523620605,
        "learning_rate": 1.2094095940959409e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.0888,
        "grad_norm": 1.2001749277114868,
        "learning_rate": 1.2066420664206642e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.2058,
        "grad_norm": 0.5146707892417908,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.3148,
        "grad_norm": 42.603614807128906,
        "learning_rate": 1.2011070110701108e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.600719690322876,
        "eval_accuracy": 0.86624,
        "eval_precision": 0.83277,
        "eval_recall": 0.91466,
        "eval_f1": 0.87179,
        "eval_runtime": 18.1947,
        "eval_samples_per_second": 59.578,
        "eval_steps_per_second": 3.737,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "loss": 0.1539,
        "grad_norm": 2.188418388366699,
        "learning_rate": 1.198339483394834e-05,
        "epoch": 24.022140221402214,
        "step": 6510
    },
    {
        "loss": 0.1784,
        "grad_norm": 1.1484763622283936,
        "learning_rate": 1.1955719557195573e-05,
        "epoch": 24.059040590405903,
        "step": 6520
    },
    {
        "loss": 0.1395,
        "grad_norm": 5.716892242431641,
        "learning_rate": 1.1928044280442804e-05,
        "epoch": 24.095940959409592,
        "step": 6530
    },
    {
        "loss": 0.2988,
        "grad_norm": 1.8135390281677246,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 24.132841328413285,
        "step": 6540
    },
    {
        "loss": 0.263,
        "grad_norm": 14.770830154418945,
        "learning_rate": 1.187269372693727e-05,
        "epoch": 24.169741697416974,
        "step": 6550
    },
    {
        "loss": 0.3336,
        "grad_norm": 3.5346498489379883,
        "learning_rate": 1.1845018450184501e-05,
        "epoch": 24.206642066420663,
        "step": 6560
    },
    {
        "loss": 0.1483,
        "grad_norm": 35.88029861450195,
        "learning_rate": 1.1817343173431735e-05,
        "epoch": 24.243542435424356,
        "step": 6570
    },
    {
        "loss": 0.1774,
        "grad_norm": 2.442101240158081,
        "learning_rate": 1.1789667896678968e-05,
        "epoch": 24.280442804428045,
        "step": 6580
    },
    {
        "loss": 0.1387,
        "grad_norm": 0.32232990860939026,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 24.317343173431734,
        "step": 6590
    },
    {
        "loss": 0.1655,
        "grad_norm": 1.0060338973999023,
        "learning_rate": 1.1734317343173432e-05,
        "epoch": 24.354243542435423,
        "step": 6600
    },
    {
        "loss": 0.2232,
        "grad_norm": 2.030050039291382,
        "learning_rate": 1.1706642066420663e-05,
        "epoch": 24.391143911439116,
        "step": 6610
    },
    {
        "loss": 0.1935,
        "grad_norm": 1.0589275360107422,
        "learning_rate": 1.1678966789667897e-05,
        "epoch": 24.428044280442805,
        "step": 6620
    },
    {
        "loss": 0.1791,
        "grad_norm": 1.4445234537124634,
        "learning_rate": 1.165129151291513e-05,
        "epoch": 24.464944649446494,
        "step": 6630
    },
    {
        "loss": 0.1534,
        "grad_norm": 3.901275157928467,
        "learning_rate": 1.1623616236162363e-05,
        "epoch": 24.501845018450183,
        "step": 6640
    },
    {
        "loss": 0.2697,
        "grad_norm": 0.46238893270492554,
        "learning_rate": 1.1595940959409594e-05,
        "epoch": 24.538745387453876,
        "step": 6650
    },
    {
        "loss": 0.1439,
        "grad_norm": 1.2511205673217773,
        "learning_rate": 1.1568265682656827e-05,
        "epoch": 24.575645756457565,
        "step": 6660
    },
    {
        "loss": 0.2457,
        "grad_norm": 36.649940490722656,
        "learning_rate": 1.154059040590406e-05,
        "epoch": 24.612546125461254,
        "step": 6670
    },
    {
        "loss": 0.1982,
        "grad_norm": 1.7182308435440063,
        "learning_rate": 1.1512915129151292e-05,
        "epoch": 24.649446494464943,
        "step": 6680
    },
    {
        "loss": 0.1624,
        "grad_norm": 1.3142982721328735,
        "learning_rate": 1.1485239852398523e-05,
        "epoch": 24.686346863468636,
        "step": 6690
    },
    {
        "loss": 0.2312,
        "grad_norm": 0.8458483219146729,
        "learning_rate": 1.1457564575645756e-05,
        "epoch": 24.723247232472325,
        "step": 6700
    },
    {
        "loss": 0.21,
        "grad_norm": 7.259210586547852,
        "learning_rate": 1.1429889298892989e-05,
        "epoch": 24.760147601476014,
        "step": 6710
    },
    {
        "loss": 0.1574,
        "grad_norm": 0.5766396522521973,
        "learning_rate": 1.1402214022140222e-05,
        "epoch": 24.797047970479706,
        "step": 6720
    },
    {
        "loss": 0.1905,
        "grad_norm": 0.8485110998153687,
        "learning_rate": 1.1374538745387455e-05,
        "epoch": 24.833948339483396,
        "step": 6730
    },
    {
        "loss": 0.2455,
        "grad_norm": 1.2862197160720825,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 24.870848708487085,
        "step": 6740
    },
    {
        "loss": 0.1681,
        "grad_norm": 4.235610008239746,
        "learning_rate": 1.131918819188192e-05,
        "epoch": 24.907749077490774,
        "step": 6750
    },
    {
        "loss": 0.2668,
        "grad_norm": 6.128146171569824,
        "learning_rate": 1.1291512915129151e-05,
        "epoch": 24.944649446494466,
        "step": 6760
    },
    {
        "loss": 0.1833,
        "grad_norm": 1.2735142707824707,
        "learning_rate": 1.1263837638376384e-05,
        "epoch": 24.981549815498155,
        "step": 6770
    },
    {
        "eval_loss": 0.571436882019043,
        "eval_accuracy": 0.85886,
        "eval_precision": 0.82823,
        "eval_recall": 0.90353,
        "eval_f1": 0.86424,
        "eval_runtime": 18.2016,
        "eval_samples_per_second": 59.555,
        "eval_steps_per_second": 3.736,
        "epoch": 25.0,
        "step": 6775
    },
    {
        "loss": 0.0869,
        "grad_norm": 4.520232200622559,
        "learning_rate": 1.1236162361623616e-05,
        "epoch": 25.018450184501845,
        "step": 6780
    },
    {
        "loss": 0.1983,
        "grad_norm": 5.521276473999023,
        "learning_rate": 1.1208487084870849e-05,
        "epoch": 25.055350553505534,
        "step": 6790
    },
    {
        "loss": 0.159,
        "grad_norm": 3.6749136447906494,
        "learning_rate": 1.1180811808118082e-05,
        "epoch": 25.092250922509226,
        "step": 6800
    },
    {
        "loss": 0.1781,
        "grad_norm": 4.214268684387207,
        "learning_rate": 1.1153136531365315e-05,
        "epoch": 25.129151291512915,
        "step": 6810
    },
    {
        "loss": 0.2688,
        "grad_norm": 11.09315013885498,
        "learning_rate": 1.1125461254612546e-05,
        "epoch": 25.166051660516604,
        "step": 6820
    },
    {
        "loss": 0.2309,
        "grad_norm": 1.457733392715454,
        "learning_rate": 1.109778597785978e-05,
        "epoch": 25.202952029520294,
        "step": 6830
    },
    {
        "loss": 0.1979,
        "grad_norm": 1.6621848344802856,
        "learning_rate": 1.107011070110701e-05,
        "epoch": 25.239852398523986,
        "step": 6840
    },
    {
        "loss": 0.2134,
        "grad_norm": 5.1294779777526855,
        "learning_rate": 1.1042435424354244e-05,
        "epoch": 25.276752767527675,
        "step": 6850
    },
    {
        "loss": 0.1956,
        "grad_norm": 0.7624732255935669,
        "learning_rate": 1.1014760147601477e-05,
        "epoch": 25.313653136531364,
        "step": 6860
    },
    {
        "loss": 0.21,
        "grad_norm": 3.833833694458008,
        "learning_rate": 1.0987084870848708e-05,
        "epoch": 25.350553505535057,
        "step": 6870
    },
    {
        "loss": 0.1566,
        "grad_norm": 0.6383540630340576,
        "learning_rate": 1.0959409594095941e-05,
        "epoch": 25.387453874538746,
        "step": 6880
    },
    {
        "loss": 0.186,
        "grad_norm": 2.2569146156311035,
        "learning_rate": 1.0931734317343174e-05,
        "epoch": 25.424354243542435,
        "step": 6890
    },
    {
        "loss": 0.1548,
        "grad_norm": 9.997238159179688,
        "learning_rate": 1.0904059040590407e-05,
        "epoch": 25.461254612546124,
        "step": 6900
    },
    {
        "loss": 0.1536,
        "grad_norm": 2.340529680252075,
        "learning_rate": 1.0876383763837637e-05,
        "epoch": 25.498154981549817,
        "step": 6910
    },
    {
        "loss": 0.2824,
        "grad_norm": 7.201061248779297,
        "learning_rate": 1.084870848708487e-05,
        "epoch": 25.535055350553506,
        "step": 6920
    },
    {
        "loss": 0.2632,
        "grad_norm": 8.457051277160645,
        "learning_rate": 1.0821033210332103e-05,
        "epoch": 25.571955719557195,
        "step": 6930
    },
    {
        "loss": 0.1591,
        "grad_norm": 1.0902148485183716,
        "learning_rate": 1.0793357933579336e-05,
        "epoch": 25.608856088560884,
        "step": 6940
    },
    {
        "loss": 0.1939,
        "grad_norm": 0.8851059079170227,
        "learning_rate": 1.076568265682657e-05,
        "epoch": 25.645756457564577,
        "step": 6950
    },
    {
        "loss": 0.1882,
        "grad_norm": 10.790022850036621,
        "learning_rate": 1.07380073800738e-05,
        "epoch": 25.682656826568266,
        "step": 6960
    },
    {
        "loss": 0.1879,
        "grad_norm": 6.769716739654541,
        "learning_rate": 1.0710332103321034e-05,
        "epoch": 25.719557195571955,
        "step": 6970
    },
    {
        "loss": 0.2233,
        "grad_norm": 24.536096572875977,
        "learning_rate": 1.0682656826568267e-05,
        "epoch": 25.756457564575644,
        "step": 6980
    },
    {
        "loss": 0.4073,
        "grad_norm": 3.0663628578186035,
        "learning_rate": 1.0654981549815498e-05,
        "epoch": 25.793357933579337,
        "step": 6990
    },
    {
        "loss": 0.1482,
        "grad_norm": 2.219712495803833,
        "learning_rate": 1.062730627306273e-05,
        "epoch": 25.830258302583026,
        "step": 7000
    },
    {
        "loss": 0.1373,
        "grad_norm": 23.599822998046875,
        "learning_rate": 1.0599630996309963e-05,
        "epoch": 25.867158671586715,
        "step": 7010
    },
    {
        "loss": 0.1348,
        "grad_norm": 1.0237351655960083,
        "learning_rate": 1.0571955719557196e-05,
        "epoch": 25.904059040590404,
        "step": 7020
    },
    {
        "loss": 0.1469,
        "grad_norm": 1.897305965423584,
        "learning_rate": 1.0544280442804429e-05,
        "epoch": 25.940959409594097,
        "step": 7030
    },
    {
        "loss": 0.2445,
        "grad_norm": 1.3600751161575317,
        "learning_rate": 1.0516605166051662e-05,
        "epoch": 25.977859778597786,
        "step": 7040
    },
    {
        "eval_loss": 0.5566644072532654,
        "eval_accuracy": 0.85517,
        "eval_precision": 0.81623,
        "eval_recall": 0.91466,
        "eval_f1": 0.86264,
        "eval_runtime": 18.2141,
        "eval_samples_per_second": 59.514,
        "eval_steps_per_second": 3.733,
        "epoch": 26.0,
        "step": 7046
    },
    {
        "loss": 0.1319,
        "grad_norm": 0.49532637000083923,
        "learning_rate": 1.0488929889298893e-05,
        "epoch": 26.014760147601475,
        "step": 7050
    },
    {
        "loss": 0.1345,
        "grad_norm": 0.33140814304351807,
        "learning_rate": 1.0461254612546126e-05,
        "epoch": 26.051660516605168,
        "step": 7060
    },
    {
        "loss": 0.2422,
        "grad_norm": 1.4284743070602417,
        "learning_rate": 1.0433579335793358e-05,
        "epoch": 26.088560885608857,
        "step": 7070
    },
    {
        "loss": 0.2993,
        "grad_norm": 2.2328743934631348,
        "learning_rate": 1.0405904059040591e-05,
        "epoch": 26.125461254612546,
        "step": 7080
    },
    {
        "loss": 0.2073,
        "grad_norm": 0.3608974814414978,
        "learning_rate": 1.0378228782287822e-05,
        "epoch": 26.162361623616235,
        "step": 7090
    },
    {
        "loss": 0.1067,
        "grad_norm": 23.9735050201416,
        "learning_rate": 1.0350553505535055e-05,
        "epoch": 26.199261992619927,
        "step": 7100
    },
    {
        "loss": 0.2426,
        "grad_norm": 3.368394136428833,
        "learning_rate": 1.0322878228782288e-05,
        "epoch": 26.236162361623617,
        "step": 7110
    },
    {
        "loss": 0.199,
        "grad_norm": 1.5565916299819946,
        "learning_rate": 1.0295202952029521e-05,
        "epoch": 26.273062730627306,
        "step": 7120
    },
    {
        "loss": 0.1997,
        "grad_norm": 4.561553478240967,
        "learning_rate": 1.0267527675276755e-05,
        "epoch": 26.309963099630995,
        "step": 7130
    },
    {
        "loss": 0.2447,
        "grad_norm": 0.8476565480232239,
        "learning_rate": 1.0239852398523984e-05,
        "epoch": 26.346863468634687,
        "step": 7140
    },
    {
        "loss": 0.2481,
        "grad_norm": 2.4064712524414062,
        "learning_rate": 1.0212177121771217e-05,
        "epoch": 26.383763837638377,
        "step": 7150
    },
    {
        "loss": 0.1864,
        "grad_norm": 4.983105182647705,
        "learning_rate": 1.018450184501845e-05,
        "epoch": 26.420664206642066,
        "step": 7160
    },
    {
        "loss": 0.1585,
        "grad_norm": 1.0099194049835205,
        "learning_rate": 1.0156826568265683e-05,
        "epoch": 26.457564575645755,
        "step": 7170
    },
    {
        "loss": 0.159,
        "grad_norm": 0.7890449166297913,
        "learning_rate": 1.0129151291512915e-05,
        "epoch": 26.494464944649447,
        "step": 7180
    },
    {
        "loss": 0.2556,
        "grad_norm": 29.61896514892578,
        "learning_rate": 1.0101476014760148e-05,
        "epoch": 26.531365313653136,
        "step": 7190
    },
    {
        "loss": 0.1869,
        "grad_norm": 0.24717570841312408,
        "learning_rate": 1.0073800738007381e-05,
        "epoch": 26.568265682656826,
        "step": 7200
    },
    {
        "loss": 0.2092,
        "grad_norm": 0.880835771560669,
        "learning_rate": 1.0046125461254614e-05,
        "epoch": 26.605166051660518,
        "step": 7210
    },
    {
        "loss": 0.122,
        "grad_norm": 0.6489872336387634,
        "learning_rate": 1.0018450184501844e-05,
        "epoch": 26.642066420664207,
        "step": 7220
    },
    {
        "loss": 0.1141,
        "grad_norm": 0.48931315541267395,
        "learning_rate": 9.990774907749077e-06,
        "epoch": 26.678966789667896,
        "step": 7230
    },
    {
        "loss": 0.1665,
        "grad_norm": 1.6622062921524048,
        "learning_rate": 9.96309963099631e-06,
        "epoch": 26.715867158671585,
        "step": 7240
    },
    {
        "loss": 0.2102,
        "grad_norm": 3.065852642059326,
        "learning_rate": 9.935424354243543e-06,
        "epoch": 26.752767527675278,
        "step": 7250
    },
    {
        "loss": 0.2365,
        "grad_norm": 1.6250802278518677,
        "learning_rate": 9.907749077490776e-06,
        "epoch": 26.789667896678967,
        "step": 7260
    },
    {
        "loss": 0.2235,
        "grad_norm": 2.6387064456939697,
        "learning_rate": 9.880073800738007e-06,
        "epoch": 26.826568265682656,
        "step": 7270
    },
    {
        "loss": 0.2633,
        "grad_norm": 0.9734385013580322,
        "learning_rate": 9.85239852398524e-06,
        "epoch": 26.863468634686345,
        "step": 7280
    },
    {
        "loss": 0.1444,
        "grad_norm": 16.980365753173828,
        "learning_rate": 9.824723247232474e-06,
        "epoch": 26.900369003690038,
        "step": 7290
    },
    {
        "loss": 0.1531,
        "grad_norm": 17.775753021240234,
        "learning_rate": 9.797047970479705e-06,
        "epoch": 26.937269372693727,
        "step": 7300
    },
    {
        "loss": 0.164,
        "grad_norm": 44.445526123046875,
        "learning_rate": 9.769372693726936e-06,
        "epoch": 26.974169741697416,
        "step": 7310
    },
    {
        "eval_loss": 0.6774472594261169,
        "eval_accuracy": 0.85701,
        "eval_precision": 0.83333,
        "eval_recall": 0.89054,
        "eval_f1": 0.86099,
        "eval_runtime": 18.1883,
        "eval_samples_per_second": 59.599,
        "eval_steps_per_second": 3.739,
        "epoch": 27.0,
        "step": 7317
    },
    {
        "loss": 0.0989,
        "grad_norm": 5.186260223388672,
        "learning_rate": 9.74169741697417e-06,
        "epoch": 27.011070110701105,
        "step": 7320
    },
    {
        "loss": 0.2252,
        "grad_norm": 0.432701975107193,
        "learning_rate": 9.714022140221402e-06,
        "epoch": 27.047970479704798,
        "step": 7330
    },
    {
        "loss": 0.25,
        "grad_norm": 11.276448249816895,
        "learning_rate": 9.686346863468636e-06,
        "epoch": 27.084870848708487,
        "step": 7340
    },
    {
        "loss": 0.1106,
        "grad_norm": 0.544306218624115,
        "learning_rate": 9.658671586715869e-06,
        "epoch": 27.121771217712176,
        "step": 7350
    },
    {
        "loss": 0.1623,
        "grad_norm": 1.5166651010513306,
        "learning_rate": 9.6309963099631e-06,
        "epoch": 27.15867158671587,
        "step": 7360
    },
    {
        "loss": 0.2155,
        "grad_norm": 1.0032217502593994,
        "learning_rate": 9.603321033210331e-06,
        "epoch": 27.195571955719558,
        "step": 7370
    },
    {
        "loss": 0.1534,
        "grad_norm": 15.149474143981934,
        "learning_rate": 9.575645756457564e-06,
        "epoch": 27.232472324723247,
        "step": 7380
    },
    {
        "loss": 0.2344,
        "grad_norm": 1.1308273077011108,
        "learning_rate": 9.547970479704798e-06,
        "epoch": 27.269372693726936,
        "step": 7390
    },
    {
        "loss": 0.1696,
        "grad_norm": 3.668978214263916,
        "learning_rate": 9.520295202952029e-06,
        "epoch": 27.30627306273063,
        "step": 7400
    },
    {
        "loss": 0.1373,
        "grad_norm": 0.7926496863365173,
        "learning_rate": 9.492619926199262e-06,
        "epoch": 27.343173431734318,
        "step": 7410
    },
    {
        "loss": 0.1605,
        "grad_norm": 2.0577800273895264,
        "learning_rate": 9.464944649446495e-06,
        "epoch": 27.380073800738007,
        "step": 7420
    },
    {
        "loss": 0.1646,
        "grad_norm": 0.7803741693496704,
        "learning_rate": 9.437269372693728e-06,
        "epoch": 27.416974169741696,
        "step": 7430
    },
    {
        "loss": 0.304,
        "grad_norm": 8.104497909545898,
        "learning_rate": 9.409594095940961e-06,
        "epoch": 27.45387453874539,
        "step": 7440
    },
    {
        "loss": 0.1238,
        "grad_norm": 3.029825448989868,
        "learning_rate": 9.381918819188191e-06,
        "epoch": 27.490774907749078,
        "step": 7450
    },
    {
        "loss": 0.156,
        "grad_norm": 3.6772677898406982,
        "learning_rate": 9.354243542435424e-06,
        "epoch": 27.527675276752767,
        "step": 7460
    },
    {
        "loss": 0.1968,
        "grad_norm": 0.9930314421653748,
        "learning_rate": 9.326568265682657e-06,
        "epoch": 27.564575645756456,
        "step": 7470
    },
    {
        "loss": 0.1065,
        "grad_norm": 8.108903884887695,
        "learning_rate": 9.29889298892989e-06,
        "epoch": 27.60147601476015,
        "step": 7480
    },
    {
        "loss": 0.2659,
        "grad_norm": 3.1459856033325195,
        "learning_rate": 9.271217712177122e-06,
        "epoch": 27.638376383763838,
        "step": 7490
    },
    {
        "loss": 0.2093,
        "grad_norm": 0.6259014010429382,
        "learning_rate": 9.243542435424355e-06,
        "epoch": 27.675276752767527,
        "step": 7500
    },
    {
        "loss": 0.2371,
        "grad_norm": 2.773751735687256,
        "learning_rate": 9.215867158671588e-06,
        "epoch": 27.71217712177122,
        "step": 7510
    },
    {
        "loss": 0.1647,
        "grad_norm": 1.0125963687896729,
        "learning_rate": 9.188191881918819e-06,
        "epoch": 27.74907749077491,
        "step": 7520
    },
    {
        "loss": 0.1203,
        "grad_norm": 4.364591598510742,
        "learning_rate": 9.160516605166052e-06,
        "epoch": 27.785977859778598,
        "step": 7530
    },
    {
        "loss": 0.1861,
        "grad_norm": 1.3807073831558228,
        "learning_rate": 9.132841328413284e-06,
        "epoch": 27.822878228782287,
        "step": 7540
    },
    {
        "loss": 0.2037,
        "grad_norm": 11.367283821105957,
        "learning_rate": 9.105166051660517e-06,
        "epoch": 27.85977859778598,
        "step": 7550
    },
    {
        "loss": 0.2174,
        "grad_norm": 4.186381816864014,
        "learning_rate": 9.07749077490775e-06,
        "epoch": 27.89667896678967,
        "step": 7560
    },
    {
        "loss": 0.1819,
        "grad_norm": 39.539100646972656,
        "learning_rate": 9.049815498154983e-06,
        "epoch": 27.933579335793358,
        "step": 7570
    },
    {
        "loss": 0.2397,
        "grad_norm": 5.8834686279296875,
        "learning_rate": 9.022140221402214e-06,
        "epoch": 27.970479704797047,
        "step": 7580
    },
    {
        "eval_loss": 0.6145679354667664,
        "eval_accuracy": 0.86162,
        "eval_precision": 0.83826,
        "eval_recall": 0.89425,
        "eval_f1": 0.86535,
        "eval_runtime": 18.189,
        "eval_samples_per_second": 59.597,
        "eval_steps_per_second": 3.739,
        "epoch": 28.0,
        "step": 7588
    },
    {
        "train_runtime": 6531.7973,
        "train_samples_per_second": 26.547,
        "train_steps_per_second": 1.66,
        "total_flos": 1.59682099497984e+16,
        "train_loss": 0.27221331474777266,
        "epoch": 28.0,
        "step": 7588
    }
]