[
    {
        "loss": 0.61,
        "grad_norm": 6.274586200714111,
        "learning_rate": 4.973642593568793e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.5084,
        "grad_norm": 7.277749061584473,
        "learning_rate": 4.947285187137586e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.4766,
        "grad_norm": 11.92335033416748,
        "learning_rate": 4.920927780706379e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.5456,
        "grad_norm": 2.0996227264404297,
        "learning_rate": 4.8945703742751715e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.487,
        "grad_norm": 2.0251693725585938,
        "learning_rate": 4.8682129678439644e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.4525,
        "grad_norm": 2.5672309398651123,
        "learning_rate": 4.841855561412757e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.5071,
        "grad_norm": 5.572989463806152,
        "learning_rate": 4.81549815498155e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.4645,
        "grad_norm": 8.204435348510742,
        "learning_rate": 4.789140748550343e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.4483,
        "grad_norm": 2.3900251388549805,
        "learning_rate": 4.7627833421191357e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.6208,
        "grad_norm": 6.20745849609375,
        "learning_rate": 4.7364259356879285e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.4249,
        "grad_norm": 1.9745551347732544,
        "learning_rate": 4.710068529256721e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.546,
        "grad_norm": 5.953708648681641,
        "learning_rate": 4.683711122825514e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4935,
        "grad_norm": 2.0102124214172363,
        "learning_rate": 4.657353716394307e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.5093,
        "grad_norm": 2.6025538444519043,
        "learning_rate": 4.6309963099631e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4355,
        "grad_norm": 6.000792026519775,
        "learning_rate": 4.6046389035318926e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.4267,
        "grad_norm": 5.425731182098389,
        "learning_rate": 4.5782814971006854e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.3651,
        "grad_norm": 1.8216900825500488,
        "learning_rate": 4.551924090669478e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.5649,
        "grad_norm": 1.9439265727996826,
        "learning_rate": 4.525566684238271e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4642,
        "grad_norm": 3.1094164848327637,
        "learning_rate": 4.499209277807064e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4653,
        "grad_norm": 3.1938467025756836,
        "learning_rate": 4.472851871375857e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.4932,
        "grad_norm": 5.842198848724365,
        "learning_rate": 4.4464944649446495e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4825,
        "grad_norm": 5.385126113891602,
        "learning_rate": 4.420137058513443e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.4238,
        "grad_norm": 3.400125026702881,
        "learning_rate": 4.393779652082235e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.4551,
        "grad_norm": 6.377236366271973,
        "learning_rate": 4.367422245651028e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.5024,
        "grad_norm": 2.5457992553710938,
        "learning_rate": 4.341064839219821e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4936,
        "grad_norm": 2.587066888809204,
        "learning_rate": 4.3147074327886137e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4072,
        "grad_norm": 3.900178909301758,
        "learning_rate": 4.2883500263574065e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.4932745397090912,
        "eval_accuracy": 0.80258,
        "eval_precision": 0.76683,
        "eval_recall": 0.86642,
        "eval_f1": 0.81359,
        "eval_runtime": 18.1314,
        "eval_samples_per_second": 59.786,
        "eval_steps_per_second": 3.75,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.561,
        "grad_norm": 3.5167644023895264,
        "learning_rate": 4.261992619926199e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4433,
        "grad_norm": 5.508460998535156,
        "learning_rate": 4.235635213494992e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.3783,
        "grad_norm": 1.3059511184692383,
        "learning_rate": 4.209277807063785e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.4715,
        "grad_norm": 3.9523956775665283,
        "learning_rate": 4.182920400632578e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.4166,
        "grad_norm": 2.4569852352142334,
        "learning_rate": 4.1565629942013706e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4716,
        "grad_norm": 8.941179275512695,
        "learning_rate": 4.1302055877701634e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.5431,
        "grad_norm": 14.548151969909668,
        "learning_rate": 4.103848181338956e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4862,
        "grad_norm": 2.8851633071899414,
        "learning_rate": 4.077490774907749e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4704,
        "grad_norm": 4.028162479400635,
        "learning_rate": 4.0511333684765426e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.6113,
        "grad_norm": 4.176361560821533,
        "learning_rate": 4.0247759620453354e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4401,
        "grad_norm": 3.056793451309204,
        "learning_rate": 3.998418555614128e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4238,
        "grad_norm": 2.852764129638672,
        "learning_rate": 3.972061149182921e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.4693,
        "grad_norm": 5.568854808807373,
        "learning_rate": 3.945703742751713e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.4044,
        "grad_norm": 1.5947593450546265,
        "learning_rate": 3.919346336320506e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.4562,
        "grad_norm": 2.237107753753662,
        "learning_rate": 3.892988929889299e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.3881,
        "grad_norm": 3.740887403488159,
        "learning_rate": 3.866631523458092e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.5161,
        "grad_norm": 1.9943368434906006,
        "learning_rate": 3.8402741170268845e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.4305,
        "grad_norm": 1.4263395071029663,
        "learning_rate": 3.813916710595677e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.4242,
        "grad_norm": 3.838932514190674,
        "learning_rate": 3.78755930416447e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.3849,
        "grad_norm": 4.014902114868164,
        "learning_rate": 3.761201897733263e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.3826,
        "grad_norm": 1.952541470527649,
        "learning_rate": 3.734844491302056e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4551,
        "grad_norm": 2.4026927947998047,
        "learning_rate": 3.7084870848708486e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.4336,
        "grad_norm": 2.5482113361358643,
        "learning_rate": 3.682129678439642e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.4046,
        "grad_norm": 3.9260082244873047,
        "learning_rate": 3.655772272008435e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.3537,
        "grad_norm": 1.1578516960144043,
        "learning_rate": 3.629414865577228e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.4004,
        "grad_norm": 2.9374752044677734,
        "learning_rate": 3.6030574591460206e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.327,
        "grad_norm": 4.654502868652344,
        "learning_rate": 3.5767000527148134e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.46649229526519775,
        "eval_accuracy": 0.8155,
        "eval_precision": 0.75261,
        "eval_recall": 0.93692,
        "eval_f1": 0.83471,
        "eval_runtime": 18.1133,
        "eval_samples_per_second": 59.846,
        "eval_steps_per_second": 3.754,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.3442,
        "grad_norm": 1.738889455795288,
        "learning_rate": 3.550342646283606e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4003,
        "grad_norm": 2.027024030685425,
        "learning_rate": 3.5239852398523984e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.3215,
        "grad_norm": 1.1972455978393555,
        "learning_rate": 3.497627833421191e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3708,
        "grad_norm": 2.1769843101501465,
        "learning_rate": 3.471270426989984e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.3924,
        "grad_norm": 2.473616600036621,
        "learning_rate": 3.444913020558777e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.4418,
        "grad_norm": 1.5717895030975342,
        "learning_rate": 3.41855561412757e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.3641,
        "grad_norm": 1.9319332838058472,
        "learning_rate": 3.3921982076963625e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4055,
        "grad_norm": 1.9416309595108032,
        "learning_rate": 3.365840801265155e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.4765,
        "grad_norm": 2.9123330116271973,
        "learning_rate": 3.339483394833948e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3527,
        "grad_norm": 2.9971938133239746,
        "learning_rate": 3.3131259884027416e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.5554,
        "grad_norm": 3.0884618759155273,
        "learning_rate": 3.2867685819715345e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.4246,
        "grad_norm": 1.6370413303375244,
        "learning_rate": 3.260411175540327e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.4028,
        "grad_norm": 4.8665642738342285,
        "learning_rate": 3.23405376910912e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.4075,
        "grad_norm": 4.117330074310303,
        "learning_rate": 3.207696362677913e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.401,
        "grad_norm": 3.040818929672241,
        "learning_rate": 3.181338956246706e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.4101,
        "grad_norm": 1.8385175466537476,
        "learning_rate": 3.1549815498154986e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3516,
        "grad_norm": 1.6596546173095703,
        "learning_rate": 3.1286241433842914e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.3927,
        "grad_norm": 1.7942415475845337,
        "learning_rate": 3.102266736953084e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3085,
        "grad_norm": 2.236116886138916,
        "learning_rate": 3.0759093305218764e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4205,
        "grad_norm": 2.069218158721924,
        "learning_rate": 3.0495519240906695e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3785,
        "grad_norm": 1.2215049266815186,
        "learning_rate": 3.0231945176594624e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4198,
        "grad_norm": 4.059845924377441,
        "learning_rate": 2.9968371112282552e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4218,
        "grad_norm": 2.0345144271850586,
        "learning_rate": 2.970479704797048e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.4402,
        "grad_norm": 3.054651975631714,
        "learning_rate": 2.9441222983658412e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.3823,
        "grad_norm": 1.589160680770874,
        "learning_rate": 2.917764891934634e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3446,
        "grad_norm": 3.6403582096099854,
        "learning_rate": 2.8914074855034268e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.4441,
        "grad_norm": 5.183603763580322,
        "learning_rate": 2.8650500790722196e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.41094666719436646,
        "eval_accuracy": 0.82565,
        "eval_precision": 0.78226,
        "eval_recall": 0.89981,
        "eval_f1": 0.83693,
        "eval_runtime": 18.1244,
        "eval_samples_per_second": 59.809,
        "eval_steps_per_second": 3.752,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3993,
        "grad_norm": 2.6799263954162598,
        "learning_rate": 2.8386926726410125e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3767,
        "grad_norm": 3.9296207427978516,
        "learning_rate": 2.8123352662098053e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.357,
        "grad_norm": 41.0802001953125,
        "learning_rate": 2.7859778597785978e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.3219,
        "grad_norm": 5.338254928588867,
        "learning_rate": 2.7596204533473906e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.4884,
        "grad_norm": 1.6072583198547363,
        "learning_rate": 2.7332630469161834e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.4272,
        "grad_norm": 1.0970573425292969,
        "learning_rate": 2.7069056404849762e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.4092,
        "grad_norm": 2.156278610229492,
        "learning_rate": 2.680548234053769e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3725,
        "grad_norm": 5.352795600891113,
        "learning_rate": 2.654190827622562e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.4733,
        "grad_norm": 1.17262601852417,
        "learning_rate": 2.6278334211913547e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3339,
        "grad_norm": 1.6193755865097046,
        "learning_rate": 2.6014760147601475e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.365,
        "grad_norm": 3.337747573852539,
        "learning_rate": 2.5751186083289407e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.362,
        "grad_norm": 4.866344928741455,
        "learning_rate": 2.5487612018977335e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.4857,
        "grad_norm": 7.541882038116455,
        "learning_rate": 2.5224037954665264e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.33,
        "grad_norm": 2.1866393089294434,
        "learning_rate": 2.4960463890353192e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.3725,
        "grad_norm": 2.2039670944213867,
        "learning_rate": 2.469688982604112e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.3945,
        "grad_norm": 2.03450608253479,
        "learning_rate": 2.4433315761729048e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3516,
        "grad_norm": 2.4916558265686035,
        "learning_rate": 2.4169741697416977e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.3325,
        "grad_norm": 3.4529972076416016,
        "learning_rate": 2.3906167633104905e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.436,
        "grad_norm": 12.855117797851562,
        "learning_rate": 2.364259356879283e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.5298,
        "grad_norm": 3.1429193019866943,
        "learning_rate": 2.3379019504480758e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.3668,
        "grad_norm": 5.695494174957275,
        "learning_rate": 2.311544544016869e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.3909,
        "grad_norm": 3.068378448486328,
        "learning_rate": 2.2851871375856618e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3635,
        "grad_norm": 1.6007367372512817,
        "learning_rate": 2.2588297311544546e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3528,
        "grad_norm": 1.3231654167175293,
        "learning_rate": 2.2324723247232474e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.4685,
        "grad_norm": 2.373298406600952,
        "learning_rate": 2.2061149182920402e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.382,
        "grad_norm": 1.103988528251648,
        "learning_rate": 2.179757511860833e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.3316,
        "grad_norm": 198.3319549560547,
        "learning_rate": 2.153400105429626e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.43076062202453613,
        "eval_accuracy": 0.82472,
        "eval_precision": 0.79035,
        "eval_recall": 0.88126,
        "eval_f1": 0.83333,
        "eval_runtime": 18.1027,
        "eval_samples_per_second": 59.881,
        "eval_steps_per_second": 3.756,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3804,
        "grad_norm": 2.3739285469055176,
        "learning_rate": 2.1270426989984187e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.3868,
        "grad_norm": 3.799753427505493,
        "learning_rate": 2.1006852925672115e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.3717,
        "grad_norm": 1.009700894355774,
        "learning_rate": 2.0743278861360044e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3993,
        "grad_norm": 69.29008483886719,
        "learning_rate": 2.0479704797047972e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3012,
        "grad_norm": 3.5764989852905273,
        "learning_rate": 2.02161307327359e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.4323,
        "grad_norm": 4.628688335418701,
        "learning_rate": 1.995255666842383e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3379,
        "grad_norm": 3.8106584548950195,
        "learning_rate": 1.9688982604111757e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3845,
        "grad_norm": 1.9880874156951904,
        "learning_rate": 1.9425408539799685e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.3701,
        "grad_norm": 13.033459663391113,
        "learning_rate": 1.9161834475487613e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.3504,
        "grad_norm": 1.9555987119674683,
        "learning_rate": 1.889826041117554e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.386,
        "grad_norm": 2.2177608013153076,
        "learning_rate": 1.863468634686347e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3919,
        "grad_norm": 6.714359760284424,
        "learning_rate": 1.8371112282551398e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.3706,
        "grad_norm": 3.999945878982544,
        "learning_rate": 1.8107538218239326e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.2938,
        "grad_norm": 2.160187244415283,
        "learning_rate": 1.7843964153927254e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3737,
        "grad_norm": 5.675056457519531,
        "learning_rate": 1.7580390089615182e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3389,
        "grad_norm": 2.9946329593658447,
        "learning_rate": 1.731681602530311e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3876,
        "grad_norm": 3.2689261436462402,
        "learning_rate": 1.705324196099104e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.3114,
        "grad_norm": 4.673147678375244,
        "learning_rate": 1.6789667896678967e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3722,
        "grad_norm": 7.823425769805908,
        "learning_rate": 1.6526093832366895e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.2587,
        "grad_norm": 1.5680018663406372,
        "learning_rate": 1.6262519768054824e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.3586,
        "grad_norm": 1.3209666013717651,
        "learning_rate": 1.5998945703742752e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.4208,
        "grad_norm": 4.7563862800598145,
        "learning_rate": 1.5735371639430684e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.3574,
        "grad_norm": 5.767336845397949,
        "learning_rate": 1.5471797575118612e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.4552,
        "grad_norm": 4.872586250305176,
        "learning_rate": 1.5208223510806538e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.3828,
        "grad_norm": 5.107255458831787,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.4333,
        "grad_norm": 5.738772392272949,
        "learning_rate": 1.4681075382182393e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.383,
        "grad_norm": 5.608090877532959,
        "learning_rate": 1.4417501317870321e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.4266620874404907,
        "eval_accuracy": 0.82934,
        "eval_precision": 0.81162,
        "eval_recall": 0.85529,
        "eval_f1": 0.83288,
        "eval_runtime": 18.1346,
        "eval_samples_per_second": 59.775,
        "eval_steps_per_second": 3.75,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "train_runtime": 1198.5029,
        "train_samples_per_second": 25.319,
        "train_steps_per_second": 1.583,
        "total_flos": 2851466062464000.0,
        "train_loss": 0.4174800760191745,
        "epoch": 5.0,
        "step": 1355
    }
]