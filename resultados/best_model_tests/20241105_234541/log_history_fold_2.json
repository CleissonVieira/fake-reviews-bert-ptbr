[
    {
        "loss": 0.6314,
        "grad_norm": 5.845015525817871,
        "learning_rate": 2.4976937269372695e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.4199,
        "grad_norm": 10.630619049072266,
        "learning_rate": 2.495387453874539e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.4898,
        "grad_norm": 3.4148497581481934,
        "learning_rate": 2.493081180811808e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.4339,
        "grad_norm": 4.382755279541016,
        "learning_rate": 2.4907749077490778e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.5128,
        "grad_norm": 4.929605960845947,
        "learning_rate": 2.488468634686347e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.4706,
        "grad_norm": 3.6586897373199463,
        "learning_rate": 2.4861623616236163e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.4243,
        "grad_norm": 7.871331691741943,
        "learning_rate": 2.4838560885608857e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.4211,
        "grad_norm": 6.049236297607422,
        "learning_rate": 2.481549815498155e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.4223,
        "grad_norm": 3.3005447387695312,
        "learning_rate": 2.4792435424354242e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.4595,
        "grad_norm": 7.134620189666748,
        "learning_rate": 2.476937269372694e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.5228,
        "grad_norm": 3.0173065662384033,
        "learning_rate": 2.474630996309963e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4983,
        "grad_norm": 2.8346927165985107,
        "learning_rate": 2.472324723247233e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4508,
        "grad_norm": 2.045344591140747,
        "learning_rate": 2.470018450184502e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4371,
        "grad_norm": 4.938347816467285,
        "learning_rate": 2.4677121771217714e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4543,
        "grad_norm": 3.602731704711914,
        "learning_rate": 2.4654059040590408e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.519,
        "grad_norm": 3.1813135147094727,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.487,
        "grad_norm": 8.31003189086914,
        "learning_rate": 2.4607933579335796e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.5475,
        "grad_norm": 4.59902811050415,
        "learning_rate": 2.4584870848708487e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4808,
        "grad_norm": 3.7313807010650635,
        "learning_rate": 2.456180811808118e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.3936,
        "grad_norm": 4.969388484954834,
        "learning_rate": 2.4538745387453876e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.4954,
        "grad_norm": 2.6498963832855225,
        "learning_rate": 2.451568265682657e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4614,
        "grad_norm": 2.927858591079712,
        "learning_rate": 2.4492619926199264e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.416,
        "grad_norm": 3.5683541297912598,
        "learning_rate": 2.4469557195571958e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.4048,
        "grad_norm": 2.135993003845215,
        "learning_rate": 2.444649446494465e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.5136,
        "grad_norm": 9.540653228759766,
        "learning_rate": 2.4423431734317347e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4683,
        "grad_norm": 2.6594955921173096,
        "learning_rate": 2.4400369003690038e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4274,
        "grad_norm": 2.0948426723480225,
        "learning_rate": 2.4377306273062732e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.4376186728477478,
        "eval_accuracy": 0.81181,
        "eval_precision": 0.75576,
        "eval_recall": 0.9162,
        "eval_f1": 0.82828,
        "eval_runtime": 18.0912,
        "eval_samples_per_second": 59.919,
        "eval_steps_per_second": 3.759,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.372,
        "grad_norm": 5.540531158447266,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4282,
        "grad_norm": 2.9800477027893066,
        "learning_rate": 2.4331180811808117e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.4044,
        "grad_norm": 3.7898123264312744,
        "learning_rate": 2.4308118081180815e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.4276,
        "grad_norm": 3.722935676574707,
        "learning_rate": 2.4285055350553505e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.4578,
        "grad_norm": 2.202345132827759,
        "learning_rate": 2.42619926199262e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4935,
        "grad_norm": 5.723567962646484,
        "learning_rate": 2.4238929889298894e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.3977,
        "grad_norm": 7.725208759307861,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4585,
        "grad_norm": 2.869396209716797,
        "learning_rate": 2.4192804428044282e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.5078,
        "grad_norm": 4.549102306365967,
        "learning_rate": 2.4169741697416977e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.4078,
        "grad_norm": 6.043166637420654,
        "learning_rate": 2.4146678966789667e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4758,
        "grad_norm": 2.597416400909424,
        "learning_rate": 2.4123616236162365e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4413,
        "grad_norm": 2.0829639434814453,
        "learning_rate": 2.4100553505535056e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.4635,
        "grad_norm": 1.8172121047973633,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.4552,
        "grad_norm": 2.9638140201568604,
        "learning_rate": 2.4054428044280444e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3242,
        "grad_norm": 4.437014579772949,
        "learning_rate": 2.403136531365314e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.5523,
        "grad_norm": 10.090919494628906,
        "learning_rate": 2.4008302583025833e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.4073,
        "grad_norm": 4.249499320983887,
        "learning_rate": 2.3985239852398524e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.4269,
        "grad_norm": 3.2657694816589355,
        "learning_rate": 2.3962177121771218e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.4617,
        "grad_norm": 5.478524208068848,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.4119,
        "grad_norm": 6.7446746826171875,
        "learning_rate": 2.3916051660516606e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.4848,
        "grad_norm": 3.2076339721679688,
        "learning_rate": 2.38929889298893e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.3963,
        "grad_norm": 3.9838249683380127,
        "learning_rate": 2.3869926199261995e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.365,
        "grad_norm": 7.8985514640808105,
        "learning_rate": 2.3846863468634686e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.4084,
        "grad_norm": 5.931761741638184,
        "learning_rate": 2.3823800738007383e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.3803,
        "grad_norm": 8.309242248535156,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.3476,
        "grad_norm": 6.7273640632629395,
        "learning_rate": 2.377767527675277e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.3981,
        "grad_norm": 3.0229146480560303,
        "learning_rate": 2.3754612546125462e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.43010228872299194,
        "eval_accuracy": 0.81827,
        "eval_precision": 0.76154,
        "eval_recall": 0.92179,
        "eval_f1": 0.83404,
        "eval_runtime": 18.1352,
        "eval_samples_per_second": 59.773,
        "eval_steps_per_second": 3.75,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.409,
        "grad_norm": 4.1113667488098145,
        "learning_rate": 2.3731549815498157e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4215,
        "grad_norm": 6.9015302658081055,
        "learning_rate": 2.370848708487085e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.2907,
        "grad_norm": 3.514317512512207,
        "learning_rate": 2.3685424354243542e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3483,
        "grad_norm": 5.721812725067139,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.4652,
        "grad_norm": 2.9499266147613525,
        "learning_rate": 2.363929889298893e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.3653,
        "grad_norm": 3.1691396236419678,
        "learning_rate": 2.3616236162361624e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.375,
        "grad_norm": 7.34479284286499,
        "learning_rate": 2.359317343173432e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4086,
        "grad_norm": 4.097279071807861,
        "learning_rate": 2.3570110701107013e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.3533,
        "grad_norm": 5.935354709625244,
        "learning_rate": 2.3547047970479704e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.536,
        "grad_norm": 9.040438652038574,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.3794,
        "grad_norm": 4.992922306060791,
        "learning_rate": 2.3500922509225092e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.3468,
        "grad_norm": 2.802394151687622,
        "learning_rate": 2.347785977859779e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3671,
        "grad_norm": 2.7873175144195557,
        "learning_rate": 2.345479704797048e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.3739,
        "grad_norm": 2.8420584201812744,
        "learning_rate": 2.3431734317343175e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.377,
        "grad_norm": 4.478791236877441,
        "learning_rate": 2.340867158671587e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.358,
        "grad_norm": 6.046357154846191,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3433,
        "grad_norm": 4.414535045623779,
        "learning_rate": 2.3362546125461258e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.4049,
        "grad_norm": 7.4653425216674805,
        "learning_rate": 2.333948339483395e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3641,
        "grad_norm": 12.680713653564453,
        "learning_rate": 2.3316420664206643e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4317,
        "grad_norm": 5.222296714782715,
        "learning_rate": 2.3293357933579337e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3686,
        "grad_norm": 6.0933942794799805,
        "learning_rate": 2.327029520295203e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4077,
        "grad_norm": 5.257615089416504,
        "learning_rate": 2.3247232472324722e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.2871,
        "grad_norm": 2.4993247985839844,
        "learning_rate": 2.322416974169742e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.3547,
        "grad_norm": 10.702228546142578,
        "learning_rate": 2.320110701107011e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.5323,
        "grad_norm": 11.992000579833984,
        "learning_rate": 2.3178044280442808e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3996,
        "grad_norm": 3.9908955097198486,
        "learning_rate": 2.31549815498155e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.4096,
        "grad_norm": 5.360260963439941,
        "learning_rate": 2.3131918819188193e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.4037761688232422,
        "eval_accuracy": 0.84041,
        "eval_precision": 0.80033,
        "eval_recall": 0.90317,
        "eval_f1": 0.84864,
        "eval_runtime": 18.1268,
        "eval_samples_per_second": 59.801,
        "eval_steps_per_second": 3.751,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3351,
        "grad_norm": 2.6368894577026367,
        "learning_rate": 2.3108856088560887e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3433,
        "grad_norm": 3.112989902496338,
        "learning_rate": 2.308579335793358e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.4152,
        "grad_norm": 5.81028938293457,
        "learning_rate": 2.3062730627306276e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.36,
        "grad_norm": 3.9117817878723145,
        "learning_rate": 2.3039667896678967e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.3495,
        "grad_norm": 3.5776329040527344,
        "learning_rate": 2.301660516605166e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.3505,
        "grad_norm": 4.533716678619385,
        "learning_rate": 2.2993542435424355e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3255,
        "grad_norm": 10.854596138000488,
        "learning_rate": 2.297047970479705e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3169,
        "grad_norm": 6.78617525100708,
        "learning_rate": 2.294741697416974e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.342,
        "grad_norm": 4.584868907928467,
        "learning_rate": 2.2924354243542438e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3393,
        "grad_norm": 6.517043590545654,
        "learning_rate": 2.290129151291513e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.4292,
        "grad_norm": 17.44111442565918,
        "learning_rate": 2.2878228782287826e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.3349,
        "grad_norm": 6.458372116088867,
        "learning_rate": 2.2855166051660517e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.299,
        "grad_norm": 10.405187606811523,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.3251,
        "grad_norm": 13.930404663085938,
        "learning_rate": 2.2809040590405906e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.379,
        "grad_norm": 2.4576687812805176,
        "learning_rate": 2.27859778597786e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.3093,
        "grad_norm": 3.8450515270233154,
        "learning_rate": 2.2762915129151294e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3017,
        "grad_norm": 25.429046630859375,
        "learning_rate": 2.2739852398523985e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.3383,
        "grad_norm": 4.361788749694824,
        "learning_rate": 2.271678966789668e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.3267,
        "grad_norm": 8.020181655883789,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.3416,
        "grad_norm": 5.631343841552734,
        "learning_rate": 2.2670664206642068e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.2948,
        "grad_norm": 4.349775791168213,
        "learning_rate": 2.2647601476014762e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.3392,
        "grad_norm": 4.166764259338379,
        "learning_rate": 2.2624538745387456e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.2319,
        "grad_norm": 1.9223347902297974,
        "learning_rate": 2.2601476014760147e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3254,
        "grad_norm": 3.0003774166107178,
        "learning_rate": 2.2578413284132844e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.4401,
        "grad_norm": 4.162355422973633,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.3737,
        "grad_norm": 6.332601547241211,
        "learning_rate": 2.253228782287823e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.299,
        "grad_norm": 5.204389572143555,
        "learning_rate": 2.2509225092250924e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.42324113845825195,
        "eval_accuracy": 0.83672,
        "eval_precision": 0.79126,
        "eval_recall": 0.91061,
        "eval_f1": 0.84675,
        "eval_runtime": 18.1132,
        "eval_samples_per_second": 59.846,
        "eval_steps_per_second": 3.754,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.303,
        "grad_norm": 8.918360710144043,
        "learning_rate": 2.2486162361623618e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.2816,
        "grad_norm": 3.7869622707366943,
        "learning_rate": 2.2463099630996312e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.2515,
        "grad_norm": 10.628435134887695,
        "learning_rate": 2.2440036900369006e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3119,
        "grad_norm": 6.967691421508789,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3027,
        "grad_norm": 5.828381538391113,
        "learning_rate": 2.239391143911439e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3362,
        "grad_norm": 11.238408088684082,
        "learning_rate": 2.2370848708487086e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3092,
        "grad_norm": 2.7951769828796387,
        "learning_rate": 2.234778597785978e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.2118,
        "grad_norm": 9.424819946289062,
        "learning_rate": 2.2324723247232474e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.3341,
        "grad_norm": 7.502833843231201,
        "learning_rate": 2.2301660516605165e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.2319,
        "grad_norm": 3.5978846549987793,
        "learning_rate": 2.2278597785977863e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.2473,
        "grad_norm": 14.058866500854492,
        "learning_rate": 2.2255535055350553e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.2861,
        "grad_norm": 4.6123833656311035,
        "learning_rate": 2.2232472324723248e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.2689,
        "grad_norm": 7.861917972564697,
        "learning_rate": 2.2209409594095942e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.2496,
        "grad_norm": 6.4015889167785645,
        "learning_rate": 2.2186346863468636e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3077,
        "grad_norm": 16.069318771362305,
        "learning_rate": 2.216328413284133e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.2507,
        "grad_norm": 5.701291084289551,
        "learning_rate": 2.2140221402214025e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3065,
        "grad_norm": 2.7971324920654297,
        "learning_rate": 2.2117158671586715e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.2329,
        "grad_norm": 3.0953848361968994,
        "learning_rate": 2.209409594095941e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.2668,
        "grad_norm": 40.03097152709961,
        "learning_rate": 2.2071033210332104e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.2354,
        "grad_norm": 12.133279800415039,
        "learning_rate": 2.2047970479704798e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.3144,
        "grad_norm": 2.966953992843628,
        "learning_rate": 2.2024907749077492e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.3191,
        "grad_norm": 11.188868522644043,
        "learning_rate": 2.2001845018450183e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.2755,
        "grad_norm": 8.026121139526367,
        "learning_rate": 2.197878228782288e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.2032,
        "grad_norm": 34.89333724975586,
        "learning_rate": 2.195571955719557e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.3238,
        "grad_norm": 4.672670364379883,
        "learning_rate": 2.193265682656827e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.4131,
        "grad_norm": 9.990133285522461,
        "learning_rate": 2.190959409594096e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.2533,
        "grad_norm": 1.3004999160766602,
        "learning_rate": 2.1886531365313654e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.5121100544929504,
        "eval_accuracy": 0.82011,
        "eval_precision": 0.75753,
        "eval_recall": 0.93669,
        "eval_f1": 0.83764,
        "eval_runtime": 18.1219,
        "eval_samples_per_second": 59.817,
        "eval_steps_per_second": 3.752,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.4038,
        "grad_norm": 4.037266731262207,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.2825,
        "grad_norm": 3.613227605819702,
        "learning_rate": 2.1840405904059043e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.2068,
        "grad_norm": 6.301301956176758,
        "learning_rate": 2.1817343173431734e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.2344,
        "grad_norm": 5.049943923950195,
        "learning_rate": 2.1794280442804428e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.2213,
        "grad_norm": 37.97258758544922,
        "learning_rate": 2.1771217712177122e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.1781,
        "grad_norm": 5.106072425842285,
        "learning_rate": 2.1748154981549816e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.2245,
        "grad_norm": 2.9697511196136475,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.2345,
        "grad_norm": 8.127513885498047,
        "learning_rate": 2.17020295202952e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.1603,
        "grad_norm": 4.665152072906494,
        "learning_rate": 2.16789667896679e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.2317,
        "grad_norm": 8.190689086914062,
        "learning_rate": 2.165590405904059e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.2805,
        "grad_norm": 7.021922588348389,
        "learning_rate": 2.1632841328413287e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.3098,
        "grad_norm": 14.80813980102539,
        "learning_rate": 2.160977859778598e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.1477,
        "grad_norm": 11.967166900634766,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.2505,
        "grad_norm": 7.365329265594482,
        "learning_rate": 2.1563653136531367e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.291,
        "grad_norm": 8.467886924743652,
        "learning_rate": 2.154059040590406e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.2644,
        "grad_norm": 4.634714126586914,
        "learning_rate": 2.1517527675276755e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.1833,
        "grad_norm": 2.40879225730896,
        "learning_rate": 2.149446494464945e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.1888,
        "grad_norm": 13.204093933105469,
        "learning_rate": 2.147140221402214e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.246,
        "grad_norm": 6.785320281982422,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.1883,
        "grad_norm": 21.528202056884766,
        "learning_rate": 2.142527675276753e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.2221,
        "grad_norm": 13.078006744384766,
        "learning_rate": 2.140221402214022e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.2202,
        "grad_norm": 3.37192964553833,
        "learning_rate": 2.1379151291512917e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.2634,
        "grad_norm": 5.014240741729736,
        "learning_rate": 2.1356088560885608e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.2898,
        "grad_norm": 10.296852111816406,
        "learning_rate": 2.1333025830258306e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.2651,
        "grad_norm": 3.1943047046661377,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.1894,
        "grad_norm": 7.790002346038818,
        "learning_rate": 2.128690036900369e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.2475,
        "grad_norm": 12.671585083007812,
        "learning_rate": 2.1263837638376385e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.5298746824264526,
        "eval_accuracy": 0.83856,
        "eval_precision": 0.81866,
        "eval_recall": 0.86592,
        "eval_f1": 0.84163,
        "eval_runtime": 18.1328,
        "eval_samples_per_second": 59.781,
        "eval_steps_per_second": 3.75,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.1741,
        "grad_norm": 0.7886961102485657,
        "learning_rate": 2.124077490774908e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.1745,
        "grad_norm": 2.9311606884002686,
        "learning_rate": 2.1217712177121773e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.1382,
        "grad_norm": 0.9461497068405151,
        "learning_rate": 2.1194649446494468e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.1469,
        "grad_norm": 3.3883230686187744,
        "learning_rate": 2.117158671586716e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.2913,
        "grad_norm": 33.218971252441406,
        "learning_rate": 2.1148523985239853e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.1417,
        "grad_norm": 4.119868278503418,
        "learning_rate": 2.1125461254612547e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.1893,
        "grad_norm": 7.522782325744629,
        "learning_rate": 2.110239852398524e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.122,
        "grad_norm": 6.824455261230469,
        "learning_rate": 2.1079335793357935e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3091,
        "grad_norm": 0.5292466878890991,
        "learning_rate": 2.1056273062730626e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.1769,
        "grad_norm": 6.37597131729126,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.2167,
        "grad_norm": 8.087626457214355,
        "learning_rate": 2.1010147601476015e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.1408,
        "grad_norm": 6.665670394897461,
        "learning_rate": 2.098708487084871e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.207,
        "grad_norm": 23.907869338989258,
        "learning_rate": 2.0964022140221403e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.1782,
        "grad_norm": 26.992408752441406,
        "learning_rate": 2.0940959409594097e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.212,
        "grad_norm": 7.0161662101745605,
        "learning_rate": 2.091789667896679e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.2037,
        "grad_norm": 0.8238626718521118,
        "learning_rate": 2.0894833948339486e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.3516,
        "grad_norm": 26.71295738220215,
        "learning_rate": 2.0871771217712177e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.1913,
        "grad_norm": 23.62995147705078,
        "learning_rate": 2.084870848708487e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.1765,
        "grad_norm": 6.225208759307861,
        "learning_rate": 2.0825645756457565e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.0863,
        "grad_norm": 2.859346389770508,
        "learning_rate": 2.080258302583026e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.2168,
        "grad_norm": 1.0254228115081787,
        "learning_rate": 2.0779520295202954e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.2426,
        "grad_norm": 2.222381114959717,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.1108,
        "grad_norm": 20.889673233032227,
        "learning_rate": 2.0733394833948342e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.2121,
        "grad_norm": 2.0861895084381104,
        "learning_rate": 2.0710332103321033e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.2733,
        "grad_norm": 8.42424201965332,
        "learning_rate": 2.0687269372693727e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.1646,
        "grad_norm": 11.981621742248535,
        "learning_rate": 2.066420664206642e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.1509,
        "grad_norm": 52.388694763183594,
        "learning_rate": 2.0641143911439116e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.6996662616729736,
        "eval_accuracy": 0.80627,
        "eval_precision": 0.82249,
        "eval_recall": 0.77654,
        "eval_f1": 0.79885,
        "eval_runtime": 18.1288,
        "eval_samples_per_second": 59.794,
        "eval_steps_per_second": 3.751,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.274,
        "grad_norm": 5.268469333648682,
        "learning_rate": 2.061808118081181e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.1505,
        "grad_norm": 31.698558807373047,
        "learning_rate": 2.0595018450184504e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.1404,
        "grad_norm": 8.710968017578125,
        "learning_rate": 2.0571955719557195e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.1131,
        "grad_norm": 0.3323672413825989,
        "learning_rate": 2.0548892988929893e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.0929,
        "grad_norm": 0.4500986933708191,
        "learning_rate": 2.0525830258302583e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.1798,
        "grad_norm": 21.02170753479004,
        "learning_rate": 2.0502767527675278e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.1302,
        "grad_norm": 10.875628471374512,
        "learning_rate": 2.0479704797047972e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.2118,
        "grad_norm": 23.38511085510254,
        "learning_rate": 2.0456642066420663e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.2668,
        "grad_norm": 48.70564270019531,
        "learning_rate": 2.043357933579336e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.1628,
        "grad_norm": 2.929060935974121,
        "learning_rate": 2.041051660516605e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.1416,
        "grad_norm": 34.252601623535156,
        "learning_rate": 2.0387453874538745e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.2451,
        "grad_norm": 44.678810119628906,
        "learning_rate": 2.036439114391144e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.2129,
        "grad_norm": 33.82863998413086,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.2766,
        "grad_norm": 9.968250274658203,
        "learning_rate": 2.0318265682656828e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.1143,
        "grad_norm": 9.083562850952148,
        "learning_rate": 2.0295202952029522e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.0906,
        "grad_norm": 29.31231689453125,
        "learning_rate": 2.0272140221402213e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.0976,
        "grad_norm": 2.789094924926758,
        "learning_rate": 2.024907749077491e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.1566,
        "grad_norm": 25.337255477905273,
        "learning_rate": 2.02260147601476e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.1552,
        "grad_norm": 17.2689208984375,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.0791,
        "grad_norm": 17.061548233032227,
        "learning_rate": 2.017988929889299e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.1533,
        "grad_norm": 3.4041097164154053,
        "learning_rate": 2.0156826568265684e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.1833,
        "grad_norm": 17.466012954711914,
        "learning_rate": 2.013376383763838e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.1888,
        "grad_norm": 22.873985290527344,
        "learning_rate": 2.011070110701107e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.2802,
        "grad_norm": 3.4424281120300293,
        "learning_rate": 2.0087638376383767e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.3026,
        "grad_norm": 110.14888000488281,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.1286,
        "grad_norm": 23.759469985961914,
        "learning_rate": 2.0041512915129152e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.0991,
        "grad_norm": 28.75419807434082,
        "learning_rate": 2.0018450184501846e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.7312666177749634,
        "eval_accuracy": 0.82011,
        "eval_precision": 0.80866,
        "eval_recall": 0.83426,
        "eval_f1": 0.82126,
        "eval_runtime": 18.1182,
        "eval_samples_per_second": 59.829,
        "eval_steps_per_second": 3.753,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "train_runtime": 1893.6298,
        "train_samples_per_second": 91.57,
        "train_steps_per_second": 5.724,
        "total_flos": 4562345699942400.0,
        "train_loss": 0.3136301093985674,
        "epoch": 8.0,
        "step": 2168
    }
]