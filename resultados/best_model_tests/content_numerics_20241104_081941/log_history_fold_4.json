[
    {
        "loss": 0.701,
        "grad_norm": 2.397801637649536,
        "learning_rate": 2.9841855561412756e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.7132,
        "grad_norm": 3.2635648250579834,
        "learning_rate": 2.9683711122825515e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.7035,
        "grad_norm": 2.271681785583496,
        "learning_rate": 2.952556668423827e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.673,
        "grad_norm": 3.372680902481079,
        "learning_rate": 2.9367422245651026e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.6581,
        "grad_norm": 3.278926372528076,
        "learning_rate": 2.9209277807063785e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.633,
        "grad_norm": 4.8384222984313965,
        "learning_rate": 2.905113336847654e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.6318,
        "grad_norm": 3.2623202800750732,
        "learning_rate": 2.8892988929889297e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.6062,
        "grad_norm": 8.51073169708252,
        "learning_rate": 2.873484449130206e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.6967,
        "grad_norm": 5.905147075653076,
        "learning_rate": 2.8576700052714815e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.6238,
        "grad_norm": 2.798072338104248,
        "learning_rate": 2.841855561412757e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.5529,
        "grad_norm": 4.8771562576293945,
        "learning_rate": 2.826041117554033e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.6476,
        "grad_norm": 2.8884458541870117,
        "learning_rate": 2.8102266736953085e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.6608,
        "grad_norm": 6.160388469696045,
        "learning_rate": 2.794412229836584e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.6844,
        "grad_norm": 6.750842571258545,
        "learning_rate": 2.77859778597786e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.6001,
        "grad_norm": 4.000215530395508,
        "learning_rate": 2.7627833421191355e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.6945,
        "grad_norm": 4.860602855682373,
        "learning_rate": 2.746968898260411e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.5402,
        "grad_norm": 3.9909322261810303,
        "learning_rate": 2.731154454401687e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.5762,
        "grad_norm": 5.3505940437316895,
        "learning_rate": 2.7153400105429625e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.5753,
        "grad_norm": 2.90358829498291,
        "learning_rate": 2.699525566684238e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.588,
        "grad_norm": 4.072284698486328,
        "learning_rate": 2.683711122825514e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.6178,
        "grad_norm": 2.5842747688293457,
        "learning_rate": 2.6678966789667895e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.6328,
        "grad_norm": 4.694674015045166,
        "learning_rate": 2.6520822351080654e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.5206,
        "grad_norm": 3.7333953380584717,
        "learning_rate": 2.6362677912493413e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.6192,
        "grad_norm": 5.397669792175293,
        "learning_rate": 2.620453347390617e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.6413,
        "grad_norm": 4.435149669647217,
        "learning_rate": 2.6046389035318924e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.612,
        "grad_norm": 3.284799098968506,
        "learning_rate": 2.5888244596731683e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.5432,
        "grad_norm": 3.9227793216705322,
        "learning_rate": 2.573010015814444e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.6290143728256226,
        "eval_accuracy": 0.6762,
        "eval_precision": 0.64968,
        "eval_recall": 0.75696,
        "eval_f1": 0.69923,
        "eval_runtime": 26.3231,
        "eval_samples_per_second": 41.181,
        "eval_steps_per_second": 2.583,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.602,
        "grad_norm": 4.822192192077637,
        "learning_rate": 2.5571955719557198e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.5617,
        "grad_norm": 3.54971981048584,
        "learning_rate": 2.5413811280969953e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.5995,
        "grad_norm": 4.1390910148620605,
        "learning_rate": 2.525566684238271e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.6361,
        "grad_norm": 5.299657821655273,
        "learning_rate": 2.5097522403795468e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.5687,
        "grad_norm": 7.029425621032715,
        "learning_rate": 2.4939377965208224e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.5654,
        "grad_norm": 6.978118896484375,
        "learning_rate": 2.478123352662098e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.6125,
        "grad_norm": 4.1609954833984375,
        "learning_rate": 2.4623089088033738e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.5953,
        "grad_norm": 3.5731382369995117,
        "learning_rate": 2.4464944649446494e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.5986,
        "grad_norm": 2.991621971130371,
        "learning_rate": 2.4306800210859253e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.7101,
        "grad_norm": 11.851698875427246,
        "learning_rate": 2.4148655772272012e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.586,
        "grad_norm": 5.6449174880981445,
        "learning_rate": 2.3990511333684767e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.6501,
        "grad_norm": 5.448109149932861,
        "learning_rate": 2.3832366895097523e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.6823,
        "grad_norm": 6.5313191413879395,
        "learning_rate": 2.3674222456510282e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.5898,
        "grad_norm": 4.315659046173096,
        "learning_rate": 2.3516078017923037e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.6554,
        "grad_norm": 16.35128402709961,
        "learning_rate": 2.3357933579335793e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.5802,
        "grad_norm": 5.8912224769592285,
        "learning_rate": 2.3199789140748552e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.6007,
        "grad_norm": 7.224627494812012,
        "learning_rate": 2.3041644702161308e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.6561,
        "grad_norm": 3.8760039806365967,
        "learning_rate": 2.2883500263574063e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.6134,
        "grad_norm": 8.12026309967041,
        "learning_rate": 2.2725355824986822e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.6512,
        "grad_norm": 8.351320266723633,
        "learning_rate": 2.2567211386399578e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.606,
        "grad_norm": 12.308938026428223,
        "learning_rate": 2.2409066947812333e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.6864,
        "grad_norm": 5.114408016204834,
        "learning_rate": 2.2250922509225092e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.6066,
        "grad_norm": 8.014395713806152,
        "learning_rate": 2.209277807063785e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.5871,
        "grad_norm": 7.487675189971924,
        "learning_rate": 2.1934633632050607e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.6086,
        "grad_norm": 15.776066780090332,
        "learning_rate": 2.1776489193463366e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.5767,
        "grad_norm": 5.113239288330078,
        "learning_rate": 2.161834475487612e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.6329,
        "grad_norm": 7.257070064544678,
        "learning_rate": 2.1460200316288877e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.6237689852714539,
        "eval_accuracy": 0.67712,
        "eval_precision": 0.65882,
        "eval_recall": 0.72727,
        "eval_f1": 0.69136,
        "eval_runtime": 24.4167,
        "eval_samples_per_second": 44.396,
        "eval_steps_per_second": 2.785,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.5726,
        "grad_norm": 3.695862054824829,
        "learning_rate": 2.1302055877701636e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.5857,
        "grad_norm": 7.180394649505615,
        "learning_rate": 2.114391143911439e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.5641,
        "grad_norm": 7.737618446350098,
        "learning_rate": 2.0985767000527147e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.5013,
        "grad_norm": 6.225820541381836,
        "learning_rate": 2.0827622561939906e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.5981,
        "grad_norm": 4.757397174835205,
        "learning_rate": 2.0669478123352662e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.5582,
        "grad_norm": 4.449227333068848,
        "learning_rate": 2.0511333684765417e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.538,
        "grad_norm": 8.549386978149414,
        "learning_rate": 2.0353189246178176e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.6203,
        "grad_norm": 4.149876594543457,
        "learning_rate": 2.0195044807590932e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.5664,
        "grad_norm": 3.4657437801361084,
        "learning_rate": 2.0036900369003687e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.5574,
        "grad_norm": 4.043001651763916,
        "learning_rate": 1.987875593041645e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.6047,
        "grad_norm": 3.727205276489258,
        "learning_rate": 1.9720611491829205e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.5983,
        "grad_norm": 3.6061031818389893,
        "learning_rate": 1.956246705324196e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.5491,
        "grad_norm": 3.7145254611968994,
        "learning_rate": 1.940432261465472e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.5092,
        "grad_norm": 3.670741558074951,
        "learning_rate": 1.9246178176067476e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.5485,
        "grad_norm": 4.787632465362549,
        "learning_rate": 1.908803373748023e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.6765,
        "grad_norm": 6.1288838386535645,
        "learning_rate": 1.892988929889299e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.5562,
        "grad_norm": 4.743917465209961,
        "learning_rate": 1.8771744860305746e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.6467,
        "grad_norm": 4.079952716827393,
        "learning_rate": 1.86136004217185e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.576,
        "grad_norm": 3.304542064666748,
        "learning_rate": 1.845545598313126e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.537,
        "grad_norm": 2.7130062580108643,
        "learning_rate": 1.8297311544544016e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.5137,
        "grad_norm": 2.8775112628936768,
        "learning_rate": 1.8139167105956775e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.526,
        "grad_norm": 4.861626625061035,
        "learning_rate": 1.798102266736953e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4897,
        "grad_norm": 6.790828704833984,
        "learning_rate": 1.7822878228782286e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.5767,
        "grad_norm": 5.480065822601318,
        "learning_rate": 1.766473379019505e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.5737,
        "grad_norm": 11.500144004821777,
        "learning_rate": 1.7506589351607804e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.5642,
        "grad_norm": 22.661663055419922,
        "learning_rate": 1.734844491302056e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.5997,
        "grad_norm": 10.551851272583008,
        "learning_rate": 1.719030047443332e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.6587991714477539,
        "eval_accuracy": 0.65683,
        "eval_precision": 0.69464,
        "eval_recall": 0.55288,
        "eval_f1": 0.6157,
        "eval_runtime": 24.8475,
        "eval_samples_per_second": 43.626,
        "eval_steps_per_second": 2.737,
        "epoch": 3.0,
        "step": 813
    },
    {
        "train_runtime": 899.8366,
        "train_samples_per_second": 33.723,
        "train_steps_per_second": 2.108,
        "total_flos": 0.0,
        "train_loss": 0.6032915363159274,
        "epoch": 3.0,
        "step": 813
    }
]