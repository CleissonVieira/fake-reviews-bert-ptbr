[
    {
        "loss": 0.6575,
        "grad_norm": 2.6506283283233643,
        "learning_rate": 2.4976937269372695e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.5722,
        "grad_norm": 4.412035942077637,
        "learning_rate": 2.495387453874539e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.5024,
        "grad_norm": 7.012018203735352,
        "learning_rate": 2.493081180811808e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.4862,
        "grad_norm": 4.551236629486084,
        "learning_rate": 2.4907749077490778e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.4298,
        "grad_norm": 6.80265998840332,
        "learning_rate": 2.488468634686347e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.4245,
        "grad_norm": 9.642316818237305,
        "learning_rate": 2.4861623616236163e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.4937,
        "grad_norm": 5.384204864501953,
        "learning_rate": 2.4838560885608857e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.5057,
        "grad_norm": 3.7535393238067627,
        "learning_rate": 2.481549815498155e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.5249,
        "grad_norm": 8.56156063079834,
        "learning_rate": 2.4792435424354242e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.4729,
        "grad_norm": 3.8630566596984863,
        "learning_rate": 2.476937269372694e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.4325,
        "grad_norm": 4.549981594085693,
        "learning_rate": 2.474630996309963e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4085,
        "grad_norm": 4.972369194030762,
        "learning_rate": 2.472324723247233e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.5039,
        "grad_norm": 8.13399887084961,
        "learning_rate": 2.470018450184502e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4457,
        "grad_norm": 3.4688494205474854,
        "learning_rate": 2.4677121771217714e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.3592,
        "grad_norm": 1.5617393255233765,
        "learning_rate": 2.4654059040590408e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.4683,
        "grad_norm": 1.8864784240722656,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.39,
        "grad_norm": 2.5973095893859863,
        "learning_rate": 2.4607933579335796e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.4137,
        "grad_norm": 4.062540054321289,
        "learning_rate": 2.4584870848708487e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4882,
        "grad_norm": 2.4591422080993652,
        "learning_rate": 2.456180811808118e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4281,
        "grad_norm": 2.0723090171813965,
        "learning_rate": 2.4538745387453876e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.4486,
        "grad_norm": 2.6893727779388428,
        "learning_rate": 2.451568265682657e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4555,
        "grad_norm": 4.691177845001221,
        "learning_rate": 2.4492619926199264e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.5088,
        "grad_norm": 3.806192636489868,
        "learning_rate": 2.4469557195571958e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.5477,
        "grad_norm": 2.9702084064483643,
        "learning_rate": 2.444649446494465e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.3669,
        "grad_norm": 2.946065902709961,
        "learning_rate": 2.4423431734317347e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.375,
        "grad_norm": 3.6851258277893066,
        "learning_rate": 2.4400369003690038e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.5014,
        "grad_norm": 4.223833084106445,
        "learning_rate": 2.4377306273062732e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.4368290603160858,
        "eval_accuracy": 0.79428,
        "eval_precision": 0.87799,
        "eval_recall": 0.68089,
        "eval_f1": 0.76698,
        "eval_runtime": 18.1221,
        "eval_samples_per_second": 59.817,
        "eval_steps_per_second": 3.752,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.4787,
        "grad_norm": 3.5482559204101562,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4136,
        "grad_norm": 2.9210803508758545,
        "learning_rate": 2.4331180811808117e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.4478,
        "grad_norm": 4.683044910430908,
        "learning_rate": 2.4308118081180815e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.4425,
        "grad_norm": 2.99436616897583,
        "learning_rate": 2.4285055350553505e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.4258,
        "grad_norm": 3.890023708343506,
        "learning_rate": 2.42619926199262e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4836,
        "grad_norm": 6.5067057609558105,
        "learning_rate": 2.4238929889298894e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.4611,
        "grad_norm": 4.769170761108398,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4296,
        "grad_norm": 4.2607221603393555,
        "learning_rate": 2.4192804428044282e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4308,
        "grad_norm": 5.32336950302124,
        "learning_rate": 2.4169741697416977e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.3851,
        "grad_norm": 4.536598205566406,
        "learning_rate": 2.4146678966789667e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4089,
        "grad_norm": 7.3208184242248535,
        "learning_rate": 2.4123616236162365e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4742,
        "grad_norm": 7.698795795440674,
        "learning_rate": 2.4100553505535056e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.4133,
        "grad_norm": 2.1942672729492188,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.3974,
        "grad_norm": 2.898685932159424,
        "learning_rate": 2.4054428044280444e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3592,
        "grad_norm": 7.055138111114502,
        "learning_rate": 2.403136531365314e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.4137,
        "grad_norm": 4.913827896118164,
        "learning_rate": 2.4008302583025833e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.4563,
        "grad_norm": 6.628101348876953,
        "learning_rate": 2.3985239852398524e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.3747,
        "grad_norm": 4.887948513031006,
        "learning_rate": 2.3962177121771218e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.385,
        "grad_norm": 3.002619981765747,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.5168,
        "grad_norm": 4.101734638214111,
        "learning_rate": 2.3916051660516606e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.4206,
        "grad_norm": 5.3907928466796875,
        "learning_rate": 2.38929889298893e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4648,
        "grad_norm": 3.633631706237793,
        "learning_rate": 2.3869926199261995e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.5146,
        "grad_norm": 3.911606788635254,
        "learning_rate": 2.3846863468634686e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.4385,
        "grad_norm": 3.527477264404297,
        "learning_rate": 2.3823800738007383e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.3928,
        "grad_norm": 2.7929627895355225,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.4337,
        "grad_norm": 3.8303797245025635,
        "learning_rate": 2.377767527675277e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.3836,
        "grad_norm": 3.596233367919922,
        "learning_rate": 2.3754612546125462e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.37401285767555237,
        "eval_accuracy": 0.84041,
        "eval_precision": 0.80198,
        "eval_recall": 0.90167,
        "eval_f1": 0.84891,
        "eval_runtime": 18.1174,
        "eval_samples_per_second": 59.832,
        "eval_steps_per_second": 3.753,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.4206,
        "grad_norm": 3.492858648300171,
        "learning_rate": 2.3731549815498157e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4638,
        "grad_norm": 5.377951145172119,
        "learning_rate": 2.370848708487085e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.413,
        "grad_norm": 4.611978054046631,
        "learning_rate": 2.3685424354243542e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.4406,
        "grad_norm": 4.854150772094727,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.396,
        "grad_norm": 2.3622395992279053,
        "learning_rate": 2.363929889298893e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.345,
        "grad_norm": 7.144217491149902,
        "learning_rate": 2.3616236162361624e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.4454,
        "grad_norm": 7.223581314086914,
        "learning_rate": 2.359317343173432e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.5086,
        "grad_norm": 4.289239406585693,
        "learning_rate": 2.3570110701107013e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.405,
        "grad_norm": 3.825762987136841,
        "learning_rate": 2.3547047970479704e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3949,
        "grad_norm": 7.414369583129883,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.4919,
        "grad_norm": 4.4542155265808105,
        "learning_rate": 2.3500922509225092e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.4216,
        "grad_norm": 2.8181915283203125,
        "learning_rate": 2.347785977859779e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3551,
        "grad_norm": 2.7058839797973633,
        "learning_rate": 2.345479704797048e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.4271,
        "grad_norm": 5.933957099914551,
        "learning_rate": 2.3431734317343175e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.4245,
        "grad_norm": 3.442722797393799,
        "learning_rate": 2.340867158671587e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.3896,
        "grad_norm": 6.008139133453369,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3893,
        "grad_norm": 2.3807168006896973,
        "learning_rate": 2.3362546125461258e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.3062,
        "grad_norm": 2.0921900272369385,
        "learning_rate": 2.333948339483395e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.4231,
        "grad_norm": 2.7832820415496826,
        "learning_rate": 2.3316420664206643e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.3293,
        "grad_norm": 3.79726505279541,
        "learning_rate": 2.3293357933579337e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.4511,
        "grad_norm": 3.0590291023254395,
        "learning_rate": 2.327029520295203e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.3779,
        "grad_norm": 1.7985562086105347,
        "learning_rate": 2.3247232472324722e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4597,
        "grad_norm": 3.3717093467712402,
        "learning_rate": 2.322416974169742e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.447,
        "grad_norm": 10.89635181427002,
        "learning_rate": 2.320110701107011e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.4046,
        "grad_norm": 8.92173957824707,
        "learning_rate": 2.3178044280442808e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.4227,
        "grad_norm": 3.7384560108184814,
        "learning_rate": 2.31549815498155e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.3185,
        "grad_norm": 3.602267265319824,
        "learning_rate": 2.3131918819188193e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.36453336477279663,
        "eval_accuracy": 0.85148,
        "eval_precision": 0.79717,
        "eval_recall": 0.94063,
        "eval_f1": 0.86298,
        "eval_runtime": 18.1567,
        "eval_samples_per_second": 59.702,
        "eval_steps_per_second": 3.745,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3428,
        "grad_norm": 2.826326370239258,
        "learning_rate": 2.3108856088560887e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.4751,
        "grad_norm": 8.853660583496094,
        "learning_rate": 2.308579335793358e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.3935,
        "grad_norm": 2.2158868312835693,
        "learning_rate": 2.3062730627306276e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.4267,
        "grad_norm": 2.2050750255584717,
        "learning_rate": 2.3039667896678967e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.3008,
        "grad_norm": 2.350285530090332,
        "learning_rate": 2.301660516605166e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.461,
        "grad_norm": 2.227783441543579,
        "learning_rate": 2.2993542435424355e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.359,
        "grad_norm": 9.689931869506836,
        "learning_rate": 2.297047970479705e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3516,
        "grad_norm": 2.7108376026153564,
        "learning_rate": 2.294741697416974e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.4371,
        "grad_norm": 4.025691986083984,
        "learning_rate": 2.2924354243542438e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3241,
        "grad_norm": 3.1299936771392822,
        "learning_rate": 2.290129151291513e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.3953,
        "grad_norm": 3.3409736156463623,
        "learning_rate": 2.2878228782287826e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.4677,
        "grad_norm": 4.360926628112793,
        "learning_rate": 2.2855166051660517e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.377,
        "grad_norm": 4.691338062286377,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.4272,
        "grad_norm": 6.150243759155273,
        "learning_rate": 2.2809040590405906e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.3672,
        "grad_norm": 1.9509179592132568,
        "learning_rate": 2.27859778597786e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.4242,
        "grad_norm": 4.220180511474609,
        "learning_rate": 2.2762915129151294e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.5104,
        "grad_norm": 2.8264191150665283,
        "learning_rate": 2.2739852398523985e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.3527,
        "grad_norm": 2.397573232650757,
        "learning_rate": 2.271678966789668e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.481,
        "grad_norm": 4.671644687652588,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.3161,
        "grad_norm": 2.156620502471924,
        "learning_rate": 2.2670664206642068e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.4678,
        "grad_norm": 4.69105863571167,
        "learning_rate": 2.2647601476014762e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.3329,
        "grad_norm": 7.427392482757568,
        "learning_rate": 2.2624538745387456e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3971,
        "grad_norm": 2.5930979251861572,
        "learning_rate": 2.2601476014760147e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.2686,
        "grad_norm": 4.526318073272705,
        "learning_rate": 2.2578413284132844e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.3818,
        "grad_norm": 6.32910680770874,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.3976,
        "grad_norm": 3.7472639083862305,
        "learning_rate": 2.253228782287823e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.2919,
        "grad_norm": 2.1605637073516846,
        "learning_rate": 2.2509225092250924e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.37152889370918274,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.84249,
        "eval_recall": 0.85343,
        "eval_f1": 0.84793,
        "eval_runtime": 18.1423,
        "eval_samples_per_second": 59.75,
        "eval_steps_per_second": 3.748,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.4369,
        "grad_norm": 4.296867370605469,
        "learning_rate": 2.2486162361623618e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.3313,
        "grad_norm": 5.697761058807373,
        "learning_rate": 2.2463099630996312e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.3363,
        "grad_norm": 7.260003566741943,
        "learning_rate": 2.2440036900369006e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.4432,
        "grad_norm": 4.356747627258301,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3369,
        "grad_norm": 3.510221242904663,
        "learning_rate": 2.239391143911439e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3466,
        "grad_norm": 2.2157466411590576,
        "learning_rate": 2.2370848708487086e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3291,
        "grad_norm": 3.54231333732605,
        "learning_rate": 2.234778597785978e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3509,
        "grad_norm": 4.447895050048828,
        "learning_rate": 2.2324723247232474e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.4107,
        "grad_norm": 2.0639843940734863,
        "learning_rate": 2.2301660516605165e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.4566,
        "grad_norm": 5.115689277648926,
        "learning_rate": 2.2278597785977863e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.3752,
        "grad_norm": 1.5535576343536377,
        "learning_rate": 2.2255535055350553e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3997,
        "grad_norm": 1.6027425527572632,
        "learning_rate": 2.2232472324723248e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.4166,
        "grad_norm": 4.51114559173584,
        "learning_rate": 2.2209409594095942e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3448,
        "grad_norm": 2.31602144241333,
        "learning_rate": 2.2186346863468636e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3567,
        "grad_norm": 3.024618625640869,
        "learning_rate": 2.216328413284133e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3161,
        "grad_norm": 2.4806134700775146,
        "learning_rate": 2.2140221402214025e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3899,
        "grad_norm": 1.4799987077713013,
        "learning_rate": 2.2117158671586715e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.3923,
        "grad_norm": 0.915511429309845,
        "learning_rate": 2.209409594095941e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.4111,
        "grad_norm": 3.1191959381103516,
        "learning_rate": 2.2071033210332104e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.3398,
        "grad_norm": 1.4213049411773682,
        "learning_rate": 2.2047970479704798e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.4117,
        "grad_norm": 2.9855117797851562,
        "learning_rate": 2.2024907749077492e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.4047,
        "grad_norm": 2.183229923248291,
        "learning_rate": 2.2001845018450183e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.3472,
        "grad_norm": 2.9563071727752686,
        "learning_rate": 2.197878228782288e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.3693,
        "grad_norm": 6.759829521179199,
        "learning_rate": 2.195571955719557e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.3343,
        "grad_norm": 5.775169849395752,
        "learning_rate": 2.193265682656827e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.4572,
        "grad_norm": 5.169986248016357,
        "learning_rate": 2.190959409594096e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.3099,
        "grad_norm": 3.0506064891815186,
        "learning_rate": 2.1886531365313654e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.36292168498039246,
        "eval_accuracy": 0.85609,
        "eval_precision": 0.81758,
        "eval_recall": 0.91466,
        "eval_f1": 0.8634,
        "eval_runtime": 18.1425,
        "eval_samples_per_second": 59.749,
        "eval_steps_per_second": 3.748,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.4048,
        "grad_norm": 1.6517078876495361,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.3022,
        "grad_norm": 3.8538618087768555,
        "learning_rate": 2.1840405904059043e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.3644,
        "grad_norm": 3.1093568801879883,
        "learning_rate": 2.1817343173431734e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.333,
        "grad_norm": 6.1254472732543945,
        "learning_rate": 2.1794280442804428e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.4587,
        "grad_norm": 5.424694538116455,
        "learning_rate": 2.1771217712177122e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.3085,
        "grad_norm": 2.3168959617614746,
        "learning_rate": 2.1748154981549816e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.3788,
        "grad_norm": 2.7857582569122314,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.3601,
        "grad_norm": 2.436345100402832,
        "learning_rate": 2.17020295202952e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.3641,
        "grad_norm": 4.13582706451416,
        "learning_rate": 2.16789667896679e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.3332,
        "grad_norm": 2.745612382888794,
        "learning_rate": 2.165590405904059e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.339,
        "grad_norm": 3.2368454933166504,
        "learning_rate": 2.1632841328413287e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.366,
        "grad_norm": 3.846600294113159,
        "learning_rate": 2.160977859778598e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.3624,
        "grad_norm": 3.3928613662719727,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.3918,
        "grad_norm": 3.750342607498169,
        "learning_rate": 2.1563653136531367e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.3749,
        "grad_norm": 5.279497146606445,
        "learning_rate": 2.154059040590406e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.3317,
        "grad_norm": 3.5974998474121094,
        "learning_rate": 2.1517527675276755e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.2631,
        "grad_norm": 2.426215410232544,
        "learning_rate": 2.149446494464945e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.3159,
        "grad_norm": 1.9603325128555298,
        "learning_rate": 2.147140221402214e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.4004,
        "grad_norm": 6.226360321044922,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.4226,
        "grad_norm": 4.510996341705322,
        "learning_rate": 2.142527675276753e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.3655,
        "grad_norm": 2.9120900630950928,
        "learning_rate": 2.140221402214022e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.3682,
        "grad_norm": 3.5603668689727783,
        "learning_rate": 2.1379151291512917e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.2518,
        "grad_norm": 1.8608851432800293,
        "learning_rate": 2.1356088560885608e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.2582,
        "grad_norm": 1.692116141319275,
        "learning_rate": 2.1333025830258306e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.4216,
        "grad_norm": 21.589336395263672,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.41,
        "grad_norm": 6.973668098449707,
        "learning_rate": 2.128690036900369e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.4095,
        "grad_norm": 4.7034687995910645,
        "learning_rate": 2.1263837638376385e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.3744400143623352,
        "eval_accuracy": 0.84133,
        "eval_precision": 0.80532,
        "eval_recall": 0.89796,
        "eval_f1": 0.84912,
        "eval_runtime": 18.1333,
        "eval_samples_per_second": 59.779,
        "eval_steps_per_second": 3.75,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.3203,
        "grad_norm": 2.5236637592315674,
        "learning_rate": 2.124077490774908e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3068,
        "grad_norm": 1.7770538330078125,
        "learning_rate": 2.1217712177121773e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.3222,
        "grad_norm": 9.003597259521484,
        "learning_rate": 2.1194649446494468e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.3969,
        "grad_norm": 6.801202297210693,
        "learning_rate": 2.117158671586716e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.349,
        "grad_norm": 8.773859024047852,
        "learning_rate": 2.1148523985239853e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.2266,
        "grad_norm": 3.03446102142334,
        "learning_rate": 2.1125461254612547e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.2781,
        "grad_norm": 5.718992233276367,
        "learning_rate": 2.110239852398524e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.3903,
        "grad_norm": 3.7117276191711426,
        "learning_rate": 2.1079335793357935e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3631,
        "grad_norm": 2.80348801612854,
        "learning_rate": 2.1056273062730626e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.3719,
        "grad_norm": 2.6658082008361816,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.3693,
        "grad_norm": 16.178630828857422,
        "learning_rate": 2.1010147601476015e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.3973,
        "grad_norm": 3.7417943477630615,
        "learning_rate": 2.098708487084871e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.3145,
        "grad_norm": 5.8444013595581055,
        "learning_rate": 2.0964022140221403e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.2939,
        "grad_norm": 3.1370925903320312,
        "learning_rate": 2.0940959409594097e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3518,
        "grad_norm": 3.3223190307617188,
        "learning_rate": 2.091789667896679e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.3548,
        "grad_norm": 3.0605533123016357,
        "learning_rate": 2.0894833948339486e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.3021,
        "grad_norm": 1.8395675420761108,
        "learning_rate": 2.0871771217712177e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.3664,
        "grad_norm": 3.811889410018921,
        "learning_rate": 2.084870848708487e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.3012,
        "grad_norm": 3.309823989868164,
        "learning_rate": 2.0825645756457565e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3266,
        "grad_norm": 2.7882239818573,
        "learning_rate": 2.080258302583026e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3575,
        "grad_norm": 4.227985382080078,
        "learning_rate": 2.0779520295202954e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3725,
        "grad_norm": 4.066193103790283,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.4265,
        "grad_norm": 5.1266632080078125,
        "learning_rate": 2.0733394833948342e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.4138,
        "grad_norm": 2.2801737785339355,
        "learning_rate": 2.0710332103321033e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.395,
        "grad_norm": 2.227745294570923,
        "learning_rate": 2.0687269372693727e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.2634,
        "grad_norm": 2.086987257003784,
        "learning_rate": 2.066420664206642e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3724,
        "grad_norm": 18.43918228149414,
        "learning_rate": 2.0641143911439116e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.3671429753303528,
        "eval_accuracy": 0.87269,
        "eval_precision": 0.83926,
        "eval_recall": 0.92022,
        "eval_f1": 0.87788,
        "eval_runtime": 18.1435,
        "eval_samples_per_second": 59.746,
        "eval_steps_per_second": 3.748,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.4673,
        "grad_norm": 5.342133522033691,
        "learning_rate": 2.061808118081181e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.3813,
        "grad_norm": 2.6241726875305176,
        "learning_rate": 2.0595018450184504e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3113,
        "grad_norm": 1.8211982250213623,
        "learning_rate": 2.0571955719557195e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.3652,
        "grad_norm": 12.009440422058105,
        "learning_rate": 2.0548892988929893e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.3018,
        "grad_norm": 2.435702085494995,
        "learning_rate": 2.0525830258302583e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.27,
        "grad_norm": 2.7877280712127686,
        "learning_rate": 2.0502767527675278e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.3289,
        "grad_norm": 29.98845100402832,
        "learning_rate": 2.0479704797047972e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.3439,
        "grad_norm": 1.8249150514602661,
        "learning_rate": 2.0456642066420663e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.2817,
        "grad_norm": 5.406935691833496,
        "learning_rate": 2.043357933579336e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.2448,
        "grad_norm": 5.943409442901611,
        "learning_rate": 2.041051660516605e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.334,
        "grad_norm": 50.83866882324219,
        "learning_rate": 2.0387453874538745e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3109,
        "grad_norm": 88.2602767944336,
        "learning_rate": 2.036439114391144e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.3241,
        "grad_norm": 8.3279447555542,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3217,
        "grad_norm": 3.8362679481506348,
        "learning_rate": 2.0318265682656828e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.3622,
        "grad_norm": 2.0991291999816895,
        "learning_rate": 2.0295202952029522e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.3745,
        "grad_norm": 6.649417877197266,
        "learning_rate": 2.0272140221402213e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.2781,
        "grad_norm": 1.8375747203826904,
        "learning_rate": 2.024907749077491e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.3247,
        "grad_norm": 3.9987599849700928,
        "learning_rate": 2.02260147601476e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.3441,
        "grad_norm": 3.0760529041290283,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.414,
        "grad_norm": 1.895123839378357,
        "learning_rate": 2.017988929889299e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.336,
        "grad_norm": 3.678666591644287,
        "learning_rate": 2.0156826568265684e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.3257,
        "grad_norm": 6.978044033050537,
        "learning_rate": 2.013376383763838e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.4058,
        "grad_norm": 8.387699127197266,
        "learning_rate": 2.011070110701107e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.2696,
        "grad_norm": 13.810623168945312,
        "learning_rate": 2.0087638376383767e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.451,
        "grad_norm": 1.4578911066055298,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.405,
        "grad_norm": 5.630333423614502,
        "learning_rate": 2.0041512915129152e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.4191,
        "grad_norm": 3.3495888710021973,
        "learning_rate": 2.0018450184501846e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.32204803824424744,
        "eval_accuracy": 0.87454,
        "eval_precision": 0.84327,
        "eval_recall": 0.91837,
        "eval_f1": 0.87922,
        "eval_runtime": 18.134,
        "eval_samples_per_second": 59.777,
        "eval_steps_per_second": 3.75,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.3086,
        "grad_norm": 2.960237741470337,
        "learning_rate": 1.999538745387454e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3055,
        "grad_norm": 1.8080356121063232,
        "learning_rate": 1.997232472324723e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.3777,
        "grad_norm": 8.002087593078613,
        "learning_rate": 1.994926199261993e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.2678,
        "grad_norm": 2.5367119312286377,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.4228,
        "grad_norm": 6.073832988739014,
        "learning_rate": 1.9903136531365314e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.2396,
        "grad_norm": 1.9423199892044067,
        "learning_rate": 1.9880073800738008e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.4098,
        "grad_norm": 5.013887405395508,
        "learning_rate": 1.9857011070110702e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.3652,
        "grad_norm": 2.305253267288208,
        "learning_rate": 1.9833948339483397e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.252,
        "grad_norm": 17.65095329284668,
        "learning_rate": 1.9810885608856088e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.3164,
        "grad_norm": 5.088073253631592,
        "learning_rate": 1.9787822878228785e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.3807,
        "grad_norm": 4.253321170806885,
        "learning_rate": 1.9764760147601476e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.2869,
        "grad_norm": 7.4430036544799805,
        "learning_rate": 1.974169741697417e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.2917,
        "grad_norm": 2.3345162868499756,
        "learning_rate": 1.9718634686346864e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.2615,
        "grad_norm": 4.975534439086914,
        "learning_rate": 1.969557195571956e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.2902,
        "grad_norm": 1.864047646522522,
        "learning_rate": 1.9672509225092253e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.3549,
        "grad_norm": 4.680107116699219,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.3828,
        "grad_norm": 5.918759822845459,
        "learning_rate": 1.9626383763837638e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3296,
        "grad_norm": 3.9833433628082275,
        "learning_rate": 1.9603321033210336e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.4036,
        "grad_norm": 11.244131088256836,
        "learning_rate": 1.9580258302583026e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.3757,
        "grad_norm": 4.051498889923096,
        "learning_rate": 1.955719557195572e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.2793,
        "grad_norm": 3.517357587814331,
        "learning_rate": 1.9534132841328415e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.3881,
        "grad_norm": 4.187271595001221,
        "learning_rate": 1.9511070110701106e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.3405,
        "grad_norm": 3.0516674518585205,
        "learning_rate": 1.9488007380073803e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.2915,
        "grad_norm": 1.5655503273010254,
        "learning_rate": 1.9464944649446494e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.3622,
        "grad_norm": 4.990323543548584,
        "learning_rate": 1.944188191881919e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.3009,
        "grad_norm": 4.769925117492676,
        "learning_rate": 1.9418819188191883e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3686,
        "grad_norm": 5.127519607543945,
        "learning_rate": 1.9395756457564577e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.4239944517612457,
        "eval_accuracy": 0.84871,
        "eval_precision": 0.86693,
        "eval_recall": 0.82189,
        "eval_f1": 0.84381,
        "eval_runtime": 18.1069,
        "eval_samples_per_second": 59.867,
        "eval_steps_per_second": 3.755,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.3163,
        "grad_norm": 3.610379219055176,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.3774,
        "grad_norm": 3.4763994216918945,
        "learning_rate": 1.9349630996309965e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3204,
        "grad_norm": 2.1346869468688965,
        "learning_rate": 1.9326568265682656e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.2713,
        "grad_norm": 2.3451128005981445,
        "learning_rate": 1.9303505535055354e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.2946,
        "grad_norm": 1.0809814929962158,
        "learning_rate": 1.9280442804428045e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.4008,
        "grad_norm": 2.941629409790039,
        "learning_rate": 1.925738007380074e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3342,
        "grad_norm": 7.994373798370361,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.2407,
        "grad_norm": 2.8241028785705566,
        "learning_rate": 1.9211254612546127e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.4275,
        "grad_norm": 6.118340015411377,
        "learning_rate": 1.918819188191882e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.2687,
        "grad_norm": 2.9897351264953613,
        "learning_rate": 1.9165129151291512e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.4342,
        "grad_norm": 2.3042244911193848,
        "learning_rate": 1.9142066420664207e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.3149,
        "grad_norm": 4.410048484802246,
        "learning_rate": 1.91190036900369e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.3222,
        "grad_norm": 5.170995235443115,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.3213,
        "grad_norm": 13.132071495056152,
        "learning_rate": 1.907287822878229e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.4486,
        "grad_norm": 4.00320291519165,
        "learning_rate": 1.9049815498154984e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.3436,
        "grad_norm": 3.2126433849334717,
        "learning_rate": 1.9026752767527674e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.3414,
        "grad_norm": 6.279739856719971,
        "learning_rate": 1.9003690036900372e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.3354,
        "grad_norm": 2.0791373252868652,
        "learning_rate": 1.8980627306273063e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.2322,
        "grad_norm": 3.6826374530792236,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.3043,
        "grad_norm": 2.178396701812744,
        "learning_rate": 1.893450184501845e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.2917,
        "grad_norm": 14.712546348571777,
        "learning_rate": 1.8911439114391146e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.3522,
        "grad_norm": 2.3745269775390625,
        "learning_rate": 1.888837638376384e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3179,
        "grad_norm": 2.959719181060791,
        "learning_rate": 1.886531365313653e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.3183,
        "grad_norm": 7.9577555656433105,
        "learning_rate": 1.8842250922509225e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.3645,
        "grad_norm": 5.870497226715088,
        "learning_rate": 1.881918819188192e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.2544,
        "grad_norm": 9.634284019470215,
        "learning_rate": 1.8796125461254613e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.2837,
        "grad_norm": 3.2450976371765137,
        "learning_rate": 1.8773062730627308e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.4346,
        "grad_norm": 8.53425121307373,
        "learning_rate": 1.8750000000000002e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.336109459400177,
        "eval_accuracy": 0.87454,
        "eval_precision": 0.82658,
        "eval_recall": 0.9462,
        "eval_f1": 0.88235,
        "eval_runtime": 18.05,
        "eval_samples_per_second": 60.055,
        "eval_steps_per_second": 3.767,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.2559,
        "grad_norm": 10.076619148254395,
        "learning_rate": 1.8726937269372693e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.3065,
        "grad_norm": 3.0433526039123535,
        "learning_rate": 1.870387453874539e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.343,
        "grad_norm": 3.217931032180786,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.4046,
        "grad_norm": 2.8453783988952637,
        "learning_rate": 1.865774907749078e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.256,
        "grad_norm": 2.2900967597961426,
        "learning_rate": 1.863468634686347e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.3365,
        "grad_norm": 1.4731130599975586,
        "learning_rate": 1.8611623616236164e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.3194,
        "grad_norm": 1.4384667873382568,
        "learning_rate": 1.8588560885608858e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.2784,
        "grad_norm": 6.449779987335205,
        "learning_rate": 1.856549815498155e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.27,
        "grad_norm": 2.03804087638855,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3141,
        "grad_norm": 6.226905822753906,
        "learning_rate": 1.8519372693726937e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.3315,
        "grad_norm": 15.612003326416016,
        "learning_rate": 1.849630996309963e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.3314,
        "grad_norm": 14.144850730895996,
        "learning_rate": 1.8473247232472326e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.3703,
        "grad_norm": 6.868429660797119,
        "learning_rate": 1.845018450184502e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.2973,
        "grad_norm": 1.957614779472351,
        "learning_rate": 1.842712177121771e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.3166,
        "grad_norm": 3.14908766746521,
        "learning_rate": 1.840405904059041e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.3459,
        "grad_norm": 24.636951446533203,
        "learning_rate": 1.83809963099631e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3727,
        "grad_norm": 3.7924532890319824,
        "learning_rate": 1.8357933579335797e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.2732,
        "grad_norm": 3.9066646099090576,
        "learning_rate": 1.8334870848708488e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2347,
        "grad_norm": 5.991362571716309,
        "learning_rate": 1.8311808118081182e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.4041,
        "grad_norm": 4.135138988494873,
        "learning_rate": 1.8288745387453876e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.3068,
        "grad_norm": 2.5181000232696533,
        "learning_rate": 1.826568265682657e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.3138,
        "grad_norm": 4.1431355476379395,
        "learning_rate": 1.8242619926199265e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.2642,
        "grad_norm": 10.371304512023926,
        "learning_rate": 1.8219557195571955e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.2885,
        "grad_norm": 1.3010419607162476,
        "learning_rate": 1.819649446494465e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.37,
        "grad_norm": 2.5507028102874756,
        "learning_rate": 1.8173431734317344e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.2952,
        "grad_norm": 1.8504843711853027,
        "learning_rate": 1.8150369003690038e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.2927,
        "grad_norm": 3.4710261821746826,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.3729311227798462,
        "eval_accuracy": 0.86716,
        "eval_precision": 0.82972,
        "eval_recall": 0.92208,
        "eval_f1": 0.87346,
        "eval_runtime": 18.1177,
        "eval_samples_per_second": 59.831,
        "eval_steps_per_second": 3.753,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.3327,
        "grad_norm": 3.4096548557281494,
        "learning_rate": 1.8104243542435427e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.3305,
        "grad_norm": 11.930118560791016,
        "learning_rate": 1.8081180811808117e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.2763,
        "grad_norm": 4.295459747314453,
        "learning_rate": 1.8058118081180815e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.3,
        "grad_norm": 8.300390243530273,
        "learning_rate": 1.8035055350553506e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.3127,
        "grad_norm": 64.33758544921875,
        "learning_rate": 1.80119926199262e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.2745,
        "grad_norm": 3.0158605575561523,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.3179,
        "grad_norm": 3.7131104469299316,
        "learning_rate": 1.796586715867159e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.2813,
        "grad_norm": 2.9037792682647705,
        "learning_rate": 1.7942804428044283e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.2881,
        "grad_norm": 3.0915215015411377,
        "learning_rate": 1.7919741697416974e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.373,
        "grad_norm": 4.589784145355225,
        "learning_rate": 1.7896678966789668e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.3223,
        "grad_norm": 6.514346599578857,
        "learning_rate": 1.7873616236162362e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.2964,
        "grad_norm": 3.3627824783325195,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.2929,
        "grad_norm": 5.1472063064575195,
        "learning_rate": 1.7827490774907747e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.347,
        "grad_norm": 98.2913818359375,
        "learning_rate": 1.7804428044280445e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.2317,
        "grad_norm": 2.9719836711883545,
        "learning_rate": 1.7781365313653136e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.3518,
        "grad_norm": 3.0508172512054443,
        "learning_rate": 1.7758302583025833e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.3558,
        "grad_norm": 3.859142780303955,
        "learning_rate": 1.7735239852398524e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.2461,
        "grad_norm": 3.0487828254699707,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.3024,
        "grad_norm": 2.0952188968658447,
        "learning_rate": 1.7689114391143913e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.352,
        "grad_norm": 12.13875675201416,
        "learning_rate": 1.7666051660516607e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2874,
        "grad_norm": 3.6622753143310547,
        "learning_rate": 1.76429889298893e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.3901,
        "grad_norm": 1.7453058958053589,
        "learning_rate": 1.7619926199261992e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.3492,
        "grad_norm": 2.1019744873046875,
        "learning_rate": 1.7596863468634686e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.2768,
        "grad_norm": 17.06069564819336,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.2814,
        "grad_norm": 3.472777843475342,
        "learning_rate": 1.7550738007380075e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2868,
        "grad_norm": 2.6073861122131348,
        "learning_rate": 1.752767527675277e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.3052,
        "grad_norm": 13.868027687072754,
        "learning_rate": 1.7504612546125463e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.3446030914783478,
        "eval_accuracy": 0.88007,
        "eval_precision": 0.85077,
        "eval_recall": 0.92022,
        "eval_f1": 0.88414,
        "eval_runtime": 18.1322,
        "eval_samples_per_second": 59.783,
        "eval_steps_per_second": 3.75,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.3228,
        "grad_norm": 1.8863134384155273,
        "learning_rate": 1.7481549815498154e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.3179,
        "grad_norm": 5.651007652282715,
        "learning_rate": 1.745848708487085e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.3233,
        "grad_norm": 2.4685842990875244,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.2353,
        "grad_norm": 4.086199760437012,
        "learning_rate": 1.7412361623616237e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2337,
        "grad_norm": 1.7044973373413086,
        "learning_rate": 1.738929889298893e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.3188,
        "grad_norm": 3.8218424320220947,
        "learning_rate": 1.7366236162361625e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.3192,
        "grad_norm": 5.681318283081055,
        "learning_rate": 1.734317343173432e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.2975,
        "grad_norm": 2.5768380165100098,
        "learning_rate": 1.7320110701107013e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.3605,
        "grad_norm": 8.367145538330078,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.2097,
        "grad_norm": 1.992793321609497,
        "learning_rate": 1.72739852398524e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.2191,
        "grad_norm": 2.6077704429626465,
        "learning_rate": 1.7250922509225093e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.2554,
        "grad_norm": 2.1346287727355957,
        "learning_rate": 1.7227859778597787e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.2456,
        "grad_norm": 1.668508529663086,
        "learning_rate": 1.720479704797048e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.2862,
        "grad_norm": 5.105154514312744,
        "learning_rate": 1.7181734317343172e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.3489,
        "grad_norm": 4.391907215118408,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.2999,
        "grad_norm": 2.827479362487793,
        "learning_rate": 1.713560885608856e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.3021,
        "grad_norm": 3.0265309810638428,
        "learning_rate": 1.7112546125461258e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.2367,
        "grad_norm": 2.6946516036987305,
        "learning_rate": 1.708948339483395e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.2745,
        "grad_norm": 3.0680174827575684,
        "learning_rate": 1.7066420664206643e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.3625,
        "grad_norm": 7.697946071624756,
        "learning_rate": 1.7043357933579337e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.2776,
        "grad_norm": 1.3195686340332031,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.403,
        "grad_norm": 6.434450149536133,
        "learning_rate": 1.6997232472324722e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.3428,
        "grad_norm": 2.522538423538208,
        "learning_rate": 1.6974169741697417e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.3039,
        "grad_norm": 2.7573349475860596,
        "learning_rate": 1.695110701107011e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.2395,
        "grad_norm": 4.777519226074219,
        "learning_rate": 1.6928044280442805e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.2688,
        "grad_norm": 2.140852928161621,
        "learning_rate": 1.69049815498155e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.2952,
        "grad_norm": 8.70899486541748,
        "learning_rate": 1.688191881918819e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.39338478446006775,
        "eval_accuracy": 0.85886,
        "eval_precision": 0.83624,
        "eval_recall": 0.89054,
        "eval_f1": 0.86253,
        "eval_runtime": 18.1511,
        "eval_samples_per_second": 59.721,
        "eval_steps_per_second": 3.746,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.2998,
        "grad_norm": 3.644559621810913,
        "learning_rate": 1.6858856088560888e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.2331,
        "grad_norm": 4.872956275939941,
        "learning_rate": 1.683579335793358e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.262,
        "grad_norm": 5.011996269226074,
        "learning_rate": 1.6812730627306276e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.3534,
        "grad_norm": 1.875809907913208,
        "learning_rate": 1.6789667896678967e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.2282,
        "grad_norm": 7.309821128845215,
        "learning_rate": 1.676660516605166e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.2949,
        "grad_norm": 6.825851917266846,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.3521,
        "grad_norm": 3.7012033462524414,
        "learning_rate": 1.672047970479705e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.3061,
        "grad_norm": 2.1864402294158936,
        "learning_rate": 1.669741697416974e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.316,
        "grad_norm": 2.832970380783081,
        "learning_rate": 1.6674354243542435e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.3273,
        "grad_norm": 3.5350089073181152,
        "learning_rate": 1.665129151291513e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.283,
        "grad_norm": 1.0189597606658936,
        "learning_rate": 1.6628228782287823e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.3035,
        "grad_norm": 4.771944999694824,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.3158,
        "grad_norm": 3.303101062774658,
        "learning_rate": 1.658210332103321e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.274,
        "grad_norm": 8.682907104492188,
        "learning_rate": 1.6559040590405906e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.3774,
        "grad_norm": 3.5847597122192383,
        "learning_rate": 1.6535977859778597e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2521,
        "grad_norm": 2.185272455215454,
        "learning_rate": 1.6512915129151295e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2168,
        "grad_norm": 7.131707668304443,
        "learning_rate": 1.6489852398523985e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.3706,
        "grad_norm": 4.658273696899414,
        "learning_rate": 1.646678966789668e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.2558,
        "grad_norm": 2.033402681350708,
        "learning_rate": 1.6443726937269374e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.2874,
        "grad_norm": 11.65546703338623,
        "learning_rate": 1.6420664206642068e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.2219,
        "grad_norm": 1.7000024318695068,
        "learning_rate": 1.6397601476014762e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.2997,
        "grad_norm": 4.703408241271973,
        "learning_rate": 1.6374538745387457e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.4443,
        "grad_norm": 3.965833902359009,
        "learning_rate": 1.6351476014760147e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.2648,
        "grad_norm": 2.0762689113616943,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.2227,
        "grad_norm": 3.6022350788116455,
        "learning_rate": 1.6305350553505536e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.3038,
        "grad_norm": 1.8965750932693481,
        "learning_rate": 1.6282287822878227e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.3262,
        "grad_norm": 2.5561182498931885,
        "learning_rate": 1.6259225092250924e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.3792639374732971,
        "eval_accuracy": 0.86716,
        "eval_precision": 0.83993,
        "eval_recall": 0.90538,
        "eval_f1": 0.87143,
        "eval_runtime": 18.1025,
        "eval_samples_per_second": 59.881,
        "eval_steps_per_second": 3.756,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.3328,
        "grad_norm": 5.902138710021973,
        "learning_rate": 1.6236162361623615e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.2161,
        "grad_norm": 6.416193008422852,
        "learning_rate": 1.6213099630996313e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.2283,
        "grad_norm": 10.050187110900879,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.3502,
        "grad_norm": 3.287799596786499,
        "learning_rate": 1.6166974169741698e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.336,
        "grad_norm": 1.5221407413482666,
        "learning_rate": 1.6143911439114392e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.291,
        "grad_norm": 4.444246292114258,
        "learning_rate": 1.6120848708487086e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.3288,
        "grad_norm": 1.8900525569915771,
        "learning_rate": 1.609778597785978e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.2445,
        "grad_norm": 3.384242296218872,
        "learning_rate": 1.6074723247232475e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2097,
        "grad_norm": 1.0865564346313477,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.2599,
        "grad_norm": 2.5540623664855957,
        "learning_rate": 1.602859778597786e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.3163,
        "grad_norm": 23.210947036743164,
        "learning_rate": 1.6005535055350554e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.2219,
        "grad_norm": 3.4201836585998535,
        "learning_rate": 1.5982472324723248e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.3706,
        "grad_norm": 14.068699836730957,
        "learning_rate": 1.5959409594095942e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.2456,
        "grad_norm": 3.319711923599243,
        "learning_rate": 1.5936346863468633e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.3053,
        "grad_norm": 4.66215181350708,
        "learning_rate": 1.591328413284133e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.2856,
        "grad_norm": 1.5457428693771362,
        "learning_rate": 1.5890221402214022e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.348,
        "grad_norm": 12.436460494995117,
        "learning_rate": 1.5867158671586716e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.2696,
        "grad_norm": 4.8097825050354,
        "learning_rate": 1.584409594095941e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.2339,
        "grad_norm": 8.486907005310059,
        "learning_rate": 1.5821033210332104e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.3422,
        "grad_norm": 12.905805587768555,
        "learning_rate": 1.57979704797048e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.2255,
        "grad_norm": 3.9468178749084473,
        "learning_rate": 1.5774907749077493e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.3749,
        "grad_norm": 6.329617023468018,
        "learning_rate": 1.5751845018450184e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.3124,
        "grad_norm": 7.096158504486084,
        "learning_rate": 1.5728782287822878e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.2975,
        "grad_norm": 1.8587045669555664,
        "learning_rate": 1.5705719557195572e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.2035,
        "grad_norm": 7.8060503005981445,
        "learning_rate": 1.5682656826568266e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.1737,
        "grad_norm": 1.221463680267334,
        "learning_rate": 1.565959409594096e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.3159,
        "grad_norm": 4.965271949768066,
        "learning_rate": 1.563653136531365e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.4087887108325958,
        "eval_accuracy": 0.869,
        "eval_precision": 0.85383,
        "eval_recall": 0.88868,
        "eval_f1": 0.87091,
        "eval_runtime": 18.1075,
        "eval_samples_per_second": 59.865,
        "eval_steps_per_second": 3.755,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.2191,
        "grad_norm": 5.272586822509766,
        "learning_rate": 1.561346863468635e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.3101,
        "grad_norm": 27.175750732421875,
        "learning_rate": 1.559040590405904e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.2323,
        "grad_norm": 5.116865634918213,
        "learning_rate": 1.5567343173431734e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.2418,
        "grad_norm": 13.115403175354004,
        "learning_rate": 1.554428044280443e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.2571,
        "grad_norm": 1.7298691272735596,
        "learning_rate": 1.5521217712177123e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.3203,
        "grad_norm": 18.2081298828125,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.3192,
        "grad_norm": 2.943495035171509,
        "learning_rate": 1.547509225092251e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.2837,
        "grad_norm": 5.9776411056518555,
        "learning_rate": 1.5452029520295202e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.3193,
        "grad_norm": 10.035587310791016,
        "learning_rate": 1.54289667896679e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.1894,
        "grad_norm": 11.187660217285156,
        "learning_rate": 1.540590405904059e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.2337,
        "grad_norm": 10.374063491821289,
        "learning_rate": 1.5382841328413285e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.1993,
        "grad_norm": 1.5505715608596802,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.2806,
        "grad_norm": 1.0361523628234863,
        "learning_rate": 1.533671586715867e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.2974,
        "grad_norm": 104.78814697265625,
        "learning_rate": 1.5313653136531367e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.3023,
        "grad_norm": 3.011813163757324,
        "learning_rate": 1.5290590405904058e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.4102,
        "grad_norm": 9.278148651123047,
        "learning_rate": 1.5267527675276756e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.2663,
        "grad_norm": 3.7156012058258057,
        "learning_rate": 1.5244464944649448e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2859,
        "grad_norm": 1.3100441694259644,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.3535,
        "grad_norm": 6.9836201667785645,
        "learning_rate": 1.5198339483394835e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.2844,
        "grad_norm": 3.3595004081726074,
        "learning_rate": 1.5175276752767528e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.3296,
        "grad_norm": 9.79337215423584,
        "learning_rate": 1.515221402214022e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.2982,
        "grad_norm": 3.306896209716797,
        "learning_rate": 1.5129151291512916e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.2171,
        "grad_norm": 12.13242244720459,
        "learning_rate": 1.5106088560885609e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.2792,
        "grad_norm": 14.34930419921875,
        "learning_rate": 1.5083025830258305e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.3443,
        "grad_norm": 3.027439594268799,
        "learning_rate": 1.5059963099630997e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.2355,
        "grad_norm": 30.784334182739258,
        "learning_rate": 1.503690036900369e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.3291,
        "grad_norm": 2.8876616954803467,
        "learning_rate": 1.5013837638376386e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.3560730814933777,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.84007,
        "eval_recall": 0.92579,
        "eval_f1": 0.88085,
        "eval_runtime": 18.1425,
        "eval_samples_per_second": 59.749,
        "eval_steps_per_second": 3.748,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.2381,
        "grad_norm": 3.644376516342163,
        "learning_rate": 1.4990774907749078e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.2968,
        "grad_norm": 12.382759094238281,
        "learning_rate": 1.4967712177121774e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.2827,
        "grad_norm": 1.9855650663375854,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.2227,
        "grad_norm": 2.7332868576049805,
        "learning_rate": 1.4921586715867159e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.3193,
        "grad_norm": 2.2728333473205566,
        "learning_rate": 1.4898523985239853e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.3941,
        "grad_norm": 8.813480377197266,
        "learning_rate": 1.4875461254612546e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.3703,
        "grad_norm": 2.070863723754883,
        "learning_rate": 1.485239852398524e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.275,
        "grad_norm": 2.62646746635437,
        "learning_rate": 1.4829335793357934e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.2057,
        "grad_norm": 1.7544989585876465,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.1773,
        "grad_norm": 1.4842169284820557,
        "learning_rate": 1.4783210332103323e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.2877,
        "grad_norm": 7.745761394500732,
        "learning_rate": 1.4760147601476015e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.2812,
        "grad_norm": 4.255610466003418,
        "learning_rate": 1.4737084870848708e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.318,
        "grad_norm": 7.345278739929199,
        "learning_rate": 1.4714022140221404e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.2218,
        "grad_norm": 1.8709969520568848,
        "learning_rate": 1.4690959409594096e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.2908,
        "grad_norm": 5.003536224365234,
        "learning_rate": 1.4667896678966792e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.1909,
        "grad_norm": 2.7590832710266113,
        "learning_rate": 1.4644833948339485e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.3595,
        "grad_norm": 5.141848087310791,
        "learning_rate": 1.4621771217712177e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.2676,
        "grad_norm": 63.50984573364258,
        "learning_rate": 1.4598708487084871e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.2862,
        "grad_norm": 8.557066917419434,
        "learning_rate": 1.4575645756457566e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.3338,
        "grad_norm": 3.968705892562866,
        "learning_rate": 1.455258302583026e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.2548,
        "grad_norm": 5.466619968414307,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.2581,
        "grad_norm": 3.798724889755249,
        "learning_rate": 1.4506457564575645e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.2461,
        "grad_norm": 18.130859375,
        "learning_rate": 1.4483394833948341e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.2289,
        "grad_norm": 3.617785930633545,
        "learning_rate": 1.4460332103321033e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.2541,
        "grad_norm": 1.5121268033981323,
        "learning_rate": 1.4437269372693726e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.292,
        "grad_norm": 31.130247116088867,
        "learning_rate": 1.4414206642066422e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.2219,
        "grad_norm": 25.169750213623047,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.3953756093978882,
        "eval_accuracy": 0.87269,
        "eval_precision": 0.83811,
        "eval_recall": 0.92208,
        "eval_f1": 0.87809,
        "eval_runtime": 18.1037,
        "eval_samples_per_second": 59.877,
        "eval_steps_per_second": 3.756,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.3785,
        "grad_norm": 6.009010314941406,
        "learning_rate": 1.436808118081181e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.168,
        "grad_norm": 10.120080947875977,
        "learning_rate": 1.4345018450184503e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.2176,
        "grad_norm": 9.002877235412598,
        "learning_rate": 1.4321955719557195e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.1836,
        "grad_norm": 18.857824325561523,
        "learning_rate": 1.4298892988929891e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.2417,
        "grad_norm": 2.080605983734131,
        "learning_rate": 1.4275830258302584e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.2559,
        "grad_norm": 6.3516058921813965,
        "learning_rate": 1.4252767527675278e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.3552,
        "grad_norm": 5.1561174392700195,
        "learning_rate": 1.422970479704797e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.3282,
        "grad_norm": 4.768713474273682,
        "learning_rate": 1.4206642066420663e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.1889,
        "grad_norm": 2.568758487701416,
        "learning_rate": 1.4183579335793359e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.2569,
        "grad_norm": 5.265893459320068,
        "learning_rate": 1.4160516605166052e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.2504,
        "grad_norm": 6.634334087371826,
        "learning_rate": 1.4137453874538744e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.2422,
        "grad_norm": 2.652742862701416,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.2525,
        "grad_norm": 26.732280731201172,
        "learning_rate": 1.4091328413284133e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.2416,
        "grad_norm": 4.486798286437988,
        "learning_rate": 1.4068265682656829e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.2416,
        "grad_norm": 7.510008335113525,
        "learning_rate": 1.4045202952029521e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.2396,
        "grad_norm": 7.215256214141846,
        "learning_rate": 1.4022140221402214e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.2697,
        "grad_norm": 44.245243072509766,
        "learning_rate": 1.399907749077491e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.258,
        "grad_norm": 1.9866441488265991,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.2615,
        "grad_norm": 10.721969604492188,
        "learning_rate": 1.3952952029520296e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.3055,
        "grad_norm": 2.9340219497680664,
        "learning_rate": 1.3929889298892989e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.3194,
        "grad_norm": 2.006596326828003,
        "learning_rate": 1.3906826568265683e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.2091,
        "grad_norm": 6.270224094390869,
        "learning_rate": 1.3883763837638377e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.2175,
        "grad_norm": 2.015718698501587,
        "learning_rate": 1.386070110701107e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.2611,
        "grad_norm": 4.246104717254639,
        "learning_rate": 1.3837638376383766e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.2924,
        "grad_norm": 4.325539588928223,
        "learning_rate": 1.3814575645756458e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.3255,
        "grad_norm": 2.351691246032715,
        "learning_rate": 1.3791512915129151e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.2767,
        "grad_norm": 2.3161442279815674,
        "learning_rate": 1.3768450184501847e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.3652253746986389,
        "eval_accuracy": 0.87638,
        "eval_precision": 0.83142,
        "eval_recall": 0.94249,
        "eval_f1": 0.88348,
        "eval_runtime": 18.0851,
        "eval_samples_per_second": 59.939,
        "eval_steps_per_second": 3.76,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.3476,
        "grad_norm": 7.617055416107178,
        "learning_rate": 1.374538745387454e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.3009,
        "grad_norm": 2.6111807823181152,
        "learning_rate": 1.3722324723247232e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.2296,
        "grad_norm": 3.424313545227051,
        "learning_rate": 1.3699261992619928e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.2775,
        "grad_norm": 24.86054229736328,
        "learning_rate": 1.367619926199262e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2545,
        "grad_norm": 9.718887329101562,
        "learning_rate": 1.3653136531365315e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.2738,
        "grad_norm": 2.8106911182403564,
        "learning_rate": 1.3630073800738009e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.3106,
        "grad_norm": 6.981973648071289,
        "learning_rate": 1.3607011070110701e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2369,
        "grad_norm": 1.2396645545959473,
        "learning_rate": 1.3583948339483396e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.2572,
        "grad_norm": 1.9579235315322876,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.2408,
        "grad_norm": 6.512982368469238,
        "learning_rate": 1.3537822878228784e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.3086,
        "grad_norm": 3.00638747215271,
        "learning_rate": 1.3514760147601477e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.2183,
        "grad_norm": 6.853180885314941,
        "learning_rate": 1.3491697416974169e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.2074,
        "grad_norm": 4.189648151397705,
        "learning_rate": 1.3468634686346865e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.2507,
        "grad_norm": 6.434183597564697,
        "learning_rate": 1.3445571955719558e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.314,
        "grad_norm": 33.821014404296875,
        "learning_rate": 1.3422509225092253e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.2831,
        "grad_norm": 1.6411691904067993,
        "learning_rate": 1.3399446494464946e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.313,
        "grad_norm": 18.653823852539062,
        "learning_rate": 1.3376383763837639e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.3443,
        "grad_norm": 26.17868995666504,
        "learning_rate": 1.3353321033210334e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.2836,
        "grad_norm": 3.033979654312134,
        "learning_rate": 1.3330258302583027e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.316,
        "grad_norm": 4.147212028503418,
        "learning_rate": 1.330719557195572e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.2678,
        "grad_norm": 32.194068908691406,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.2267,
        "grad_norm": 5.737212181091309,
        "learning_rate": 1.3261070110701106e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.323,
        "grad_norm": 7.8635053634643555,
        "learning_rate": 1.3238007380073802e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2108,
        "grad_norm": 1.8805291652679443,
        "learning_rate": 1.3214944649446495e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.1752,
        "grad_norm": 16.17267608642578,
        "learning_rate": 1.3191881918819187e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.1668,
        "grad_norm": 2.6619651317596436,
        "learning_rate": 1.3168819188191883e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.3238,
        "grad_norm": 3.928508996963501,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.3856015205383301,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.84589,
        "eval_recall": 0.91651,
        "eval_f1": 0.87979,
        "eval_runtime": 18.0678,
        "eval_samples_per_second": 59.996,
        "eval_steps_per_second": 3.764,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.2322,
        "grad_norm": 4.29979944229126,
        "learning_rate": 1.3122693726937272e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.2536,
        "grad_norm": 3.6508078575134277,
        "learning_rate": 1.3099630996309964e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.2916,
        "grad_norm": 4.218455791473389,
        "learning_rate": 1.3076568265682657e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.1254,
        "grad_norm": 6.563473224639893,
        "learning_rate": 1.3053505535055353e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.3294,
        "grad_norm": 3.1900110244750977,
        "learning_rate": 1.3030442804428045e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.1916,
        "grad_norm": 3.6864187717437744,
        "learning_rate": 1.3007380073800738e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2526,
        "grad_norm": 10.37639045715332,
        "learning_rate": 1.2984317343173432e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.1642,
        "grad_norm": 7.407524585723877,
        "learning_rate": 1.2961254612546126e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.3093,
        "grad_norm": 13.19316577911377,
        "learning_rate": 1.293819188191882e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.3069,
        "grad_norm": 34.19048309326172,
        "learning_rate": 1.2915129151291513e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.2714,
        "grad_norm": 5.628503799438477,
        "learning_rate": 1.2892066420664205e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.227,
        "grad_norm": 17.43050765991211,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.2528,
        "grad_norm": 2.320152521133423,
        "learning_rate": 1.2845940959409594e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2839,
        "grad_norm": 2.6086881160736084,
        "learning_rate": 1.282287822878229e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.2548,
        "grad_norm": 5.8018012046813965,
        "learning_rate": 1.2799815498154982e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.2917,
        "grad_norm": 4.06500244140625,
        "learning_rate": 1.2776752767527675e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.3142,
        "grad_norm": 1.4324324131011963,
        "learning_rate": 1.2753690036900371e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.2004,
        "grad_norm": 2.2349696159362793,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.3099,
        "grad_norm": 11.767231941223145,
        "learning_rate": 1.2707564575645758e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.2563,
        "grad_norm": 3.2368428707122803,
        "learning_rate": 1.2684501845018452e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.2049,
        "grad_norm": 1.4017419815063477,
        "learning_rate": 1.2661439114391144e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.2586,
        "grad_norm": 2.070681571960449,
        "learning_rate": 1.2638376383763839e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.3173,
        "grad_norm": 18.607728958129883,
        "learning_rate": 1.2615313653136531e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.2764,
        "grad_norm": 34.4659538269043,
        "learning_rate": 1.2592250922509224e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.2496,
        "grad_norm": 4.258509159088135,
        "learning_rate": 1.256918819188192e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.1924,
        "grad_norm": 1.8152437210083008,
        "learning_rate": 1.2546125461254612e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.2651,
        "grad_norm": 2.3063883781433105,
        "learning_rate": 1.2523062730627308e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.2997,
        "grad_norm": 5.8831281661987305,
        "learning_rate": 1.25e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.3771167993545532,
        "eval_accuracy": 0.87823,
        "eval_precision": 0.84433,
        "eval_recall": 0.92579,
        "eval_f1": 0.88319,
        "eval_runtime": 18.0424,
        "eval_samples_per_second": 60.081,
        "eval_steps_per_second": 3.769,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.3037,
        "grad_norm": 7.732147693634033,
        "learning_rate": 1.2476937269372695e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.2944,
        "grad_norm": 2.11301851272583,
        "learning_rate": 1.2453874538745389e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2511,
        "grad_norm": 2.3654887676239014,
        "learning_rate": 1.2430811808118082e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.2401,
        "grad_norm": 4.657824516296387,
        "learning_rate": 1.2407749077490776e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2365,
        "grad_norm": 2.8987743854522705,
        "learning_rate": 1.238468634686347e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.2448,
        "grad_norm": 2.7610514163970947,
        "learning_rate": 1.2361623616236164e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.1484,
        "grad_norm": 7.839371204376221,
        "learning_rate": 1.2338560885608857e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.1972,
        "grad_norm": 7.0494704246521,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.289,
        "grad_norm": 3.3614590167999268,
        "learning_rate": 1.2292435424354244e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.2093,
        "grad_norm": 24.46701431274414,
        "learning_rate": 1.2269372693726938e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.3354,
        "grad_norm": 2.7049405574798584,
        "learning_rate": 1.2246309963099632e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.1731,
        "grad_norm": 2.8028743267059326,
        "learning_rate": 1.2223247232472325e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.2236,
        "grad_norm": 1.7444382905960083,
        "learning_rate": 1.2200184501845019e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.2107,
        "grad_norm": 1.7184574604034424,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.3335,
        "grad_norm": 21.19080924987793,
        "learning_rate": 1.2154059040590407e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.1686,
        "grad_norm": 4.019966125488281,
        "learning_rate": 1.21309963099631e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.2655,
        "grad_norm": 2.7960429191589355,
        "learning_rate": 1.2107933579335794e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.1943,
        "grad_norm": 6.5248918533325195,
        "learning_rate": 1.2084870848708488e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.3886,
        "grad_norm": 10.436773300170898,
        "learning_rate": 1.2061808118081182e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.2297,
        "grad_norm": 3.3109960556030273,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.2191,
        "grad_norm": 8.888348579406738,
        "learning_rate": 1.201568265682657e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.282,
        "grad_norm": 3.258882522583008,
        "learning_rate": 1.1992619926199262e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.2386,
        "grad_norm": 2.938743829727173,
        "learning_rate": 1.1969557195571956e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.2775,
        "grad_norm": 4.352596759796143,
        "learning_rate": 1.194649446494465e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.184,
        "grad_norm": 4.529046058654785,
        "learning_rate": 1.1923431734317343e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.2722,
        "grad_norm": 3.570840835571289,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.1738,
        "grad_norm": 12.255379676818848,
        "learning_rate": 1.1877306273062731e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.40890395641326904,
        "eval_accuracy": 0.87085,
        "eval_precision": 0.82867,
        "eval_recall": 0.93321,
        "eval_f1": 0.87784,
        "eval_runtime": 18.0801,
        "eval_samples_per_second": 59.956,
        "eval_steps_per_second": 3.761,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.2996,
        "grad_norm": 5.41058874130249,
        "learning_rate": 1.1854243542435425e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.2353,
        "grad_norm": 3.28328275680542,
        "learning_rate": 1.1831180811808118e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.2275,
        "grad_norm": 2.8973228931427,
        "learning_rate": 1.1808118081180812e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.2641,
        "grad_norm": 1.9813696146011353,
        "learning_rate": 1.1785055350553506e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.2772,
        "grad_norm": 3.501513719558716,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.1771,
        "grad_norm": 3.3603689670562744,
        "learning_rate": 1.1738929889298895e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.2275,
        "grad_norm": 6.666300296783447,
        "learning_rate": 1.1715867158671587e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.2669,
        "grad_norm": 4.213059425354004,
        "learning_rate": 1.1692804428044282e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.3222,
        "grad_norm": 8.570878028869629,
        "learning_rate": 1.1669741697416974e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.2055,
        "grad_norm": 5.1515984535217285,
        "learning_rate": 1.1646678966789668e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.2962,
        "grad_norm": 4.711178302764893,
        "learning_rate": 1.1623616236162361e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.1451,
        "grad_norm": 1.8841322660446167,
        "learning_rate": 1.1600553505535055e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.2962,
        "grad_norm": 2.513648271560669,
        "learning_rate": 1.157749077490775e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.2456,
        "grad_norm": 4.014299392700195,
        "learning_rate": 1.1554428044280444e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.2501,
        "grad_norm": 13.338297843933105,
        "learning_rate": 1.1531365313653138e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.2188,
        "grad_norm": 2.4618701934814453,
        "learning_rate": 1.150830258302583e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.2702,
        "grad_norm": 4.7543535232543945,
        "learning_rate": 1.1485239852398525e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.2426,
        "grad_norm": 2.5697293281555176,
        "learning_rate": 1.1462177121771219e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.1682,
        "grad_norm": 7.0188093185424805,
        "learning_rate": 1.1439114391143913e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.2197,
        "grad_norm": 2.1326332092285156,
        "learning_rate": 1.1416051660516606e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.1687,
        "grad_norm": 1.1333224773406982,
        "learning_rate": 1.13929889298893e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.1956,
        "grad_norm": 3.846686601638794,
        "learning_rate": 1.1369926199261992e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.2342,
        "grad_norm": 94.76051330566406,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.2139,
        "grad_norm": 4.759578227996826,
        "learning_rate": 1.1323800738007381e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.2839,
        "grad_norm": 63.82825469970703,
        "learning_rate": 1.1300738007380073e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.3465,
        "grad_norm": 2.65022611618042,
        "learning_rate": 1.1277675276752768e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.2466,
        "grad_norm": 3.53570294380188,
        "learning_rate": 1.1254612546125462e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.41529005765914917,
        "eval_accuracy": 0.86439,
        "eval_precision": 0.82026,
        "eval_recall": 0.93135,
        "eval_f1": 0.87228,
        "eval_runtime": 18.1418,
        "eval_samples_per_second": 59.752,
        "eval_steps_per_second": 3.748,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "train_runtime": 5153.366,
        "train_samples_per_second": 33.648,
        "train_steps_per_second": 2.103,
        "total_flos": 1.25464506748416e+16,
        "train_loss": 0.3229809014019811,
        "epoch": 22.0,
        "step": 5962
    }
]