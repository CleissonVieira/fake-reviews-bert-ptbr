[
    {
        "loss": 0.6285,
        "grad_norm": 14.44301986694336,
        "learning_rate": 2.4976937269372695e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.4885,
        "grad_norm": 7.478944778442383,
        "learning_rate": 2.495387453874539e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.491,
        "grad_norm": 7.371729373931885,
        "learning_rate": 2.493081180811808e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.4288,
        "grad_norm": 8.945064544677734,
        "learning_rate": 2.4907749077490778e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.502,
        "grad_norm": 8.084108352661133,
        "learning_rate": 2.488468634686347e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.5413,
        "grad_norm": 3.1245923042297363,
        "learning_rate": 2.4861623616236163e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.4214,
        "grad_norm": 4.567160606384277,
        "learning_rate": 2.4838560885608857e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.4113,
        "grad_norm": 5.070827960968018,
        "learning_rate": 2.481549815498155e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.425,
        "grad_norm": 3.2644906044006348,
        "learning_rate": 2.4792435424354242e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.4404,
        "grad_norm": 4.400032997131348,
        "learning_rate": 2.476937269372694e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.4603,
        "grad_norm": 5.204530239105225,
        "learning_rate": 2.474630996309963e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.5079,
        "grad_norm": 3.489499807357788,
        "learning_rate": 2.472324723247233e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4465,
        "grad_norm": 4.113524913787842,
        "learning_rate": 2.470018450184502e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4566,
        "grad_norm": 5.526686191558838,
        "learning_rate": 2.4677121771217714e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4467,
        "grad_norm": 3.1515023708343506,
        "learning_rate": 2.4654059040590408e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.5772,
        "grad_norm": 4.780453681945801,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.5058,
        "grad_norm": 5.87509298324585,
        "learning_rate": 2.4607933579335796e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.5023,
        "grad_norm": 4.9778337478637695,
        "learning_rate": 2.4584870848708487e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4295,
        "grad_norm": 3.2622756958007812,
        "learning_rate": 2.456180811808118e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4286,
        "grad_norm": 6.670543670654297,
        "learning_rate": 2.4538745387453876e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.5287,
        "grad_norm": 3.6194655895233154,
        "learning_rate": 2.451568265682657e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4367,
        "grad_norm": 2.4810380935668945,
        "learning_rate": 2.4492619926199264e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.4297,
        "grad_norm": 1.9794814586639404,
        "learning_rate": 2.4469557195571958e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.4239,
        "grad_norm": 2.290527582168579,
        "learning_rate": 2.444649446494465e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.5061,
        "grad_norm": 5.657931804656982,
        "learning_rate": 2.4423431734317347e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4652,
        "grad_norm": 2.6751837730407715,
        "learning_rate": 2.4400369003690038e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4298,
        "grad_norm": 2.2570714950561523,
        "learning_rate": 2.4377306273062732e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.42683905363082886,
        "eval_accuracy": 0.82565,
        "eval_precision": 0.77273,
        "eval_recall": 0.91806,
        "eval_f1": 0.83915,
        "eval_runtime": 18.1178,
        "eval_samples_per_second": 59.831,
        "eval_steps_per_second": 3.753,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.3413,
        "grad_norm": 2.4592671394348145,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.3683,
        "grad_norm": 1.6849467754364014,
        "learning_rate": 2.4331180811808117e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.4962,
        "grad_norm": 1.537837028503418,
        "learning_rate": 2.4308118081180815e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.3634,
        "grad_norm": 1.8053027391433716,
        "learning_rate": 2.4285055350553505e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.442,
        "grad_norm": 3.259995222091675,
        "learning_rate": 2.42619926199262e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.517,
        "grad_norm": 2.8371002674102783,
        "learning_rate": 2.4238929889298894e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.3841,
        "grad_norm": 3.00050950050354,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4927,
        "grad_norm": 5.208267688751221,
        "learning_rate": 2.4192804428044282e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4309,
        "grad_norm": 4.206704616546631,
        "learning_rate": 2.4169741697416977e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.3936,
        "grad_norm": 6.194457054138184,
        "learning_rate": 2.4146678966789667e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4267,
        "grad_norm": 2.5391530990600586,
        "learning_rate": 2.4123616236162365e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.3954,
        "grad_norm": 1.6884554624557495,
        "learning_rate": 2.4100553505535056e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.45,
        "grad_norm": 1.8733998537063599,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.4426,
        "grad_norm": 2.749051570892334,
        "learning_rate": 2.4054428044280444e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3271,
        "grad_norm": 3.166168451309204,
        "learning_rate": 2.403136531365314e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.5595,
        "grad_norm": 6.091935634613037,
        "learning_rate": 2.4008302583025833e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.427,
        "grad_norm": 3.8471620082855225,
        "learning_rate": 2.3985239852398524e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.4608,
        "grad_norm": 2.7234041690826416,
        "learning_rate": 2.3962177121771218e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.4268,
        "grad_norm": 2.329045295715332,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.4083,
        "grad_norm": 2.965207576751709,
        "learning_rate": 2.3916051660516606e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.518,
        "grad_norm": 3.6250972747802734,
        "learning_rate": 2.38929889298893e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4286,
        "grad_norm": 2.37440824508667,
        "learning_rate": 2.3869926199261995e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.3721,
        "grad_norm": 5.689784049987793,
        "learning_rate": 2.3846863468634686e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.3946,
        "grad_norm": 3.664717197418213,
        "learning_rate": 2.3823800738007383e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.3462,
        "grad_norm": 3.5141069889068604,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.3443,
        "grad_norm": 2.69340181350708,
        "learning_rate": 2.377767527675277e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.4052,
        "grad_norm": 2.984839916229248,
        "learning_rate": 2.3754612546125462e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.43160760402679443,
        "eval_accuracy": 0.78598,
        "eval_precision": 0.7121,
        "eval_recall": 0.95345,
        "eval_f1": 0.81529,
        "eval_runtime": 18.0648,
        "eval_samples_per_second": 60.006,
        "eval_steps_per_second": 3.764,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.4241,
        "grad_norm": 2.25795578956604,
        "learning_rate": 2.3731549815498157e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4472,
        "grad_norm": 5.819504261016846,
        "learning_rate": 2.370848708487085e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.2884,
        "grad_norm": 1.9476710557937622,
        "learning_rate": 2.3685424354243542e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3494,
        "grad_norm": 1.9299029111862183,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.4243,
        "grad_norm": 1.5897718667984009,
        "learning_rate": 2.363929889298893e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.3877,
        "grad_norm": 1.8680660724639893,
        "learning_rate": 2.3616236162361624e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.4416,
        "grad_norm": 7.601996421813965,
        "learning_rate": 2.359317343173432e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4629,
        "grad_norm": 4.188368797302246,
        "learning_rate": 2.3570110701107013e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.3397,
        "grad_norm": 1.7408318519592285,
        "learning_rate": 2.3547047970479704e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.4649,
        "grad_norm": 4.030142784118652,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.3529,
        "grad_norm": 1.6711279153823853,
        "learning_rate": 2.3500922509225092e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.3174,
        "grad_norm": 2.4843356609344482,
        "learning_rate": 2.347785977859779e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3821,
        "grad_norm": 2.5922772884368896,
        "learning_rate": 2.345479704797048e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.3596,
        "grad_norm": 2.143904685974121,
        "learning_rate": 2.3431734317343175e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.4056,
        "grad_norm": 4.135839939117432,
        "learning_rate": 2.340867158671587e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.346,
        "grad_norm": 2.112816572189331,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.342,
        "grad_norm": 2.8358218669891357,
        "learning_rate": 2.3362546125461258e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.3614,
        "grad_norm": 3.275914192199707,
        "learning_rate": 2.333948339483395e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3597,
        "grad_norm": 0.9274168014526367,
        "learning_rate": 2.3316420664206643e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4688,
        "grad_norm": 2.1369245052337646,
        "learning_rate": 2.3293357933579337e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3534,
        "grad_norm": 1.7168591022491455,
        "learning_rate": 2.327029520295203e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.3902,
        "grad_norm": 3.056259870529175,
        "learning_rate": 2.3247232472324722e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.3146,
        "grad_norm": 2.6821815967559814,
        "learning_rate": 2.322416974169742e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.3597,
        "grad_norm": 4.883639812469482,
        "learning_rate": 2.320110701107011e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.5832,
        "grad_norm": 5.6348724365234375,
        "learning_rate": 2.3178044280442808e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3928,
        "grad_norm": 2.5157885551452637,
        "learning_rate": 2.31549815498155e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.4651,
        "grad_norm": 3.5730113983154297,
        "learning_rate": 2.3131918819188193e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.4128633737564087,
        "eval_accuracy": 0.83948,
        "eval_precision": 0.79417,
        "eval_recall": 0.91248,
        "eval_f1": 0.84922,
        "eval_runtime": 18.0833,
        "eval_samples_per_second": 59.945,
        "eval_steps_per_second": 3.76,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3664,
        "grad_norm": 2.924565076828003,
        "learning_rate": 2.3108856088560887e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3474,
        "grad_norm": 2.7806057929992676,
        "learning_rate": 2.308579335793358e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.4282,
        "grad_norm": 4.253681659698486,
        "learning_rate": 2.3062730627306276e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.3997,
        "grad_norm": 2.204569101333618,
        "learning_rate": 2.3039667896678967e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.3506,
        "grad_norm": 3.6321163177490234,
        "learning_rate": 2.301660516605166e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.3824,
        "grad_norm": 1.1475545167922974,
        "learning_rate": 2.2993542435424355e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.4074,
        "grad_norm": 5.167178630828857,
        "learning_rate": 2.297047970479705e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3469,
        "grad_norm": 4.634147644042969,
        "learning_rate": 2.294741697416974e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.3447,
        "grad_norm": 1.9620563983917236,
        "learning_rate": 2.2924354243542438e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3739,
        "grad_norm": 3.3733534812927246,
        "learning_rate": 2.290129151291513e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.409,
        "grad_norm": 13.702044486999512,
        "learning_rate": 2.2878228782287826e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.4021,
        "grad_norm": 3.1840474605560303,
        "learning_rate": 2.2855166051660517e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.3503,
        "grad_norm": 3.9922244548797607,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.3377,
        "grad_norm": 5.020839214324951,
        "learning_rate": 2.2809040590405906e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.434,
        "grad_norm": 2.6446759700775146,
        "learning_rate": 2.27859778597786e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.3585,
        "grad_norm": 6.949090480804443,
        "learning_rate": 2.2762915129151294e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3128,
        "grad_norm": 2.4371747970581055,
        "learning_rate": 2.2739852398523985e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.4034,
        "grad_norm": 2.693439483642578,
        "learning_rate": 2.271678966789668e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.342,
        "grad_norm": 5.684597015380859,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.399,
        "grad_norm": 2.471794366836548,
        "learning_rate": 2.2670664206642068e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.2918,
        "grad_norm": 1.3683476448059082,
        "learning_rate": 2.2647601476014762e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.3368,
        "grad_norm": 1.939009428024292,
        "learning_rate": 2.2624538745387456e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3066,
        "grad_norm": 1.0986641645431519,
        "learning_rate": 2.2601476014760147e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3587,
        "grad_norm": 1.5920008420944214,
        "learning_rate": 2.2578413284132844e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.427,
        "grad_norm": 3.3755016326904297,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.4238,
        "grad_norm": 5.849358558654785,
        "learning_rate": 2.253228782287823e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.2795,
        "grad_norm": 2.18214750289917,
        "learning_rate": 2.2509225092250924e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.3796559274196625,
        "eval_accuracy": 0.85609,
        "eval_precision": 0.80676,
        "eval_recall": 0.93296,
        "eval_f1": 0.86528,
        "eval_runtime": 18.0718,
        "eval_samples_per_second": 59.983,
        "eval_steps_per_second": 3.763,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3409,
        "grad_norm": 7.809508323669434,
        "learning_rate": 2.2486162361623618e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.4208,
        "grad_norm": 2.696589231491089,
        "learning_rate": 2.2463099630996312e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.2909,
        "grad_norm": 2.8566699028015137,
        "learning_rate": 2.2440036900369006e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3865,
        "grad_norm": 5.113746643066406,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.4126,
        "grad_norm": 2.0557773113250732,
        "learning_rate": 2.239391143911439e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3733,
        "grad_norm": 1.1692771911621094,
        "learning_rate": 2.2370848708487086e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3648,
        "grad_norm": 2.26096773147583,
        "learning_rate": 2.234778597785978e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3243,
        "grad_norm": 1.3896214962005615,
        "learning_rate": 2.2324723247232474e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.3438,
        "grad_norm": 4.688501834869385,
        "learning_rate": 2.2301660516605165e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.3477,
        "grad_norm": 8.365548133850098,
        "learning_rate": 2.2278597785977863e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.3114,
        "grad_norm": 3.5679409503936768,
        "learning_rate": 2.2255535055350553e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3707,
        "grad_norm": 1.1898653507232666,
        "learning_rate": 2.2232472324723248e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.2828,
        "grad_norm": 7.080223083496094,
        "learning_rate": 2.2209409594095942e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3256,
        "grad_norm": 2.677983283996582,
        "learning_rate": 2.2186346863468636e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.4153,
        "grad_norm": 3.78304123878479,
        "learning_rate": 2.216328413284133e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3033,
        "grad_norm": 6.587501525878906,
        "learning_rate": 2.2140221402214025e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.353,
        "grad_norm": 3.196458578109741,
        "learning_rate": 2.2117158671586715e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.2596,
        "grad_norm": 1.6009217500686646,
        "learning_rate": 2.209409594095941e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3372,
        "grad_norm": 3.73227596282959,
        "learning_rate": 2.2071033210332104e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.3014,
        "grad_norm": 4.743771553039551,
        "learning_rate": 2.2047970479704798e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.363,
        "grad_norm": 4.016939163208008,
        "learning_rate": 2.2024907749077492e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.3514,
        "grad_norm": 16.606508255004883,
        "learning_rate": 2.2001845018450183e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.3225,
        "grad_norm": 2.260279417037964,
        "learning_rate": 2.197878228782288e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.336,
        "grad_norm": 4.886483192443848,
        "learning_rate": 2.195571955719557e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.29,
        "grad_norm": 4.578133583068848,
        "learning_rate": 2.193265682656827e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.4294,
        "grad_norm": 1.5531879663467407,
        "learning_rate": 2.190959409594096e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.2936,
        "grad_norm": 12.10541820526123,
        "learning_rate": 2.1886531365313654e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.40105897188186646,
        "eval_accuracy": 0.8524,
        "eval_precision": 0.79592,
        "eval_recall": 0.94413,
        "eval_f1": 0.86371,
        "eval_runtime": 18.0736,
        "eval_samples_per_second": 59.977,
        "eval_steps_per_second": 3.762,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.453,
        "grad_norm": 2.3383123874664307,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.4274,
        "grad_norm": 2.2486579418182373,
        "learning_rate": 2.1840405904059043e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.2829,
        "grad_norm": 3.126844644546509,
        "learning_rate": 2.1817343173431734e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.3461,
        "grad_norm": 1.2414186000823975,
        "learning_rate": 2.1794280442804428e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.2359,
        "grad_norm": 1.7841811180114746,
        "learning_rate": 2.1771217712177122e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.4389,
        "grad_norm": 5.639988422393799,
        "learning_rate": 2.1748154981549816e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.3927,
        "grad_norm": 3.4273550510406494,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.3341,
        "grad_norm": 22.38312530517578,
        "learning_rate": 2.17020295202952e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.2847,
        "grad_norm": 2.1792211532592773,
        "learning_rate": 2.16789667896679e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.2939,
        "grad_norm": 5.956272602081299,
        "learning_rate": 2.165590405904059e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.3206,
        "grad_norm": 1.806484580039978,
        "learning_rate": 2.1632841328413287e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.3649,
        "grad_norm": 5.373586177825928,
        "learning_rate": 2.160977859778598e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.2876,
        "grad_norm": 9.417250633239746,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.3511,
        "grad_norm": 12.713028907775879,
        "learning_rate": 2.1563653136531367e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.3236,
        "grad_norm": 8.499258995056152,
        "learning_rate": 2.154059040590406e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.3772,
        "grad_norm": 1.8544639348983765,
        "learning_rate": 2.1517527675276755e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.2828,
        "grad_norm": 0.9981850385665894,
        "learning_rate": 2.149446494464945e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.3884,
        "grad_norm": 3.904623031616211,
        "learning_rate": 2.147140221402214e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.3414,
        "grad_norm": 4.888516426086426,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.2712,
        "grad_norm": 5.988472938537598,
        "learning_rate": 2.142527675276753e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.3725,
        "grad_norm": 4.275907039642334,
        "learning_rate": 2.140221402214022e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.3018,
        "grad_norm": 3.155871629714966,
        "learning_rate": 2.1379151291512917e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.3027,
        "grad_norm": 1.9688315391540527,
        "learning_rate": 2.1356088560885608e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.4612,
        "grad_norm": 3.6848466396331787,
        "learning_rate": 2.1333025830258306e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.3422,
        "grad_norm": 2.8955078125,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.3325,
        "grad_norm": 1.9194185733795166,
        "learning_rate": 2.128690036900369e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.3306,
        "grad_norm": 1.3279231786727905,
        "learning_rate": 2.1263837638376385e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.3845832049846649,
        "eval_accuracy": 0.85609,
        "eval_precision": 0.80976,
        "eval_recall": 0.92737,
        "eval_f1": 0.86458,
        "eval_runtime": 18.0749,
        "eval_samples_per_second": 59.973,
        "eval_steps_per_second": 3.762,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.2802,
        "grad_norm": 1.8604791164398193,
        "learning_rate": 2.124077490774908e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3577,
        "grad_norm": 0.7148536443710327,
        "learning_rate": 2.1217712177121773e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.2527,
        "grad_norm": 2.413078546524048,
        "learning_rate": 2.1194649446494468e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.3204,
        "grad_norm": 4.11019229888916,
        "learning_rate": 2.117158671586716e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.4767,
        "grad_norm": 5.023024559020996,
        "learning_rate": 2.1148523985239853e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.2634,
        "grad_norm": 1.615621566772461,
        "learning_rate": 2.1125461254612547e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.3216,
        "grad_norm": 0.9179818630218506,
        "learning_rate": 2.110239852398524e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.2783,
        "grad_norm": 4.16704797744751,
        "learning_rate": 2.1079335793357935e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3834,
        "grad_norm": 3.0049655437469482,
        "learning_rate": 2.1056273062730626e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.2784,
        "grad_norm": 9.075891494750977,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.3764,
        "grad_norm": 4.459514141082764,
        "learning_rate": 2.1010147601476015e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.2128,
        "grad_norm": 3.7647006511688232,
        "learning_rate": 2.098708487084871e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.3455,
        "grad_norm": 5.545303821563721,
        "learning_rate": 2.0964022140221403e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.3934,
        "grad_norm": 24.159618377685547,
        "learning_rate": 2.0940959409594097e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3128,
        "grad_norm": 2.5323832035064697,
        "learning_rate": 2.091789667896679e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.2757,
        "grad_norm": 20.488510131835938,
        "learning_rate": 2.0894833948339486e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.4044,
        "grad_norm": 5.113313674926758,
        "learning_rate": 2.0871771217712177e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.2631,
        "grad_norm": 3.923964023590088,
        "learning_rate": 2.084870848708487e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.2704,
        "grad_norm": 4.110067844390869,
        "learning_rate": 2.0825645756457565e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3103,
        "grad_norm": 2.6489903926849365,
        "learning_rate": 2.080258302583026e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3416,
        "grad_norm": 2.234671115875244,
        "learning_rate": 2.0779520295202954e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3216,
        "grad_norm": 3.125638723373413,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.2749,
        "grad_norm": 7.639080047607422,
        "learning_rate": 2.0733394833948342e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.3614,
        "grad_norm": 14.367594718933105,
        "learning_rate": 2.0710332103321033e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.2601,
        "grad_norm": 16.290281295776367,
        "learning_rate": 2.0687269372693727e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.3074,
        "grad_norm": 2.251227617263794,
        "learning_rate": 2.066420664206642e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3129,
        "grad_norm": 9.495134353637695,
        "learning_rate": 2.0641143911439116e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.3856932520866394,
        "eval_accuracy": 0.85055,
        "eval_precision": 0.81095,
        "eval_recall": 0.91061,
        "eval_f1": 0.85789,
        "eval_runtime": 18.0719,
        "eval_samples_per_second": 59.983,
        "eval_steps_per_second": 3.763,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.321,
        "grad_norm": 2.232421875,
        "learning_rate": 2.061808118081181e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.3378,
        "grad_norm": 2.2351653575897217,
        "learning_rate": 2.0595018450184504e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3271,
        "grad_norm": 6.029372692108154,
        "learning_rate": 2.0571955719557195e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.2623,
        "grad_norm": 3.514181137084961,
        "learning_rate": 2.0548892988929893e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.2347,
        "grad_norm": 3.0212202072143555,
        "learning_rate": 2.0525830258302583e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3243,
        "grad_norm": 3.4002017974853516,
        "learning_rate": 2.0502767527675278e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.3121,
        "grad_norm": 5.140223026275635,
        "learning_rate": 2.0479704797047972e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.3453,
        "grad_norm": 22.650901794433594,
        "learning_rate": 2.0456642066420663e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.2557,
        "grad_norm": 2.8366739749908447,
        "learning_rate": 2.043357933579336e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.2734,
        "grad_norm": 3.690913200378418,
        "learning_rate": 2.041051660516605e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.3143,
        "grad_norm": 6.521719932556152,
        "learning_rate": 2.0387453874538745e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3187,
        "grad_norm": 8.137688636779785,
        "learning_rate": 2.036439114391144e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.3674,
        "grad_norm": 3.397819757461548,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3228,
        "grad_norm": 7.102027416229248,
        "learning_rate": 2.0318265682656828e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.2935,
        "grad_norm": 3.2240681648254395,
        "learning_rate": 2.0295202952029522e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.2977,
        "grad_norm": 2.834639310836792,
        "learning_rate": 2.0272140221402213e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.1675,
        "grad_norm": 2.3826634883880615,
        "learning_rate": 2.024907749077491e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.2753,
        "grad_norm": 3.7118899822235107,
        "learning_rate": 2.02260147601476e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.3272,
        "grad_norm": 5.8589701652526855,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.359,
        "grad_norm": 9.378406524658203,
        "learning_rate": 2.017988929889299e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.4165,
        "grad_norm": 3.188298225402832,
        "learning_rate": 2.0156826568265684e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.2646,
        "grad_norm": 4.145162582397461,
        "learning_rate": 2.013376383763838e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.3977,
        "grad_norm": 4.8877973556518555,
        "learning_rate": 2.011070110701107e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.3288,
        "grad_norm": 8.178618431091309,
        "learning_rate": 2.0087638376383767e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.3242,
        "grad_norm": 9.892218589782715,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.3375,
        "grad_norm": 2.3658506870269775,
        "learning_rate": 2.0041512915129152e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.3662,
        "grad_norm": 2.8810787200927734,
        "learning_rate": 2.0018450184501846e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.3784523904323578,
        "eval_accuracy": 0.85978,
        "eval_precision": 0.82462,
        "eval_recall": 0.91061,
        "eval_f1": 0.86549,
        "eval_runtime": 18.0636,
        "eval_samples_per_second": 60.01,
        "eval_steps_per_second": 3.764,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.2842,
        "grad_norm": 8.972404479980469,
        "learning_rate": 1.999538745387454e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.324,
        "grad_norm": 2.7833244800567627,
        "learning_rate": 1.997232472324723e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.2565,
        "grad_norm": 6.479126930236816,
        "learning_rate": 1.994926199261993e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.1932,
        "grad_norm": 3.781643867492676,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.3101,
        "grad_norm": 6.985536575317383,
        "learning_rate": 1.9903136531365314e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.2065,
        "grad_norm": 19.25499153137207,
        "learning_rate": 1.9880073800738008e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.3921,
        "grad_norm": 5.718306541442871,
        "learning_rate": 1.9857011070110702e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.2509,
        "grad_norm": 4.075249195098877,
        "learning_rate": 1.9833948339483397e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.3299,
        "grad_norm": 3.5258946418762207,
        "learning_rate": 1.9810885608856088e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.3504,
        "grad_norm": 2.8939197063446045,
        "learning_rate": 1.9787822878228785e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.3332,
        "grad_norm": 2.251115560531616,
        "learning_rate": 1.9764760147601476e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.2844,
        "grad_norm": 5.978257656097412,
        "learning_rate": 1.974169741697417e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.2839,
        "grad_norm": 2.163220167160034,
        "learning_rate": 1.9718634686346864e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.3482,
        "grad_norm": 2.336344003677368,
        "learning_rate": 1.969557195571956e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.3048,
        "grad_norm": 5.383065223693848,
        "learning_rate": 1.9672509225092253e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.2632,
        "grad_norm": 2.330674409866333,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.3356,
        "grad_norm": 1.9543473720550537,
        "learning_rate": 1.9626383763837638e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3132,
        "grad_norm": 1.1522096395492554,
        "learning_rate": 1.9603321033210336e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.2694,
        "grad_norm": 14.203681945800781,
        "learning_rate": 1.9580258302583026e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.3129,
        "grad_norm": 2.7389676570892334,
        "learning_rate": 1.955719557195572e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3578,
        "grad_norm": 4.131920337677002,
        "learning_rate": 1.9534132841328415e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.3512,
        "grad_norm": 5.222145080566406,
        "learning_rate": 1.9511070110701106e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.2733,
        "grad_norm": 2.084228754043579,
        "learning_rate": 1.9488007380073803e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.253,
        "grad_norm": 1.3894437551498413,
        "learning_rate": 1.9464944649446494e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.3824,
        "grad_norm": 7.042158126831055,
        "learning_rate": 1.944188191881919e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.2834,
        "grad_norm": 4.284273624420166,
        "learning_rate": 1.9418819188191883e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3255,
        "grad_norm": 6.445160388946533,
        "learning_rate": 1.9395756457564577e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.3899192214012146,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.80583,
        "eval_recall": 0.92737,
        "eval_f1": 0.86234,
        "eval_runtime": 18.0731,
        "eval_samples_per_second": 59.979,
        "eval_steps_per_second": 3.762,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.2878,
        "grad_norm": 3.037367582321167,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.2234,
        "grad_norm": 2.470794916152954,
        "learning_rate": 1.9349630996309965e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3826,
        "grad_norm": 9.51639175415039,
        "learning_rate": 1.9326568265682656e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.2735,
        "grad_norm": 4.009552955627441,
        "learning_rate": 1.9303505535055354e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.2798,
        "grad_norm": 8.645243644714355,
        "learning_rate": 1.9280442804428045e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.3058,
        "grad_norm": 5.312842845916748,
        "learning_rate": 1.925738007380074e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3854,
        "grad_norm": 5.687657356262207,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.3372,
        "grad_norm": 5.7309465408325195,
        "learning_rate": 1.9211254612546127e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.2431,
        "grad_norm": 1.5030252933502197,
        "learning_rate": 1.918819188191882e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.3765,
        "grad_norm": 17.55634117126465,
        "learning_rate": 1.9165129151291512e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.3518,
        "grad_norm": 5.131786823272705,
        "learning_rate": 1.9142066420664207e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.3424,
        "grad_norm": 3.547578811645508,
        "learning_rate": 1.91190036900369e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.2596,
        "grad_norm": 1.861718773841858,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.2893,
        "grad_norm": 3.052239179611206,
        "learning_rate": 1.907287822878229e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.296,
        "grad_norm": 9.068310737609863,
        "learning_rate": 1.9049815498154984e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.1767,
        "grad_norm": 5.350156784057617,
        "learning_rate": 1.9026752767527674e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.2659,
        "grad_norm": 3.225494146347046,
        "learning_rate": 1.9003690036900372e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.423,
        "grad_norm": 7.2037272453308105,
        "learning_rate": 1.8980627306273063e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.1614,
        "grad_norm": 7.645941257476807,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.2662,
        "grad_norm": 16.03661346435547,
        "learning_rate": 1.893450184501845e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.2823,
        "grad_norm": 6.852962970733643,
        "learning_rate": 1.8911439114391146e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.283,
        "grad_norm": 3.782179355621338,
        "learning_rate": 1.888837638376384e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.255,
        "grad_norm": 2.110154390335083,
        "learning_rate": 1.886531365313653e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.2741,
        "grad_norm": 1.858284592628479,
        "learning_rate": 1.8842250922509225e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.2623,
        "grad_norm": 7.981845378875732,
        "learning_rate": 1.881918819188192e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.2751,
        "grad_norm": 1.0240174531936646,
        "learning_rate": 1.8796125461254613e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.4473,
        "grad_norm": 2.5885872840881348,
        "learning_rate": 1.8773062730627308e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.2668,
        "grad_norm": 3.9997310638427734,
        "learning_rate": 1.8750000000000002e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.37740808725357056,
        "eval_accuracy": 0.86347,
        "eval_precision": 0.83362,
        "eval_recall": 0.90503,
        "eval_f1": 0.86786,
        "eval_runtime": 18.0437,
        "eval_samples_per_second": 60.076,
        "eval_steps_per_second": 3.769,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.2733,
        "grad_norm": 7.838198661804199,
        "learning_rate": 1.8726937269372693e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.2374,
        "grad_norm": 8.377423286437988,
        "learning_rate": 1.870387453874539e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.2023,
        "grad_norm": 6.242789268493652,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.2856,
        "grad_norm": 0.9763500094413757,
        "learning_rate": 1.865774907749078e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.2906,
        "grad_norm": 0.7172797918319702,
        "learning_rate": 1.863468634686347e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.2205,
        "grad_norm": 2.194328546524048,
        "learning_rate": 1.8611623616236164e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.3335,
        "grad_norm": 8.909774780273438,
        "learning_rate": 1.8588560885608858e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.2947,
        "grad_norm": 2.0558254718780518,
        "learning_rate": 1.856549815498155e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.3873,
        "grad_norm": 9.984427452087402,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3135,
        "grad_norm": 4.418636322021484,
        "learning_rate": 1.8519372693726937e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.2683,
        "grad_norm": 4.032258987426758,
        "learning_rate": 1.849630996309963e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.2552,
        "grad_norm": 6.047248840332031,
        "learning_rate": 1.8473247232472326e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.3609,
        "grad_norm": 16.603862762451172,
        "learning_rate": 1.845018450184502e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.3649,
        "grad_norm": 7.364208698272705,
        "learning_rate": 1.842712177121771e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.3068,
        "grad_norm": 3.8310630321502686,
        "learning_rate": 1.840405904059041e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.2481,
        "grad_norm": 3.533031702041626,
        "learning_rate": 1.83809963099631e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.2434,
        "grad_norm": 13.276281356811523,
        "learning_rate": 1.8357933579335797e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.2447,
        "grad_norm": 3.1129298210144043,
        "learning_rate": 1.8334870848708488e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2006,
        "grad_norm": 6.3906731605529785,
        "learning_rate": 1.8311808118081182e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.2749,
        "grad_norm": 9.329397201538086,
        "learning_rate": 1.8288745387453876e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.2963,
        "grad_norm": 22.38303565979004,
        "learning_rate": 1.826568265682657e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.2933,
        "grad_norm": 7.134751319885254,
        "learning_rate": 1.8242619926199265e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.2675,
        "grad_norm": 4.558863162994385,
        "learning_rate": 1.8219557195571955e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.3471,
        "grad_norm": 10.494982719421387,
        "learning_rate": 1.819649446494465e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.3654,
        "grad_norm": 9.407645225524902,
        "learning_rate": 1.8173431734317344e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.2996,
        "grad_norm": 9.10827350616455,
        "learning_rate": 1.8150369003690038e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.284,
        "grad_norm": 9.474169731140137,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.4034155011177063,
        "eval_accuracy": 0.85793,
        "eval_precision": 0.80738,
        "eval_recall": 0.93669,
        "eval_f1": 0.86724,
        "eval_runtime": 18.078,
        "eval_samples_per_second": 59.962,
        "eval_steps_per_second": 3.761,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.2661,
        "grad_norm": 2.523113250732422,
        "learning_rate": 1.8104243542435427e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.2925,
        "grad_norm": 1.766987681388855,
        "learning_rate": 1.8081180811808117e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.3173,
        "grad_norm": 5.4077229499816895,
        "learning_rate": 1.8058118081180815e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.3774,
        "grad_norm": 4.386114597320557,
        "learning_rate": 1.8035055350553506e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.2566,
        "grad_norm": 2.068352699279785,
        "learning_rate": 1.80119926199262e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.1759,
        "grad_norm": 5.163170337677002,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.2599,
        "grad_norm": 3.4405224323272705,
        "learning_rate": 1.796586715867159e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.1548,
        "grad_norm": 8.357013702392578,
        "learning_rate": 1.7942804428044283e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.4085,
        "grad_norm": 2.125319242477417,
        "learning_rate": 1.7919741697416974e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.378,
        "grad_norm": 4.257080554962158,
        "learning_rate": 1.7896678966789668e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.2701,
        "grad_norm": 8.777610778808594,
        "learning_rate": 1.7873616236162362e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.2684,
        "grad_norm": 3.0133018493652344,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.2723,
        "grad_norm": 10.021350860595703,
        "learning_rate": 1.7827490774907747e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.3025,
        "grad_norm": 3.598357677459717,
        "learning_rate": 1.7804428044280445e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.2415,
        "grad_norm": 5.125465393066406,
        "learning_rate": 1.7781365313653136e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.3021,
        "grad_norm": 1.9541072845458984,
        "learning_rate": 1.7758302583025833e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.2454,
        "grad_norm": 1.6572065353393555,
        "learning_rate": 1.7735239852398524e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.2693,
        "grad_norm": 3.6696250438690186,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.3061,
        "grad_norm": 22.133827209472656,
        "learning_rate": 1.7689114391143913e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.2682,
        "grad_norm": 7.121306419372559,
        "learning_rate": 1.7666051660516607e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2414,
        "grad_norm": 11.961832046508789,
        "learning_rate": 1.76429889298893e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.2686,
        "grad_norm": 2.72206711769104,
        "learning_rate": 1.7619926199261992e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.2791,
        "grad_norm": 1.0765396356582642,
        "learning_rate": 1.7596863468634686e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.4044,
        "grad_norm": 5.142112731933594,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.2048,
        "grad_norm": 1.4725061655044556,
        "learning_rate": 1.7550738007380075e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2558,
        "grad_norm": 1.651504397392273,
        "learning_rate": 1.752767527675277e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.3176,
        "grad_norm": 2.318204641342163,
        "learning_rate": 1.7504612546125463e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.4096832573413849,
        "eval_accuracy": 0.86993,
        "eval_precision": 0.82673,
        "eval_recall": 0.93296,
        "eval_f1": 0.87664,
        "eval_runtime": 18.0688,
        "eval_samples_per_second": 59.993,
        "eval_steps_per_second": 3.763,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.3719,
        "grad_norm": 6.775883674621582,
        "learning_rate": 1.7481549815498154e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.2969,
        "grad_norm": 8.965615272521973,
        "learning_rate": 1.745848708487085e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.2832,
        "grad_norm": 2.0491185188293457,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.2448,
        "grad_norm": 3.7970359325408936,
        "learning_rate": 1.7412361623616237e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2236,
        "grad_norm": 0.9971399307250977,
        "learning_rate": 1.738929889298893e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.319,
        "grad_norm": 2.5018150806427,
        "learning_rate": 1.7366236162361625e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.3292,
        "grad_norm": 1.604730248451233,
        "learning_rate": 1.734317343173432e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.2632,
        "grad_norm": 6.913519382476807,
        "learning_rate": 1.7320110701107013e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.3862,
        "grad_norm": 13.876912117004395,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.2279,
        "grad_norm": 1.6985679864883423,
        "learning_rate": 1.72739852398524e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.306,
        "grad_norm": 4.217651844024658,
        "learning_rate": 1.7250922509225093e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.2973,
        "grad_norm": 1.5707365274429321,
        "learning_rate": 1.7227859778597787e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.2416,
        "grad_norm": 6.443972587585449,
        "learning_rate": 1.720479704797048e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.248,
        "grad_norm": 21.603782653808594,
        "learning_rate": 1.7181734317343172e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.2467,
        "grad_norm": 5.9085917472839355,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.25,
        "grad_norm": 13.295347213745117,
        "learning_rate": 1.713560885608856e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.2928,
        "grad_norm": 1.9098622798919678,
        "learning_rate": 1.7112546125461258e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.3142,
        "grad_norm": 22.7313175201416,
        "learning_rate": 1.708948339483395e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.3011,
        "grad_norm": 1.9964619874954224,
        "learning_rate": 1.7066420664206643e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.3389,
        "grad_norm": 4.655456066131592,
        "learning_rate": 1.7043357933579337e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.2934,
        "grad_norm": 9.51851749420166,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.2817,
        "grad_norm": 1.5990413427352905,
        "learning_rate": 1.6997232472324722e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.2101,
        "grad_norm": 2.7389981746673584,
        "learning_rate": 1.6974169741697417e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.2505,
        "grad_norm": 4.597395896911621,
        "learning_rate": 1.695110701107011e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.1894,
        "grad_norm": 2.2217259407043457,
        "learning_rate": 1.6928044280442805e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.2677,
        "grad_norm": 3.9815564155578613,
        "learning_rate": 1.69049815498155e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.2673,
        "grad_norm": 5.8272624015808105,
        "learning_rate": 1.688191881918819e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.4338766038417816,
        "eval_accuracy": 0.86162,
        "eval_precision": 0.82521,
        "eval_recall": 0.91434,
        "eval_f1": 0.86749,
        "eval_runtime": 18.0752,
        "eval_samples_per_second": 59.972,
        "eval_steps_per_second": 3.762,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.2359,
        "grad_norm": 1.434920072555542,
        "learning_rate": 1.6858856088560888e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.3076,
        "grad_norm": 3.4519431591033936,
        "learning_rate": 1.683579335793358e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.2037,
        "grad_norm": 4.808722972869873,
        "learning_rate": 1.6812730627306276e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.2506,
        "grad_norm": 4.7693095207214355,
        "learning_rate": 1.6789667896678967e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.2344,
        "grad_norm": 4.60065221786499,
        "learning_rate": 1.676660516605166e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.2954,
        "grad_norm": 15.783588409423828,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.3744,
        "grad_norm": 10.389545440673828,
        "learning_rate": 1.672047970479705e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.242,
        "grad_norm": 3.555511474609375,
        "learning_rate": 1.669741697416974e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.3039,
        "grad_norm": 2.368039131164551,
        "learning_rate": 1.6674354243542435e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.21,
        "grad_norm": 4.286088466644287,
        "learning_rate": 1.665129151291513e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.1934,
        "grad_norm": 0.7274029850959778,
        "learning_rate": 1.6628228782287823e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.1661,
        "grad_norm": 1.5191452503204346,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.2495,
        "grad_norm": 1.5655419826507568,
        "learning_rate": 1.658210332103321e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.1848,
        "grad_norm": 1.437422513961792,
        "learning_rate": 1.6559040590405906e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.2268,
        "grad_norm": 2.68827486038208,
        "learning_rate": 1.6535977859778597e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2099,
        "grad_norm": 25.419466018676758,
        "learning_rate": 1.6512915129151295e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2525,
        "grad_norm": 1.7925764322280884,
        "learning_rate": 1.6489852398523985e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.1667,
        "grad_norm": 1.4030393362045288,
        "learning_rate": 1.646678966789668e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.3509,
        "grad_norm": 3.713714599609375,
        "learning_rate": 1.6443726937269374e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.4019,
        "grad_norm": 2.6347451210021973,
        "learning_rate": 1.6420664206642068e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.3497,
        "grad_norm": 1.9748576879501343,
        "learning_rate": 1.6397601476014762e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.2177,
        "grad_norm": 5.786718368530273,
        "learning_rate": 1.6374538745387457e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.1946,
        "grad_norm": 6.316777229309082,
        "learning_rate": 1.6351476014760147e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.2286,
        "grad_norm": 2.326124668121338,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.3243,
        "grad_norm": 17.75165367126465,
        "learning_rate": 1.6305350553505536e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.2758,
        "grad_norm": 1.248375415802002,
        "learning_rate": 1.6282287822878227e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.3073,
        "grad_norm": 6.779783725738525,
        "learning_rate": 1.6259225092250924e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.4306703209877014,
        "eval_accuracy": 0.86162,
        "eval_precision": 0.81159,
        "eval_recall": 0.93855,
        "eval_f1": 0.87047,
        "eval_runtime": 18.0719,
        "eval_samples_per_second": 59.983,
        "eval_steps_per_second": 3.763,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.2576,
        "grad_norm": 4.358968734741211,
        "learning_rate": 1.6236162361623615e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.325,
        "grad_norm": 14.610264778137207,
        "learning_rate": 1.6213099630996313e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.2189,
        "grad_norm": 1.755470871925354,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.1613,
        "grad_norm": 0.4455839991569519,
        "learning_rate": 1.6166974169741698e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.2172,
        "grad_norm": 37.23448181152344,
        "learning_rate": 1.6143911439114392e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.243,
        "grad_norm": 18.636306762695312,
        "learning_rate": 1.6120848708487086e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.3919,
        "grad_norm": 4.7801103591918945,
        "learning_rate": 1.609778597785978e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.262,
        "grad_norm": 2.5125772953033447,
        "learning_rate": 1.6074723247232475e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2276,
        "grad_norm": 1.1303308010101318,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.1776,
        "grad_norm": 2.6427793502807617,
        "learning_rate": 1.602859778597786e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.2625,
        "grad_norm": 9.799762725830078,
        "learning_rate": 1.6005535055350554e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.2254,
        "grad_norm": 0.8894997239112854,
        "learning_rate": 1.5982472324723248e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.3131,
        "grad_norm": 2.3604047298431396,
        "learning_rate": 1.5959409594095942e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.2767,
        "grad_norm": 2.7068703174591064,
        "learning_rate": 1.5936346863468633e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.2341,
        "grad_norm": 3.346987247467041,
        "learning_rate": 1.591328413284133e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.2982,
        "grad_norm": 6.097326755523682,
        "learning_rate": 1.5890221402214022e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.2636,
        "grad_norm": 1.4460967779159546,
        "learning_rate": 1.5867158671586716e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.2493,
        "grad_norm": 1.5505105257034302,
        "learning_rate": 1.584409594095941e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.2553,
        "grad_norm": 3.7212162017822266,
        "learning_rate": 1.5821033210332104e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.245,
        "grad_norm": 0.8089053630828857,
        "learning_rate": 1.57979704797048e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.3291,
        "grad_norm": 11.60673713684082,
        "learning_rate": 1.5774907749077493e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.2957,
        "grad_norm": 6.420746326446533,
        "learning_rate": 1.5751845018450184e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.2173,
        "grad_norm": 3.649689197540283,
        "learning_rate": 1.5728782287822878e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.2517,
        "grad_norm": 1.561074137687683,
        "learning_rate": 1.5705719557195572e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.3021,
        "grad_norm": 3.5963847637176514,
        "learning_rate": 1.5682656826568266e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.2663,
        "grad_norm": 6.375422954559326,
        "learning_rate": 1.565959409594096e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.2544,
        "grad_norm": 1.4007737636566162,
        "learning_rate": 1.563653136531365e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.4471500515937805,
        "eval_accuracy": 0.86255,
        "eval_precision": 0.8119,
        "eval_recall": 0.94041,
        "eval_f1": 0.87144,
        "eval_runtime": 18.0718,
        "eval_samples_per_second": 59.983,
        "eval_steps_per_second": 3.763,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.2322,
        "grad_norm": 3.9329967498779297,
        "learning_rate": 1.561346863468635e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.2132,
        "grad_norm": 10.31400203704834,
        "learning_rate": 1.559040590405904e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.2012,
        "grad_norm": 6.653350353240967,
        "learning_rate": 1.5567343173431734e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.2077,
        "grad_norm": 4.491565227508545,
        "learning_rate": 1.554428044280443e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.269,
        "grad_norm": 6.538615703582764,
        "learning_rate": 1.5521217712177123e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.1833,
        "grad_norm": 1.6420866250991821,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.1852,
        "grad_norm": 1.3113163709640503,
        "learning_rate": 1.547509225092251e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.2375,
        "grad_norm": 13.081480979919434,
        "learning_rate": 1.5452029520295202e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.3177,
        "grad_norm": 7.870521068572998,
        "learning_rate": 1.54289667896679e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.2556,
        "grad_norm": 1.5984362363815308,
        "learning_rate": 1.540590405904059e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.321,
        "grad_norm": 1.739554524421692,
        "learning_rate": 1.5382841328413285e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.2543,
        "grad_norm": 6.540882110595703,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.2872,
        "grad_norm": 5.637874603271484,
        "learning_rate": 1.533671586715867e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.1624,
        "grad_norm": 2.4024691581726074,
        "learning_rate": 1.5313653136531367e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.2831,
        "grad_norm": 15.834601402282715,
        "learning_rate": 1.5290590405904058e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.2544,
        "grad_norm": 2.152771234512329,
        "learning_rate": 1.5267527675276756e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.2678,
        "grad_norm": 5.874699115753174,
        "learning_rate": 1.5244464944649448e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2689,
        "grad_norm": 4.861298084259033,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.2177,
        "grad_norm": 2.1298515796661377,
        "learning_rate": 1.5198339483394835e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.1927,
        "grad_norm": 3.913289785385132,
        "learning_rate": 1.5175276752767528e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.2327,
        "grad_norm": 6.160028457641602,
        "learning_rate": 1.515221402214022e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.243,
        "grad_norm": 1.915202021598816,
        "learning_rate": 1.5129151291512916e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.2728,
        "grad_norm": 12.382522583007812,
        "learning_rate": 1.5106088560885609e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.2678,
        "grad_norm": 6.53208589553833,
        "learning_rate": 1.5083025830258305e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.2355,
        "grad_norm": 3.467420816421509,
        "learning_rate": 1.5059963099630997e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.3195,
        "grad_norm": 21.02370834350586,
        "learning_rate": 1.503690036900369e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.2678,
        "grad_norm": 12.58588695526123,
        "learning_rate": 1.5013837638376386e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.3716312646865845,
        "eval_accuracy": 0.87823,
        "eval_precision": 0.83471,
        "eval_recall": 0.94041,
        "eval_f1": 0.88441,
        "eval_runtime": 18.0615,
        "eval_samples_per_second": 60.017,
        "eval_steps_per_second": 3.765,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.2785,
        "grad_norm": 3.0087740421295166,
        "learning_rate": 1.4990774907749078e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.2484,
        "grad_norm": 10.163104057312012,
        "learning_rate": 1.4967712177121774e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.2687,
        "grad_norm": 6.726130485534668,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.1861,
        "grad_norm": 2.9107933044433594,
        "learning_rate": 1.4921586715867159e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.2373,
        "grad_norm": 5.90305757522583,
        "learning_rate": 1.4898523985239853e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.1864,
        "grad_norm": 9.900388717651367,
        "learning_rate": 1.4875461254612546e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.204,
        "grad_norm": 6.525581359863281,
        "learning_rate": 1.485239852398524e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.2721,
        "grad_norm": 6.139217853546143,
        "learning_rate": 1.4829335793357934e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.2856,
        "grad_norm": 1.9212032556533813,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.1814,
        "grad_norm": 37.36978530883789,
        "learning_rate": 1.4783210332103323e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.276,
        "grad_norm": 8.112625122070312,
        "learning_rate": 1.4760147601476015e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.1959,
        "grad_norm": 4.38937520980835,
        "learning_rate": 1.4737084870848708e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.2393,
        "grad_norm": 8.712814331054688,
        "learning_rate": 1.4714022140221404e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.2809,
        "grad_norm": 25.89957618713379,
        "learning_rate": 1.4690959409594096e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.2054,
        "grad_norm": 0.9780186414718628,
        "learning_rate": 1.4667896678966792e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.1765,
        "grad_norm": 0.5338972210884094,
        "learning_rate": 1.4644833948339485e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.2693,
        "grad_norm": 12.57615852355957,
        "learning_rate": 1.4621771217712177e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.3796,
        "grad_norm": 4.862215518951416,
        "learning_rate": 1.4598708487084871e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.1706,
        "grad_norm": 5.19173526763916,
        "learning_rate": 1.4575645756457566e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.2326,
        "grad_norm": 1.11415433883667,
        "learning_rate": 1.455258302583026e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.1922,
        "grad_norm": 1.4212758541107178,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.2869,
        "grad_norm": 1.1603909730911255,
        "learning_rate": 1.4506457564575645e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.1864,
        "grad_norm": 4.447836875915527,
        "learning_rate": 1.4483394833948341e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.2367,
        "grad_norm": 7.874937534332275,
        "learning_rate": 1.4460332103321033e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.2789,
        "grad_norm": 9.183704376220703,
        "learning_rate": 1.4437269372693726e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.238,
        "grad_norm": 1.7887232303619385,
        "learning_rate": 1.4414206642066422e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.2397,
        "grad_norm": 1.1230847835540771,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.42246878147125244,
        "eval_accuracy": 0.87362,
        "eval_precision": 0.83333,
        "eval_recall": 0.9311,
        "eval_f1": 0.87951,
        "eval_runtime": 18.0772,
        "eval_samples_per_second": 59.965,
        "eval_steps_per_second": 3.762,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.2569,
        "grad_norm": 2.8073127269744873,
        "learning_rate": 1.436808118081181e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.2023,
        "grad_norm": 0.9699745178222656,
        "learning_rate": 1.4345018450184503e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.2877,
        "grad_norm": 7.9946675300598145,
        "learning_rate": 1.4321955719557195e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.2809,
        "grad_norm": 13.624850273132324,
        "learning_rate": 1.4298892988929891e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.1984,
        "grad_norm": 2.4489476680755615,
        "learning_rate": 1.4275830258302584e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.2787,
        "grad_norm": 10.193216323852539,
        "learning_rate": 1.4252767527675278e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.2258,
        "grad_norm": 1.6670997142791748,
        "learning_rate": 1.422970479704797e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.1883,
        "grad_norm": 2.1725339889526367,
        "learning_rate": 1.4206642066420663e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2315,
        "grad_norm": 1.93262779712677,
        "learning_rate": 1.4183579335793359e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.1948,
        "grad_norm": 0.36691656708717346,
        "learning_rate": 1.4160516605166052e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.3009,
        "grad_norm": 50.49391555786133,
        "learning_rate": 1.4137453874538744e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.2738,
        "grad_norm": 0.7967872023582458,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.2838,
        "grad_norm": 0.9797747731208801,
        "learning_rate": 1.4091328413284133e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.1791,
        "grad_norm": 47.50541687011719,
        "learning_rate": 1.4068265682656829e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.2552,
        "grad_norm": 14.237205505371094,
        "learning_rate": 1.4045202952029521e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.1914,
        "grad_norm": 5.976240158081055,
        "learning_rate": 1.4022140221402214e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.222,
        "grad_norm": 10.292006492614746,
        "learning_rate": 1.399907749077491e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.3108,
        "grad_norm": 3.9517245292663574,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.1357,
        "grad_norm": 1.8269505500793457,
        "learning_rate": 1.3952952029520296e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.2114,
        "grad_norm": 28.987581253051758,
        "learning_rate": 1.3929889298892989e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.285,
        "grad_norm": 1.9320149421691895,
        "learning_rate": 1.3906826568265683e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.2233,
        "grad_norm": 3.28334903717041,
        "learning_rate": 1.3883763837638377e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.2377,
        "grad_norm": 27.69015121459961,
        "learning_rate": 1.386070110701107e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.1861,
        "grad_norm": 1.408209204673767,
        "learning_rate": 1.3837638376383766e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.2728,
        "grad_norm": 21.933048248291016,
        "learning_rate": 1.3814575645756458e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.2463,
        "grad_norm": 5.312510013580322,
        "learning_rate": 1.3791512915129151e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.2349,
        "grad_norm": 40.097373962402344,
        "learning_rate": 1.3768450184501847e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.4411752223968506,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.83278,
        "eval_recall": 0.93669,
        "eval_f1": 0.88168,
        "eval_runtime": 18.082,
        "eval_samples_per_second": 59.949,
        "eval_steps_per_second": 3.761,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.1741,
        "grad_norm": 1.883022665977478,
        "learning_rate": 1.374538745387454e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.2762,
        "grad_norm": 13.255263328552246,
        "learning_rate": 1.3722324723247232e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.1767,
        "grad_norm": 0.9331271052360535,
        "learning_rate": 1.3699261992619928e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.225,
        "grad_norm": 2.3441267013549805,
        "learning_rate": 1.367619926199262e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.1655,
        "grad_norm": 1.361228108406067,
        "learning_rate": 1.3653136531365315e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.3083,
        "grad_norm": 6.29367733001709,
        "learning_rate": 1.3630073800738009e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.2357,
        "grad_norm": 4.514141082763672,
        "learning_rate": 1.3607011070110701e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2232,
        "grad_norm": 7.089046001434326,
        "learning_rate": 1.3583948339483396e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.1943,
        "grad_norm": 10.364452362060547,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.2487,
        "grad_norm": 1.32480788230896,
        "learning_rate": 1.3537822878228784e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.3575,
        "grad_norm": 1.112539291381836,
        "learning_rate": 1.3514760147601477e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.1988,
        "grad_norm": 0.980774998664856,
        "learning_rate": 1.3491697416974169e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.1432,
        "grad_norm": 2.6641807556152344,
        "learning_rate": 1.3468634686346865e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.187,
        "grad_norm": 0.31637483835220337,
        "learning_rate": 1.3445571955719558e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.2177,
        "grad_norm": 1.6550418138504028,
        "learning_rate": 1.3422509225092253e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.3101,
        "grad_norm": 1.446914792060852,
        "learning_rate": 1.3399446494464946e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.1934,
        "grad_norm": 18.12173843383789,
        "learning_rate": 1.3376383763837639e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.251,
        "grad_norm": 2.0643346309661865,
        "learning_rate": 1.3353321033210334e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.2731,
        "grad_norm": 3.869802236557007,
        "learning_rate": 1.3330258302583027e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.2174,
        "grad_norm": 4.478309154510498,
        "learning_rate": 1.330719557195572e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.1791,
        "grad_norm": 0.7557082772254944,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.3074,
        "grad_norm": 7.985504627227783,
        "learning_rate": 1.3261070110701106e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.3578,
        "grad_norm": 2.36856746673584,
        "learning_rate": 1.3238007380073802e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.1972,
        "grad_norm": 1.649695634841919,
        "learning_rate": 1.3214944649446495e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.2678,
        "grad_norm": 2.919900894165039,
        "learning_rate": 1.3191881918819187e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2001,
        "grad_norm": 18.209148406982422,
        "learning_rate": 1.3168819188191883e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.2594,
        "grad_norm": 1.0677696466445923,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.5084540247917175,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.82843,
        "eval_recall": 0.94413,
        "eval_f1": 0.88251,
        "eval_runtime": 18.123,
        "eval_samples_per_second": 59.814,
        "eval_steps_per_second": 3.752,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.211,
        "grad_norm": 1.594980239868164,
        "learning_rate": 1.3122693726937272e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.3191,
        "grad_norm": 2.6093406677246094,
        "learning_rate": 1.3099630996309964e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.2179,
        "grad_norm": 1.3698878288269043,
        "learning_rate": 1.3076568265682657e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.1658,
        "grad_norm": 7.043964862823486,
        "learning_rate": 1.3053505535055353e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.1315,
        "grad_norm": 1.547311782836914,
        "learning_rate": 1.3030442804428045e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.2648,
        "grad_norm": 3.085529327392578,
        "learning_rate": 1.3007380073800738e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2255,
        "grad_norm": 0.9816437363624573,
        "learning_rate": 1.2984317343173432e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.3498,
        "grad_norm": 2.303128719329834,
        "learning_rate": 1.2961254612546126e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.2519,
        "grad_norm": 0.9939152002334595,
        "learning_rate": 1.293819188191882e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.1432,
        "grad_norm": 3.9965803623199463,
        "learning_rate": 1.2915129151291513e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.2779,
        "grad_norm": 49.00271224975586,
        "learning_rate": 1.2892066420664205e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.2053,
        "grad_norm": 5.270806789398193,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.1631,
        "grad_norm": 1.9778388738632202,
        "learning_rate": 1.2845940959409594e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2022,
        "grad_norm": 11.609502792358398,
        "learning_rate": 1.282287822878229e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.2362,
        "grad_norm": 5.103541374206543,
        "learning_rate": 1.2799815498154982e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.1377,
        "grad_norm": 4.327340602874756,
        "learning_rate": 1.2776752767527675e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.1181,
        "grad_norm": 1.4853570461273193,
        "learning_rate": 1.2753690036900371e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.1721,
        "grad_norm": 28.467512130737305,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.2279,
        "grad_norm": 0.8424383997917175,
        "learning_rate": 1.2707564575645758e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.2849,
        "grad_norm": 4.468143939971924,
        "learning_rate": 1.2684501845018452e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.3239,
        "grad_norm": 3.828465461730957,
        "learning_rate": 1.2661439114391144e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.2213,
        "grad_norm": 4.6078033447265625,
        "learning_rate": 1.2638376383763839e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.3189,
        "grad_norm": 7.732511043548584,
        "learning_rate": 1.2615313653136531e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.2586,
        "grad_norm": 4.918064117431641,
        "learning_rate": 1.2592250922509224e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.2557,
        "grad_norm": 4.996661186218262,
        "learning_rate": 1.256918819188192e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.2232,
        "grad_norm": 9.455975532531738,
        "learning_rate": 1.2546125461254612e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.263,
        "grad_norm": 3.289444923400879,
        "learning_rate": 1.2523062730627308e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.1952,
        "grad_norm": 5.297111511230469,
        "learning_rate": 1.25e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.4335724115371704,
        "eval_accuracy": 0.87085,
        "eval_precision": 0.8281,
        "eval_recall": 0.93296,
        "eval_f1": 0.87741,
        "eval_runtime": 18.0421,
        "eval_samples_per_second": 60.082,
        "eval_steps_per_second": 3.769,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.2742,
        "grad_norm": 3.2472753524780273,
        "learning_rate": 1.2476937269372695e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.1993,
        "grad_norm": 1.9009348154067993,
        "learning_rate": 1.2453874538745389e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2096,
        "grad_norm": 3.9004127979278564,
        "learning_rate": 1.2430811808118082e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.2379,
        "grad_norm": 6.004692077636719,
        "learning_rate": 1.2407749077490776e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2292,
        "grad_norm": 3.54721736907959,
        "learning_rate": 1.238468634686347e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.1425,
        "grad_norm": 2.0756897926330566,
        "learning_rate": 1.2361623616236164e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.1781,
        "grad_norm": 0.6704162955284119,
        "learning_rate": 1.2338560885608857e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.2442,
        "grad_norm": 21.25238037109375,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.1811,
        "grad_norm": 7.183924674987793,
        "learning_rate": 1.2292435424354244e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.2419,
        "grad_norm": 3.247995376586914,
        "learning_rate": 1.2269372693726938e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.207,
        "grad_norm": 14.119887351989746,
        "learning_rate": 1.2246309963099632e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.1743,
        "grad_norm": 7.607728958129883,
        "learning_rate": 1.2223247232472325e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.2295,
        "grad_norm": 13.265629768371582,
        "learning_rate": 1.2200184501845019e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.27,
        "grad_norm": 2.401630163192749,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.1718,
        "grad_norm": 6.315909385681152,
        "learning_rate": 1.2154059040590407e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.1851,
        "grad_norm": 4.693980693817139,
        "learning_rate": 1.21309963099631e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.1813,
        "grad_norm": 1.1544315814971924,
        "learning_rate": 1.2107933579335794e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.2266,
        "grad_norm": 22.81083106994629,
        "learning_rate": 1.2084870848708488e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.1651,
        "grad_norm": 9.171820640563965,
        "learning_rate": 1.2061808118081182e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.2758,
        "grad_norm": 7.512446403503418,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.3386,
        "grad_norm": 13.920599937438965,
        "learning_rate": 1.201568265682657e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.2077,
        "grad_norm": 8.22232723236084,
        "learning_rate": 1.1992619926199262e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.3532,
        "grad_norm": 2.9249954223632812,
        "learning_rate": 1.1969557195571956e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.1991,
        "grad_norm": 6.144620895385742,
        "learning_rate": 1.194649446494465e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.1379,
        "grad_norm": 67.436279296875,
        "learning_rate": 1.1923431734317343e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.2552,
        "grad_norm": 1.31520676612854,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.2121,
        "grad_norm": 35.29753875732422,
        "learning_rate": 1.1877306273062731e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.5047363638877869,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.83059,
        "eval_recall": 0.94041,
        "eval_f1": 0.8821,
        "eval_runtime": 18.0592,
        "eval_samples_per_second": 60.025,
        "eval_steps_per_second": 3.765,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.1827,
        "grad_norm": 5.127601146697998,
        "learning_rate": 1.1854243542435425e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.2682,
        "grad_norm": 4.387482643127441,
        "learning_rate": 1.1831180811808118e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.1891,
        "grad_norm": 1.1643304824829102,
        "learning_rate": 1.1808118081180812e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.2147,
        "grad_norm": 12.504183769226074,
        "learning_rate": 1.1785055350553506e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.1829,
        "grad_norm": 4.413618087768555,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.2705,
        "grad_norm": 19.768068313598633,
        "learning_rate": 1.1738929889298895e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.2148,
        "grad_norm": 2.167239189147949,
        "learning_rate": 1.1715867158671587e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.1394,
        "grad_norm": 7.497730255126953,
        "learning_rate": 1.1692804428044282e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.1334,
        "grad_norm": 6.145455837249756,
        "learning_rate": 1.1669741697416974e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.1616,
        "grad_norm": 3.8717150688171387,
        "learning_rate": 1.1646678966789668e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.1731,
        "grad_norm": 0.3154325485229492,
        "learning_rate": 1.1623616236162361e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.2505,
        "grad_norm": 2.8415732383728027,
        "learning_rate": 1.1600553505535055e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.1499,
        "grad_norm": 1.637850046157837,
        "learning_rate": 1.157749077490775e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.2044,
        "grad_norm": 4.139204025268555,
        "learning_rate": 1.1554428044280444e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.1366,
        "grad_norm": 1.3469027280807495,
        "learning_rate": 1.1531365313653138e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.1981,
        "grad_norm": 5.894276142120361,
        "learning_rate": 1.150830258302583e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.2912,
        "grad_norm": 2.9769372940063477,
        "learning_rate": 1.1485239852398525e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.1119,
        "grad_norm": 2.471958637237549,
        "learning_rate": 1.1462177121771219e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.3371,
        "grad_norm": 1.7373679876327515,
        "learning_rate": 1.1439114391143913e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.1876,
        "grad_norm": 1.3237100839614868,
        "learning_rate": 1.1416051660516606e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.2122,
        "grad_norm": 1.9544322490692139,
        "learning_rate": 1.13929889298893e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.2235,
        "grad_norm": 2.832730531692505,
        "learning_rate": 1.1369926199261992e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.1925,
        "grad_norm": 0.8718747496604919,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.2437,
        "grad_norm": 4.062868118286133,
        "learning_rate": 1.1323800738007381e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.1911,
        "grad_norm": 6.424564361572266,
        "learning_rate": 1.1300738007380073e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.2039,
        "grad_norm": 3.8781023025512695,
        "learning_rate": 1.1277675276752768e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.2415,
        "grad_norm": 6.122599124908447,
        "learning_rate": 1.1254612546125462e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.44558531045913696,
        "eval_accuracy": 0.88007,
        "eval_precision": 0.84668,
        "eval_recall": 0.92551,
        "eval_f1": 0.88434,
        "eval_runtime": 18.0645,
        "eval_samples_per_second": 60.007,
        "eval_steps_per_second": 3.764,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.2701,
        "grad_norm": 2.6860885620117188,
        "learning_rate": 1.1231549815498156e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.2476,
        "grad_norm": 1.2233015298843384,
        "learning_rate": 1.1208487084870849e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.136,
        "grad_norm": 1.6808485984802246,
        "learning_rate": 1.1185424354243543e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.1786,
        "grad_norm": 3.521306276321411,
        "learning_rate": 1.1162361623616237e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.1652,
        "grad_norm": 0.5976667404174805,
        "learning_rate": 1.1139298892988931e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.1624,
        "grad_norm": 1.8559224605560303,
        "learning_rate": 1.1116236162361624e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.2292,
        "grad_norm": 3.125770092010498,
        "learning_rate": 1.1093173431734318e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.1463,
        "grad_norm": 0.9872851967811584,
        "learning_rate": 1.1070110701107012e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.1989,
        "grad_norm": 22.569734573364258,
        "learning_rate": 1.1047047970479705e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.1609,
        "grad_norm": 0.5875389575958252,
        "learning_rate": 1.1023985239852399e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.1346,
        "grad_norm": 2.262451648712158,
        "learning_rate": 1.1000922509225092e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.1341,
        "grad_norm": 0.4740411937236786,
        "learning_rate": 1.0977859778597786e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.2037,
        "grad_norm": 7.776682376861572,
        "learning_rate": 1.095479704797048e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.1362,
        "grad_norm": 4.382448673248291,
        "learning_rate": 1.0931734317343174e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.3247,
        "grad_norm": 4.154349327087402,
        "learning_rate": 1.0908671586715867e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.2707,
        "grad_norm": 0.9028738141059875,
        "learning_rate": 1.0885608856088561e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.1922,
        "grad_norm": 1.3370945453643799,
        "learning_rate": 1.0862546125461255e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.1828,
        "grad_norm": 2.5338783264160156,
        "learning_rate": 1.083948339483395e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.2119,
        "grad_norm": 18.66682243347168,
        "learning_rate": 1.0816420664206644e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.251,
        "grad_norm": 1.8134099245071411,
        "learning_rate": 1.0793357933579336e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.2615,
        "grad_norm": 11.618544578552246,
        "learning_rate": 1.077029520295203e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.2009,
        "grad_norm": 4.195691108703613,
        "learning_rate": 1.0747232472324725e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.1535,
        "grad_norm": 0.7069903016090393,
        "learning_rate": 1.0724169741697417e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.235,
        "grad_norm": 10.536521911621094,
        "learning_rate": 1.070110701107011e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.2209,
        "grad_norm": 1.678634762763977,
        "learning_rate": 1.0678044280442804e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.2859,
        "grad_norm": 2.192305088043213,
        "learning_rate": 1.0654981549815498e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.2812,
        "grad_norm": 6.067714214324951,
        "learning_rate": 1.0631918819188192e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.47144246101379395,
        "eval_accuracy": 0.87546,
        "eval_precision": 0.83278,
        "eval_recall": 0.93669,
        "eval_f1": 0.88168,
        "eval_runtime": 18.0615,
        "eval_samples_per_second": 60.017,
        "eval_steps_per_second": 3.765,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.2214,
        "grad_norm": 8.145574569702148,
        "learning_rate": 1.0608856088560887e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.2117,
        "grad_norm": 1.5106275081634521,
        "learning_rate": 1.058579335793358e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.1959,
        "grad_norm": 16.744155883789062,
        "learning_rate": 1.0562730627306273e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.1418,
        "grad_norm": 24.633102416992188,
        "learning_rate": 1.0539667896678968e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.1116,
        "grad_norm": 3.9214906692504883,
        "learning_rate": 1.0516605166051662e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.1748,
        "grad_norm": 23.564983367919922,
        "learning_rate": 1.0493542435424354e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.1551,
        "grad_norm": 0.5573771595954895,
        "learning_rate": 1.0470479704797049e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.2527,
        "grad_norm": 3.8250174522399902,
        "learning_rate": 1.0447416974169743e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.206,
        "grad_norm": 5.1917853355407715,
        "learning_rate": 1.0424354243542435e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.1624,
        "grad_norm": 15.688446044921875,
        "learning_rate": 1.040129151291513e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.2818,
        "grad_norm": 12.80094051361084,
        "learning_rate": 1.0378228782287822e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.2113,
        "grad_norm": 4.928027153015137,
        "learning_rate": 1.0355166051660516e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.1793,
        "grad_norm": 3.477213144302368,
        "learning_rate": 1.033210332103321e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.1676,
        "grad_norm": 3.1663031578063965,
        "learning_rate": 1.0309040590405905e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.2495,
        "grad_norm": 21.79450798034668,
        "learning_rate": 1.0285977859778597e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.2324,
        "grad_norm": 8.717057228088379,
        "learning_rate": 1.0262915129151292e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.1995,
        "grad_norm": 5.395924091339111,
        "learning_rate": 1.0239852398523986e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.231,
        "grad_norm": 34.50849914550781,
        "learning_rate": 1.021678966789668e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.287,
        "grad_norm": 47.337005615234375,
        "learning_rate": 1.0193726937269373e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.1325,
        "grad_norm": 16.47673988342285,
        "learning_rate": 1.0170664206642067e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.1979,
        "grad_norm": 0.9241631031036377,
        "learning_rate": 1.0147601476014761e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.2804,
        "grad_norm": 2.097501516342163,
        "learning_rate": 1.0124538745387455e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.1432,
        "grad_norm": 0.5514249205589294,
        "learning_rate": 1.0101476014760148e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.2731,
        "grad_norm": 1.7045053243637085,
        "learning_rate": 1.0078413284132842e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.2007,
        "grad_norm": 14.032892227172852,
        "learning_rate": 1.0055350553505535e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.2497,
        "grad_norm": 2.960803270339966,
        "learning_rate": 1.0032287822878229e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.0995,
        "grad_norm": 3.6037490367889404,
        "learning_rate": 1.0009225092250923e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.5056483149528503,
        "eval_accuracy": 0.87731,
        "eval_precision": 0.84122,
        "eval_recall": 0.92737,
        "eval_f1": 0.8822,
        "eval_runtime": 18.0595,
        "eval_samples_per_second": 60.024,
        "eval_steps_per_second": 3.765,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "loss": 0.1445,
        "grad_norm": 0.7880446910858154,
        "learning_rate": 9.986162361623616e-06,
        "epoch": 24.022140221402214,
        "step": 6510
    },
    {
        "loss": 0.2285,
        "grad_norm": 12.01872730255127,
        "learning_rate": 9.96309963099631e-06,
        "epoch": 24.059040590405903,
        "step": 6520
    },
    {
        "loss": 0.3639,
        "grad_norm": 1.4494632482528687,
        "learning_rate": 9.940036900369004e-06,
        "epoch": 24.095940959409592,
        "step": 6530
    },
    {
        "loss": 0.2061,
        "grad_norm": 19.470640182495117,
        "learning_rate": 9.916974169741698e-06,
        "epoch": 24.132841328413285,
        "step": 6540
    },
    {
        "loss": 0.2166,
        "grad_norm": 2.8944647312164307,
        "learning_rate": 9.893911439114393e-06,
        "epoch": 24.169741697416974,
        "step": 6550
    },
    {
        "loss": 0.2115,
        "grad_norm": 5.507913589477539,
        "learning_rate": 9.870848708487085e-06,
        "epoch": 24.206642066420663,
        "step": 6560
    },
    {
        "loss": 0.1182,
        "grad_norm": 22.85083770751953,
        "learning_rate": 9.84778597785978e-06,
        "epoch": 24.243542435424356,
        "step": 6570
    },
    {
        "loss": 0.1254,
        "grad_norm": 22.295154571533203,
        "learning_rate": 9.824723247232474e-06,
        "epoch": 24.280442804428045,
        "step": 6580
    },
    {
        "loss": 0.204,
        "grad_norm": 8.127503395080566,
        "learning_rate": 9.801660516605168e-06,
        "epoch": 24.317343173431734,
        "step": 6590
    },
    {
        "loss": 0.2307,
        "grad_norm": 1.8092254400253296,
        "learning_rate": 9.77859778597786e-06,
        "epoch": 24.354243542435423,
        "step": 6600
    },
    {
        "loss": 0.1308,
        "grad_norm": 9.511061668395996,
        "learning_rate": 9.755535055350553e-06,
        "epoch": 24.391143911439116,
        "step": 6610
    },
    {
        "loss": 0.2504,
        "grad_norm": 19.51400375366211,
        "learning_rate": 9.732472324723247e-06,
        "epoch": 24.428044280442805,
        "step": 6620
    },
    {
        "loss": 0.3072,
        "grad_norm": 0.22729051113128662,
        "learning_rate": 9.709409594095941e-06,
        "epoch": 24.464944649446494,
        "step": 6630
    },
    {
        "loss": 0.2135,
        "grad_norm": 5.267801284790039,
        "learning_rate": 9.686346863468636e-06,
        "epoch": 24.501845018450183,
        "step": 6640
    },
    {
        "loss": 0.1365,
        "grad_norm": 1.7287253141403198,
        "learning_rate": 9.663284132841328e-06,
        "epoch": 24.538745387453876,
        "step": 6650
    },
    {
        "loss": 0.2272,
        "grad_norm": 21.505605697631836,
        "learning_rate": 9.640221402214022e-06,
        "epoch": 24.575645756457565,
        "step": 6660
    },
    {
        "loss": 0.1611,
        "grad_norm": 3.8211028575897217,
        "learning_rate": 9.617158671586717e-06,
        "epoch": 24.612546125461254,
        "step": 6670
    },
    {
        "loss": 0.1266,
        "grad_norm": 1.8806917667388916,
        "learning_rate": 9.59409594095941e-06,
        "epoch": 24.649446494464943,
        "step": 6680
    },
    {
        "loss": 0.1657,
        "grad_norm": 2.532073974609375,
        "learning_rate": 9.571033210332103e-06,
        "epoch": 24.686346863468636,
        "step": 6690
    },
    {
        "loss": 0.0765,
        "grad_norm": 5.0334086418151855,
        "learning_rate": 9.547970479704798e-06,
        "epoch": 24.723247232472325,
        "step": 6700
    },
    {
        "loss": 0.1632,
        "grad_norm": 5.089023590087891,
        "learning_rate": 9.524907749077492e-06,
        "epoch": 24.760147601476014,
        "step": 6710
    },
    {
        "loss": 0.3101,
        "grad_norm": 6.347482681274414,
        "learning_rate": 9.501845018450186e-06,
        "epoch": 24.797047970479706,
        "step": 6720
    },
    {
        "loss": 0.199,
        "grad_norm": 1.6622825860977173,
        "learning_rate": 9.478782287822879e-06,
        "epoch": 24.833948339483396,
        "step": 6730
    },
    {
        "loss": 0.2017,
        "grad_norm": 24.944398880004883,
        "learning_rate": 9.455719557195573e-06,
        "epoch": 24.870848708487085,
        "step": 6740
    },
    {
        "loss": 0.1975,
        "grad_norm": 22.793630599975586,
        "learning_rate": 9.432656826568265e-06,
        "epoch": 24.907749077490774,
        "step": 6750
    },
    {
        "loss": 0.1698,
        "grad_norm": 3.846224546432495,
        "learning_rate": 9.40959409594096e-06,
        "epoch": 24.944649446494466,
        "step": 6760
    },
    {
        "loss": 0.1952,
        "grad_norm": 1.6311863660812378,
        "learning_rate": 9.386531365313654e-06,
        "epoch": 24.981549815498155,
        "step": 6770
    },
    {
        "eval_loss": 0.5300233364105225,
        "eval_accuracy": 0.86808,
        "eval_precision": 0.83618,
        "eval_recall": 0.91248,
        "eval_f1": 0.87266,
        "eval_runtime": 18.1189,
        "eval_samples_per_second": 59.827,
        "eval_steps_per_second": 3.753,
        "epoch": 25.0,
        "step": 6775
    },
    {
        "loss": 0.2332,
        "grad_norm": 10.790215492248535,
        "learning_rate": 9.363468634686346e-06,
        "epoch": 25.018450184501845,
        "step": 6780
    },
    {
        "loss": 0.1605,
        "grad_norm": 2.0825953483581543,
        "learning_rate": 9.34040590405904e-06,
        "epoch": 25.055350553505534,
        "step": 6790
    },
    {
        "loss": 0.0997,
        "grad_norm": 0.6140528917312622,
        "learning_rate": 9.317343173431735e-06,
        "epoch": 25.092250922509226,
        "step": 6800
    },
    {
        "loss": 0.1797,
        "grad_norm": 6.719727516174316,
        "learning_rate": 9.294280442804429e-06,
        "epoch": 25.129151291512915,
        "step": 6810
    },
    {
        "loss": 0.1227,
        "grad_norm": 0.5843273401260376,
        "learning_rate": 9.271217712177122e-06,
        "epoch": 25.166051660516604,
        "step": 6820
    },
    {
        "loss": 0.1555,
        "grad_norm": 1.2262067794799805,
        "learning_rate": 9.248154981549816e-06,
        "epoch": 25.202952029520294,
        "step": 6830
    },
    {
        "loss": 0.2042,
        "grad_norm": 11.175469398498535,
        "learning_rate": 9.22509225092251e-06,
        "epoch": 25.239852398523986,
        "step": 6840
    },
    {
        "loss": 0.2057,
        "grad_norm": 8.535933494567871,
        "learning_rate": 9.202029520295204e-06,
        "epoch": 25.276752767527675,
        "step": 6850
    },
    {
        "loss": 0.3941,
        "grad_norm": 4.874942302703857,
        "learning_rate": 9.178966789667898e-06,
        "epoch": 25.313653136531364,
        "step": 6860
    },
    {
        "loss": 0.2126,
        "grad_norm": 2.9258339405059814,
        "learning_rate": 9.155904059040591e-06,
        "epoch": 25.350553505535057,
        "step": 6870
    },
    {
        "loss": 0.3573,
        "grad_norm": 1.1434608697891235,
        "learning_rate": 9.132841328413285e-06,
        "epoch": 25.387453874538746,
        "step": 6880
    },
    {
        "loss": 0.0968,
        "grad_norm": 37.61495590209961,
        "learning_rate": 9.109778597785978e-06,
        "epoch": 25.424354243542435,
        "step": 6890
    },
    {
        "loss": 0.1277,
        "grad_norm": 0.29880374670028687,
        "learning_rate": 9.086715867158672e-06,
        "epoch": 25.461254612546124,
        "step": 6900
    },
    {
        "loss": 0.1576,
        "grad_norm": 2.3296544551849365,
        "learning_rate": 9.063653136531364e-06,
        "epoch": 25.498154981549817,
        "step": 6910
    },
    {
        "loss": 0.08,
        "grad_norm": 8.612224578857422,
        "learning_rate": 9.040590405904059e-06,
        "epoch": 25.535055350553506,
        "step": 6920
    },
    {
        "loss": 0.1699,
        "grad_norm": 3.4334611892700195,
        "learning_rate": 9.017527675276753e-06,
        "epoch": 25.571955719557195,
        "step": 6930
    },
    {
        "loss": 0.2468,
        "grad_norm": 1.390914797782898,
        "learning_rate": 8.994464944649447e-06,
        "epoch": 25.608856088560884,
        "step": 6940
    },
    {
        "loss": 0.2115,
        "grad_norm": 4.9834442138671875,
        "learning_rate": 8.971402214022141e-06,
        "epoch": 25.645756457564577,
        "step": 6950
    },
    {
        "loss": 0.2088,
        "grad_norm": 5.2655558586120605,
        "learning_rate": 8.948339483394834e-06,
        "epoch": 25.682656826568266,
        "step": 6960
    },
    {
        "loss": 0.2136,
        "grad_norm": 1.0575919151306152,
        "learning_rate": 8.925276752767528e-06,
        "epoch": 25.719557195571955,
        "step": 6970
    },
    {
        "loss": 0.2,
        "grad_norm": 34.19758605957031,
        "learning_rate": 8.902214022140222e-06,
        "epoch": 25.756457564575644,
        "step": 6980
    },
    {
        "loss": 0.2237,
        "grad_norm": 2.3645331859588623,
        "learning_rate": 8.879151291512917e-06,
        "epoch": 25.793357933579337,
        "step": 6990
    },
    {
        "loss": 0.1466,
        "grad_norm": 2.470083475112915,
        "learning_rate": 8.85608856088561e-06,
        "epoch": 25.830258302583026,
        "step": 7000
    },
    {
        "loss": 0.2355,
        "grad_norm": 0.7288889288902283,
        "learning_rate": 8.833025830258303e-06,
        "epoch": 25.867158671586715,
        "step": 7010
    },
    {
        "loss": 0.12,
        "grad_norm": 1.3145426511764526,
        "learning_rate": 8.809963099630996e-06,
        "epoch": 25.904059040590404,
        "step": 7020
    },
    {
        "loss": 0.1847,
        "grad_norm": 8.993589401245117,
        "learning_rate": 8.78690036900369e-06,
        "epoch": 25.940959409594097,
        "step": 7030
    },
    {
        "loss": 0.1353,
        "grad_norm": 1.3026286363601685,
        "learning_rate": 8.763837638376384e-06,
        "epoch": 25.977859778597786,
        "step": 7040
    },
    {
        "eval_loss": 0.5579874515533447,
        "eval_accuracy": 0.86624,
        "eval_precision": 0.83108,
        "eval_recall": 0.9162,
        "eval_f1": 0.87157,
        "eval_runtime": 18.1216,
        "eval_samples_per_second": 59.818,
        "eval_steps_per_second": 3.752,
        "epoch": 26.0,
        "step": 7046
    },
    {
        "train_runtime": 6042.9139,
        "train_samples_per_second": 28.695,
        "train_steps_per_second": 1.794,
        "total_flos": 1.48276235248128e+16,
        "train_loss": 0.2819850829017795,
        "epoch": 26.0,
        "step": 7046
    }
]