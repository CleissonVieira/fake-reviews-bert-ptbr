[
    {
        "loss": 0.646,
        "grad_norm": 10.287921905517578,
        "learning_rate": 2.4976937269372695e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.5453,
        "grad_norm": 13.75543212890625,
        "learning_rate": 2.495387453874539e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.4608,
        "grad_norm": 5.3085503578186035,
        "learning_rate": 2.493081180811808e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.3897,
        "grad_norm": 5.2095417976379395,
        "learning_rate": 2.4907749077490778e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.5126,
        "grad_norm": 3.0949740409851074,
        "learning_rate": 2.488468634686347e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.5108,
        "grad_norm": 6.484792709350586,
        "learning_rate": 2.4861623616236163e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.5294,
        "grad_norm": 3.600517511367798,
        "learning_rate": 2.4838560885608857e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.3964,
        "grad_norm": 4.286661624908447,
        "learning_rate": 2.481549815498155e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.4582,
        "grad_norm": 6.912108421325684,
        "learning_rate": 2.4792435424354242e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.5135,
        "grad_norm": 2.9386024475097656,
        "learning_rate": 2.476937269372694e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.5143,
        "grad_norm": 3.0559473037719727,
        "learning_rate": 2.474630996309963e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4975,
        "grad_norm": 8.753201484680176,
        "learning_rate": 2.472324723247233e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4682,
        "grad_norm": 3.694782018661499,
        "learning_rate": 2.470018450184502e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.467,
        "grad_norm": 4.429357051849365,
        "learning_rate": 2.4677121771217714e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.454,
        "grad_norm": 2.8869142532348633,
        "learning_rate": 2.4654059040590408e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.3958,
        "grad_norm": 3.3722431659698486,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.459,
        "grad_norm": 5.434959888458252,
        "learning_rate": 2.4607933579335796e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.4613,
        "grad_norm": 2.608175039291382,
        "learning_rate": 2.4584870848708487e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.5078,
        "grad_norm": 3.5444791316986084,
        "learning_rate": 2.456180811808118e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4518,
        "grad_norm": 5.625025749206543,
        "learning_rate": 2.4538745387453876e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.4153,
        "grad_norm": 2.8036322593688965,
        "learning_rate": 2.451568265682657e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4312,
        "grad_norm": 7.138509750366211,
        "learning_rate": 2.4492619926199264e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.388,
        "grad_norm": 2.4156906604766846,
        "learning_rate": 2.4469557195571958e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.4517,
        "grad_norm": 5.0120086669921875,
        "learning_rate": 2.444649446494465e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.3586,
        "grad_norm": 4.802760124206543,
        "learning_rate": 2.4423431734317347e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4363,
        "grad_norm": 8.909996032714844,
        "learning_rate": 2.4400369003690038e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4412,
        "grad_norm": 4.790923118591309,
        "learning_rate": 2.4377306273062732e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.41384321451187134,
        "eval_accuracy": 0.83472,
        "eval_precision": 0.81063,
        "eval_recall": 0.88246,
        "eval_f1": 0.84502,
        "eval_runtime": 18.1132,
        "eval_samples_per_second": 59.791,
        "eval_steps_per_second": 3.754,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.4141,
        "grad_norm": 1.8731509447097778,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4256,
        "grad_norm": 3.5690464973449707,
        "learning_rate": 2.4331180811808117e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.4779,
        "grad_norm": 4.299202919006348,
        "learning_rate": 2.4308118081180815e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.486,
        "grad_norm": 3.6149673461914062,
        "learning_rate": 2.4285055350553505e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.3686,
        "grad_norm": 6.926929473876953,
        "learning_rate": 2.42619926199262e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4252,
        "grad_norm": 5.334925174713135,
        "learning_rate": 2.4238929889298894e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.3594,
        "grad_norm": 2.5854334831237793,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.47,
        "grad_norm": 2.5300419330596924,
        "learning_rate": 2.4192804428044282e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.3329,
        "grad_norm": 4.044376373291016,
        "learning_rate": 2.4169741697416977e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.5199,
        "grad_norm": 3.754281997680664,
        "learning_rate": 2.4146678966789667e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.3899,
        "grad_norm": 2.9312756061553955,
        "learning_rate": 2.4123616236162365e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4812,
        "grad_norm": 3.7151222229003906,
        "learning_rate": 2.4100553505535056e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.3782,
        "grad_norm": 4.105433464050293,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.4423,
        "grad_norm": 2.1346423625946045,
        "learning_rate": 2.4054428044280444e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3828,
        "grad_norm": 2.9884531497955322,
        "learning_rate": 2.403136531365314e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.3988,
        "grad_norm": 6.1246137619018555,
        "learning_rate": 2.4008302583025833e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.4857,
        "grad_norm": 3.554497241973877,
        "learning_rate": 2.3985239852398524e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.5467,
        "grad_norm": 3.0662267208099365,
        "learning_rate": 2.3962177121771218e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.4236,
        "grad_norm": 2.047527551651001,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.5168,
        "grad_norm": 6.318937301635742,
        "learning_rate": 2.3916051660516606e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.3189,
        "grad_norm": 1.975480079650879,
        "learning_rate": 2.38929889298893e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.3757,
        "grad_norm": 3.9946441650390625,
        "learning_rate": 2.3869926199261995e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.3332,
        "grad_norm": 2.9703011512756348,
        "learning_rate": 2.3846863468634686e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.3004,
        "grad_norm": 7.543911457061768,
        "learning_rate": 2.3823800738007383e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.5169,
        "grad_norm": 4.695509910583496,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.4871,
        "grad_norm": 9.023849487304688,
        "learning_rate": 2.377767527675277e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.4518,
        "grad_norm": 2.03836989402771,
        "learning_rate": 2.3754612546125462e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.3902313709259033,
        "eval_accuracy": 0.83287,
        "eval_precision": 0.81633,
        "eval_recall": 0.86799,
        "eval_f1": 0.84137,
        "eval_runtime": 18.1268,
        "eval_samples_per_second": 59.746,
        "eval_steps_per_second": 3.751,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.3541,
        "grad_norm": 3.275656223297119,
        "learning_rate": 2.3731549815498157e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4593,
        "grad_norm": 3.852738618850708,
        "learning_rate": 2.370848708487085e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.4059,
        "grad_norm": 3.615483283996582,
        "learning_rate": 2.3685424354243542e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3291,
        "grad_norm": 2.499798536300659,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.3735,
        "grad_norm": 7.45696496963501,
        "learning_rate": 2.363929889298893e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.4348,
        "grad_norm": 1.5542460680007935,
        "learning_rate": 2.3616236162361624e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.4016,
        "grad_norm": 3.846461772918701,
        "learning_rate": 2.359317343173432e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.415,
        "grad_norm": 7.0556254386901855,
        "learning_rate": 2.3570110701107013e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.3522,
        "grad_norm": 3.3037097454071045,
        "learning_rate": 2.3547047970479704e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3639,
        "grad_norm": 1.8889763355255127,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.3735,
        "grad_norm": 1.320595622062683,
        "learning_rate": 2.3500922509225092e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.4505,
        "grad_norm": 4.170404434204102,
        "learning_rate": 2.347785977859779e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3987,
        "grad_norm": 4.658867359161377,
        "learning_rate": 2.345479704797048e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.3968,
        "grad_norm": 1.5839329957962036,
        "learning_rate": 2.3431734317343175e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.4045,
        "grad_norm": 3.7915778160095215,
        "learning_rate": 2.340867158671587e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.3931,
        "grad_norm": 3.666102886199951,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.4742,
        "grad_norm": 3.2689192295074463,
        "learning_rate": 2.3362546125461258e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.3746,
        "grad_norm": 1.7844823598861694,
        "learning_rate": 2.333948339483395e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3663,
        "grad_norm": 1.8747581243515015,
        "learning_rate": 2.3316420664206643e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4447,
        "grad_norm": 4.141909599304199,
        "learning_rate": 2.3293357933579337e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3622,
        "grad_norm": 2.217226505279541,
        "learning_rate": 2.327029520295203e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.3404,
        "grad_norm": 1.2694998979568481,
        "learning_rate": 2.3247232472324722e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.3137,
        "grad_norm": 1.3598953485488892,
        "learning_rate": 2.322416974169742e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.3524,
        "grad_norm": 0.694858968257904,
        "learning_rate": 2.320110701107011e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.3799,
        "grad_norm": 2.5614354610443115,
        "learning_rate": 2.3178044280442808e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.5481,
        "grad_norm": 4.314613342285156,
        "learning_rate": 2.31549815498155e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.3911,
        "grad_norm": 2.357112169265747,
        "learning_rate": 2.3131918819188193e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.3677954375743866,
        "eval_accuracy": 0.86057,
        "eval_precision": 0.81905,
        "eval_recall": 0.93309,
        "eval_f1": 0.87236,
        "eval_runtime": 18.1019,
        "eval_samples_per_second": 59.828,
        "eval_steps_per_second": 3.757,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3709,
        "grad_norm": 3.7892110347747803,
        "learning_rate": 2.3108856088560887e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3759,
        "grad_norm": 4.254272937774658,
        "learning_rate": 2.308579335793358e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.3285,
        "grad_norm": 1.0950002670288086,
        "learning_rate": 2.3062730627306276e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.4255,
        "grad_norm": 1.861038088798523,
        "learning_rate": 2.3039667896678967e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.4183,
        "grad_norm": 1.9828717708587646,
        "learning_rate": 2.301660516605166e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.4307,
        "grad_norm": 1.5831700563430786,
        "learning_rate": 2.2993542435424355e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3393,
        "grad_norm": 2.309213638305664,
        "learning_rate": 2.297047970479705e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3776,
        "grad_norm": 4.049558162689209,
        "learning_rate": 2.294741697416974e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.3816,
        "grad_norm": 3.8973188400268555,
        "learning_rate": 2.2924354243542438e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3939,
        "grad_norm": 2.39270281791687,
        "learning_rate": 2.290129151291513e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.3546,
        "grad_norm": 4.0297770500183105,
        "learning_rate": 2.2878228782287826e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.4122,
        "grad_norm": 3.896245241165161,
        "learning_rate": 2.2855166051660517e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.3669,
        "grad_norm": 3.1006906032562256,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.3551,
        "grad_norm": 2.3989787101745605,
        "learning_rate": 2.2809040590405906e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.395,
        "grad_norm": 4.102634906768799,
        "learning_rate": 2.27859778597786e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.4678,
        "grad_norm": 1.8401451110839844,
        "learning_rate": 2.2762915129151294e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3697,
        "grad_norm": 2.796799659729004,
        "learning_rate": 2.2739852398523985e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.3431,
        "grad_norm": 4.618913650512695,
        "learning_rate": 2.271678966789668e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.3718,
        "grad_norm": 19.457157135009766,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.321,
        "grad_norm": 1.873063325881958,
        "learning_rate": 2.2670664206642068e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.3064,
        "grad_norm": 3.238403081893921,
        "learning_rate": 2.2647601476014762e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.4258,
        "grad_norm": 1.9363478422164917,
        "learning_rate": 2.2624538745387456e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.4077,
        "grad_norm": 2.355290412902832,
        "learning_rate": 2.2601476014760147e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3502,
        "grad_norm": 3.978952646255493,
        "learning_rate": 2.2578413284132844e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.3575,
        "grad_norm": 10.202875137329102,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.3423,
        "grad_norm": 3.8781425952911377,
        "learning_rate": 2.253228782287823e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.3228,
        "grad_norm": 2.1915998458862305,
        "learning_rate": 2.2509225092250924e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.3738958239555359,
        "eval_accuracy": 0.85873,
        "eval_precision": 0.81546,
        "eval_recall": 0.9349,
        "eval_f1": 0.8711,
        "eval_runtime": 18.1067,
        "eval_samples_per_second": 59.812,
        "eval_steps_per_second": 3.756,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3183,
        "grad_norm": 6.733253479003906,
        "learning_rate": 2.2486162361623618e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.4218,
        "grad_norm": 7.9750075340271,
        "learning_rate": 2.2463099630996312e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.2922,
        "grad_norm": 14.401834487915039,
        "learning_rate": 2.2440036900369006e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3904,
        "grad_norm": 1.0693480968475342,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3347,
        "grad_norm": 2.41709566116333,
        "learning_rate": 2.239391143911439e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3585,
        "grad_norm": 4.215532302856445,
        "learning_rate": 2.2370848708487086e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3394,
        "grad_norm": 5.886569499969482,
        "learning_rate": 2.234778597785978e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3831,
        "grad_norm": 3.0992648601531982,
        "learning_rate": 2.2324723247232474e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.46,
        "grad_norm": 3.954604148864746,
        "learning_rate": 2.2301660516605165e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.4452,
        "grad_norm": 2.0470316410064697,
        "learning_rate": 2.2278597785977863e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.3219,
        "grad_norm": 1.4271619319915771,
        "learning_rate": 2.2255535055350553e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3478,
        "grad_norm": 2.0983757972717285,
        "learning_rate": 2.2232472324723248e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.3691,
        "grad_norm": 1.1198499202728271,
        "learning_rate": 2.2209409594095942e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3866,
        "grad_norm": 1.2548972368240356,
        "learning_rate": 2.2186346863468636e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.2878,
        "grad_norm": 2.9336838722229004,
        "learning_rate": 2.216328413284133e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3028,
        "grad_norm": 6.75211238861084,
        "learning_rate": 2.2140221402214025e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3239,
        "grad_norm": 1.8427159786224365,
        "learning_rate": 2.2117158671586715e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.3762,
        "grad_norm": 1.5561879873275757,
        "learning_rate": 2.209409594095941e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3692,
        "grad_norm": 2.3593263626098633,
        "learning_rate": 2.2071033210332104e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.3922,
        "grad_norm": 15.114259719848633,
        "learning_rate": 2.2047970479704798e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.3727,
        "grad_norm": 3.852246046066284,
        "learning_rate": 2.2024907749077492e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.3816,
        "grad_norm": 3.843050718307495,
        "learning_rate": 2.2001845018450183e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.2647,
        "grad_norm": 3.586993455886841,
        "learning_rate": 2.197878228782288e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.3629,
        "grad_norm": 11.77547550201416,
        "learning_rate": 2.195571955719557e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.4459,
        "grad_norm": 2.813809394836426,
        "learning_rate": 2.193265682656827e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.343,
        "grad_norm": 3.285661458969116,
        "learning_rate": 2.190959409594096e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.2849,
        "grad_norm": 1.0133064985275269,
        "learning_rate": 2.1886531365313654e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.39605939388275146,
        "eval_accuracy": 0.86242,
        "eval_precision": 0.83667,
        "eval_recall": 0.90778,
        "eval_f1": 0.87077,
        "eval_runtime": 18.102,
        "eval_samples_per_second": 59.828,
        "eval_steps_per_second": 3.756,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.433,
        "grad_norm": 3.026942014694214,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.2867,
        "grad_norm": 8.248682975769043,
        "learning_rate": 2.1840405904059043e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.3886,
        "grad_norm": 1.8650277853012085,
        "learning_rate": 2.1817343173431734e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.3784,
        "grad_norm": 1.7023627758026123,
        "learning_rate": 2.1794280442804428e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.3227,
        "grad_norm": 2.5409600734710693,
        "learning_rate": 2.1771217712177122e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.3945,
        "grad_norm": 4.502971172332764,
        "learning_rate": 2.1748154981549816e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.4031,
        "grad_norm": 3.4733331203460693,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.3719,
        "grad_norm": 3.019979476928711,
        "learning_rate": 2.17020295202952e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.339,
        "grad_norm": 1.9396401643753052,
        "learning_rate": 2.16789667896679e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.34,
        "grad_norm": 9.322999954223633,
        "learning_rate": 2.165590405904059e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.2613,
        "grad_norm": 1.7645745277404785,
        "learning_rate": 2.1632841328413287e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.3783,
        "grad_norm": 3.9157896041870117,
        "learning_rate": 2.160977859778598e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.3793,
        "grad_norm": 6.535701274871826,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.3296,
        "grad_norm": 2.9622390270233154,
        "learning_rate": 2.1563653136531367e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.2933,
        "grad_norm": 1.9019358158111572,
        "learning_rate": 2.154059040590406e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.3289,
        "grad_norm": 3.4382293224334717,
        "learning_rate": 2.1517527675276755e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.2313,
        "grad_norm": 2.198815107345581,
        "learning_rate": 2.149446494464945e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.3704,
        "grad_norm": 3.6179122924804688,
        "learning_rate": 2.147140221402214e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.3758,
        "grad_norm": 5.3088059425354,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.2991,
        "grad_norm": 5.627506732940674,
        "learning_rate": 2.142527675276753e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.3445,
        "grad_norm": 2.639986276626587,
        "learning_rate": 2.140221402214022e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.3275,
        "grad_norm": 6.820504188537598,
        "learning_rate": 2.1379151291512917e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.3605,
        "grad_norm": 9.799793243408203,
        "learning_rate": 2.1356088560885608e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.3494,
        "grad_norm": 3.0462381839752197,
        "learning_rate": 2.1333025830258306e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.3916,
        "grad_norm": 2.30495285987854,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.3149,
        "grad_norm": 2.200974941253662,
        "learning_rate": 2.128690036900369e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.4185,
        "grad_norm": 2.565703868865967,
        "learning_rate": 2.1263837638376385e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.3590308725833893,
        "eval_accuracy": 0.8615,
        "eval_precision": 0.81633,
        "eval_recall": 0.94033,
        "eval_f1": 0.87395,
        "eval_runtime": 18.097,
        "eval_samples_per_second": 59.844,
        "eval_steps_per_second": 3.758,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.3217,
        "grad_norm": 1.6577872037887573,
        "learning_rate": 2.124077490774908e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3046,
        "grad_norm": 3.8501007556915283,
        "learning_rate": 2.1217712177121773e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.345,
        "grad_norm": 9.653395652770996,
        "learning_rate": 2.1194649446494468e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.3305,
        "grad_norm": 6.9694905281066895,
        "learning_rate": 2.117158671586716e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.2436,
        "grad_norm": 1.4813144207000732,
        "learning_rate": 2.1148523985239853e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.2573,
        "grad_norm": 2.128187656402588,
        "learning_rate": 2.1125461254612547e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.4192,
        "grad_norm": 4.798260688781738,
        "learning_rate": 2.110239852398524e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.3706,
        "grad_norm": 7.445882320404053,
        "learning_rate": 2.1079335793357935e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3176,
        "grad_norm": 3.555107831954956,
        "learning_rate": 2.1056273062730626e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.3494,
        "grad_norm": 5.521788120269775,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.2937,
        "grad_norm": 1.180767297744751,
        "learning_rate": 2.1010147601476015e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.3554,
        "grad_norm": 7.312889575958252,
        "learning_rate": 2.098708487084871e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.3789,
        "grad_norm": 52.322021484375,
        "learning_rate": 2.0964022140221403e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.2622,
        "grad_norm": 1.0103528499603271,
        "learning_rate": 2.0940959409594097e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3368,
        "grad_norm": 3.1638801097869873,
        "learning_rate": 2.091789667896679e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.3358,
        "grad_norm": 1.5382778644561768,
        "learning_rate": 2.0894833948339486e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.4007,
        "grad_norm": 8.200620651245117,
        "learning_rate": 2.0871771217712177e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.3953,
        "grad_norm": 1.6079610586166382,
        "learning_rate": 2.084870848708487e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.3505,
        "grad_norm": 9.523816108703613,
        "learning_rate": 2.0825645756457565e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3572,
        "grad_norm": 2.86629056930542,
        "learning_rate": 2.080258302583026e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.2937,
        "grad_norm": 5.972110748291016,
        "learning_rate": 2.0779520295202954e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3072,
        "grad_norm": 0.9452866911888123,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.3234,
        "grad_norm": 3.7245357036590576,
        "learning_rate": 2.0733394833948342e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.4615,
        "grad_norm": 2.338770866394043,
        "learning_rate": 2.0710332103321033e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.3699,
        "grad_norm": 3.545245409011841,
        "learning_rate": 2.0687269372693727e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.3559,
        "grad_norm": 8.320547103881836,
        "learning_rate": 2.066420664206642e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3748,
        "grad_norm": 3.0614004135131836,
        "learning_rate": 2.0641143911439116e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.37037932872772217,
        "eval_accuracy": 0.8458,
        "eval_precision": 0.86007,
        "eval_recall": 0.83363,
        "eval_f1": 0.84665,
        "eval_runtime": 18.1141,
        "eval_samples_per_second": 59.788,
        "eval_steps_per_second": 3.754,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.3676,
        "grad_norm": 5.954141616821289,
        "learning_rate": 2.061808118081181e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.2999,
        "grad_norm": 7.850009918212891,
        "learning_rate": 2.0595018450184504e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.2701,
        "grad_norm": 6.309845447540283,
        "learning_rate": 2.0571955719557195e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.2376,
        "grad_norm": 3.2821192741394043,
        "learning_rate": 2.0548892988929893e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.3469,
        "grad_norm": 2.859745502471924,
        "learning_rate": 2.0525830258302583e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3741,
        "grad_norm": 33.45960998535156,
        "learning_rate": 2.0502767527675278e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.2901,
        "grad_norm": 21.920352935791016,
        "learning_rate": 2.0479704797047972e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.3294,
        "grad_norm": 1.4153271913528442,
        "learning_rate": 2.0456642066420663e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.4132,
        "grad_norm": 3.5015621185302734,
        "learning_rate": 2.043357933579336e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.3328,
        "grad_norm": 3.237018585205078,
        "learning_rate": 2.041051660516605e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.3273,
        "grad_norm": 2.8211073875427246,
        "learning_rate": 2.0387453874538745e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.2715,
        "grad_norm": 2.4336612224578857,
        "learning_rate": 2.036439114391144e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.2908,
        "grad_norm": 4.569924831390381,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.4011,
        "grad_norm": 26.04219627380371,
        "learning_rate": 2.0318265682656828e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.2571,
        "grad_norm": 15.19737434387207,
        "learning_rate": 2.0295202952029522e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.3171,
        "grad_norm": 2.5182886123657227,
        "learning_rate": 2.0272140221402213e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.3661,
        "grad_norm": 2.6851541996002197,
        "learning_rate": 2.024907749077491e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.3345,
        "grad_norm": 2.420799493789673,
        "learning_rate": 2.02260147601476e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.3768,
        "grad_norm": 7.27186393737793,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.2451,
        "grad_norm": 1.119411826133728,
        "learning_rate": 2.017988929889299e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.3931,
        "grad_norm": 2.191175937652588,
        "learning_rate": 2.0156826568265684e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.294,
        "grad_norm": 1.76197350025177,
        "learning_rate": 2.013376383763838e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.3181,
        "grad_norm": 2.6098134517669678,
        "learning_rate": 2.011070110701107e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.5229,
        "grad_norm": 4.721043109893799,
        "learning_rate": 2.0087638376383767e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.3639,
        "grad_norm": 10.329019546508789,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.2565,
        "grad_norm": 3.243687152862549,
        "learning_rate": 2.0041512915129152e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.3769,
        "grad_norm": 2.888139247894287,
        "learning_rate": 2.0018450184501846e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.3593333661556244,
        "eval_accuracy": 0.87535,
        "eval_precision": 0.84375,
        "eval_recall": 0.92767,
        "eval_f1": 0.88372,
        "eval_runtime": 18.1124,
        "eval_samples_per_second": 59.793,
        "eval_steps_per_second": 3.754,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.2926,
        "grad_norm": 18.082229614257812,
        "learning_rate": 1.999538745387454e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3086,
        "grad_norm": 2.759298324584961,
        "learning_rate": 1.997232472324723e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.3135,
        "grad_norm": 5.275181293487549,
        "learning_rate": 1.994926199261993e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.2899,
        "grad_norm": 1.7902613878250122,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.3978,
        "grad_norm": 4.222219944000244,
        "learning_rate": 1.9903136531365314e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.2539,
        "grad_norm": 2.3113815784454346,
        "learning_rate": 1.9880073800738008e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.3599,
        "grad_norm": 4.485259532928467,
        "learning_rate": 1.9857011070110702e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.3579,
        "grad_norm": 2.2781660556793213,
        "learning_rate": 1.9833948339483397e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.2328,
        "grad_norm": 16.234891891479492,
        "learning_rate": 1.9810885608856088e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.337,
        "grad_norm": 12.924189567565918,
        "learning_rate": 1.9787822878228785e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.2631,
        "grad_norm": 1.9553279876708984,
        "learning_rate": 1.9764760147601476e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.3601,
        "grad_norm": 9.388773918151855,
        "learning_rate": 1.974169741697417e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.1852,
        "grad_norm": 0.7390443086624146,
        "learning_rate": 1.9718634686346864e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.3729,
        "grad_norm": 4.781890392303467,
        "learning_rate": 1.969557195571956e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.4261,
        "grad_norm": 1.7657015323638916,
        "learning_rate": 1.9672509225092253e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.2267,
        "grad_norm": 1.8256090879440308,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.3708,
        "grad_norm": 6.623445510864258,
        "learning_rate": 1.9626383763837638e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3624,
        "grad_norm": 4.673515796661377,
        "learning_rate": 1.9603321033210336e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.3617,
        "grad_norm": 2.6959643363952637,
        "learning_rate": 1.9580258302583026e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.3153,
        "grad_norm": 3.6659605503082275,
        "learning_rate": 1.955719557195572e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3436,
        "grad_norm": 3.2716121673583984,
        "learning_rate": 1.9534132841328415e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.2297,
        "grad_norm": 3.6197543144226074,
        "learning_rate": 1.9511070110701106e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.4295,
        "grad_norm": 28.829002380371094,
        "learning_rate": 1.9488007380073803e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.3568,
        "grad_norm": 3.381157636642456,
        "learning_rate": 1.9464944649446494e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.2328,
        "grad_norm": 1.3669606447219849,
        "learning_rate": 1.944188191881919e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.2737,
        "grad_norm": 3.34102463722229,
        "learning_rate": 1.9418819188191883e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3113,
        "grad_norm": 3.2884199619293213,
        "learning_rate": 1.9395756457564577e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.3622026741504669,
        "eval_accuracy": 0.8735,
        "eval_precision": 0.83876,
        "eval_recall": 0.93128,
        "eval_f1": 0.8826,
        "eval_runtime": 18.0525,
        "eval_samples_per_second": 59.992,
        "eval_steps_per_second": 3.767,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.3303,
        "grad_norm": 1.3364534378051758,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.3185,
        "grad_norm": 1.2382750511169434,
        "learning_rate": 1.9349630996309965e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3363,
        "grad_norm": 2.7905306816101074,
        "learning_rate": 1.9326568265682656e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.2747,
        "grad_norm": 1.1159214973449707,
        "learning_rate": 1.9303505535055354e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.305,
        "grad_norm": 4.146052360534668,
        "learning_rate": 1.9280442804428045e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.2928,
        "grad_norm": 14.312564849853516,
        "learning_rate": 1.925738007380074e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3538,
        "grad_norm": 9.335433006286621,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.3019,
        "grad_norm": 3.178057909011841,
        "learning_rate": 1.9211254612546127e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.2888,
        "grad_norm": 4.247066974639893,
        "learning_rate": 1.918819188191882e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.2275,
        "grad_norm": 2.795429229736328,
        "learning_rate": 1.9165129151291512e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.2089,
        "grad_norm": 0.9133520126342773,
        "learning_rate": 1.9142066420664207e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.47,
        "grad_norm": 3.9258854389190674,
        "learning_rate": 1.91190036900369e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.3229,
        "grad_norm": 3.287137031555176,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.2769,
        "grad_norm": 1.6097769737243652,
        "learning_rate": 1.907287822878229e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.2588,
        "grad_norm": 1.2560442686080933,
        "learning_rate": 1.9049815498154984e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.2357,
        "grad_norm": 6.456359386444092,
        "learning_rate": 1.9026752767527674e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.3552,
        "grad_norm": 1.2926568984985352,
        "learning_rate": 1.9003690036900372e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.3985,
        "grad_norm": 7.664482116699219,
        "learning_rate": 1.8980627306273063e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.3834,
        "grad_norm": 1.6411120891571045,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.2281,
        "grad_norm": 8.000699043273926,
        "learning_rate": 1.893450184501845e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.2852,
        "grad_norm": 4.730839729309082,
        "learning_rate": 1.8911439114391146e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.2846,
        "grad_norm": 1.2116221189498901,
        "learning_rate": 1.888837638376384e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3667,
        "grad_norm": 2.2057292461395264,
        "learning_rate": 1.886531365313653e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.3168,
        "grad_norm": 1.0968478918075562,
        "learning_rate": 1.8842250922509225e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.2788,
        "grad_norm": 10.801691055297852,
        "learning_rate": 1.881918819188192e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.392,
        "grad_norm": 8.03596019744873,
        "learning_rate": 1.8796125461254613e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.29,
        "grad_norm": 1.2681705951690674,
        "learning_rate": 1.8773062730627308e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.3559,
        "grad_norm": 3.136512517929077,
        "learning_rate": 1.8750000000000002e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.3731273412704468,
        "eval_accuracy": 0.86334,
        "eval_precision": 0.84497,
        "eval_recall": 0.89693,
        "eval_f1": 0.87018,
        "eval_runtime": 18.0108,
        "eval_samples_per_second": 60.131,
        "eval_steps_per_second": 3.776,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.2605,
        "grad_norm": 2.5958621501922607,
        "learning_rate": 1.8726937269372693e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.4054,
        "grad_norm": 2.930375337600708,
        "learning_rate": 1.870387453874539e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.2945,
        "grad_norm": 8.60982894897461,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.2981,
        "grad_norm": 7.098296165466309,
        "learning_rate": 1.865774907749078e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3564,
        "grad_norm": 2.2609705924987793,
        "learning_rate": 1.863468634686347e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.3137,
        "grad_norm": 3.5023956298828125,
        "learning_rate": 1.8611623616236164e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.263,
        "grad_norm": 3.7859394550323486,
        "learning_rate": 1.8588560885608858e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.2325,
        "grad_norm": 2.5598905086517334,
        "learning_rate": 1.856549815498155e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.2181,
        "grad_norm": 4.470206260681152,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3255,
        "grad_norm": 10.563793182373047,
        "learning_rate": 1.8519372693726937e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.2609,
        "grad_norm": 5.184947490692139,
        "learning_rate": 1.849630996309963e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.2423,
        "grad_norm": 1.5979976654052734,
        "learning_rate": 1.8473247232472326e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.3379,
        "grad_norm": 7.27398681640625,
        "learning_rate": 1.845018450184502e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.3315,
        "grad_norm": 6.050599098205566,
        "learning_rate": 1.842712177121771e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.2978,
        "grad_norm": 7.1207661628723145,
        "learning_rate": 1.840405904059041e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.2643,
        "grad_norm": 1.7146226167678833,
        "learning_rate": 1.83809963099631e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3066,
        "grad_norm": 3.8835225105285645,
        "learning_rate": 1.8357933579335797e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.3094,
        "grad_norm": 2.865139961242676,
        "learning_rate": 1.8334870848708488e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2879,
        "grad_norm": 1.3998059034347534,
        "learning_rate": 1.8311808118081182e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.3415,
        "grad_norm": 1.035433053970337,
        "learning_rate": 1.8288745387453876e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.328,
        "grad_norm": 1.068406105041504,
        "learning_rate": 1.826568265682657e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.3699,
        "grad_norm": 1.47780442237854,
        "learning_rate": 1.8242619926199265e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.3487,
        "grad_norm": 2.552668571472168,
        "learning_rate": 1.8219557195571955e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.2799,
        "grad_norm": 1.1367652416229248,
        "learning_rate": 1.819649446494465e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.3807,
        "grad_norm": 2.5694944858551025,
        "learning_rate": 1.8173431734317344e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.3062,
        "grad_norm": 2.485238790512085,
        "learning_rate": 1.8150369003690038e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.3215,
        "grad_norm": 1.8947409391403198,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.35158011317253113,
        "eval_accuracy": 0.86888,
        "eval_precision": 0.84538,
        "eval_recall": 0.90958,
        "eval_f1": 0.87631,
        "eval_runtime": 18.1061,
        "eval_samples_per_second": 59.814,
        "eval_steps_per_second": 3.756,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.2541,
        "grad_norm": 1.795236349105835,
        "learning_rate": 1.8104243542435427e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.322,
        "grad_norm": 8.904817581176758,
        "learning_rate": 1.8081180811808117e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.2773,
        "grad_norm": 6.945827007293701,
        "learning_rate": 1.8058118081180815e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.2737,
        "grad_norm": 1.8277473449707031,
        "learning_rate": 1.8035055350553506e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.3486,
        "grad_norm": 5.600178241729736,
        "learning_rate": 1.80119926199262e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.4274,
        "grad_norm": 2.08724045753479,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.3159,
        "grad_norm": 13.269579887390137,
        "learning_rate": 1.796586715867159e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.2286,
        "grad_norm": 4.923859119415283,
        "learning_rate": 1.7942804428044283e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.32,
        "grad_norm": 3.750811815261841,
        "learning_rate": 1.7919741697416974e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.3108,
        "grad_norm": 2.242465019226074,
        "learning_rate": 1.7896678966789668e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.2053,
        "grad_norm": 2.138056516647339,
        "learning_rate": 1.7873616236162362e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.3131,
        "grad_norm": 5.4328131675720215,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.2204,
        "grad_norm": 5.9629364013671875,
        "learning_rate": 1.7827490774907747e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.2629,
        "grad_norm": 1.5095680952072144,
        "learning_rate": 1.7804428044280445e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.2992,
        "grad_norm": 1.8695296049118042,
        "learning_rate": 1.7781365313653136e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.2584,
        "grad_norm": 4.661712646484375,
        "learning_rate": 1.7758302583025833e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.3364,
        "grad_norm": 1.0883681774139404,
        "learning_rate": 1.7735239852398524e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.3363,
        "grad_norm": 2.1024158000946045,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.2655,
        "grad_norm": 1.2342568635940552,
        "learning_rate": 1.7689114391143913e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.427,
        "grad_norm": 7.953907012939453,
        "learning_rate": 1.7666051660516607e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.3045,
        "grad_norm": 8.552308082580566,
        "learning_rate": 1.76429889298893e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.2849,
        "grad_norm": 9.894501686096191,
        "learning_rate": 1.7619926199261992e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.2456,
        "grad_norm": 2.6307339668273926,
        "learning_rate": 1.7596863468634686e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.3585,
        "grad_norm": 3.478863477706909,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.3172,
        "grad_norm": 1.5197383165359497,
        "learning_rate": 1.7550738007380075e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2867,
        "grad_norm": 2.813951015472412,
        "learning_rate": 1.752767527675277e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.1921,
        "grad_norm": 2.3184945583343506,
        "learning_rate": 1.7504612546125463e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.38130706548690796,
        "eval_accuracy": 0.87904,
        "eval_precision": 0.84477,
        "eval_recall": 0.9349,
        "eval_f1": 0.88755,
        "eval_runtime": 18.0974,
        "eval_samples_per_second": 59.843,
        "eval_steps_per_second": 3.757,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.2797,
        "grad_norm": 5.491975784301758,
        "learning_rate": 1.7481549815498154e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.3091,
        "grad_norm": 7.640390396118164,
        "learning_rate": 1.745848708487085e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.2842,
        "grad_norm": 9.95770263671875,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.2303,
        "grad_norm": 3.8591196537017822,
        "learning_rate": 1.7412361623616237e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2942,
        "grad_norm": 1.4182852506637573,
        "learning_rate": 1.738929889298893e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.1906,
        "grad_norm": 10.708748817443848,
        "learning_rate": 1.7366236162361625e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.2508,
        "grad_norm": 3.5068960189819336,
        "learning_rate": 1.734317343173432e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.2588,
        "grad_norm": 2.809678792953491,
        "learning_rate": 1.7320110701107013e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.332,
        "grad_norm": 1.170872449874878,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.371,
        "grad_norm": 1.3446955680847168,
        "learning_rate": 1.72739852398524e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.2712,
        "grad_norm": 2.53627872467041,
        "learning_rate": 1.7250922509225093e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.3522,
        "grad_norm": 6.081546783447266,
        "learning_rate": 1.7227859778597787e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.2738,
        "grad_norm": 12.810152053833008,
        "learning_rate": 1.720479704797048e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.3191,
        "grad_norm": 1.7232708930969238,
        "learning_rate": 1.7181734317343172e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.308,
        "grad_norm": 1.5743261575698853,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.3155,
        "grad_norm": 2.0517778396606445,
        "learning_rate": 1.713560885608856e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.2686,
        "grad_norm": 7.443554401397705,
        "learning_rate": 1.7112546125461258e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.2972,
        "grad_norm": 9.800891876220703,
        "learning_rate": 1.708948339483395e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.2845,
        "grad_norm": 3.473423719406128,
        "learning_rate": 1.7066420664206643e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.2703,
        "grad_norm": 5.957879066467285,
        "learning_rate": 1.7043357933579337e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.3027,
        "grad_norm": 12.76024055480957,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.3483,
        "grad_norm": 4.623650550842285,
        "learning_rate": 1.6997232472324722e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.3728,
        "grad_norm": 4.284265995025635,
        "learning_rate": 1.6974169741697417e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.265,
        "grad_norm": 1.6724121570587158,
        "learning_rate": 1.695110701107011e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.2113,
        "grad_norm": 3.049490451812744,
        "learning_rate": 1.6928044280442805e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.291,
        "grad_norm": 4.352173805236816,
        "learning_rate": 1.69049815498155e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.2504,
        "grad_norm": 3.5360560417175293,
        "learning_rate": 1.688191881918819e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.37634512782096863,
        "eval_accuracy": 0.8735,
        "eval_precision": 0.83016,
        "eval_recall": 0.94575,
        "eval_f1": 0.88419,
        "eval_runtime": 18.0864,
        "eval_samples_per_second": 59.879,
        "eval_steps_per_second": 3.76,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.195,
        "grad_norm": 12.554863929748535,
        "learning_rate": 1.6858856088560888e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.2804,
        "grad_norm": 4.01814079284668,
        "learning_rate": 1.683579335793358e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.286,
        "grad_norm": 0.7670072913169861,
        "learning_rate": 1.6812730627306276e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.2418,
        "grad_norm": 0.9225600957870483,
        "learning_rate": 1.6789667896678967e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.2934,
        "grad_norm": 3.7390599250793457,
        "learning_rate": 1.676660516605166e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.377,
        "grad_norm": 1.677690029144287,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.2788,
        "grad_norm": 1.9822291135787964,
        "learning_rate": 1.672047970479705e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.194,
        "grad_norm": 1.337231159210205,
        "learning_rate": 1.669741697416974e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.2106,
        "grad_norm": 11.286148071289062,
        "learning_rate": 1.6674354243542435e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.3063,
        "grad_norm": 14.781620025634766,
        "learning_rate": 1.665129151291513e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.233,
        "grad_norm": 1.7700244188308716,
        "learning_rate": 1.6628228782287823e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.2712,
        "grad_norm": 4.432166576385498,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.263,
        "grad_norm": 1.3350660800933838,
        "learning_rate": 1.658210332103321e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.3074,
        "grad_norm": 1.0953468084335327,
        "learning_rate": 1.6559040590405906e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.2832,
        "grad_norm": 1.8120406866073608,
        "learning_rate": 1.6535977859778597e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2762,
        "grad_norm": 3.1457648277282715,
        "learning_rate": 1.6512915129151295e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2754,
        "grad_norm": 23.385169982910156,
        "learning_rate": 1.6489852398523985e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.4449,
        "grad_norm": 14.020846366882324,
        "learning_rate": 1.646678966789668e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.2514,
        "grad_norm": 1.8792665004730225,
        "learning_rate": 1.6443726937269374e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.4114,
        "grad_norm": 2.3562777042388916,
        "learning_rate": 1.6420664206642068e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.3008,
        "grad_norm": 7.383169174194336,
        "learning_rate": 1.6397601476014762e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.2497,
        "grad_norm": 4.904787063598633,
        "learning_rate": 1.6374538745387457e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.2988,
        "grad_norm": 23.703632354736328,
        "learning_rate": 1.6351476014760147e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.2648,
        "grad_norm": 2.0871689319610596,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.2718,
        "grad_norm": 0.7745195627212524,
        "learning_rate": 1.6305350553505536e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.3148,
        "grad_norm": 2.1547842025756836,
        "learning_rate": 1.6282287822878227e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.2858,
        "grad_norm": 4.964738845825195,
        "learning_rate": 1.6259225092250924e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.36534371972084045,
        "eval_accuracy": 0.87535,
        "eval_precision": 0.83819,
        "eval_recall": 0.93671,
        "eval_f1": 0.88471,
        "eval_runtime": 18.2309,
        "eval_samples_per_second": 59.405,
        "eval_steps_per_second": 3.73,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.3214,
        "grad_norm": 4.696868896484375,
        "learning_rate": 1.6236162361623615e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.2788,
        "grad_norm": 1.479265809059143,
        "learning_rate": 1.6213099630996313e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.3031,
        "grad_norm": 1.651716947555542,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.3936,
        "grad_norm": 2.606959342956543,
        "learning_rate": 1.6166974169741698e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.2256,
        "grad_norm": 17.33098793029785,
        "learning_rate": 1.6143911439114392e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.2933,
        "grad_norm": 3.308894634246826,
        "learning_rate": 1.6120848708487086e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.24,
        "grad_norm": 3.9994118213653564,
        "learning_rate": 1.609778597785978e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.2053,
        "grad_norm": 17.676252365112305,
        "learning_rate": 1.6074723247232475e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2523,
        "grad_norm": 1.128171682357788,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.2467,
        "grad_norm": 10.019051551818848,
        "learning_rate": 1.602859778597786e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.2777,
        "grad_norm": 3.0129854679107666,
        "learning_rate": 1.6005535055350554e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.2485,
        "grad_norm": 9.531976699829102,
        "learning_rate": 1.5982472324723248e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.2799,
        "grad_norm": 11.779256820678711,
        "learning_rate": 1.5959409594095942e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.3003,
        "grad_norm": 0.9370707869529724,
        "learning_rate": 1.5936346863468633e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.2849,
        "grad_norm": 2.501514196395874,
        "learning_rate": 1.591328413284133e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.2393,
        "grad_norm": 4.005121231079102,
        "learning_rate": 1.5890221402214022e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.2547,
        "grad_norm": 0.9127806425094604,
        "learning_rate": 1.5867158671586716e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.2779,
        "grad_norm": 3.625343084335327,
        "learning_rate": 1.584409594095941e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.2479,
        "grad_norm": 52.22539520263672,
        "learning_rate": 1.5821033210332104e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.2405,
        "grad_norm": 2.630197048187256,
        "learning_rate": 1.57979704797048e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.2729,
        "grad_norm": 1.652256727218628,
        "learning_rate": 1.5774907749077493e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.3045,
        "grad_norm": 1.8506734371185303,
        "learning_rate": 1.5751845018450184e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.3622,
        "grad_norm": 5.654271125793457,
        "learning_rate": 1.5728782287822878e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.3381,
        "grad_norm": 2.284349203109741,
        "learning_rate": 1.5705719557195572e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.1942,
        "grad_norm": 3.6126763820648193,
        "learning_rate": 1.5682656826568266e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.3573,
        "grad_norm": 5.420169830322266,
        "learning_rate": 1.565959409594096e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.2841,
        "grad_norm": 1.4196014404296875,
        "learning_rate": 1.563653136531365e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.375205397605896,
        "eval_accuracy": 0.87904,
        "eval_precision": 0.84142,
        "eval_recall": 0.94033,
        "eval_f1": 0.88813,
        "eval_runtime": 18.0433,
        "eval_samples_per_second": 60.022,
        "eval_steps_per_second": 3.769,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.2178,
        "grad_norm": 1.8390469551086426,
        "learning_rate": 1.561346863468635e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.2486,
        "grad_norm": 2.658442735671997,
        "learning_rate": 1.559040590405904e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.1652,
        "grad_norm": 31.50418472290039,
        "learning_rate": 1.5567343173431734e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.4221,
        "grad_norm": 4.152522087097168,
        "learning_rate": 1.554428044280443e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.2942,
        "grad_norm": 3.1298584938049316,
        "learning_rate": 1.5521217712177123e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.2259,
        "grad_norm": 1.3481842279434204,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.2052,
        "grad_norm": 5.4186882972717285,
        "learning_rate": 1.547509225092251e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.3531,
        "grad_norm": 7.9582695960998535,
        "learning_rate": 1.5452029520295202e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.2278,
        "grad_norm": 11.565837860107422,
        "learning_rate": 1.54289667896679e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.245,
        "grad_norm": 2.4541776180267334,
        "learning_rate": 1.540590405904059e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.3353,
        "grad_norm": 1.0259284973144531,
        "learning_rate": 1.5382841328413285e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.2472,
        "grad_norm": 29.513763427734375,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.2127,
        "grad_norm": 4.247775554656982,
        "learning_rate": 1.533671586715867e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.3061,
        "grad_norm": 7.929562091827393,
        "learning_rate": 1.5313653136531367e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.1882,
        "grad_norm": 2.689512014389038,
        "learning_rate": 1.5290590405904058e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.281,
        "grad_norm": 3.000241756439209,
        "learning_rate": 1.5267527675276756e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.2965,
        "grad_norm": 5.5959038734436035,
        "learning_rate": 1.5244464944649448e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2534,
        "grad_norm": 3.450815439224243,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.2602,
        "grad_norm": 1.8721506595611572,
        "learning_rate": 1.5198339483394835e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.1492,
        "grad_norm": 1.5502053499221802,
        "learning_rate": 1.5175276752767528e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.3748,
        "grad_norm": 18.102888107299805,
        "learning_rate": 1.515221402214022e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.306,
        "grad_norm": 4.85653829574585,
        "learning_rate": 1.5129151291512916e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.2899,
        "grad_norm": 5.301210403442383,
        "learning_rate": 1.5106088560885609e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.3122,
        "grad_norm": 14.630560874938965,
        "learning_rate": 1.5083025830258305e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.1879,
        "grad_norm": 1.6047755479812622,
        "learning_rate": 1.5059963099630997e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.2767,
        "grad_norm": 12.849129676818848,
        "learning_rate": 1.503690036900369e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.2497,
        "grad_norm": 3.2301344871520996,
        "learning_rate": 1.5013837638376386e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.3749220669269562,
        "eval_accuracy": 0.87627,
        "eval_precision": 0.84628,
        "eval_recall": 0.92586,
        "eval_f1": 0.88428,
        "eval_runtime": 965.4614,
        "eval_samples_per_second": 1.122,
        "eval_steps_per_second": 0.07,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.2462,
        "grad_norm": 0.6636919379234314,
        "learning_rate": 1.4990774907749078e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.3174,
        "grad_norm": 0.9770304560661316,
        "learning_rate": 1.4967712177121774e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.3361,
        "grad_norm": 4.325512409210205,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.2621,
        "grad_norm": 21.135770797729492,
        "learning_rate": 1.4921586715867159e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.268,
        "grad_norm": 1.7336829900741577,
        "learning_rate": 1.4898523985239853e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.3001,
        "grad_norm": 1.7989351749420166,
        "learning_rate": 1.4875461254612546e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.2444,
        "grad_norm": 2.0379669666290283,
        "learning_rate": 1.485239852398524e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.2462,
        "grad_norm": 23.848093032836914,
        "learning_rate": 1.4829335793357934e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.2423,
        "grad_norm": 1.6737803220748901,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.3661,
        "grad_norm": 3.5143826007843018,
        "learning_rate": 1.4783210332103323e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.3202,
        "grad_norm": 1.1401402950286865,
        "learning_rate": 1.4760147601476015e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.2638,
        "grad_norm": 18.88595962524414,
        "learning_rate": 1.4737084870848708e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.2206,
        "grad_norm": 1.8771297931671143,
        "learning_rate": 1.4714022140221404e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.3055,
        "grad_norm": 61.98204803466797,
        "learning_rate": 1.4690959409594096e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.2798,
        "grad_norm": 1.2241520881652832,
        "learning_rate": 1.4667896678966792e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.2044,
        "grad_norm": 2.516559362411499,
        "learning_rate": 1.4644833948339485e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.2665,
        "grad_norm": 1.506339430809021,
        "learning_rate": 1.4621771217712177e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.2614,
        "grad_norm": 3.000267267227173,
        "learning_rate": 1.4598708487084871e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.3327,
        "grad_norm": 1.5110437870025635,
        "learning_rate": 1.4575645756457566e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.1781,
        "grad_norm": 2.9262912273406982,
        "learning_rate": 1.455258302583026e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.2081,
        "grad_norm": 1.4645531177520752,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.3054,
        "grad_norm": 1.35541570186615,
        "learning_rate": 1.4506457564575645e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.2764,
        "grad_norm": 10.984614372253418,
        "learning_rate": 1.4483394833948341e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.1997,
        "grad_norm": 4.274777412414551,
        "learning_rate": 1.4460332103321033e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.278,
        "grad_norm": 0.45045244693756104,
        "learning_rate": 1.4437269372693726e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.1966,
        "grad_norm": 1.7447220087051392,
        "learning_rate": 1.4414206642066422e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.1827,
        "grad_norm": 15.312137603759766,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.39895182847976685,
        "eval_accuracy": 0.87535,
        "eval_precision": 0.8415,
        "eval_recall": 0.93128,
        "eval_f1": 0.88412,
        "eval_runtime": 32.109,
        "eval_samples_per_second": 33.729,
        "eval_steps_per_second": 2.118,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.2407,
        "grad_norm": 5.358603000640869,
        "learning_rate": 1.436808118081181e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.2103,
        "grad_norm": 8.325824737548828,
        "learning_rate": 1.4345018450184503e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.2383,
        "grad_norm": 10.95619010925293,
        "learning_rate": 1.4321955719557195e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.2255,
        "grad_norm": 3.7790720462799072,
        "learning_rate": 1.4298892988929891e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.4059,
        "grad_norm": 6.1297478675842285,
        "learning_rate": 1.4275830258302584e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.3329,
        "grad_norm": 1.82290518283844,
        "learning_rate": 1.4252767527675278e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.2325,
        "grad_norm": 2.0845859050750732,
        "learning_rate": 1.422970479704797e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.169,
        "grad_norm": 35.16307067871094,
        "learning_rate": 1.4206642066420663e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2403,
        "grad_norm": 22.463584899902344,
        "learning_rate": 1.4183579335793359e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.2908,
        "grad_norm": 8.73747444152832,
        "learning_rate": 1.4160516605166052e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.4772,
        "grad_norm": 24.601720809936523,
        "learning_rate": 1.4137453874538744e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.2645,
        "grad_norm": 2.3579633235931396,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.2668,
        "grad_norm": 1.0881602764129639,
        "learning_rate": 1.4091328413284133e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.2371,
        "grad_norm": 3.5855040550231934,
        "learning_rate": 1.4068265682656829e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.2101,
        "grad_norm": 1.4992549419403076,
        "learning_rate": 1.4045202952029521e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.2136,
        "grad_norm": 2.831601858139038,
        "learning_rate": 1.4022140221402214e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.2924,
        "grad_norm": 3.440762758255005,
        "learning_rate": 1.399907749077491e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.3178,
        "grad_norm": 2.870000123977661,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.3136,
        "grad_norm": 2.6222636699676514,
        "learning_rate": 1.3952952029520296e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.234,
        "grad_norm": 3.365525960922241,
        "learning_rate": 1.3929889298892989e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.2443,
        "grad_norm": 4.9115166664123535,
        "learning_rate": 1.3906826568265683e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.2135,
        "grad_norm": 3.204019069671631,
        "learning_rate": 1.3883763837638377e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.2089,
        "grad_norm": 4.679652690887451,
        "learning_rate": 1.386070110701107e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.3313,
        "grad_norm": 27.302038192749023,
        "learning_rate": 1.3837638376383766e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.1975,
        "grad_norm": 3.693979501724243,
        "learning_rate": 1.3814575645756458e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.3718,
        "grad_norm": 2.773283004760742,
        "learning_rate": 1.3791512915129151e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.1066,
        "grad_norm": 14.523736000061035,
        "learning_rate": 1.3768450184501847e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.4434981346130371,
        "eval_accuracy": 0.86611,
        "eval_precision": 0.82692,
        "eval_recall": 0.93309,
        "eval_f1": 0.87681,
        "eval_runtime": 30.392,
        "eval_samples_per_second": 35.634,
        "eval_steps_per_second": 2.237,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.3089,
        "grad_norm": 11.552918434143066,
        "learning_rate": 1.374538745387454e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.2197,
        "grad_norm": 2.1311774253845215,
        "learning_rate": 1.3722324723247232e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.2866,
        "grad_norm": 2.4513943195343018,
        "learning_rate": 1.3699261992619928e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.274,
        "grad_norm": 21.579973220825195,
        "learning_rate": 1.367619926199262e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2192,
        "grad_norm": 1.2512900829315186,
        "learning_rate": 1.3653136531365315e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.1663,
        "grad_norm": 1.174393892288208,
        "learning_rate": 1.3630073800738009e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.2992,
        "grad_norm": 1.43906569480896,
        "learning_rate": 1.3607011070110701e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2959,
        "grad_norm": 4.315361499786377,
        "learning_rate": 1.3583948339483396e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.1939,
        "grad_norm": 2.2399096488952637,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.2712,
        "grad_norm": 4.223773956298828,
        "learning_rate": 1.3537822878228784e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.2187,
        "grad_norm": 2.9358925819396973,
        "learning_rate": 1.3514760147601477e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.2643,
        "grad_norm": 4.546814441680908,
        "learning_rate": 1.3491697416974169e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.1769,
        "grad_norm": 4.2210893630981445,
        "learning_rate": 1.3468634686346865e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.2427,
        "grad_norm": 2.321093797683716,
        "learning_rate": 1.3445571955719558e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.3094,
        "grad_norm": 2.144573211669922,
        "learning_rate": 1.3422509225092253e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.308,
        "grad_norm": 36.49833679199219,
        "learning_rate": 1.3399446494464946e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.2365,
        "grad_norm": 2.743183135986328,
        "learning_rate": 1.3376383763837639e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.324,
        "grad_norm": 27.615764617919922,
        "learning_rate": 1.3353321033210334e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.2361,
        "grad_norm": 2.925233840942383,
        "learning_rate": 1.3330258302583027e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.2015,
        "grad_norm": 11.521238327026367,
        "learning_rate": 1.330719557195572e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.2328,
        "grad_norm": 0.8665445446968079,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.2878,
        "grad_norm": 2.3259243965148926,
        "learning_rate": 1.3261070110701106e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.2781,
        "grad_norm": 14.429567337036133,
        "learning_rate": 1.3238007380073802e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2851,
        "grad_norm": 12.128901481628418,
        "learning_rate": 1.3214944649446495e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.2363,
        "grad_norm": 32.693214416503906,
        "learning_rate": 1.3191881918819187e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.3043,
        "grad_norm": 2.3740763664245605,
        "learning_rate": 1.3168819188191883e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.2661,
        "grad_norm": 4.20119047164917,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.36266252398490906,
        "eval_accuracy": 0.88273,
        "eval_precision": 0.84804,
        "eval_recall": 0.93852,
        "eval_f1": 0.89099,
        "eval_runtime": 42.0193,
        "eval_samples_per_second": 25.774,
        "eval_steps_per_second": 1.618,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.2631,
        "grad_norm": 4.155176162719727,
        "learning_rate": 1.3122693726937272e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.19,
        "grad_norm": 3.879199504852295,
        "learning_rate": 1.3099630996309964e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.2338,
        "grad_norm": 1.0163005590438843,
        "learning_rate": 1.3076568265682657e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.218,
        "grad_norm": 1.4335989952087402,
        "learning_rate": 1.3053505535055353e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.3402,
        "grad_norm": 6.559154987335205,
        "learning_rate": 1.3030442804428045e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.2986,
        "grad_norm": 8.186699867248535,
        "learning_rate": 1.3007380073800738e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.2758,
        "grad_norm": 23.90599822998047,
        "learning_rate": 1.2984317343173432e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.2458,
        "grad_norm": 1.702726125717163,
        "learning_rate": 1.2961254612546126e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.2941,
        "grad_norm": 1.2876074314117432,
        "learning_rate": 1.293819188191882e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.1559,
        "grad_norm": 4.905570030212402,
        "learning_rate": 1.2915129151291513e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.2898,
        "grad_norm": 1.0872923135757446,
        "learning_rate": 1.2892066420664205e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.2016,
        "grad_norm": 1.1884231567382812,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.2179,
        "grad_norm": 5.200404167175293,
        "learning_rate": 1.2845940959409594e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2952,
        "grad_norm": 16.04871368408203,
        "learning_rate": 1.282287822878229e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.1614,
        "grad_norm": 0.6505724191665649,
        "learning_rate": 1.2799815498154982e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.3003,
        "grad_norm": 4.415220260620117,
        "learning_rate": 1.2776752767527675e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.2647,
        "grad_norm": 4.019614219665527,
        "learning_rate": 1.2753690036900371e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.2169,
        "grad_norm": 9.5962495803833,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.3124,
        "grad_norm": 4.4277873039245605,
        "learning_rate": 1.2707564575645758e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.1998,
        "grad_norm": 2.3072497844696045,
        "learning_rate": 1.2684501845018452e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.3336,
        "grad_norm": 3.4785821437835693,
        "learning_rate": 1.2661439114391144e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.3307,
        "grad_norm": 4.146921157836914,
        "learning_rate": 1.2638376383763839e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.161,
        "grad_norm": 0.9784267544746399,
        "learning_rate": 1.2615313653136531e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.2408,
        "grad_norm": 5.939335823059082,
        "learning_rate": 1.2592250922509224e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.2704,
        "grad_norm": 4.8341875076293945,
        "learning_rate": 1.256918819188192e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.223,
        "grad_norm": 11.685921669006348,
        "learning_rate": 1.2546125461254612e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.2719,
        "grad_norm": 1.939274549484253,
        "learning_rate": 1.2523062730627308e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.183,
        "grad_norm": 2.2205090522766113,
        "learning_rate": 1.25e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.40734773874282837,
        "eval_accuracy": 0.87073,
        "eval_precision": 0.8402,
        "eval_recall": 0.92224,
        "eval_f1": 0.87931,
        "eval_runtime": 30.0115,
        "eval_samples_per_second": 36.086,
        "eval_steps_per_second": 2.266,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.2716,
        "grad_norm": 10.206958770751953,
        "learning_rate": 1.2476937269372695e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.3378,
        "grad_norm": 4.793795585632324,
        "learning_rate": 1.2453874538745389e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2026,
        "grad_norm": 2.490567207336426,
        "learning_rate": 1.2430811808118082e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.2173,
        "grad_norm": 6.536752700805664,
        "learning_rate": 1.2407749077490776e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2046,
        "grad_norm": 6.238786697387695,
        "learning_rate": 1.238468634686347e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.336,
        "grad_norm": 7.668115615844727,
        "learning_rate": 1.2361623616236164e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.174,
        "grad_norm": 2.5951740741729736,
        "learning_rate": 1.2338560885608857e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.2275,
        "grad_norm": 1.620703935623169,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.2474,
        "grad_norm": 1.9772486686706543,
        "learning_rate": 1.2292435424354244e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.1784,
        "grad_norm": 15.726655006408691,
        "learning_rate": 1.2269372693726938e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.1849,
        "grad_norm": 43.06772232055664,
        "learning_rate": 1.2246309963099632e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.2204,
        "grad_norm": 48.77534103393555,
        "learning_rate": 1.2223247232472325e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.1897,
        "grad_norm": 2.7800793647766113,
        "learning_rate": 1.2200184501845019e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.2275,
        "grad_norm": 3.2191388607025146,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.2408,
        "grad_norm": 5.190028667449951,
        "learning_rate": 1.2154059040590407e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.2764,
        "grad_norm": 1.9086049795150757,
        "learning_rate": 1.21309963099631e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.348,
        "grad_norm": 20.575716018676758,
        "learning_rate": 1.2107933579335794e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.2481,
        "grad_norm": 8.825613975524902,
        "learning_rate": 1.2084870848708488e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.2939,
        "grad_norm": 2.7207953929901123,
        "learning_rate": 1.2061808118081182e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.1778,
        "grad_norm": 1.5428261756896973,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.2105,
        "grad_norm": 1.7747682332992554,
        "learning_rate": 1.201568265682657e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.2546,
        "grad_norm": 1.3746193647384644,
        "learning_rate": 1.1992619926199262e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.255,
        "grad_norm": 30.945032119750977,
        "learning_rate": 1.1969557195571956e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.2829,
        "grad_norm": 7.230361461639404,
        "learning_rate": 1.194649446494465e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.3029,
        "grad_norm": 1.6635998487472534,
        "learning_rate": 1.1923431734317343e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.1984,
        "grad_norm": 8.152499198913574,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.1638,
        "grad_norm": 0.47185173630714417,
        "learning_rate": 1.1877306273062731e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.41759419441223145,
        "eval_accuracy": 0.88273,
        "eval_precision": 0.86102,
        "eval_recall": 0.91863,
        "eval_f1": 0.88889,
        "eval_runtime": 35.6095,
        "eval_samples_per_second": 30.413,
        "eval_steps_per_second": 1.91,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.1884,
        "grad_norm": 1.2691341638565063,
        "learning_rate": 1.1854243542435425e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.2216,
        "grad_norm": 3.203923225402832,
        "learning_rate": 1.1831180811808118e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.2644,
        "grad_norm": 1.4030312299728394,
        "learning_rate": 1.1808118081180812e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.2412,
        "grad_norm": 28.955917358398438,
        "learning_rate": 1.1785055350553506e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.2778,
        "grad_norm": 1.9006128311157227,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.259,
        "grad_norm": 7.128456115722656,
        "learning_rate": 1.1738929889298895e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.2361,
        "grad_norm": 19.703689575195312,
        "learning_rate": 1.1715867158671587e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.2226,
        "grad_norm": 27.028728485107422,
        "learning_rate": 1.1692804428044282e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.1798,
        "grad_norm": 3.1391983032226562,
        "learning_rate": 1.1669741697416974e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.2525,
        "grad_norm": 2.8407576084136963,
        "learning_rate": 1.1646678966789668e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.2348,
        "grad_norm": 49.25239562988281,
        "learning_rate": 1.1623616236162361e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.2899,
        "grad_norm": 5.594426155090332,
        "learning_rate": 1.1600553505535055e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.3228,
        "grad_norm": 4.106967449188232,
        "learning_rate": 1.157749077490775e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.1739,
        "grad_norm": 5.320061683654785,
        "learning_rate": 1.1554428044280444e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.1454,
        "grad_norm": 1.704201102256775,
        "learning_rate": 1.1531365313653138e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.1566,
        "grad_norm": 3.6836681365966797,
        "learning_rate": 1.150830258302583e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.1954,
        "grad_norm": 18.22484588623047,
        "learning_rate": 1.1485239852398525e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.3442,
        "grad_norm": 6.495309352874756,
        "learning_rate": 1.1462177121771219e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.2422,
        "grad_norm": 4.359833240509033,
        "learning_rate": 1.1439114391143913e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.2825,
        "grad_norm": 2.6373026371002197,
        "learning_rate": 1.1416051660516606e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.2353,
        "grad_norm": 1.7851349115371704,
        "learning_rate": 1.13929889298893e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.2464,
        "grad_norm": 0.6771135926246643,
        "learning_rate": 1.1369926199261992e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.1962,
        "grad_norm": 1.289502739906311,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.346,
        "grad_norm": 19.021778106689453,
        "learning_rate": 1.1323800738007381e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.2648,
        "grad_norm": 8.016953468322754,
        "learning_rate": 1.1300738007380073e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.2699,
        "grad_norm": 2.917201042175293,
        "learning_rate": 1.1277675276752768e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.246,
        "grad_norm": 8.70902156829834,
        "learning_rate": 1.1254612546125462e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.43897131085395813,
        "eval_accuracy": 0.87073,
        "eval_precision": 0.84706,
        "eval_recall": 0.91139,
        "eval_f1": 0.87805,
        "eval_runtime": 35.7949,
        "eval_samples_per_second": 30.256,
        "eval_steps_per_second": 1.9,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.2072,
        "grad_norm": 1.1647144556045532,
        "learning_rate": 1.1231549815498156e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.1774,
        "grad_norm": 0.7473883032798767,
        "learning_rate": 1.1208487084870849e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.2364,
        "grad_norm": 2.7369842529296875,
        "learning_rate": 1.1185424354243543e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.2007,
        "grad_norm": 5.965064525604248,
        "learning_rate": 1.1162361623616237e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.2782,
        "grad_norm": 1.3927345275878906,
        "learning_rate": 1.1139298892988931e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.1828,
        "grad_norm": 1.1687712669372559,
        "learning_rate": 1.1116236162361624e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.2031,
        "grad_norm": 1.6232329607009888,
        "learning_rate": 1.1093173431734318e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.2942,
        "grad_norm": 62.96607971191406,
        "learning_rate": 1.1070110701107012e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.2521,
        "grad_norm": 0.8213063478469849,
        "learning_rate": 1.1047047970479705e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.2483,
        "grad_norm": 0.9442242980003357,
        "learning_rate": 1.1023985239852399e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.1966,
        "grad_norm": 4.798644065856934,
        "learning_rate": 1.1000922509225092e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.3188,
        "grad_norm": 5.035640239715576,
        "learning_rate": 1.0977859778597786e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.1681,
        "grad_norm": 0.7693195343017578,
        "learning_rate": 1.095479704797048e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.3542,
        "grad_norm": 1.1821796894073486,
        "learning_rate": 1.0931734317343174e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.2139,
        "grad_norm": 5.795101165771484,
        "learning_rate": 1.0908671586715867e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.2098,
        "grad_norm": 9.236327171325684,
        "learning_rate": 1.0885608856088561e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.1893,
        "grad_norm": 10.494441986083984,
        "learning_rate": 1.0862546125461255e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.1876,
        "grad_norm": 6.8192338943481445,
        "learning_rate": 1.083948339483395e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.1486,
        "grad_norm": 0.44161921739578247,
        "learning_rate": 1.0816420664206644e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.3426,
        "grad_norm": 2.4167985916137695,
        "learning_rate": 1.0793357933579336e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.2462,
        "grad_norm": 11.577789306640625,
        "learning_rate": 1.077029520295203e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.1884,
        "grad_norm": 1.3426040410995483,
        "learning_rate": 1.0747232472324725e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.2344,
        "grad_norm": 1.4126801490783691,
        "learning_rate": 1.0724169741697417e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.2327,
        "grad_norm": 3.975219488143921,
        "learning_rate": 1.070110701107011e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.3982,
        "grad_norm": 5.063944339752197,
        "learning_rate": 1.0678044280442804e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.1975,
        "grad_norm": 4.037108421325684,
        "learning_rate": 1.0654981549815498e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.2051,
        "grad_norm": 1.1626263856887817,
        "learning_rate": 1.0631918819188192e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.42894139885902405,
        "eval_accuracy": 0.87165,
        "eval_precision": 0.85445,
        "eval_recall": 0.90235,
        "eval_f1": 0.87775,
        "eval_runtime": 28.1596,
        "eval_samples_per_second": 38.459,
        "eval_steps_per_second": 2.415,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.2431,
        "grad_norm": 2.6067957878112793,
        "learning_rate": 1.0608856088560887e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.2068,
        "grad_norm": 1.0852919816970825,
        "learning_rate": 1.058579335793358e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.2837,
        "grad_norm": 3.862744092941284,
        "learning_rate": 1.0562730627306273e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.2035,
        "grad_norm": 11.841842651367188,
        "learning_rate": 1.0539667896678968e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.1397,
        "grad_norm": 12.564252853393555,
        "learning_rate": 1.0516605166051662e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.2056,
        "grad_norm": 4.3222527503967285,
        "learning_rate": 1.0493542435424354e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.2064,
        "grad_norm": 2.852593421936035,
        "learning_rate": 1.0470479704797049e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.2197,
        "grad_norm": 13.79660415649414,
        "learning_rate": 1.0447416974169743e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.2613,
        "grad_norm": 1.4919400215148926,
        "learning_rate": 1.0424354243542435e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.1884,
        "grad_norm": 1.292132019996643,
        "learning_rate": 1.040129151291513e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.2128,
        "grad_norm": 20.803760528564453,
        "learning_rate": 1.0378228782287822e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.2176,
        "grad_norm": 1.0837496519088745,
        "learning_rate": 1.0355166051660516e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.1053,
        "grad_norm": 0.5300042629241943,
        "learning_rate": 1.033210332103321e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.2395,
        "grad_norm": 1.222322702407837,
        "learning_rate": 1.0309040590405905e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.269,
        "grad_norm": 25.38168716430664,
        "learning_rate": 1.0285977859778597e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.2745,
        "grad_norm": 10.625732421875,
        "learning_rate": 1.0262915129151292e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.2589,
        "grad_norm": 21.10770606994629,
        "learning_rate": 1.0239852398523986e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.2839,
        "grad_norm": 29.01028060913086,
        "learning_rate": 1.021678966789668e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.2335,
        "grad_norm": 2.5724291801452637,
        "learning_rate": 1.0193726937269373e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.2886,
        "grad_norm": 1.842003345489502,
        "learning_rate": 1.0170664206642067e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.2636,
        "grad_norm": 2.585604667663574,
        "learning_rate": 1.0147601476014761e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.2793,
        "grad_norm": 7.834539413452148,
        "learning_rate": 1.0124538745387455e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.2292,
        "grad_norm": 2.0784058570861816,
        "learning_rate": 1.0101476014760148e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.2264,
        "grad_norm": 0.8336887359619141,
        "learning_rate": 1.0078413284132842e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.2167,
        "grad_norm": 2.762376546859741,
        "learning_rate": 1.0055350553505535e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.282,
        "grad_norm": 1.7707738876342773,
        "learning_rate": 1.0032287822878229e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.1759,
        "grad_norm": 1.0118149518966675,
        "learning_rate": 1.0009225092250923e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.39712393283843994,
        "eval_accuracy": 0.87719,
        "eval_precision": 0.85959,
        "eval_recall": 0.90778,
        "eval_f1": 0.88303,
        "eval_runtime": 25.3087,
        "eval_samples_per_second": 42.792,
        "eval_steps_per_second": 2.687,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "loss": 0.2273,
        "grad_norm": 1.447783350944519,
        "learning_rate": 9.986162361623616e-06,
        "epoch": 24.022140221402214,
        "step": 6510
    },
    {
        "loss": 0.1515,
        "grad_norm": 8.731196403503418,
        "learning_rate": 9.96309963099631e-06,
        "epoch": 24.059040590405903,
        "step": 6520
    },
    {
        "loss": 0.2083,
        "grad_norm": 2.1235134601593018,
        "learning_rate": 9.940036900369004e-06,
        "epoch": 24.095940959409592,
        "step": 6530
    },
    {
        "loss": 0.2147,
        "grad_norm": 2.071443796157837,
        "learning_rate": 9.916974169741698e-06,
        "epoch": 24.132841328413285,
        "step": 6540
    },
    {
        "loss": 0.1212,
        "grad_norm": 1.0267391204833984,
        "learning_rate": 9.893911439114393e-06,
        "epoch": 24.169741697416974,
        "step": 6550
    },
    {
        "loss": 0.1818,
        "grad_norm": 21.588598251342773,
        "learning_rate": 9.870848708487085e-06,
        "epoch": 24.206642066420663,
        "step": 6560
    },
    {
        "loss": 0.2958,
        "grad_norm": 0.4710174798965454,
        "learning_rate": 9.84778597785978e-06,
        "epoch": 24.243542435424356,
        "step": 6570
    },
    {
        "loss": 0.2718,
        "grad_norm": 1.1636537313461304,
        "learning_rate": 9.824723247232474e-06,
        "epoch": 24.280442804428045,
        "step": 6580
    },
    {
        "loss": 0.2285,
        "grad_norm": 42.145050048828125,
        "learning_rate": 9.801660516605168e-06,
        "epoch": 24.317343173431734,
        "step": 6590
    },
    {
        "loss": 0.1649,
        "grad_norm": 3.2830824851989746,
        "learning_rate": 9.77859778597786e-06,
        "epoch": 24.354243542435423,
        "step": 6600
    },
    {
        "loss": 0.2262,
        "grad_norm": 1.6550296545028687,
        "learning_rate": 9.755535055350553e-06,
        "epoch": 24.391143911439116,
        "step": 6610
    },
    {
        "loss": 0.2764,
        "grad_norm": 28.044851303100586,
        "learning_rate": 9.732472324723247e-06,
        "epoch": 24.428044280442805,
        "step": 6620
    },
    {
        "loss": 0.185,
        "grad_norm": 8.347497940063477,
        "learning_rate": 9.709409594095941e-06,
        "epoch": 24.464944649446494,
        "step": 6630
    },
    {
        "loss": 0.1877,
        "grad_norm": 2.336343765258789,
        "learning_rate": 9.686346863468636e-06,
        "epoch": 24.501845018450183,
        "step": 6640
    },
    {
        "loss": 0.1565,
        "grad_norm": 0.2500346004962921,
        "learning_rate": 9.663284132841328e-06,
        "epoch": 24.538745387453876,
        "step": 6650
    },
    {
        "loss": 0.226,
        "grad_norm": 4.599919319152832,
        "learning_rate": 9.640221402214022e-06,
        "epoch": 24.575645756457565,
        "step": 6660
    },
    {
        "loss": 0.3354,
        "grad_norm": 2.745443105697632,
        "learning_rate": 9.617158671586717e-06,
        "epoch": 24.612546125461254,
        "step": 6670
    },
    {
        "loss": 0.2269,
        "grad_norm": 5.6425909996032715,
        "learning_rate": 9.59409594095941e-06,
        "epoch": 24.649446494464943,
        "step": 6680
    },
    {
        "loss": 0.2518,
        "grad_norm": 1.0390310287475586,
        "learning_rate": 9.571033210332103e-06,
        "epoch": 24.686346863468636,
        "step": 6690
    },
    {
        "loss": 0.1474,
        "grad_norm": 4.290189743041992,
        "learning_rate": 9.547970479704798e-06,
        "epoch": 24.723247232472325,
        "step": 6700
    },
    {
        "loss": 0.2066,
        "grad_norm": 0.3685927093029022,
        "learning_rate": 9.524907749077492e-06,
        "epoch": 24.760147601476014,
        "step": 6710
    },
    {
        "loss": 0.239,
        "grad_norm": 4.650360107421875,
        "learning_rate": 9.501845018450186e-06,
        "epoch": 24.797047970479706,
        "step": 6720
    },
    {
        "loss": 0.2386,
        "grad_norm": 0.5385186076164246,
        "learning_rate": 9.478782287822879e-06,
        "epoch": 24.833948339483396,
        "step": 6730
    },
    {
        "loss": 0.2509,
        "grad_norm": 0.9006528258323669,
        "learning_rate": 9.455719557195573e-06,
        "epoch": 24.870848708487085,
        "step": 6740
    },
    {
        "loss": 0.1695,
        "grad_norm": 0.755620002746582,
        "learning_rate": 9.432656826568265e-06,
        "epoch": 24.907749077490774,
        "step": 6750
    },
    {
        "loss": 0.2459,
        "grad_norm": 4.510465621948242,
        "learning_rate": 9.40959409594096e-06,
        "epoch": 24.944649446494466,
        "step": 6760
    },
    {
        "loss": 0.2163,
        "grad_norm": 6.18047571182251,
        "learning_rate": 9.386531365313654e-06,
        "epoch": 24.981549815498155,
        "step": 6770
    },
    {
        "eval_loss": 0.467570036649704,
        "eval_accuracy": 0.87812,
        "eval_precision": 0.84228,
        "eval_recall": 0.93671,
        "eval_f1": 0.88699,
        "eval_runtime": 24.4938,
        "eval_samples_per_second": 44.215,
        "eval_steps_per_second": 2.776,
        "epoch": 25.0,
        "step": 6775
    },
    {
        "loss": 0.3381,
        "grad_norm": 1.8752135038375854,
        "learning_rate": 9.363468634686346e-06,
        "epoch": 25.018450184501845,
        "step": 6780
    },
    {
        "loss": 0.2059,
        "grad_norm": 2.5178966522216797,
        "learning_rate": 9.34040590405904e-06,
        "epoch": 25.055350553505534,
        "step": 6790
    },
    {
        "loss": 0.1997,
        "grad_norm": 1.067974328994751,
        "learning_rate": 9.317343173431735e-06,
        "epoch": 25.092250922509226,
        "step": 6800
    },
    {
        "loss": 0.1946,
        "grad_norm": 20.445968627929688,
        "learning_rate": 9.294280442804429e-06,
        "epoch": 25.129151291512915,
        "step": 6810
    },
    {
        "loss": 0.2558,
        "grad_norm": 1.6675457954406738,
        "learning_rate": 9.271217712177122e-06,
        "epoch": 25.166051660516604,
        "step": 6820
    },
    {
        "loss": 0.2558,
        "grad_norm": 3.164888858795166,
        "learning_rate": 9.248154981549816e-06,
        "epoch": 25.202952029520294,
        "step": 6830
    },
    {
        "loss": 0.1395,
        "grad_norm": 1.7911498546600342,
        "learning_rate": 9.22509225092251e-06,
        "epoch": 25.239852398523986,
        "step": 6840
    },
    {
        "loss": 0.2345,
        "grad_norm": 2.1017024517059326,
        "learning_rate": 9.202029520295204e-06,
        "epoch": 25.276752767527675,
        "step": 6850
    },
    {
        "loss": 0.333,
        "grad_norm": 2.6478540897369385,
        "learning_rate": 9.178966789667898e-06,
        "epoch": 25.313653136531364,
        "step": 6860
    },
    {
        "loss": 0.2075,
        "grad_norm": 14.429642677307129,
        "learning_rate": 9.155904059040591e-06,
        "epoch": 25.350553505535057,
        "step": 6870
    },
    {
        "loss": 0.1523,
        "grad_norm": 6.612401008605957,
        "learning_rate": 9.132841328413285e-06,
        "epoch": 25.387453874538746,
        "step": 6880
    },
    {
        "loss": 0.1508,
        "grad_norm": 0.27106139063835144,
        "learning_rate": 9.109778597785978e-06,
        "epoch": 25.424354243542435,
        "step": 6890
    },
    {
        "loss": 0.2213,
        "grad_norm": 1.9596540927886963,
        "learning_rate": 9.086715867158672e-06,
        "epoch": 25.461254612546124,
        "step": 6900
    },
    {
        "loss": 0.3463,
        "grad_norm": 103.74320220947266,
        "learning_rate": 9.063653136531364e-06,
        "epoch": 25.498154981549817,
        "step": 6910
    },
    {
        "loss": 0.208,
        "grad_norm": 1.9912829399108887,
        "learning_rate": 9.040590405904059e-06,
        "epoch": 25.535055350553506,
        "step": 6920
    },
    {
        "loss": 0.2407,
        "grad_norm": 1.663998007774353,
        "learning_rate": 9.017527675276753e-06,
        "epoch": 25.571955719557195,
        "step": 6930
    },
    {
        "loss": 0.2514,
        "grad_norm": 1.8983097076416016,
        "learning_rate": 8.994464944649447e-06,
        "epoch": 25.608856088560884,
        "step": 6940
    },
    {
        "loss": 0.1781,
        "grad_norm": 1.346824049949646,
        "learning_rate": 8.971402214022141e-06,
        "epoch": 25.645756457564577,
        "step": 6950
    },
    {
        "loss": 0.1917,
        "grad_norm": 2.2599775791168213,
        "learning_rate": 8.948339483394834e-06,
        "epoch": 25.682656826568266,
        "step": 6960
    },
    {
        "loss": 0.2775,
        "grad_norm": 5.5523481369018555,
        "learning_rate": 8.925276752767528e-06,
        "epoch": 25.719557195571955,
        "step": 6970
    },
    {
        "loss": 0.0816,
        "grad_norm": 6.654764652252197,
        "learning_rate": 8.902214022140222e-06,
        "epoch": 25.756457564575644,
        "step": 6980
    },
    {
        "loss": 0.2124,
        "grad_norm": 1.3891465663909912,
        "learning_rate": 8.879151291512917e-06,
        "epoch": 25.793357933579337,
        "step": 6990
    },
    {
        "loss": 0.1734,
        "grad_norm": 14.979752540588379,
        "learning_rate": 8.85608856088561e-06,
        "epoch": 25.830258302583026,
        "step": 7000
    },
    {
        "loss": 0.3275,
        "grad_norm": 8.222705841064453,
        "learning_rate": 8.833025830258303e-06,
        "epoch": 25.867158671586715,
        "step": 7010
    },
    {
        "loss": 0.3214,
        "grad_norm": 0.6207901239395142,
        "learning_rate": 8.809963099630996e-06,
        "epoch": 25.904059040590404,
        "step": 7020
    },
    {
        "loss": 0.2594,
        "grad_norm": 6.559484004974365,
        "learning_rate": 8.78690036900369e-06,
        "epoch": 25.940959409594097,
        "step": 7030
    },
    {
        "loss": 0.2206,
        "grad_norm": 6.187831878662109,
        "learning_rate": 8.763837638376384e-06,
        "epoch": 25.977859778597786,
        "step": 7040
    },
    {
        "eval_loss": 0.4248986840248108,
        "eval_accuracy": 0.87258,
        "eval_precision": 0.84526,
        "eval_recall": 0.91863,
        "eval_f1": 0.88042,
        "eval_runtime": 25.465,
        "eval_samples_per_second": 42.529,
        "eval_steps_per_second": 2.67,
        "epoch": 26.0,
        "step": 7046
    },
    {
        "loss": 0.2405,
        "grad_norm": 1.6130247116088867,
        "learning_rate": 8.740774907749077e-06,
        "epoch": 26.014760147601475,
        "step": 7050
    },
    {
        "loss": 0.1494,
        "grad_norm": 25.109390258789062,
        "learning_rate": 8.717712177121771e-06,
        "epoch": 26.051660516605168,
        "step": 7060
    },
    {
        "loss": 0.1776,
        "grad_norm": 6.2099785804748535,
        "learning_rate": 8.694649446494465e-06,
        "epoch": 26.088560885608857,
        "step": 7070
    },
    {
        "loss": 0.2611,
        "grad_norm": 5.653271198272705,
        "learning_rate": 8.67158671586716e-06,
        "epoch": 26.125461254612546,
        "step": 7080
    },
    {
        "loss": 0.2819,
        "grad_norm": 5.237722873687744,
        "learning_rate": 8.648523985239852e-06,
        "epoch": 26.162361623616235,
        "step": 7090
    },
    {
        "loss": 0.1864,
        "grad_norm": 9.521300315856934,
        "learning_rate": 8.625461254612546e-06,
        "epoch": 26.199261992619927,
        "step": 7100
    },
    {
        "loss": 0.2478,
        "grad_norm": 23.655635833740234,
        "learning_rate": 8.60239852398524e-06,
        "epoch": 26.236162361623617,
        "step": 7110
    },
    {
        "loss": 0.2437,
        "grad_norm": 2.8668501377105713,
        "learning_rate": 8.579335793357935e-06,
        "epoch": 26.273062730627306,
        "step": 7120
    },
    {
        "loss": 0.1669,
        "grad_norm": 1.5874031782150269,
        "learning_rate": 8.556273062730629e-06,
        "epoch": 26.309963099630995,
        "step": 7130
    },
    {
        "loss": 0.1887,
        "grad_norm": 0.8402485251426697,
        "learning_rate": 8.533210332103322e-06,
        "epoch": 26.346863468634687,
        "step": 7140
    },
    {
        "loss": 0.1657,
        "grad_norm": 0.5538114905357361,
        "learning_rate": 8.510147601476016e-06,
        "epoch": 26.383763837638377,
        "step": 7150
    },
    {
        "loss": 0.3487,
        "grad_norm": 2.0943539142608643,
        "learning_rate": 8.487084870848708e-06,
        "epoch": 26.420664206642066,
        "step": 7160
    },
    {
        "loss": 0.1805,
        "grad_norm": 5.262815952301025,
        "learning_rate": 8.464022140221403e-06,
        "epoch": 26.457564575645755,
        "step": 7170
    },
    {
        "loss": 0.1527,
        "grad_norm": 1.0853571891784668,
        "learning_rate": 8.440959409594095e-06,
        "epoch": 26.494464944649447,
        "step": 7180
    },
    {
        "loss": 0.1473,
        "grad_norm": 10.561165809631348,
        "learning_rate": 8.41789667896679e-06,
        "epoch": 26.531365313653136,
        "step": 7190
    },
    {
        "loss": 0.2031,
        "grad_norm": 0.5776732563972473,
        "learning_rate": 8.394833948339484e-06,
        "epoch": 26.568265682656826,
        "step": 7200
    },
    {
        "loss": 0.2761,
        "grad_norm": 28.848346710205078,
        "learning_rate": 8.371771217712178e-06,
        "epoch": 26.605166051660518,
        "step": 7210
    },
    {
        "loss": 0.1485,
        "grad_norm": 2.2183837890625,
        "learning_rate": 8.34870848708487e-06,
        "epoch": 26.642066420664207,
        "step": 7220
    },
    {
        "loss": 0.2638,
        "grad_norm": 36.589351654052734,
        "learning_rate": 8.325645756457565e-06,
        "epoch": 26.678966789667896,
        "step": 7230
    },
    {
        "loss": 0.2472,
        "grad_norm": 0.6604955196380615,
        "learning_rate": 8.302583025830259e-06,
        "epoch": 26.715867158671585,
        "step": 7240
    },
    {
        "loss": 0.2321,
        "grad_norm": 3.3329317569732666,
        "learning_rate": 8.279520295202953e-06,
        "epoch": 26.752767527675278,
        "step": 7250
    },
    {
        "loss": 0.1909,
        "grad_norm": 1.3059457540512085,
        "learning_rate": 8.256457564575647e-06,
        "epoch": 26.789667896678967,
        "step": 7260
    },
    {
        "loss": 0.1989,
        "grad_norm": 0.9073490500450134,
        "learning_rate": 8.23339483394834e-06,
        "epoch": 26.826568265682656,
        "step": 7270
    },
    {
        "loss": 0.1676,
        "grad_norm": 1.751629114151001,
        "learning_rate": 8.210332103321034e-06,
        "epoch": 26.863468634686345,
        "step": 7280
    },
    {
        "loss": 0.239,
        "grad_norm": 36.008243560791016,
        "learning_rate": 8.187269372693728e-06,
        "epoch": 26.900369003690038,
        "step": 7290
    },
    {
        "loss": 0.4149,
        "grad_norm": 6.675352573394775,
        "learning_rate": 8.16420664206642e-06,
        "epoch": 26.937269372693727,
        "step": 7300
    },
    {
        "loss": 0.176,
        "grad_norm": 1.134333848953247,
        "learning_rate": 8.141143911439113e-06,
        "epoch": 26.974169741697416,
        "step": 7310
    },
    {
        "eval_loss": 0.46151530742645264,
        "eval_accuracy": 0.87442,
        "eval_precision": 0.85763,
        "eval_recall": 0.90416,
        "eval_f1": 0.88028,
        "eval_runtime": 24.5786,
        "eval_samples_per_second": 44.063,
        "eval_steps_per_second": 2.767,
        "epoch": 27.0,
        "step": 7317
    },
    {
        "loss": 0.1935,
        "grad_norm": 3.381091833114624,
        "learning_rate": 8.118081180811808e-06,
        "epoch": 27.011070110701105,
        "step": 7320
    },
    {
        "loss": 0.2378,
        "grad_norm": 2.335463762283325,
        "learning_rate": 8.095018450184502e-06,
        "epoch": 27.047970479704798,
        "step": 7330
    },
    {
        "loss": 0.1252,
        "grad_norm": 4.757845878601074,
        "learning_rate": 8.071955719557196e-06,
        "epoch": 27.084870848708487,
        "step": 7340
    },
    {
        "loss": 0.2433,
        "grad_norm": 41.41559600830078,
        "learning_rate": 8.04889298892989e-06,
        "epoch": 27.121771217712176,
        "step": 7350
    },
    {
        "loss": 0.1806,
        "grad_norm": 4.428668975830078,
        "learning_rate": 8.025830258302583e-06,
        "epoch": 27.15867158671587,
        "step": 7360
    },
    {
        "loss": 0.1837,
        "grad_norm": 1.222191333770752,
        "learning_rate": 8.002767527675277e-06,
        "epoch": 27.195571955719558,
        "step": 7370
    },
    {
        "loss": 0.1435,
        "grad_norm": 9.849444389343262,
        "learning_rate": 7.979704797047971e-06,
        "epoch": 27.232472324723247,
        "step": 7380
    },
    {
        "loss": 0.2186,
        "grad_norm": 11.751998901367188,
        "learning_rate": 7.956642066420665e-06,
        "epoch": 27.269372693726936,
        "step": 7390
    },
    {
        "loss": 0.2067,
        "grad_norm": 10.281082153320312,
        "learning_rate": 7.933579335793358e-06,
        "epoch": 27.30627306273063,
        "step": 7400
    },
    {
        "loss": 0.1841,
        "grad_norm": 4.614783763885498,
        "learning_rate": 7.910516605166052e-06,
        "epoch": 27.343173431734318,
        "step": 7410
    },
    {
        "loss": 0.2038,
        "grad_norm": 5.311445236206055,
        "learning_rate": 7.887453874538746e-06,
        "epoch": 27.380073800738007,
        "step": 7420
    },
    {
        "loss": 0.1374,
        "grad_norm": 1.341851830482483,
        "learning_rate": 7.864391143911439e-06,
        "epoch": 27.416974169741696,
        "step": 7430
    },
    {
        "loss": 0.14,
        "grad_norm": 5.990386486053467,
        "learning_rate": 7.841328413284133e-06,
        "epoch": 27.45387453874539,
        "step": 7440
    },
    {
        "loss": 0.1877,
        "grad_norm": 0.8158909678459167,
        "learning_rate": 7.818265682656826e-06,
        "epoch": 27.490774907749078,
        "step": 7450
    },
    {
        "loss": 0.2034,
        "grad_norm": 4.880712985992432,
        "learning_rate": 7.79520295202952e-06,
        "epoch": 27.527675276752767,
        "step": 7460
    },
    {
        "loss": 0.2302,
        "grad_norm": 35.43180847167969,
        "learning_rate": 7.772140221402214e-06,
        "epoch": 27.564575645756456,
        "step": 7470
    },
    {
        "loss": 0.1863,
        "grad_norm": 0.3247354030609131,
        "learning_rate": 7.749077490774908e-06,
        "epoch": 27.60147601476015,
        "step": 7480
    },
    {
        "loss": 0.3128,
        "grad_norm": 10.355708122253418,
        "learning_rate": 7.726014760147601e-06,
        "epoch": 27.638376383763838,
        "step": 7490
    },
    {
        "loss": 0.1985,
        "grad_norm": 2.6115076541900635,
        "learning_rate": 7.702952029520295e-06,
        "epoch": 27.675276752767527,
        "step": 7500
    },
    {
        "loss": 0.2431,
        "grad_norm": 4.036438941955566,
        "learning_rate": 7.67988929889299e-06,
        "epoch": 27.71217712177122,
        "step": 7510
    },
    {
        "loss": 0.1606,
        "grad_norm": 3.6384224891662598,
        "learning_rate": 7.656826568265684e-06,
        "epoch": 27.74907749077491,
        "step": 7520
    },
    {
        "loss": 0.3105,
        "grad_norm": 7.733667373657227,
        "learning_rate": 7.633763837638378e-06,
        "epoch": 27.785977859778598,
        "step": 7530
    },
    {
        "loss": 0.2262,
        "grad_norm": 19.33036231994629,
        "learning_rate": 7.6107011070110704e-06,
        "epoch": 27.822878228782287,
        "step": 7540
    },
    {
        "loss": 0.2474,
        "grad_norm": 8.577784538269043,
        "learning_rate": 7.587638376383764e-06,
        "epoch": 27.85977859778598,
        "step": 7550
    },
    {
        "loss": 0.1884,
        "grad_norm": 1.710531234741211,
        "learning_rate": 7.564575645756458e-06,
        "epoch": 27.89667896678967,
        "step": 7560
    },
    {
        "loss": 0.1537,
        "grad_norm": 1.8822662830352783,
        "learning_rate": 7.541512915129152e-06,
        "epoch": 27.933579335793358,
        "step": 7570
    },
    {
        "loss": 0.2005,
        "grad_norm": 9.578474044799805,
        "learning_rate": 7.518450184501845e-06,
        "epoch": 27.970479704797047,
        "step": 7580
    },
    {
        "eval_loss": 0.4689924120903015,
        "eval_accuracy": 0.88181,
        "eval_precision": 0.85714,
        "eval_recall": 0.92224,
        "eval_f1": 0.8885,
        "eval_runtime": 25.8046,
        "eval_samples_per_second": 41.969,
        "eval_steps_per_second": 2.635,
        "epoch": 28.0,
        "step": 7588
    },
    {
        "loss": 0.1986,
        "grad_norm": 18.028793334960938,
        "learning_rate": 7.495387453874539e-06,
        "epoch": 28.00738007380074,
        "step": 7590
    },
    {
        "loss": 0.2693,
        "grad_norm": 5.175109386444092,
        "learning_rate": 7.472324723247233e-06,
        "epoch": 28.04428044280443,
        "step": 7600
    },
    {
        "loss": 0.1955,
        "grad_norm": 1.2007204294204712,
        "learning_rate": 7.449261992619927e-06,
        "epoch": 28.081180811808117,
        "step": 7610
    },
    {
        "loss": 0.1724,
        "grad_norm": 0.6035874485969543,
        "learning_rate": 7.42619926199262e-06,
        "epoch": 28.118081180811807,
        "step": 7620
    },
    {
        "loss": 0.2516,
        "grad_norm": 5.821142673492432,
        "learning_rate": 7.403136531365313e-06,
        "epoch": 28.1549815498155,
        "step": 7630
    },
    {
        "loss": 0.1968,
        "grad_norm": 59.403160095214844,
        "learning_rate": 7.380073800738008e-06,
        "epoch": 28.19188191881919,
        "step": 7640
    },
    {
        "loss": 0.1502,
        "grad_norm": 51.4607048034668,
        "learning_rate": 7.357011070110702e-06,
        "epoch": 28.228782287822877,
        "step": 7650
    },
    {
        "loss": 0.2056,
        "grad_norm": 7.621734619140625,
        "learning_rate": 7.333948339483396e-06,
        "epoch": 28.26568265682657,
        "step": 7660
    },
    {
        "loss": 0.1286,
        "grad_norm": 3.586202621459961,
        "learning_rate": 7.310885608856089e-06,
        "epoch": 28.30258302583026,
        "step": 7670
    },
    {
        "loss": 0.2361,
        "grad_norm": 16.284778594970703,
        "learning_rate": 7.287822878228783e-06,
        "epoch": 28.339483394833948,
        "step": 7680
    },
    {
        "loss": 0.2658,
        "grad_norm": 2.0794835090637207,
        "learning_rate": 7.264760147601476e-06,
        "epoch": 28.376383763837637,
        "step": 7690
    },
    {
        "loss": 0.1954,
        "grad_norm": 1.158318042755127,
        "learning_rate": 7.2416974169741705e-06,
        "epoch": 28.41328413284133,
        "step": 7700
    },
    {
        "loss": 0.1236,
        "grad_norm": 2.2467644214630127,
        "learning_rate": 7.218634686346863e-06,
        "epoch": 28.45018450184502,
        "step": 7710
    },
    {
        "loss": 0.1998,
        "grad_norm": 17.33637809753418,
        "learning_rate": 7.195571955719557e-06,
        "epoch": 28.487084870848708,
        "step": 7720
    },
    {
        "loss": 0.077,
        "grad_norm": 1.4713431596755981,
        "learning_rate": 7.1725092250922515e-06,
        "epoch": 28.523985239852397,
        "step": 7730
    },
    {
        "loss": 0.199,
        "grad_norm": 31.065526962280273,
        "learning_rate": 7.149446494464946e-06,
        "epoch": 28.56088560885609,
        "step": 7740
    },
    {
        "loss": 0.3442,
        "grad_norm": 2.0020830631256104,
        "learning_rate": 7.126383763837639e-06,
        "epoch": 28.59778597785978,
        "step": 7750
    },
    {
        "loss": 0.2287,
        "grad_norm": 1.9084559679031372,
        "learning_rate": 7.103321033210332e-06,
        "epoch": 28.634686346863468,
        "step": 7760
    },
    {
        "loss": 0.3138,
        "grad_norm": 2.307340145111084,
        "learning_rate": 7.080258302583026e-06,
        "epoch": 28.671586715867157,
        "step": 7770
    },
    {
        "loss": 0.1722,
        "grad_norm": 6.107901096343994,
        "learning_rate": 7.05719557195572e-06,
        "epoch": 28.70848708487085,
        "step": 7780
    },
    {
        "loss": 0.309,
        "grad_norm": 0.9760138392448425,
        "learning_rate": 7.034132841328414e-06,
        "epoch": 28.74538745387454,
        "step": 7790
    },
    {
        "loss": 0.2532,
        "grad_norm": 3.8867218494415283,
        "learning_rate": 7.011070110701107e-06,
        "epoch": 28.782287822878228,
        "step": 7800
    },
    {
        "loss": 0.1939,
        "grad_norm": 34.842491149902344,
        "learning_rate": 6.988007380073801e-06,
        "epoch": 28.81918819188192,
        "step": 7810
    },
    {
        "loss": 0.1345,
        "grad_norm": 12.523690223693848,
        "learning_rate": 6.9649446494464944e-06,
        "epoch": 28.85608856088561,
        "step": 7820
    },
    {
        "loss": 0.1581,
        "grad_norm": 5.863292217254639,
        "learning_rate": 6.941881918819189e-06,
        "epoch": 28.8929889298893,
        "step": 7830
    },
    {
        "loss": 0.2784,
        "grad_norm": 3.231058120727539,
        "learning_rate": 6.918819188191883e-06,
        "epoch": 28.929889298892988,
        "step": 7840
    },
    {
        "loss": 0.1962,
        "grad_norm": 1.7618900537490845,
        "learning_rate": 6.8957564575645754e-06,
        "epoch": 28.96678966789668,
        "step": 7850
    },
    {
        "eval_loss": 0.4695489704608917,
        "eval_accuracy": 0.88735,
        "eval_precision": 0.86097,
        "eval_recall": 0.92948,
        "eval_f1": 0.89391,
        "eval_runtime": 24.6224,
        "eval_samples_per_second": 43.984,
        "eval_steps_per_second": 2.762,
        "epoch": 29.0,
        "step": 7859
    },
    {
        "loss": 0.1981,
        "grad_norm": 1.9271451234817505,
        "learning_rate": 6.87269372693727e-06,
        "epoch": 29.00369003690037,
        "step": 7860
    },
    {
        "loss": 0.1138,
        "grad_norm": 0.9111025333404541,
        "learning_rate": 6.849630996309964e-06,
        "epoch": 29.04059040590406,
        "step": 7870
    },
    {
        "loss": 0.1315,
        "grad_norm": 11.731289863586426,
        "learning_rate": 6.826568265682657e-06,
        "epoch": 29.077490774907748,
        "step": 7880
    },
    {
        "loss": 0.2287,
        "grad_norm": 0.37665486335754395,
        "learning_rate": 6.803505535055351e-06,
        "epoch": 29.11439114391144,
        "step": 7890
    },
    {
        "loss": 0.3131,
        "grad_norm": 24.083845138549805,
        "learning_rate": 6.780442804428044e-06,
        "epoch": 29.15129151291513,
        "step": 7900
    },
    {
        "loss": 0.1851,
        "grad_norm": 1.3819375038146973,
        "learning_rate": 6.757380073800738e-06,
        "epoch": 29.18819188191882,
        "step": 7910
    },
    {
        "loss": 0.2691,
        "grad_norm": 7.183684349060059,
        "learning_rate": 6.7343173431734325e-06,
        "epoch": 29.225092250922508,
        "step": 7920
    },
    {
        "loss": 0.178,
        "grad_norm": 0.9448326826095581,
        "learning_rate": 6.711254612546127e-06,
        "epoch": 29.2619926199262,
        "step": 7930
    },
    {
        "loss": 0.1516,
        "grad_norm": 1.4646705389022827,
        "learning_rate": 6.688191881918819e-06,
        "epoch": 29.29889298892989,
        "step": 7940
    },
    {
        "loss": 0.1364,
        "grad_norm": 33.79518508911133,
        "learning_rate": 6.6651291512915135e-06,
        "epoch": 29.33579335793358,
        "step": 7950
    },
    {
        "loss": 0.2267,
        "grad_norm": 8.8726806640625,
        "learning_rate": 6.642066420664207e-06,
        "epoch": 29.372693726937268,
        "step": 7960
    },
    {
        "loss": 0.1836,
        "grad_norm": 0.4053221046924591,
        "learning_rate": 6.619003690036901e-06,
        "epoch": 29.40959409594096,
        "step": 7970
    },
    {
        "loss": 0.3614,
        "grad_norm": 8.726555824279785,
        "learning_rate": 6.595940959409594e-06,
        "epoch": 29.44649446494465,
        "step": 7980
    },
    {
        "loss": 0.1357,
        "grad_norm": 0.702539324760437,
        "learning_rate": 6.572878228782288e-06,
        "epoch": 29.48339483394834,
        "step": 7990
    },
    {
        "loss": 0.2048,
        "grad_norm": 1.4990386962890625,
        "learning_rate": 6.549815498154982e-06,
        "epoch": 29.52029520295203,
        "step": 8000
    },
    {
        "loss": 0.1706,
        "grad_norm": 1.8735638856887817,
        "learning_rate": 6.526752767527676e-06,
        "epoch": 29.55719557195572,
        "step": 8010
    },
    {
        "loss": 0.2172,
        "grad_norm": 11.844707489013672,
        "learning_rate": 6.503690036900369e-06,
        "epoch": 29.59409594095941,
        "step": 8020
    },
    {
        "loss": 0.2372,
        "grad_norm": 10.303775787353516,
        "learning_rate": 6.480627306273063e-06,
        "epoch": 29.6309963099631,
        "step": 8030
    },
    {
        "loss": 0.2169,
        "grad_norm": 8.507843017578125,
        "learning_rate": 6.4575645756457565e-06,
        "epoch": 29.66789667896679,
        "step": 8040
    },
    {
        "loss": 0.1792,
        "grad_norm": 20.882644653320312,
        "learning_rate": 6.434501845018451e-06,
        "epoch": 29.70479704797048,
        "step": 8050
    },
    {
        "loss": 0.207,
        "grad_norm": 23.42782211303711,
        "learning_rate": 6.411439114391145e-06,
        "epoch": 29.74169741697417,
        "step": 8060
    },
    {
        "loss": 0.1746,
        "grad_norm": 13.125045776367188,
        "learning_rate": 6.3883763837638375e-06,
        "epoch": 29.77859778597786,
        "step": 8070
    },
    {
        "loss": 0.1997,
        "grad_norm": 0.2847995162010193,
        "learning_rate": 6.365313653136532e-06,
        "epoch": 29.81549815498155,
        "step": 8080
    },
    {
        "loss": 0.2006,
        "grad_norm": 4.237137794494629,
        "learning_rate": 6.342250922509226e-06,
        "epoch": 29.85239852398524,
        "step": 8090
    },
    {
        "loss": 0.1196,
        "grad_norm": 1.4225273132324219,
        "learning_rate": 6.319188191881919e-06,
        "epoch": 29.88929889298893,
        "step": 8100
    },
    {
        "loss": 0.1819,
        "grad_norm": 2.7748470306396484,
        "learning_rate": 6.296125461254612e-06,
        "epoch": 29.92619926199262,
        "step": 8110
    },
    {
        "loss": 0.1881,
        "grad_norm": 5.204766273498535,
        "learning_rate": 6.273062730627306e-06,
        "epoch": 29.96309963099631,
        "step": 8120
    },
    {
        "loss": 0.2476,
        "grad_norm": 3.466597318649292,
        "learning_rate": 6.25e-06,
        "epoch": 30.0,
        "step": 8130
    },
    {
        "eval_loss": 0.5090354681015015,
        "eval_accuracy": 0.87535,
        "eval_precision": 0.86285,
        "eval_recall": 0.89873,
        "eval_f1": 0.88043,
        "eval_runtime": 24.6786,
        "eval_samples_per_second": 43.884,
        "eval_steps_per_second": 2.755,
        "epoch": 30.0,
        "step": 8130
    },
    {
        "loss": 0.1983,
        "grad_norm": 4.487306118011475,
        "learning_rate": 6.2269372693726945e-06,
        "epoch": 30.03690036900369,
        "step": 8140
    },
    {
        "loss": 0.1568,
        "grad_norm": 24.003538131713867,
        "learning_rate": 6.203874538745388e-06,
        "epoch": 30.07380073800738,
        "step": 8150
    },
    {
        "loss": 0.204,
        "grad_norm": 1.7680851221084595,
        "learning_rate": 6.180811808118082e-06,
        "epoch": 30.11070110701107,
        "step": 8160
    },
    {
        "loss": 0.2323,
        "grad_norm": 8.46772289276123,
        "learning_rate": 6.157749077490775e-06,
        "epoch": 30.14760147601476,
        "step": 8170
    },
    {
        "loss": 0.2342,
        "grad_norm": 35.77690124511719,
        "learning_rate": 6.134686346863469e-06,
        "epoch": 30.18450184501845,
        "step": 8180
    },
    {
        "loss": 0.1927,
        "grad_norm": 1.7722891569137573,
        "learning_rate": 6.111623616236162e-06,
        "epoch": 30.22140221402214,
        "step": 8190
    },
    {
        "loss": 0.242,
        "grad_norm": 12.235204696655273,
        "learning_rate": 6.0885608856088565e-06,
        "epoch": 30.25830258302583,
        "step": 8200
    },
    {
        "loss": 0.2177,
        "grad_norm": 4.111029148101807,
        "learning_rate": 6.06549815498155e-06,
        "epoch": 30.29520295202952,
        "step": 8210
    },
    {
        "loss": 0.1786,
        "grad_norm": 1.7737594842910767,
        "learning_rate": 6.042435424354244e-06,
        "epoch": 30.33210332103321,
        "step": 8220
    },
    {
        "loss": 0.1232,
        "grad_norm": 1.7071621417999268,
        "learning_rate": 6.0193726937269375e-06,
        "epoch": 30.3690036900369,
        "step": 8230
    },
    {
        "loss": 0.1775,
        "grad_norm": 3.5408360958099365,
        "learning_rate": 5.996309963099631e-06,
        "epoch": 30.40590405904059,
        "step": 8240
    },
    {
        "loss": 0.1591,
        "grad_norm": 2.5781407356262207,
        "learning_rate": 5.973247232472325e-06,
        "epoch": 30.44280442804428,
        "step": 8250
    },
    {
        "loss": 0.1407,
        "grad_norm": 11.963147163391113,
        "learning_rate": 5.9501845018450185e-06,
        "epoch": 30.47970479704797,
        "step": 8260
    },
    {
        "loss": 0.1787,
        "grad_norm": 1.3276375532150269,
        "learning_rate": 5.927121771217713e-06,
        "epoch": 30.51660516605166,
        "step": 8270
    },
    {
        "loss": 0.2235,
        "grad_norm": 8.281367301940918,
        "learning_rate": 5.904059040590406e-06,
        "epoch": 30.55350553505535,
        "step": 8280
    },
    {
        "loss": 0.1936,
        "grad_norm": 1.1022112369537354,
        "learning_rate": 5.8809963099631e-06,
        "epoch": 30.59040590405904,
        "step": 8290
    },
    {
        "loss": 0.2418,
        "grad_norm": 5.7952561378479,
        "learning_rate": 5.857933579335794e-06,
        "epoch": 30.627306273062732,
        "step": 8300
    },
    {
        "loss": 0.1552,
        "grad_norm": 12.468231201171875,
        "learning_rate": 5.834870848708487e-06,
        "epoch": 30.66420664206642,
        "step": 8310
    },
    {
        "loss": 0.1565,
        "grad_norm": 2.725792169570923,
        "learning_rate": 5.8118081180811805e-06,
        "epoch": 30.70110701107011,
        "step": 8320
    },
    {
        "loss": 0.2114,
        "grad_norm": 12.674238204956055,
        "learning_rate": 5.788745387453875e-06,
        "epoch": 30.7380073800738,
        "step": 8330
    },
    {
        "loss": 0.0668,
        "grad_norm": 2.187877893447876,
        "learning_rate": 5.765682656826569e-06,
        "epoch": 30.774907749077492,
        "step": 8340
    },
    {
        "loss": 0.1964,
        "grad_norm": 60.2564582824707,
        "learning_rate": 5.742619926199262e-06,
        "epoch": 30.81180811808118,
        "step": 8350
    },
    {
        "loss": 0.2129,
        "grad_norm": 121.87654113769531,
        "learning_rate": 5.7195571955719566e-06,
        "epoch": 30.84870848708487,
        "step": 8360
    },
    {
        "loss": 0.1187,
        "grad_norm": 0.14826153218746185,
        "learning_rate": 5.69649446494465e-06,
        "epoch": 30.88560885608856,
        "step": 8370
    },
    {
        "loss": 0.3549,
        "grad_norm": 1.0346369743347168,
        "learning_rate": 5.673431734317343e-06,
        "epoch": 30.922509225092252,
        "step": 8380
    },
    {
        "loss": 0.3848,
        "grad_norm": 0.8483135104179382,
        "learning_rate": 5.650369003690037e-06,
        "epoch": 30.95940959409594,
        "step": 8390
    },
    {
        "loss": 0.1764,
        "grad_norm": 2.1639881134033203,
        "learning_rate": 5.627306273062731e-06,
        "epoch": 30.99630996309963,
        "step": 8400
    },
    {
        "eval_loss": 0.5060362219810486,
        "eval_accuracy": 0.87258,
        "eval_precision": 0.85349,
        "eval_recall": 0.90597,
        "eval_f1": 0.87895,
        "eval_runtime": 27.6079,
        "eval_samples_per_second": 39.228,
        "eval_steps_per_second": 2.463,
        "epoch": 31.0,
        "step": 8401
    },
    {
        "loss": 0.231,
        "grad_norm": 1.330008625984192,
        "learning_rate": 5.604243542435424e-06,
        "epoch": 31.03321033210332,
        "step": 8410
    },
    {
        "loss": 0.1421,
        "grad_norm": 11.28137493133545,
        "learning_rate": 5.5811808118081185e-06,
        "epoch": 31.070110701107012,
        "step": 8420
    },
    {
        "loss": 0.1938,
        "grad_norm": 4.5997724533081055,
        "learning_rate": 5.558118081180812e-06,
        "epoch": 31.1070110701107,
        "step": 8430
    },
    {
        "loss": 0.1223,
        "grad_norm": 6.057631492614746,
        "learning_rate": 5.535055350553506e-06,
        "epoch": 31.14391143911439,
        "step": 8440
    },
    {
        "loss": 0.166,
        "grad_norm": 17.195556640625,
        "learning_rate": 5.5119926199261995e-06,
        "epoch": 31.18081180811808,
        "step": 8450
    },
    {
        "loss": 0.1596,
        "grad_norm": 4.154688835144043,
        "learning_rate": 5.488929889298893e-06,
        "epoch": 31.217712177121772,
        "step": 8460
    },
    {
        "loss": 0.1207,
        "grad_norm": 3.4600229263305664,
        "learning_rate": 5.465867158671587e-06,
        "epoch": 31.25461254612546,
        "step": 8470
    },
    {
        "loss": 0.2172,
        "grad_norm": 5.533458709716797,
        "learning_rate": 5.4428044280442805e-06,
        "epoch": 31.29151291512915,
        "step": 8480
    },
    {
        "loss": 0.2163,
        "grad_norm": 7.163881778717041,
        "learning_rate": 5.419741697416975e-06,
        "epoch": 31.328413284132843,
        "step": 8490
    },
    {
        "loss": 0.1909,
        "grad_norm": 9.658502578735352,
        "learning_rate": 5.396678966789668e-06,
        "epoch": 31.365313653136532,
        "step": 8500
    },
    {
        "loss": 0.0947,
        "grad_norm": 3.8470818996429443,
        "learning_rate": 5.373616236162362e-06,
        "epoch": 31.40221402214022,
        "step": 8510
    },
    {
        "loss": 0.1757,
        "grad_norm": 3.8981409072875977,
        "learning_rate": 5.350553505535055e-06,
        "epoch": 31.43911439114391,
        "step": 8520
    },
    {
        "loss": 0.2035,
        "grad_norm": 24.339086532592773,
        "learning_rate": 5.327490774907749e-06,
        "epoch": 31.476014760147603,
        "step": 8530
    },
    {
        "loss": 0.2745,
        "grad_norm": 1.5158016681671143,
        "learning_rate": 5.304428044280443e-06,
        "epoch": 31.512915129151292,
        "step": 8540
    },
    {
        "loss": 0.1804,
        "grad_norm": 1.416368842124939,
        "learning_rate": 5.281365313653137e-06,
        "epoch": 31.54981549815498,
        "step": 8550
    },
    {
        "loss": 0.2193,
        "grad_norm": 1.3026927709579468,
        "learning_rate": 5.258302583025831e-06,
        "epoch": 31.58671586715867,
        "step": 8560
    },
    {
        "loss": 0.2186,
        "grad_norm": 2.0588319301605225,
        "learning_rate": 5.235239852398524e-06,
        "epoch": 31.623616236162363,
        "step": 8570
    },
    {
        "loss": 0.1908,
        "grad_norm": 13.523087501525879,
        "learning_rate": 5.212177121771218e-06,
        "epoch": 31.660516605166052,
        "step": 8580
    },
    {
        "loss": 0.1081,
        "grad_norm": 15.979727745056152,
        "learning_rate": 5.189114391143911e-06,
        "epoch": 31.69741697416974,
        "step": 8590
    },
    {
        "loss": 0.2067,
        "grad_norm": 1.0076367855072021,
        "learning_rate": 5.166051660516605e-06,
        "epoch": 31.73431734317343,
        "step": 8600
    },
    {
        "loss": 0.1972,
        "grad_norm": 7.680861949920654,
        "learning_rate": 5.142988929889299e-06,
        "epoch": 31.771217712177123,
        "step": 8610
    },
    {
        "loss": 0.1373,
        "grad_norm": 0.8883171081542969,
        "learning_rate": 5.119926199261993e-06,
        "epoch": 31.80811808118081,
        "step": 8620
    },
    {
        "loss": 0.1423,
        "grad_norm": 5.667280673980713,
        "learning_rate": 5.096863468634686e-06,
        "epoch": 31.8450184501845,
        "step": 8630
    },
    {
        "loss": 0.1616,
        "grad_norm": 5.164626121520996,
        "learning_rate": 5.0738007380073806e-06,
        "epoch": 31.881918819188193,
        "step": 8640
    },
    {
        "loss": 0.2591,
        "grad_norm": 6.795578956604004,
        "learning_rate": 5.050738007380074e-06,
        "epoch": 31.918819188191883,
        "step": 8650
    },
    {
        "loss": 0.2869,
        "grad_norm": 1.2239515781402588,
        "learning_rate": 5.027675276752767e-06,
        "epoch": 31.95571955719557,
        "step": 8660
    },
    {
        "loss": 0.2159,
        "grad_norm": 10.995925903320312,
        "learning_rate": 5.0046125461254616e-06,
        "epoch": 31.99261992619926,
        "step": 8670
    },
    {
        "eval_loss": 0.5042623281478882,
        "eval_accuracy": 0.87812,
        "eval_precision": 0.8586,
        "eval_recall": 0.91139,
        "eval_f1": 0.88421,
        "eval_runtime": 25.3442,
        "eval_samples_per_second": 42.732,
        "eval_steps_per_second": 2.683,
        "epoch": 32.0,
        "step": 8672
    },
    {
        "loss": 0.2337,
        "grad_norm": 6.771218776702881,
        "learning_rate": 4.981549815498155e-06,
        "epoch": 32.02952029520295,
        "step": 8680
    },
    {
        "loss": 0.1654,
        "grad_norm": 1.087172269821167,
        "learning_rate": 4.958487084870849e-06,
        "epoch": 32.06642066420664,
        "step": 8690
    },
    {
        "loss": 0.165,
        "grad_norm": 16.24566078186035,
        "learning_rate": 4.9354243542435426e-06,
        "epoch": 32.103321033210335,
        "step": 8700
    },
    {
        "loss": 0.2208,
        "grad_norm": 83.63652801513672,
        "learning_rate": 4.912361623616237e-06,
        "epoch": 32.140221402214024,
        "step": 8710
    },
    {
        "loss": 0.1713,
        "grad_norm": 9.599071502685547,
        "learning_rate": 4.88929889298893e-06,
        "epoch": 32.17712177121771,
        "step": 8720
    },
    {
        "loss": 0.1665,
        "grad_norm": 24.840320587158203,
        "learning_rate": 4.8662361623616235e-06,
        "epoch": 32.2140221402214,
        "step": 8730
    },
    {
        "loss": 0.2071,
        "grad_norm": 3.2371597290039062,
        "learning_rate": 4.843173431734318e-06,
        "epoch": 32.25092250922509,
        "step": 8740
    },
    {
        "loss": 0.154,
        "grad_norm": 3.7384209632873535,
        "learning_rate": 4.820110701107011e-06,
        "epoch": 32.28782287822878,
        "step": 8750
    },
    {
        "loss": 0.1315,
        "grad_norm": 0.7411069273948669,
        "learning_rate": 4.797047970479705e-06,
        "epoch": 32.32472324723247,
        "step": 8760
    },
    {
        "loss": 0.197,
        "grad_norm": 0.3658818006515503,
        "learning_rate": 4.773985239852399e-06,
        "epoch": 32.36162361623616,
        "step": 8770
    },
    {
        "loss": 0.2797,
        "grad_norm": 7.354302406311035,
        "learning_rate": 4.750922509225093e-06,
        "epoch": 32.398523985239855,
        "step": 8780
    },
    {
        "loss": 0.2057,
        "grad_norm": 19.436199188232422,
        "learning_rate": 4.727859778597786e-06,
        "epoch": 32.435424354243544,
        "step": 8790
    },
    {
        "loss": 0.2262,
        "grad_norm": 1.1114085912704468,
        "learning_rate": 4.70479704797048e-06,
        "epoch": 32.47232472324723,
        "step": 8800
    },
    {
        "loss": 0.2116,
        "grad_norm": 16.04353141784668,
        "learning_rate": 4.681734317343173e-06,
        "epoch": 32.50922509225092,
        "step": 8810
    },
    {
        "loss": 0.141,
        "grad_norm": 7.414330005645752,
        "learning_rate": 4.658671586715867e-06,
        "epoch": 32.54612546125461,
        "step": 8820
    },
    {
        "loss": 0.1164,
        "grad_norm": 0.9727196097373962,
        "learning_rate": 4.635608856088561e-06,
        "epoch": 32.5830258302583,
        "step": 8830
    },
    {
        "loss": 0.2385,
        "grad_norm": 0.3211764693260193,
        "learning_rate": 4.612546125461255e-06,
        "epoch": 32.61992619926199,
        "step": 8840
    },
    {
        "loss": 0.206,
        "grad_norm": 26.338359832763672,
        "learning_rate": 4.589483394833949e-06,
        "epoch": 32.656826568265686,
        "step": 8850
    },
    {
        "loss": 0.1251,
        "grad_norm": 3.8187103271484375,
        "learning_rate": 4.566420664206643e-06,
        "epoch": 32.693726937269375,
        "step": 8860
    },
    {
        "loss": 0.2215,
        "grad_norm": 54.01813507080078,
        "learning_rate": 4.543357933579336e-06,
        "epoch": 32.730627306273064,
        "step": 8870
    },
    {
        "loss": 0.1972,
        "grad_norm": 25.807104110717773,
        "learning_rate": 4.520295202952029e-06,
        "epoch": 32.76752767527675,
        "step": 8880
    },
    {
        "loss": 0.1296,
        "grad_norm": 1.7972577810287476,
        "learning_rate": 4.497232472324724e-06,
        "epoch": 32.80442804428044,
        "step": 8890
    },
    {
        "loss": 0.2465,
        "grad_norm": 48.65580368041992,
        "learning_rate": 4.474169741697417e-06,
        "epoch": 32.84132841328413,
        "step": 8900
    },
    {
        "loss": 0.1879,
        "grad_norm": 3.5201263427734375,
        "learning_rate": 4.451107011070111e-06,
        "epoch": 32.87822878228782,
        "step": 8910
    },
    {
        "loss": 0.1881,
        "grad_norm": 2.4594078063964844,
        "learning_rate": 4.428044280442805e-06,
        "epoch": 32.91512915129151,
        "step": 8920
    },
    {
        "loss": 0.2118,
        "grad_norm": 7.9987473487854,
        "learning_rate": 4.404981549815498e-06,
        "epoch": 32.952029520295206,
        "step": 8930
    },
    {
        "loss": 0.1995,
        "grad_norm": 14.056171417236328,
        "learning_rate": 4.381918819188192e-06,
        "epoch": 32.988929889298895,
        "step": 8940
    },
    {
        "eval_loss": 0.5483618378639221,
        "eval_accuracy": 0.88089,
        "eval_precision": 0.86301,
        "eval_recall": 0.91139,
        "eval_f1": 0.88654,
        "eval_runtime": 27.2891,
        "eval_samples_per_second": 39.686,
        "eval_steps_per_second": 2.492,
        "epoch": 33.0,
        "step": 8943
    },
    {
        "loss": 0.2361,
        "grad_norm": 2.4640164375305176,
        "learning_rate": 4.358856088560886e-06,
        "epoch": 33.025830258302584,
        "step": 8950
    },
    {
        "loss": 0.2323,
        "grad_norm": 13.592251777648926,
        "learning_rate": 4.33579335793358e-06,
        "epoch": 33.06273062730627,
        "step": 8960
    },
    {
        "loss": 0.1785,
        "grad_norm": 0.536074697971344,
        "learning_rate": 4.312730627306273e-06,
        "epoch": 33.09963099630996,
        "step": 8970
    },
    {
        "loss": 0.2064,
        "grad_norm": 1.4141850471496582,
        "learning_rate": 4.289667896678967e-06,
        "epoch": 33.13653136531365,
        "step": 8980
    },
    {
        "loss": 0.1471,
        "grad_norm": 4.349944114685059,
        "learning_rate": 4.266605166051661e-06,
        "epoch": 33.17343173431734,
        "step": 8990
    },
    {
        "loss": 0.1681,
        "grad_norm": 1.9880002737045288,
        "learning_rate": 4.243542435424354e-06,
        "epoch": 33.210332103321036,
        "step": 9000
    },
    {
        "loss": 0.2161,
        "grad_norm": 8.753090858459473,
        "learning_rate": 4.2204797047970476e-06,
        "epoch": 33.247232472324725,
        "step": 9010
    },
    {
        "loss": 0.1883,
        "grad_norm": 9.398208618164062,
        "learning_rate": 4.197416974169742e-06,
        "epoch": 33.284132841328415,
        "step": 9020
    },
    {
        "loss": 0.1491,
        "grad_norm": 2.502662181854248,
        "learning_rate": 4.174354243542435e-06,
        "epoch": 33.321033210332104,
        "step": 9030
    },
    {
        "loss": 0.2171,
        "grad_norm": 3.7804856300354004,
        "learning_rate": 4.151291512915129e-06,
        "epoch": 33.35793357933579,
        "step": 9040
    },
    {
        "loss": 0.1781,
        "grad_norm": 10.726401329040527,
        "learning_rate": 4.128228782287824e-06,
        "epoch": 33.39483394833948,
        "step": 9050
    },
    {
        "loss": 0.1711,
        "grad_norm": 12.750001907348633,
        "learning_rate": 4.105166051660517e-06,
        "epoch": 33.43173431734317,
        "step": 9060
    },
    {
        "loss": 0.1269,
        "grad_norm": 23.749671936035156,
        "learning_rate": 4.08210332103321e-06,
        "epoch": 33.46863468634686,
        "step": 9070
    },
    {
        "loss": 0.2416,
        "grad_norm": 14.066640853881836,
        "learning_rate": 4.059040590405904e-06,
        "epoch": 33.505535055350556,
        "step": 9080
    },
    {
        "loss": 0.1528,
        "grad_norm": 1.3842945098876953,
        "learning_rate": 4.035977859778598e-06,
        "epoch": 33.542435424354245,
        "step": 9090
    },
    {
        "loss": 0.1516,
        "grad_norm": 34.54798126220703,
        "learning_rate": 4.012915129151291e-06,
        "epoch": 33.579335793357934,
        "step": 9100
    },
    {
        "loss": 0.2366,
        "grad_norm": 10.492949485778809,
        "learning_rate": 3.989852398523986e-06,
        "epoch": 33.61623616236162,
        "step": 9110
    },
    {
        "loss": 0.2225,
        "grad_norm": 1.9846538305282593,
        "learning_rate": 3.966789667896679e-06,
        "epoch": 33.65313653136531,
        "step": 9120
    },
    {
        "loss": 0.1588,
        "grad_norm": 2.1953823566436768,
        "learning_rate": 3.943726937269373e-06,
        "epoch": 33.690036900369,
        "step": 9130
    },
    {
        "loss": 0.222,
        "grad_norm": 4.129220485687256,
        "learning_rate": 3.920664206642067e-06,
        "epoch": 33.72693726937269,
        "step": 9140
    },
    {
        "loss": 0.1409,
        "grad_norm": 2.2233331203460693,
        "learning_rate": 3.89760147601476e-06,
        "epoch": 33.76383763837639,
        "step": 9150
    },
    {
        "loss": 0.1665,
        "grad_norm": 2.5712382793426514,
        "learning_rate": 3.874538745387454e-06,
        "epoch": 33.800738007380076,
        "step": 9160
    },
    {
        "loss": 0.1651,
        "grad_norm": 2.6737279891967773,
        "learning_rate": 3.851476014760148e-06,
        "epoch": 33.837638376383765,
        "step": 9170
    },
    {
        "loss": 0.2169,
        "grad_norm": 11.865184783935547,
        "learning_rate": 3.828413284132842e-06,
        "epoch": 33.874538745387454,
        "step": 9180
    },
    {
        "loss": 0.2176,
        "grad_norm": 0.6040733456611633,
        "learning_rate": 3.8053505535055352e-06,
        "epoch": 33.91143911439114,
        "step": 9190
    },
    {
        "loss": 0.1502,
        "grad_norm": 3.8590424060821533,
        "learning_rate": 3.782287822878229e-06,
        "epoch": 33.94833948339483,
        "step": 9200
    },
    {
        "loss": 0.1187,
        "grad_norm": 0.8860734105110168,
        "learning_rate": 3.7592250922509224e-06,
        "epoch": 33.98523985239852,
        "step": 9210
    },
    {
        "eval_loss": 0.58042311668396,
        "eval_accuracy": 0.8735,
        "eval_precision": 0.86111,
        "eval_recall": 0.89693,
        "eval_f1": 0.87865,
        "eval_runtime": 23.6424,
        "eval_samples_per_second": 45.807,
        "eval_steps_per_second": 2.876,
        "epoch": 34.0,
        "step": 9214
    },
    {
        "loss": 0.2468,
        "grad_norm": 25.15119171142578,
        "learning_rate": 3.7361623616236166e-06,
        "epoch": 34.02214022140221,
        "step": 9220
    },
    {
        "loss": 0.1108,
        "grad_norm": 0.8677922487258911,
        "learning_rate": 3.71309963099631e-06,
        "epoch": 34.05904059040591,
        "step": 9230
    },
    {
        "loss": 0.1922,
        "grad_norm": 6.327823162078857,
        "learning_rate": 3.690036900369004e-06,
        "epoch": 34.095940959409596,
        "step": 9240
    },
    {
        "loss": 0.1503,
        "grad_norm": 78.92636108398438,
        "learning_rate": 3.666974169741698e-06,
        "epoch": 34.132841328413285,
        "step": 9250
    },
    {
        "loss": 0.2054,
        "grad_norm": 13.082409858703613,
        "learning_rate": 3.6439114391143914e-06,
        "epoch": 34.169741697416974,
        "step": 9260
    },
    {
        "loss": 0.1194,
        "grad_norm": 0.41627541184425354,
        "learning_rate": 3.6208487084870852e-06,
        "epoch": 34.20664206642066,
        "step": 9270
    },
    {
        "loss": 0.1545,
        "grad_norm": 1.0372734069824219,
        "learning_rate": 3.5977859778597786e-06,
        "epoch": 34.24354243542435,
        "step": 9280
    },
    {
        "loss": 0.2051,
        "grad_norm": 0.9009578824043274,
        "learning_rate": 3.574723247232473e-06,
        "epoch": 34.28044280442804,
        "step": 9290
    },
    {
        "loss": 0.2136,
        "grad_norm": 0.34760719537734985,
        "learning_rate": 3.551660516605166e-06,
        "epoch": 34.31734317343174,
        "step": 9300
    },
    {
        "loss": 0.1326,
        "grad_norm": 2.8803038597106934,
        "learning_rate": 3.52859778597786e-06,
        "epoch": 34.35424354243543,
        "step": 9310
    },
    {
        "loss": 0.2239,
        "grad_norm": 8.099438667297363,
        "learning_rate": 3.5055350553505534e-06,
        "epoch": 34.391143911439116,
        "step": 9320
    },
    {
        "loss": 0.1534,
        "grad_norm": 6.733651638031006,
        "learning_rate": 3.4824723247232472e-06,
        "epoch": 34.428044280442805,
        "step": 9330
    },
    {
        "loss": 0.1884,
        "grad_norm": 0.6614553332328796,
        "learning_rate": 3.4594095940959415e-06,
        "epoch": 34.464944649446494,
        "step": 9340
    },
    {
        "loss": 0.1423,
        "grad_norm": 2.0455636978149414,
        "learning_rate": 3.436346863468635e-06,
        "epoch": 34.50184501845018,
        "step": 9350
    },
    {
        "loss": 0.1307,
        "grad_norm": 2.7243168354034424,
        "learning_rate": 3.4132841328413286e-06,
        "epoch": 34.53874538745387,
        "step": 9360
    },
    {
        "loss": 0.2411,
        "grad_norm": 1.6659657955169678,
        "learning_rate": 3.390221402214022e-06,
        "epoch": 34.57564575645756,
        "step": 9370
    },
    {
        "loss": 0.129,
        "grad_norm": 0.5316201448440552,
        "learning_rate": 3.3671586715867163e-06,
        "epoch": 34.61254612546126,
        "step": 9380
    },
    {
        "loss": 0.2862,
        "grad_norm": 12.35019588470459,
        "learning_rate": 3.3440959409594096e-06,
        "epoch": 34.64944649446495,
        "step": 9390
    },
    {
        "loss": 0.1609,
        "grad_norm": 26.273849487304688,
        "learning_rate": 3.3210332103321034e-06,
        "epoch": 34.686346863468636,
        "step": 9400
    },
    {
        "loss": 0.2002,
        "grad_norm": 0.9108060002326965,
        "learning_rate": 3.297970479704797e-06,
        "epoch": 34.723247232472325,
        "step": 9410
    },
    {
        "loss": 0.2012,
        "grad_norm": 43.39148712158203,
        "learning_rate": 3.274907749077491e-06,
        "epoch": 34.760147601476014,
        "step": 9420
    },
    {
        "loss": 0.1347,
        "grad_norm": 7.901461124420166,
        "learning_rate": 3.2518450184501844e-06,
        "epoch": 34.7970479704797,
        "step": 9430
    },
    {
        "loss": 0.1795,
        "grad_norm": 3.0054218769073486,
        "learning_rate": 3.2287822878228782e-06,
        "epoch": 34.83394833948339,
        "step": 9440
    },
    {
        "loss": 0.2513,
        "grad_norm": 1.4789735078811646,
        "learning_rate": 3.2057195571955725e-06,
        "epoch": 34.87084870848709,
        "step": 9450
    },
    {
        "loss": 0.111,
        "grad_norm": 3.9899630546569824,
        "learning_rate": 3.182656826568266e-06,
        "epoch": 34.90774907749078,
        "step": 9460
    },
    {
        "loss": 0.1742,
        "grad_norm": 3.750798225402832,
        "learning_rate": 3.1595940959409597e-06,
        "epoch": 34.944649446494466,
        "step": 9470
    },
    {
        "loss": 0.2991,
        "grad_norm": 0.48513883352279663,
        "learning_rate": 3.136531365313653e-06,
        "epoch": 34.981549815498155,
        "step": 9480
    },
    {
        "eval_loss": 0.5762829184532166,
        "eval_accuracy": 0.87627,
        "eval_precision": 0.86059,
        "eval_recall": 0.90416,
        "eval_f1": 0.88183,
        "eval_runtime": 29.5652,
        "eval_samples_per_second": 36.631,
        "eval_steps_per_second": 2.3,
        "epoch": 35.0,
        "step": 9485
    },
    {
        "loss": 0.213,
        "grad_norm": 5.564947605133057,
        "learning_rate": 3.1134686346863473e-06,
        "epoch": 35.018450184501845,
        "step": 9490
    },
    {
        "loss": 0.1929,
        "grad_norm": 22.696748733520508,
        "learning_rate": 3.090405904059041e-06,
        "epoch": 35.055350553505534,
        "step": 9500
    },
    {
        "loss": 0.1061,
        "grad_norm": 1.7043004035949707,
        "learning_rate": 3.0673431734317345e-06,
        "epoch": 35.09225092250922,
        "step": 9510
    },
    {
        "loss": 0.1696,
        "grad_norm": 4.930606842041016,
        "learning_rate": 3.0442804428044283e-06,
        "epoch": 35.12915129151291,
        "step": 9520
    },
    {
        "loss": 0.1973,
        "grad_norm": 1.558229684829712,
        "learning_rate": 3.021217712177122e-06,
        "epoch": 35.16605166051661,
        "step": 9530
    },
    {
        "loss": 0.1392,
        "grad_norm": 3.3663837909698486,
        "learning_rate": 2.9981549815498154e-06,
        "epoch": 35.2029520295203,
        "step": 9540
    },
    {
        "loss": 0.1047,
        "grad_norm": 0.4519491195678711,
        "learning_rate": 2.9750922509225093e-06,
        "epoch": 35.239852398523986,
        "step": 9550
    },
    {
        "loss": 0.2297,
        "grad_norm": 9.098773956298828,
        "learning_rate": 2.952029520295203e-06,
        "epoch": 35.276752767527675,
        "step": 9560
    },
    {
        "loss": 0.2509,
        "grad_norm": 2.7276854515075684,
        "learning_rate": 2.928966789667897e-06,
        "epoch": 35.313653136531364,
        "step": 9570
    },
    {
        "loss": 0.1882,
        "grad_norm": 4.133274078369141,
        "learning_rate": 2.9059040590405902e-06,
        "epoch": 35.35055350553505,
        "step": 9580
    },
    {
        "loss": 0.1486,
        "grad_norm": 8.56558895111084,
        "learning_rate": 2.8828413284132845e-06,
        "epoch": 35.38745387453874,
        "step": 9590
    },
    {
        "loss": 0.1648,
        "grad_norm": 0.8394259810447693,
        "learning_rate": 2.8597785977859783e-06,
        "epoch": 35.42435424354244,
        "step": 9600
    },
    {
        "loss": 0.1882,
        "grad_norm": 13.888800621032715,
        "learning_rate": 2.8367158671586717e-06,
        "epoch": 35.46125461254613,
        "step": 9610
    },
    {
        "loss": 0.0941,
        "grad_norm": 2.660247564315796,
        "learning_rate": 2.8136531365313655e-06,
        "epoch": 35.49815498154982,
        "step": 9620
    },
    {
        "loss": 0.1647,
        "grad_norm": 50.9174919128418,
        "learning_rate": 2.7905904059040593e-06,
        "epoch": 35.535055350553506,
        "step": 9630
    },
    {
        "loss": 0.2502,
        "grad_norm": 13.55370044708252,
        "learning_rate": 2.767527675276753e-06,
        "epoch": 35.571955719557195,
        "step": 9640
    },
    {
        "loss": 0.1633,
        "grad_norm": 1.9941998720169067,
        "learning_rate": 2.7444649446494465e-06,
        "epoch": 35.608856088560884,
        "step": 9650
    },
    {
        "loss": 0.176,
        "grad_norm": 9.119678497314453,
        "learning_rate": 2.7214022140221403e-06,
        "epoch": 35.64575645756457,
        "step": 9660
    },
    {
        "loss": 0.3031,
        "grad_norm": 3.8815739154815674,
        "learning_rate": 2.698339483394834e-06,
        "epoch": 35.68265682656826,
        "step": 9670
    },
    {
        "loss": 0.1572,
        "grad_norm": 1.7719427347183228,
        "learning_rate": 2.6752767527675275e-06,
        "epoch": 35.71955719557196,
        "step": 9680
    },
    {
        "loss": 0.2212,
        "grad_norm": 9.250824928283691,
        "learning_rate": 2.6522140221402217e-06,
        "epoch": 35.75645756457565,
        "step": 9690
    },
    {
        "loss": 0.1883,
        "grad_norm": 3.3515877723693848,
        "learning_rate": 2.6291512915129155e-06,
        "epoch": 35.79335793357934,
        "step": 9700
    },
    {
        "loss": 0.1212,
        "grad_norm": 1.957565188407898,
        "learning_rate": 2.606088560885609e-06,
        "epoch": 35.830258302583026,
        "step": 9710
    },
    {
        "loss": 0.1449,
        "grad_norm": 3.386522054672241,
        "learning_rate": 2.5830258302583027e-06,
        "epoch": 35.867158671586715,
        "step": 9720
    },
    {
        "loss": 0.1779,
        "grad_norm": 4.536306381225586,
        "learning_rate": 2.5599630996309965e-06,
        "epoch": 35.904059040590404,
        "step": 9730
    },
    {
        "loss": 0.2331,
        "grad_norm": 28.46639060974121,
        "learning_rate": 2.5369003690036903e-06,
        "epoch": 35.94095940959409,
        "step": 9740
    },
    {
        "loss": 0.1779,
        "grad_norm": 1.994104266166687,
        "learning_rate": 2.5138376383763837e-06,
        "epoch": 35.97785977859779,
        "step": 9750
    },
    {
        "eval_loss": 0.5571919083595276,
        "eval_accuracy": 0.87904,
        "eval_precision": 0.8613,
        "eval_recall": 0.90958,
        "eval_f1": 0.88478,
        "eval_runtime": 30.2065,
        "eval_samples_per_second": 35.853,
        "eval_steps_per_second": 2.251,
        "epoch": 36.0,
        "step": 9756
    },
    {
        "loss": 0.106,
        "grad_norm": 2.5530943870544434,
        "learning_rate": 2.4907749077490775e-06,
        "epoch": 36.01476014760148,
        "step": 9760
    },
    {
        "loss": 0.1013,
        "grad_norm": 1.4541335105895996,
        "learning_rate": 2.4677121771217713e-06,
        "epoch": 36.05166051660517,
        "step": 9770
    },
    {
        "loss": 0.1661,
        "grad_norm": 8.676523208618164,
        "learning_rate": 2.444649446494465e-06,
        "epoch": 36.08856088560886,
        "step": 9780
    },
    {
        "loss": 0.1524,
        "grad_norm": 2.210996150970459,
        "learning_rate": 2.421586715867159e-06,
        "epoch": 36.125461254612546,
        "step": 9790
    },
    {
        "loss": 0.316,
        "grad_norm": 4.56170654296875,
        "learning_rate": 2.3985239852398527e-06,
        "epoch": 36.162361623616235,
        "step": 9800
    },
    {
        "loss": 0.2161,
        "grad_norm": 4.394493579864502,
        "learning_rate": 2.3754612546125465e-06,
        "epoch": 36.199261992619924,
        "step": 9810
    },
    {
        "loss": 0.2233,
        "grad_norm": 6.049571990966797,
        "learning_rate": 2.35239852398524e-06,
        "epoch": 36.23616236162361,
        "step": 9820
    },
    {
        "loss": 0.1787,
        "grad_norm": 10.608881950378418,
        "learning_rate": 2.3293357933579337e-06,
        "epoch": 36.27306273062731,
        "step": 9830
    },
    {
        "loss": 0.186,
        "grad_norm": 1.3148921728134155,
        "learning_rate": 2.3062730627306275e-06,
        "epoch": 36.309963099631,
        "step": 9840
    },
    {
        "loss": 0.1671,
        "grad_norm": 1.3056857585906982,
        "learning_rate": 2.2832103321033213e-06,
        "epoch": 36.34686346863469,
        "step": 9850
    },
    {
        "loss": 0.1282,
        "grad_norm": 8.852049827575684,
        "learning_rate": 2.2601476014760147e-06,
        "epoch": 36.38376383763838,
        "step": 9860
    },
    {
        "loss": 0.1277,
        "grad_norm": 1.9614251852035522,
        "learning_rate": 2.2370848708487085e-06,
        "epoch": 36.420664206642066,
        "step": 9870
    },
    {
        "loss": 0.1974,
        "grad_norm": 1.3464714288711548,
        "learning_rate": 2.2140221402214023e-06,
        "epoch": 36.457564575645755,
        "step": 9880
    },
    {
        "loss": 0.186,
        "grad_norm": 0.5709310173988342,
        "learning_rate": 2.190959409594096e-06,
        "epoch": 36.494464944649444,
        "step": 9890
    },
    {
        "loss": 0.1415,
        "grad_norm": 1.506460189819336,
        "learning_rate": 2.16789667896679e-06,
        "epoch": 36.53136531365314,
        "step": 9900
    },
    {
        "loss": 0.1327,
        "grad_norm": 1.301102876663208,
        "learning_rate": 2.1448339483394837e-06,
        "epoch": 36.56826568265683,
        "step": 9910
    },
    {
        "loss": 0.1906,
        "grad_norm": 1.9862134456634521,
        "learning_rate": 2.121771217712177e-06,
        "epoch": 36.60516605166052,
        "step": 9920
    },
    {
        "loss": 0.1339,
        "grad_norm": 1.4605748653411865,
        "learning_rate": 2.098708487084871e-06,
        "epoch": 36.64206642066421,
        "step": 9930
    },
    {
        "loss": 0.2117,
        "grad_norm": 2.4073071479797363,
        "learning_rate": 2.0756457564575647e-06,
        "epoch": 36.678966789667896,
        "step": 9940
    },
    {
        "loss": 0.2256,
        "grad_norm": 2.715284824371338,
        "learning_rate": 2.0525830258302585e-06,
        "epoch": 36.715867158671585,
        "step": 9950
    },
    {
        "loss": 0.1222,
        "grad_norm": 1.5927767753601074,
        "learning_rate": 2.029520295202952e-06,
        "epoch": 36.752767527675275,
        "step": 9960
    },
    {
        "loss": 0.2095,
        "grad_norm": 2.5531113147735596,
        "learning_rate": 2.0064575645756457e-06,
        "epoch": 36.789667896678964,
        "step": 9970
    },
    {
        "loss": 0.1089,
        "grad_norm": 1.409011960029602,
        "learning_rate": 1.9833948339483395e-06,
        "epoch": 36.82656826568266,
        "step": 9980
    },
    {
        "loss": 0.1157,
        "grad_norm": 12.147854804992676,
        "learning_rate": 1.9603321033210333e-06,
        "epoch": 36.86346863468635,
        "step": 9990
    },
    {
        "loss": 0.1798,
        "grad_norm": 15.581361770629883,
        "learning_rate": 1.937269372693727e-06,
        "epoch": 36.90036900369004,
        "step": 10000
    },
    {
        "loss": 0.1905,
        "grad_norm": 3.633091688156128,
        "learning_rate": 1.914206642066421e-06,
        "epoch": 36.93726937269373,
        "step": 10010
    },
    {
        "loss": 0.1814,
        "grad_norm": 9.851784706115723,
        "learning_rate": 1.8911439114391145e-06,
        "epoch": 36.974169741697416,
        "step": 10020
    },
    {
        "eval_loss": 0.5934549570083618,
        "eval_accuracy": 0.87535,
        "eval_precision": 0.86034,
        "eval_recall": 0.90235,
        "eval_f1": 0.88085,
        "eval_runtime": 27.945,
        "eval_samples_per_second": 38.755,
        "eval_steps_per_second": 2.433,
        "epoch": 37.0,
        "step": 10027
    },
    {
        "loss": 0.1417,
        "grad_norm": 1.550692081451416,
        "learning_rate": 1.8680811808118083e-06,
        "epoch": 37.011070110701105,
        "step": 10030
    },
    {
        "loss": 0.196,
        "grad_norm": 12.69774341583252,
        "learning_rate": 1.845018450184502e-06,
        "epoch": 37.047970479704794,
        "step": 10040
    },
    {
        "loss": 0.1084,
        "grad_norm": 8.314081192016602,
        "learning_rate": 1.8219557195571957e-06,
        "epoch": 37.08487084870849,
        "step": 10050
    },
    {
        "loss": 0.0703,
        "grad_norm": 1.1124675273895264,
        "learning_rate": 1.7988929889298893e-06,
        "epoch": 37.12177121771218,
        "step": 10060
    },
    {
        "loss": 0.1412,
        "grad_norm": 4.057479381561279,
        "learning_rate": 1.775830258302583e-06,
        "epoch": 37.15867158671587,
        "step": 10070
    },
    {
        "loss": 0.1921,
        "grad_norm": 4.1514692306518555,
        "learning_rate": 1.7527675276752767e-06,
        "epoch": 37.19557195571956,
        "step": 10080
    },
    {
        "loss": 0.1393,
        "grad_norm": 1.9775623083114624,
        "learning_rate": 1.7297047970479707e-06,
        "epoch": 37.23247232472325,
        "step": 10090
    },
    {
        "loss": 0.2055,
        "grad_norm": 2.8394947052001953,
        "learning_rate": 1.7066420664206643e-06,
        "epoch": 37.269372693726936,
        "step": 10100
    },
    {
        "loss": 0.1392,
        "grad_norm": 2.3374714851379395,
        "learning_rate": 1.6835793357933581e-06,
        "epoch": 37.306273062730625,
        "step": 10110
    },
    {
        "loss": 0.1682,
        "grad_norm": 29.080886840820312,
        "learning_rate": 1.6605166051660517e-06,
        "epoch": 37.343173431734314,
        "step": 10120
    },
    {
        "loss": 0.156,
        "grad_norm": 6.278713226318359,
        "learning_rate": 1.6374538745387455e-06,
        "epoch": 37.38007380073801,
        "step": 10130
    },
    {
        "loss": 0.2067,
        "grad_norm": 3.093189239501953,
        "learning_rate": 1.6143911439114391e-06,
        "epoch": 37.4169741697417,
        "step": 10140
    },
    {
        "loss": 0.1426,
        "grad_norm": 1.6729907989501953,
        "learning_rate": 1.591328413284133e-06,
        "epoch": 37.45387453874539,
        "step": 10150
    },
    {
        "loss": 0.1423,
        "grad_norm": 1.2902179956436157,
        "learning_rate": 1.5682656826568265e-06,
        "epoch": 37.49077490774908,
        "step": 10160
    },
    {
        "loss": 0.1568,
        "grad_norm": 2.393800735473633,
        "learning_rate": 1.5452029520295205e-06,
        "epoch": 37.52767527675277,
        "step": 10170
    },
    {
        "loss": 0.2132,
        "grad_norm": 4.2100934982299805,
        "learning_rate": 1.5221402214022141e-06,
        "epoch": 37.564575645756456,
        "step": 10180
    },
    {
        "loss": 0.1523,
        "grad_norm": 1.676155686378479,
        "learning_rate": 1.4990774907749077e-06,
        "epoch": 37.601476014760145,
        "step": 10190
    },
    {
        "loss": 0.233,
        "grad_norm": 3.3378403186798096,
        "learning_rate": 1.4760147601476015e-06,
        "epoch": 37.63837638376384,
        "step": 10200
    },
    {
        "loss": 0.3919,
        "grad_norm": 9.879551887512207,
        "learning_rate": 1.4529520295202951e-06,
        "epoch": 37.67527675276753,
        "step": 10210
    },
    {
        "loss": 0.2142,
        "grad_norm": 2.223640203475952,
        "learning_rate": 1.4298892988929891e-06,
        "epoch": 37.71217712177122,
        "step": 10220
    },
    {
        "loss": 0.1573,
        "grad_norm": 0.5210813879966736,
        "learning_rate": 1.4068265682656827e-06,
        "epoch": 37.74907749077491,
        "step": 10230
    },
    {
        "loss": 0.1334,
        "grad_norm": 3.61547589302063,
        "learning_rate": 1.3837638376383765e-06,
        "epoch": 37.7859778597786,
        "step": 10240
    },
    {
        "loss": 0.1915,
        "grad_norm": 3.5932323932647705,
        "learning_rate": 1.3607011070110701e-06,
        "epoch": 37.82287822878229,
        "step": 10250
    },
    {
        "loss": 0.2515,
        "grad_norm": 13.20911979675293,
        "learning_rate": 1.3376383763837637e-06,
        "epoch": 37.859778597785976,
        "step": 10260
    },
    {
        "loss": 0.1095,
        "grad_norm": 1.0922209024429321,
        "learning_rate": 1.3145756457564577e-06,
        "epoch": 37.896678966789665,
        "step": 10270
    },
    {
        "loss": 0.2569,
        "grad_norm": 6.463441371917725,
        "learning_rate": 1.2915129151291513e-06,
        "epoch": 37.93357933579336,
        "step": 10280
    },
    {
        "loss": 0.2134,
        "grad_norm": 0.7893290519714355,
        "learning_rate": 1.2684501845018451e-06,
        "epoch": 37.97047970479705,
        "step": 10290
    },
    {
        "eval_loss": 0.5821157693862915,
        "eval_accuracy": 0.87535,
        "eval_precision": 0.85911,
        "eval_recall": 0.90416,
        "eval_f1": 0.88106,
        "eval_runtime": 61.0706,
        "eval_samples_per_second": 17.734,
        "eval_steps_per_second": 1.113,
        "epoch": 38.0,
        "step": 10298
    },
    {
        "loss": 0.1833,
        "grad_norm": 29.051677703857422,
        "learning_rate": 1.2453874538745387e-06,
        "epoch": 38.00738007380074,
        "step": 10300
    },
    {
        "loss": 0.1612,
        "grad_norm": 0.41821378469467163,
        "learning_rate": 1.2223247232472325e-06,
        "epoch": 38.04428044280443,
        "step": 10310
    },
    {
        "loss": 0.0982,
        "grad_norm": 3.1928069591522217,
        "learning_rate": 1.1992619926199263e-06,
        "epoch": 38.08118081180812,
        "step": 10320
    },
    {
        "loss": 0.0997,
        "grad_norm": 3.251500368118286,
        "learning_rate": 1.17619926199262e-06,
        "epoch": 38.11808118081181,
        "step": 10330
    },
    {
        "loss": 0.1634,
        "grad_norm": 0.46992653608322144,
        "learning_rate": 1.1531365313653137e-06,
        "epoch": 38.154981549815496,
        "step": 10340
    },
    {
        "loss": 0.2113,
        "grad_norm": 1.7121433019638062,
        "learning_rate": 1.1300738007380073e-06,
        "epoch": 38.191881918819185,
        "step": 10350
    },
    {
        "loss": 0.1092,
        "grad_norm": 2.095471143722534,
        "learning_rate": 1.1070110701107011e-06,
        "epoch": 38.22878228782288,
        "step": 10360
    },
    {
        "loss": 0.0743,
        "grad_norm": 1.5930863618850708,
        "learning_rate": 1.083948339483395e-06,
        "epoch": 38.26568265682657,
        "step": 10370
    },
    {
        "loss": 0.1377,
        "grad_norm": 6.448335647583008,
        "learning_rate": 1.0608856088560885e-06,
        "epoch": 38.30258302583026,
        "step": 10380
    },
    {
        "loss": 0.1028,
        "grad_norm": 0.6346544027328491,
        "learning_rate": 1.0378228782287824e-06,
        "epoch": 38.33948339483395,
        "step": 10390
    },
    {
        "loss": 0.1567,
        "grad_norm": 0.8684478998184204,
        "learning_rate": 1.014760147601476e-06,
        "epoch": 38.37638376383764,
        "step": 10400
    },
    {
        "loss": 0.2121,
        "grad_norm": 6.433273792266846,
        "learning_rate": 9.916974169741698e-07,
        "epoch": 38.413284132841326,
        "step": 10410
    },
    {
        "loss": 0.3133,
        "grad_norm": 4.400539875030518,
        "learning_rate": 9.686346863468636e-07,
        "epoch": 38.450184501845015,
        "step": 10420
    },
    {
        "loss": 0.1074,
        "grad_norm": 3.2942206859588623,
        "learning_rate": 9.455719557195573e-07,
        "epoch": 38.48708487084871,
        "step": 10430
    },
    {
        "loss": 0.1471,
        "grad_norm": 3.3155696392059326,
        "learning_rate": 9.22509225092251e-07,
        "epoch": 38.5239852398524,
        "step": 10440
    },
    {
        "loss": 0.2222,
        "grad_norm": 0.42630821466445923,
        "learning_rate": 8.994464944649447e-07,
        "epoch": 38.56088560885609,
        "step": 10450
    },
    {
        "loss": 0.2341,
        "grad_norm": 1.8657569885253906,
        "learning_rate": 8.763837638376384e-07,
        "epoch": 38.59778597785978,
        "step": 10460
    },
    {
        "loss": 0.123,
        "grad_norm": 2.534353733062744,
        "learning_rate": 8.533210332103322e-07,
        "epoch": 38.63468634686347,
        "step": 10470
    },
    {
        "loss": 0.1731,
        "grad_norm": 0.606412947177887,
        "learning_rate": 8.302583025830259e-07,
        "epoch": 38.67158671586716,
        "step": 10480
    },
    {
        "loss": 0.1781,
        "grad_norm": 4.12754487991333,
        "learning_rate": 8.071955719557196e-07,
        "epoch": 38.708487084870846,
        "step": 10490
    },
    {
        "loss": 0.2153,
        "grad_norm": 2.6069724559783936,
        "learning_rate": 7.841328413284133e-07,
        "epoch": 38.745387453874535,
        "step": 10500
    },
    {
        "loss": 0.1624,
        "grad_norm": 13.331774711608887,
        "learning_rate": 7.610701107011071e-07,
        "epoch": 38.78228782287823,
        "step": 10510
    },
    {
        "loss": 0.2202,
        "grad_norm": 4.8678765296936035,
        "learning_rate": 7.380073800738008e-07,
        "epoch": 38.81918819188192,
        "step": 10520
    },
    {
        "loss": 0.1838,
        "grad_norm": 9.345148086547852,
        "learning_rate": 7.149446494464946e-07,
        "epoch": 38.85608856088561,
        "step": 10530
    },
    {
        "loss": 0.1782,
        "grad_norm": 57.83150863647461,
        "learning_rate": 6.918819188191883e-07,
        "epoch": 38.8929889298893,
        "step": 10540
    },
    {
        "loss": 0.2438,
        "grad_norm": 0.4392617642879486,
        "learning_rate": 6.688191881918819e-07,
        "epoch": 38.92988929889299,
        "step": 10550
    },
    {
        "loss": 0.1189,
        "grad_norm": 1.2168750762939453,
        "learning_rate": 6.457564575645757e-07,
        "epoch": 38.96678966789668,
        "step": 10560
    },
    {
        "eval_loss": 0.6059131026268005,
        "eval_accuracy": 0.87627,
        "eval_precision": 0.86059,
        "eval_recall": 0.90416,
        "eval_f1": 0.88183,
        "eval_runtime": 60.5876,
        "eval_samples_per_second": 17.875,
        "eval_steps_per_second": 1.122,
        "epoch": 39.0,
        "step": 10569
    },
    {
        "train_runtime": 14245.7865,
        "train_samples_per_second": 12.175,
        "train_steps_per_second": 0.761,
        "total_flos": 2.224656595279872e+16,
        "train_loss": 0.2634620862591852,
        "epoch": 39.0,
        "step": 10569
    }
]