[
    {
        "loss": 0.6261,
        "grad_norm": 3.5755515098571777,
        "learning_rate": 2.4976937269372695e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.4838,
        "grad_norm": 6.455125331878662,
        "learning_rate": 2.495387453874539e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.5408,
        "grad_norm": 3.335043430328369,
        "learning_rate": 2.493081180811808e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.479,
        "grad_norm": 4.587995529174805,
        "learning_rate": 2.4907749077490778e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.4839,
        "grad_norm": 4.452125549316406,
        "learning_rate": 2.488468634686347e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.4922,
        "grad_norm": 5.228388786315918,
        "learning_rate": 2.4861623616236163e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.4449,
        "grad_norm": 1.3843032121658325,
        "learning_rate": 2.4838560885608857e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.4646,
        "grad_norm": 3.413647174835205,
        "learning_rate": 2.481549815498155e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.5335,
        "grad_norm": 5.923424243927002,
        "learning_rate": 2.4792435424354242e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.5098,
        "grad_norm": 4.30662727355957,
        "learning_rate": 2.476937269372694e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.4078,
        "grad_norm": 6.1684370040893555,
        "learning_rate": 2.474630996309963e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.4401,
        "grad_norm": 3.985776662826538,
        "learning_rate": 2.472324723247233e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4561,
        "grad_norm": 2.8480939865112305,
        "learning_rate": 2.470018450184502e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4194,
        "grad_norm": 2.607368230819702,
        "learning_rate": 2.4677121771217714e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4047,
        "grad_norm": 2.8900630474090576,
        "learning_rate": 2.4654059040590408e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.4046,
        "grad_norm": 6.026519775390625,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.4063,
        "grad_norm": 2.841449737548828,
        "learning_rate": 2.4607933579335796e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.4642,
        "grad_norm": 2.2581474781036377,
        "learning_rate": 2.4584870848708487e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4459,
        "grad_norm": 3.1444506645202637,
        "learning_rate": 2.456180811808118e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4226,
        "grad_norm": 5.91029691696167,
        "learning_rate": 2.4538745387453876e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.426,
        "grad_norm": 1.8794617652893066,
        "learning_rate": 2.451568265682657e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.3856,
        "grad_norm": 2.2339813709259033,
        "learning_rate": 2.4492619926199264e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.342,
        "grad_norm": 2.546359062194824,
        "learning_rate": 2.4469557195571958e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.3673,
        "grad_norm": 1.6095777750015259,
        "learning_rate": 2.444649446494465e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.4569,
        "grad_norm": 2.5786843299865723,
        "learning_rate": 2.4423431734317347e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.5142,
        "grad_norm": 6.258303165435791,
        "learning_rate": 2.4400369003690038e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4427,
        "grad_norm": 6.514782428741455,
        "learning_rate": 2.4377306273062732e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.45320406556129456,
        "eval_accuracy": 0.78967,
        "eval_precision": 0.73141,
        "eval_recall": 0.90432,
        "eval_f1": 0.80872,
        "eval_runtime": 18.12,
        "eval_samples_per_second": 59.823,
        "eval_steps_per_second": 3.753,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.4811,
        "grad_norm": 2.653780698776245,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.3857,
        "grad_norm": 3.2109837532043457,
        "learning_rate": 2.4331180811808117e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.3709,
        "grad_norm": 2.155182123184204,
        "learning_rate": 2.4308118081180815e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.5672,
        "grad_norm": 2.3208999633789062,
        "learning_rate": 2.4285055350553505e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.3774,
        "grad_norm": 1.285325288772583,
        "learning_rate": 2.42619926199262e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4403,
        "grad_norm": 2.3125078678131104,
        "learning_rate": 2.4238929889298894e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.3632,
        "grad_norm": 4.9272780418396,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4139,
        "grad_norm": 1.7029916048049927,
        "learning_rate": 2.4192804428044282e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4427,
        "grad_norm": 5.808594226837158,
        "learning_rate": 2.4169741697416977e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.4139,
        "grad_norm": 3.9281325340270996,
        "learning_rate": 2.4146678966789667e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4933,
        "grad_norm": 6.713074207305908,
        "learning_rate": 2.4123616236162365e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4597,
        "grad_norm": 2.992924690246582,
        "learning_rate": 2.4100553505535056e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.4063,
        "grad_norm": 2.790172815322876,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.459,
        "grad_norm": 2.807126998901367,
        "learning_rate": 2.4054428044280444e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.3518,
        "grad_norm": 2.3660669326782227,
        "learning_rate": 2.403136531365314e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.3553,
        "grad_norm": 2.759416341781616,
        "learning_rate": 2.4008302583025833e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.329,
        "grad_norm": 2.1295416355133057,
        "learning_rate": 2.3985239852398524e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.4703,
        "grad_norm": 6.053935527801514,
        "learning_rate": 2.3962177121771218e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.3978,
        "grad_norm": 7.003580570220947,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.3705,
        "grad_norm": 2.431114435195923,
        "learning_rate": 2.3916051660516606e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.3575,
        "grad_norm": 2.383537530899048,
        "learning_rate": 2.38929889298893e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4066,
        "grad_norm": 7.526409149169922,
        "learning_rate": 2.3869926199261995e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.3539,
        "grad_norm": 1.1894266605377197,
        "learning_rate": 2.3846863468634686e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.3633,
        "grad_norm": 2.6161835193634033,
        "learning_rate": 2.3823800738007383e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.4418,
        "grad_norm": 5.217974662780762,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.3935,
        "grad_norm": 1.7235647439956665,
        "learning_rate": 2.377767527675277e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.4353,
        "grad_norm": 1.9202758073806763,
        "learning_rate": 2.3754612546125462e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.43381211161613464,
        "eval_accuracy": 0.81089,
        "eval_precision": 0.76974,
        "eval_recall": 0.87805,
        "eval_f1": 0.82033,
        "eval_runtime": 18.121,
        "eval_samples_per_second": 59.82,
        "eval_steps_per_second": 3.753,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.3267,
        "grad_norm": 3.196779727935791,
        "learning_rate": 2.3731549815498157e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.3806,
        "grad_norm": 10.115506172180176,
        "learning_rate": 2.370848708487085e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.3486,
        "grad_norm": 1.5502530336380005,
        "learning_rate": 2.3685424354243542e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.3896,
        "grad_norm": 5.027420997619629,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.3463,
        "grad_norm": 1.4816287755966187,
        "learning_rate": 2.363929889298893e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.3961,
        "grad_norm": 2.227308988571167,
        "learning_rate": 2.3616236162361624e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.4147,
        "grad_norm": 12.802163124084473,
        "learning_rate": 2.359317343173432e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4482,
        "grad_norm": 3.7547974586486816,
        "learning_rate": 2.3570110701107013e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.4211,
        "grad_norm": 4.880298137664795,
        "learning_rate": 2.3547047970479704e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3672,
        "grad_norm": 2.8466827869415283,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.4593,
        "grad_norm": 4.268446445465088,
        "learning_rate": 2.3500922509225092e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.3452,
        "grad_norm": 8.530539512634277,
        "learning_rate": 2.347785977859779e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3612,
        "grad_norm": 2.3657894134521484,
        "learning_rate": 2.345479704797048e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.4204,
        "grad_norm": 3.359354257583618,
        "learning_rate": 2.3431734317343175e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.3987,
        "grad_norm": 3.9818661212921143,
        "learning_rate": 2.340867158671587e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.314,
        "grad_norm": 1.8513356447219849,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.2915,
        "grad_norm": 3.0898959636688232,
        "learning_rate": 2.3362546125461258e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.3792,
        "grad_norm": 2.4731483459472656,
        "learning_rate": 2.333948339483395e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.4492,
        "grad_norm": 4.574010848999023,
        "learning_rate": 2.3316420664206643e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4007,
        "grad_norm": 4.750035285949707,
        "learning_rate": 2.3293357933579337e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3172,
        "grad_norm": 5.5391316413879395,
        "learning_rate": 2.327029520295203e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4351,
        "grad_norm": 21.188472747802734,
        "learning_rate": 2.3247232472324722e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4107,
        "grad_norm": 2.4122097492218018,
        "learning_rate": 2.322416974169742e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.4377,
        "grad_norm": 1.7798659801483154,
        "learning_rate": 2.320110701107011e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.4171,
        "grad_norm": 2.9980528354644775,
        "learning_rate": 2.3178044280442808e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3578,
        "grad_norm": 5.936018943786621,
        "learning_rate": 2.31549815498155e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.3832,
        "grad_norm": 4.227477073669434,
        "learning_rate": 2.3131918819188193e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.42908284068107605,
        "eval_accuracy": 0.81734,
        "eval_precision": 0.77147,
        "eval_recall": 0.89306,
        "eval_f1": 0.82783,
        "eval_runtime": 18.123,
        "eval_samples_per_second": 59.813,
        "eval_steps_per_second": 3.752,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.3099,
        "grad_norm": 1.6537600755691528,
        "learning_rate": 2.3108856088560887e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3084,
        "grad_norm": 1.720187783241272,
        "learning_rate": 2.308579335793358e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.3321,
        "grad_norm": 2.6161434650421143,
        "learning_rate": 2.3062730627306276e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.388,
        "grad_norm": 18.844417572021484,
        "learning_rate": 2.3039667896678967e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.3937,
        "grad_norm": 7.683138847351074,
        "learning_rate": 2.301660516605166e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.3869,
        "grad_norm": 6.729772090911865,
        "learning_rate": 2.2993542435424355e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3514,
        "grad_norm": 2.4461584091186523,
        "learning_rate": 2.297047970479705e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3032,
        "grad_norm": 5.420146942138672,
        "learning_rate": 2.294741697416974e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.4082,
        "grad_norm": 2.0357906818389893,
        "learning_rate": 2.2924354243542438e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3735,
        "grad_norm": 8.334702491760254,
        "learning_rate": 2.290129151291513e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.3812,
        "grad_norm": 2.596074104309082,
        "learning_rate": 2.2878228782287826e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.2912,
        "grad_norm": 1.3730391263961792,
        "learning_rate": 2.2855166051660517e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.347,
        "grad_norm": 3.8998255729675293,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.3895,
        "grad_norm": 3.1618523597717285,
        "learning_rate": 2.2809040590405906e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.3598,
        "grad_norm": 2.9418699741363525,
        "learning_rate": 2.27859778597786e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.3296,
        "grad_norm": 3.3917829990386963,
        "learning_rate": 2.2762915129151294e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.3701,
        "grad_norm": 2.049071788787842,
        "learning_rate": 2.2739852398523985e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.2916,
        "grad_norm": 4.158455848693848,
        "learning_rate": 2.271678966789668e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.4497,
        "grad_norm": 3.7305281162261963,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.3531,
        "grad_norm": 2.5614445209503174,
        "learning_rate": 2.2670664206642068e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.3358,
        "grad_norm": 4.293964385986328,
        "learning_rate": 2.2647601476014762e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.3773,
        "grad_norm": 2.573988914489746,
        "learning_rate": 2.2624538745387456e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.313,
        "grad_norm": 3.1947720050811768,
        "learning_rate": 2.2601476014760147e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.4575,
        "grad_norm": 2.8640027046203613,
        "learning_rate": 2.2578413284132844e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.3245,
        "grad_norm": 3.692958354949951,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.4141,
        "grad_norm": 3.205589532852173,
        "learning_rate": 2.253228782287823e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.3428,
        "grad_norm": 2.018409013748169,
        "learning_rate": 2.2509225092250924e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.43565937876701355,
        "eval_accuracy": 0.81827,
        "eval_precision": 0.75926,
        "eval_recall": 0.92308,
        "eval_f1": 0.83319,
        "eval_runtime": 18.1009,
        "eval_samples_per_second": 59.887,
        "eval_steps_per_second": 3.757,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3139,
        "grad_norm": 4.292746543884277,
        "learning_rate": 2.2486162361623618e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.3546,
        "grad_norm": 2.2007946968078613,
        "learning_rate": 2.2463099630996312e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.273,
        "grad_norm": 9.709746360778809,
        "learning_rate": 2.2440036900369006e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.2904,
        "grad_norm": 1.1946238279342651,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.3584,
        "grad_norm": 4.678497791290283,
        "learning_rate": 2.239391143911439e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3847,
        "grad_norm": 4.004302501678467,
        "learning_rate": 2.2370848708487086e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3104,
        "grad_norm": 2.0113203525543213,
        "learning_rate": 2.234778597785978e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.4042,
        "grad_norm": 3.377446174621582,
        "learning_rate": 2.2324723247232474e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.3193,
        "grad_norm": 19.384153366088867,
        "learning_rate": 2.2301660516605165e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.3476,
        "grad_norm": 1.7182310819625854,
        "learning_rate": 2.2278597785977863e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.3668,
        "grad_norm": 2.070655584335327,
        "learning_rate": 2.2255535055350553e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.3924,
        "grad_norm": 6.569400787353516,
        "learning_rate": 2.2232472324723248e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.3833,
        "grad_norm": 1.538286566734314,
        "learning_rate": 2.2209409594095942e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.3486,
        "grad_norm": 13.637301445007324,
        "learning_rate": 2.2186346863468636e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3488,
        "grad_norm": 5.16305685043335,
        "learning_rate": 2.216328413284133e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.4188,
        "grad_norm": 1.5787545442581177,
        "learning_rate": 2.2140221402214025e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.3665,
        "grad_norm": 1.6516860723495483,
        "learning_rate": 2.2117158671586715e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.3898,
        "grad_norm": 2.7594797611236572,
        "learning_rate": 2.209409594095941e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3534,
        "grad_norm": 5.664053916931152,
        "learning_rate": 2.2071033210332104e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.3157,
        "grad_norm": 2.7781121730804443,
        "learning_rate": 2.2047970479704798e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.3712,
        "grad_norm": 8.050294876098633,
        "learning_rate": 2.2024907749077492e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.3072,
        "grad_norm": 2.0767993927001953,
        "learning_rate": 2.2001845018450183e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.3765,
        "grad_norm": 3.9549355506896973,
        "learning_rate": 2.197878228782288e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.3024,
        "grad_norm": 2.5204129219055176,
        "learning_rate": 2.195571955719557e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.3785,
        "grad_norm": 5.0810866355896,
        "learning_rate": 2.193265682656827e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.37,
        "grad_norm": 4.61469841003418,
        "learning_rate": 2.190959409594096e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.3204,
        "grad_norm": 1.9488781690597534,
        "learning_rate": 2.1886531365313654e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.42119672894477844,
        "eval_accuracy": 0.82472,
        "eval_precision": 0.7993,
        "eval_recall": 0.85929,
        "eval_f1": 0.82821,
        "eval_runtime": 18.0848,
        "eval_samples_per_second": 59.94,
        "eval_steps_per_second": 3.76,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.2745,
        "grad_norm": 1.4869651794433594,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.3565,
        "grad_norm": 3.4423458576202393,
        "learning_rate": 2.1840405904059043e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.2971,
        "grad_norm": 2.741154670715332,
        "learning_rate": 2.1817343173431734e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.3214,
        "grad_norm": 2.127453565597534,
        "learning_rate": 2.1794280442804428e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.3236,
        "grad_norm": 3.108323335647583,
        "learning_rate": 2.1771217712177122e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.2981,
        "grad_norm": 4.712710857391357,
        "learning_rate": 2.1748154981549816e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.3506,
        "grad_norm": 7.126043796539307,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.2614,
        "grad_norm": 2.715193748474121,
        "learning_rate": 2.17020295202952e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.4456,
        "grad_norm": 3.033546209335327,
        "learning_rate": 2.16789667896679e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.32,
        "grad_norm": 1.3624540567398071,
        "learning_rate": 2.165590405904059e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.2762,
        "grad_norm": 7.825794219970703,
        "learning_rate": 2.1632841328413287e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.267,
        "grad_norm": 2.894383192062378,
        "learning_rate": 2.160977859778598e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.333,
        "grad_norm": 1.7271238565444946,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.379,
        "grad_norm": 1.1081209182739258,
        "learning_rate": 2.1563653136531367e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.357,
        "grad_norm": 6.325575351715088,
        "learning_rate": 2.154059040590406e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.3243,
        "grad_norm": 4.61991548538208,
        "learning_rate": 2.1517527675276755e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.2972,
        "grad_norm": 5.307252883911133,
        "learning_rate": 2.149446494464945e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.3052,
        "grad_norm": 3.3848230838775635,
        "learning_rate": 2.147140221402214e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.3027,
        "grad_norm": 1.8141535520553589,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.3485,
        "grad_norm": 3.0495173931121826,
        "learning_rate": 2.142527675276753e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.399,
        "grad_norm": 3.2287938594818115,
        "learning_rate": 2.140221402214022e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.3362,
        "grad_norm": 1.594929575920105,
        "learning_rate": 2.1379151291512917e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.31,
        "grad_norm": 1.2474218606948853,
        "learning_rate": 2.1356088560885608e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.3563,
        "grad_norm": 1.6583703756332397,
        "learning_rate": 2.1333025830258306e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.3418,
        "grad_norm": 2.422987937927246,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.346,
        "grad_norm": 3.193186044692993,
        "learning_rate": 2.128690036900369e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.3798,
        "grad_norm": 2.704258441925049,
        "learning_rate": 2.1263837638376385e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.41597825288772583,
        "eval_accuracy": 0.83948,
        "eval_precision": 0.78812,
        "eval_recall": 0.9212,
        "eval_f1": 0.84948,
        "eval_runtime": 18.0711,
        "eval_samples_per_second": 59.985,
        "eval_steps_per_second": 3.763,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.3243,
        "grad_norm": 2.0065438747406006,
        "learning_rate": 2.124077490774908e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.2776,
        "grad_norm": 2.3041744232177734,
        "learning_rate": 2.1217712177121773e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.3687,
        "grad_norm": 1.0235536098480225,
        "learning_rate": 2.1194649446494468e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.4343,
        "grad_norm": 10.798041343688965,
        "learning_rate": 2.117158671586716e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.3904,
        "grad_norm": 4.703547954559326,
        "learning_rate": 2.1148523985239853e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.3194,
        "grad_norm": 2.1656694412231445,
        "learning_rate": 2.1125461254612547e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.2945,
        "grad_norm": 12.31178092956543,
        "learning_rate": 2.110239852398524e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.3242,
        "grad_norm": 1.0168616771697998,
        "learning_rate": 2.1079335793357935e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.3583,
        "grad_norm": 1.9965622425079346,
        "learning_rate": 2.1056273062730626e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.2776,
        "grad_norm": 2.8672289848327637,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.2667,
        "grad_norm": 1.9537322521209717,
        "learning_rate": 2.1010147601476015e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.2687,
        "grad_norm": 1.1646836996078491,
        "learning_rate": 2.098708487084871e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.3789,
        "grad_norm": 10.582146644592285,
        "learning_rate": 2.0964022140221403e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.3028,
        "grad_norm": 1.4275462627410889,
        "learning_rate": 2.0940959409594097e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3746,
        "grad_norm": 6.129005432128906,
        "learning_rate": 2.091789667896679e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.2515,
        "grad_norm": 1.75522780418396,
        "learning_rate": 2.0894833948339486e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.4028,
        "grad_norm": 2.006802558898926,
        "learning_rate": 2.0871771217712177e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.3222,
        "grad_norm": 1.458064317703247,
        "learning_rate": 2.084870848708487e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.2598,
        "grad_norm": 2.6824092864990234,
        "learning_rate": 2.0825645756457565e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.221,
        "grad_norm": 1.9447946548461914,
        "learning_rate": 2.080258302583026e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3114,
        "grad_norm": 1.7925390005111694,
        "learning_rate": 2.0779520295202954e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3415,
        "grad_norm": 3.491144895553589,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.422,
        "grad_norm": 2.7844808101654053,
        "learning_rate": 2.0733394833948342e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.323,
        "grad_norm": 3.426621198654175,
        "learning_rate": 2.0710332103321033e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.2615,
        "grad_norm": 1.4982779026031494,
        "learning_rate": 2.0687269372693727e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.3272,
        "grad_norm": 0.9417532682418823,
        "learning_rate": 2.066420664206642e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3507,
        "grad_norm": 6.334029197692871,
        "learning_rate": 2.0641143911439116e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.43567970395088196,
        "eval_accuracy": 0.84502,
        "eval_precision": 0.78922,
        "eval_recall": 0.93433,
        "eval_f1": 0.85567,
        "eval_runtime": 18.0813,
        "eval_samples_per_second": 59.952,
        "eval_steps_per_second": 3.761,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.2572,
        "grad_norm": 0.9963981509208679,
        "learning_rate": 2.061808118081181e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.333,
        "grad_norm": 3.7033188343048096,
        "learning_rate": 2.0595018450184504e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3871,
        "grad_norm": 13.2657470703125,
        "learning_rate": 2.0571955719557195e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.2739,
        "grad_norm": 1.8227876424789429,
        "learning_rate": 2.0548892988929893e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.2511,
        "grad_norm": 1.912918210029602,
        "learning_rate": 2.0525830258302583e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3536,
        "grad_norm": 4.9713897705078125,
        "learning_rate": 2.0502767527675278e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.3105,
        "grad_norm": 3.2494254112243652,
        "learning_rate": 2.0479704797047972e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.3385,
        "grad_norm": 8.046112060546875,
        "learning_rate": 2.0456642066420663e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.3188,
        "grad_norm": 2.4601004123687744,
        "learning_rate": 2.043357933579336e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.3034,
        "grad_norm": 2.4682233333587646,
        "learning_rate": 2.041051660516605e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.2588,
        "grad_norm": 28.723970413208008,
        "learning_rate": 2.0387453874538745e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3616,
        "grad_norm": 5.598277568817139,
        "learning_rate": 2.036439114391144e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.281,
        "grad_norm": 2.8078019618988037,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.3147,
        "grad_norm": 2.9221482276916504,
        "learning_rate": 2.0318265682656828e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.3427,
        "grad_norm": 20.78443717956543,
        "learning_rate": 2.0295202952029522e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.318,
        "grad_norm": 7.644237995147705,
        "learning_rate": 2.0272140221402213e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.3092,
        "grad_norm": 13.674548149108887,
        "learning_rate": 2.024907749077491e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.2311,
        "grad_norm": 2.4999897480010986,
        "learning_rate": 2.02260147601476e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.446,
        "grad_norm": 6.378366947174072,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.2534,
        "grad_norm": 10.979512214660645,
        "learning_rate": 2.017988929889299e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.2138,
        "grad_norm": 1.0708839893341064,
        "learning_rate": 2.0156826568265684e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.3374,
        "grad_norm": 25.077465057373047,
        "learning_rate": 2.013376383763838e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.3828,
        "grad_norm": 6.086095333099365,
        "learning_rate": 2.011070110701107e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.2559,
        "grad_norm": 14.430252075195312,
        "learning_rate": 2.0087638376383767e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.3586,
        "grad_norm": 6.289900302886963,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.3232,
        "grad_norm": 3.1196460723876953,
        "learning_rate": 2.0041512915129152e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.3614,
        "grad_norm": 3.3374221324920654,
        "learning_rate": 2.0018450184501846e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.4232768416404724,
        "eval_accuracy": 0.83856,
        "eval_precision": 0.79058,
        "eval_recall": 0.9137,
        "eval_f1": 0.84769,
        "eval_runtime": 18.0784,
        "eval_samples_per_second": 59.961,
        "eval_steps_per_second": 3.761,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.2388,
        "grad_norm": 1.3849490880966187,
        "learning_rate": 1.999538745387454e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.2904,
        "grad_norm": 1.810593843460083,
        "learning_rate": 1.997232472324723e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.2745,
        "grad_norm": 2.5130372047424316,
        "learning_rate": 1.994926199261993e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.2515,
        "grad_norm": 5.547204971313477,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.3585,
        "grad_norm": 6.544524669647217,
        "learning_rate": 1.9903136531365314e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.3493,
        "grad_norm": 3.6213927268981934,
        "learning_rate": 1.9880073800738008e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.2743,
        "grad_norm": 2.0400593280792236,
        "learning_rate": 1.9857011070110702e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.3212,
        "grad_norm": 2.9995176792144775,
        "learning_rate": 1.9833948339483397e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.3855,
        "grad_norm": 3.1172022819519043,
        "learning_rate": 1.9810885608856088e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.3807,
        "grad_norm": 6.275179862976074,
        "learning_rate": 1.9787822878228785e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.3249,
        "grad_norm": 2.0468194484710693,
        "learning_rate": 1.9764760147601476e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.2427,
        "grad_norm": 4.035081386566162,
        "learning_rate": 1.974169741697417e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.2942,
        "grad_norm": 2.8244574069976807,
        "learning_rate": 1.9718634686346864e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.2966,
        "grad_norm": 3.8914620876312256,
        "learning_rate": 1.969557195571956e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.3487,
        "grad_norm": 0.9609279632568359,
        "learning_rate": 1.9672509225092253e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.3341,
        "grad_norm": 4.735385417938232,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.2841,
        "grad_norm": 46.81296157836914,
        "learning_rate": 1.9626383763837638e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.2511,
        "grad_norm": 7.762409687042236,
        "learning_rate": 1.9603321033210336e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.247,
        "grad_norm": 6.988099098205566,
        "learning_rate": 1.9580258302583026e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.409,
        "grad_norm": 37.665245056152344,
        "learning_rate": 1.955719557195572e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.2445,
        "grad_norm": 1.1619418859481812,
        "learning_rate": 1.9534132841328415e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.2506,
        "grad_norm": 1.5682567358016968,
        "learning_rate": 1.9511070110701106e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.2595,
        "grad_norm": 5.508168697357178,
        "learning_rate": 1.9488007380073803e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.3065,
        "grad_norm": 9.492473602294922,
        "learning_rate": 1.9464944649446494e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.3118,
        "grad_norm": 3.2266361713409424,
        "learning_rate": 1.944188191881919e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.3026,
        "grad_norm": 9.863003730773926,
        "learning_rate": 1.9418819188191883e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3545,
        "grad_norm": 5.241524696350098,
        "learning_rate": 1.9395756457564577e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.4116925597190857,
        "eval_accuracy": 0.83395,
        "eval_precision": 0.79174,
        "eval_recall": 0.89869,
        "eval_f1": 0.84183,
        "eval_runtime": 18.0769,
        "eval_samples_per_second": 59.966,
        "eval_steps_per_second": 3.762,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.2861,
        "grad_norm": 3.8828694820404053,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.2876,
        "grad_norm": 1.6772801876068115,
        "learning_rate": 1.9349630996309965e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3112,
        "grad_norm": 31.880311965942383,
        "learning_rate": 1.9326568265682656e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.364,
        "grad_norm": 5.184223651885986,
        "learning_rate": 1.9303505535055354e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.3379,
        "grad_norm": 2.368055820465088,
        "learning_rate": 1.9280442804428045e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.2896,
        "grad_norm": 1.3635172843933105,
        "learning_rate": 1.925738007380074e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3034,
        "grad_norm": 9.958112716674805,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.2396,
        "grad_norm": 2.611365556716919,
        "learning_rate": 1.9211254612546127e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.2521,
        "grad_norm": 1.672106385231018,
        "learning_rate": 1.918819188191882e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.252,
        "grad_norm": 2.982715606689453,
        "learning_rate": 1.9165129151291512e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.2465,
        "grad_norm": 2.5265393257141113,
        "learning_rate": 1.9142066420664207e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.3122,
        "grad_norm": 4.6434783935546875,
        "learning_rate": 1.91190036900369e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.2878,
        "grad_norm": 1.9119579792022705,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.3433,
        "grad_norm": 3.191505193710327,
        "learning_rate": 1.907287822878229e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.1636,
        "grad_norm": 1.4325776100158691,
        "learning_rate": 1.9049815498154984e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.3747,
        "grad_norm": 6.066826820373535,
        "learning_rate": 1.9026752767527674e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.2853,
        "grad_norm": 6.312951564788818,
        "learning_rate": 1.9003690036900372e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.4819,
        "grad_norm": 3.581441640853882,
        "learning_rate": 1.8980627306273063e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.3145,
        "grad_norm": 2.1486995220184326,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.3002,
        "grad_norm": 5.798515796661377,
        "learning_rate": 1.893450184501845e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.2778,
        "grad_norm": 11.894499778747559,
        "learning_rate": 1.8911439114391146e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.3014,
        "grad_norm": 8.876062393188477,
        "learning_rate": 1.888837638376384e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3279,
        "grad_norm": 5.969273090362549,
        "learning_rate": 1.886531365313653e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.331,
        "grad_norm": 3.7666451930999756,
        "learning_rate": 1.8842250922509225e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.2421,
        "grad_norm": 3.3058578968048096,
        "learning_rate": 1.881918819188192e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.2648,
        "grad_norm": 4.767800807952881,
        "learning_rate": 1.8796125461254613e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.2429,
        "grad_norm": 1.599360466003418,
        "learning_rate": 1.8773062730627308e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.303,
        "grad_norm": 4.60864782333374,
        "learning_rate": 1.8750000000000002e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.4478834569454193,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.79487,
        "eval_recall": 0.93058,
        "eval_f1": 0.85739,
        "eval_runtime": 18.0501,
        "eval_samples_per_second": 60.055,
        "eval_steps_per_second": 3.767,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.3083,
        "grad_norm": 2.4461987018585205,
        "learning_rate": 1.8726937269372693e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.3078,
        "grad_norm": 3.734017848968506,
        "learning_rate": 1.870387453874539e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.2815,
        "grad_norm": 3.757766008377075,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.379,
        "grad_norm": 1.2147901058197021,
        "learning_rate": 1.865774907749078e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3164,
        "grad_norm": 3.2691073417663574,
        "learning_rate": 1.863468634686347e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.2,
        "grad_norm": 2.383479118347168,
        "learning_rate": 1.8611623616236164e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.3415,
        "grad_norm": 5.9024577140808105,
        "learning_rate": 1.8588560885608858e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.3125,
        "grad_norm": 28.36981964111328,
        "learning_rate": 1.856549815498155e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.2251,
        "grad_norm": 4.650977611541748,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3565,
        "grad_norm": 1.8783996105194092,
        "learning_rate": 1.8519372693726937e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.2508,
        "grad_norm": 2.8804609775543213,
        "learning_rate": 1.849630996309963e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.2451,
        "grad_norm": 3.75576114654541,
        "learning_rate": 1.8473247232472326e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.2795,
        "grad_norm": 5.961848258972168,
        "learning_rate": 1.845018450184502e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.1908,
        "grad_norm": 5.551273822784424,
        "learning_rate": 1.842712177121771e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.2934,
        "grad_norm": 5.9765706062316895,
        "learning_rate": 1.840405904059041e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.189,
        "grad_norm": 11.937254905700684,
        "learning_rate": 1.83809963099631e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3175,
        "grad_norm": 1.633256196975708,
        "learning_rate": 1.8357933579335797e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.2403,
        "grad_norm": 28.76543426513672,
        "learning_rate": 1.8334870848708488e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.3141,
        "grad_norm": 23.958650588989258,
        "learning_rate": 1.8311808118081182e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.405,
        "grad_norm": 3.9539685249328613,
        "learning_rate": 1.8288745387453876e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.3094,
        "grad_norm": 6.0890326499938965,
        "learning_rate": 1.826568265682657e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.2156,
        "grad_norm": 1.5264168977737427,
        "learning_rate": 1.8242619926199265e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.2711,
        "grad_norm": 1.900853157043457,
        "learning_rate": 1.8219557195571955e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.382,
        "grad_norm": 5.5351338386535645,
        "learning_rate": 1.819649446494465e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.3284,
        "grad_norm": 6.304195404052734,
        "learning_rate": 1.8173431734317344e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.2658,
        "grad_norm": 5.040297031402588,
        "learning_rate": 1.8150369003690038e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.3098,
        "grad_norm": 5.13137149810791,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.4376469552516937,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.79582,
        "eval_recall": 0.92871,
        "eval_f1": 0.85714,
        "eval_runtime": 18.0816,
        "eval_samples_per_second": 59.95,
        "eval_steps_per_second": 3.761,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.2491,
        "grad_norm": 1.575957179069519,
        "learning_rate": 1.8104243542435427e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.3382,
        "grad_norm": 2.15535306930542,
        "learning_rate": 1.8081180811808117e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.2172,
        "grad_norm": 2.1586766242980957,
        "learning_rate": 1.8058118081180815e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.3318,
        "grad_norm": 4.405935287475586,
        "learning_rate": 1.8035055350553506e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.3459,
        "grad_norm": 3.191348075866699,
        "learning_rate": 1.80119926199262e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.2781,
        "grad_norm": 9.150644302368164,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.2839,
        "grad_norm": 17.05361557006836,
        "learning_rate": 1.796586715867159e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.3031,
        "grad_norm": 1.8156670331954956,
        "learning_rate": 1.7942804428044283e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.2417,
        "grad_norm": 1.38699471950531,
        "learning_rate": 1.7919741697416974e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.1787,
        "grad_norm": 1.4003267288208008,
        "learning_rate": 1.7896678966789668e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.3117,
        "grad_norm": 4.634769439697266,
        "learning_rate": 1.7873616236162362e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.3839,
        "grad_norm": 8.654860496520996,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.2486,
        "grad_norm": 1.112706184387207,
        "learning_rate": 1.7827490774907747e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.2799,
        "grad_norm": 2.2003259658813477,
        "learning_rate": 1.7804428044280445e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.257,
        "grad_norm": 0.9992181658744812,
        "learning_rate": 1.7781365313653136e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.1917,
        "grad_norm": 3.7227485179901123,
        "learning_rate": 1.7758302583025833e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.2631,
        "grad_norm": 3.574535369873047,
        "learning_rate": 1.7735239852398524e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.242,
        "grad_norm": 4.300841808319092,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.3614,
        "grad_norm": 7.542741775512695,
        "learning_rate": 1.7689114391143913e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.3924,
        "grad_norm": 1.5768883228302002,
        "learning_rate": 1.7666051660516607e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2685,
        "grad_norm": 1.4001975059509277,
        "learning_rate": 1.76429889298893e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.2581,
        "grad_norm": 4.024591445922852,
        "learning_rate": 1.7619926199261992e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.2622,
        "grad_norm": 2.73772931098938,
        "learning_rate": 1.7596863468634686e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.2676,
        "grad_norm": 4.241899490356445,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.2591,
        "grad_norm": 4.848814487457275,
        "learning_rate": 1.7550738007380075e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2812,
        "grad_norm": 24.2233829498291,
        "learning_rate": 1.752767527675277e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.2773,
        "grad_norm": 2.322225332260132,
        "learning_rate": 1.7504612546125463e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.4884739816188812,
        "eval_accuracy": 0.84133,
        "eval_precision": 0.78696,
        "eval_recall": 0.92871,
        "eval_f1": 0.85198,
        "eval_runtime": 18.0724,
        "eval_samples_per_second": 59.981,
        "eval_steps_per_second": 3.763,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.3113,
        "grad_norm": 1.7131630182266235,
        "learning_rate": 1.7481549815498154e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.2789,
        "grad_norm": 5.218878746032715,
        "learning_rate": 1.745848708487085e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.2566,
        "grad_norm": 8.292996406555176,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.312,
        "grad_norm": 6.565888404846191,
        "learning_rate": 1.7412361623616237e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2385,
        "grad_norm": 15.639573097229004,
        "learning_rate": 1.738929889298893e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.1956,
        "grad_norm": 6.079824447631836,
        "learning_rate": 1.7366236162361625e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.2831,
        "grad_norm": 1.3405340909957886,
        "learning_rate": 1.734317343173432e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.3019,
        "grad_norm": 17.423675537109375,
        "learning_rate": 1.7320110701107013e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.193,
        "grad_norm": 3.393156051635742,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.263,
        "grad_norm": 6.590600490570068,
        "learning_rate": 1.72739852398524e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.3077,
        "grad_norm": 1.1204147338867188,
        "learning_rate": 1.7250922509225093e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.311,
        "grad_norm": 5.641719818115234,
        "learning_rate": 1.7227859778597787e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.2611,
        "grad_norm": 2.6288132667541504,
        "learning_rate": 1.720479704797048e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.2674,
        "grad_norm": 7.200516700744629,
        "learning_rate": 1.7181734317343172e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.2852,
        "grad_norm": 1.210806965827942,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.2412,
        "grad_norm": 19.677417755126953,
        "learning_rate": 1.713560885608856e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.1998,
        "grad_norm": 4.946193695068359,
        "learning_rate": 1.7112546125461258e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.2589,
        "grad_norm": 23.02625846862793,
        "learning_rate": 1.708948339483395e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.2142,
        "grad_norm": 1.5244096517562866,
        "learning_rate": 1.7066420664206643e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.2687,
        "grad_norm": 0.8069146275520325,
        "learning_rate": 1.7043357933579337e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.3585,
        "grad_norm": 3.8008949756622314,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.3545,
        "grad_norm": 5.695476055145264,
        "learning_rate": 1.6997232472324722e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.282,
        "grad_norm": 2.758309841156006,
        "learning_rate": 1.6974169741697417e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.3098,
        "grad_norm": 2.8524508476257324,
        "learning_rate": 1.695110701107011e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.2769,
        "grad_norm": 6.118732452392578,
        "learning_rate": 1.6928044280442805e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.3137,
        "grad_norm": 14.366291999816895,
        "learning_rate": 1.69049815498155e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.199,
        "grad_norm": 1.0707250833511353,
        "learning_rate": 1.688191881918819e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.49724552035331726,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.79582,
        "eval_recall": 0.92871,
        "eval_f1": 0.85714,
        "eval_runtime": 18.0793,
        "eval_samples_per_second": 59.958,
        "eval_steps_per_second": 3.761,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.3048,
        "grad_norm": 36.52272415161133,
        "learning_rate": 1.6858856088560888e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.2831,
        "grad_norm": 1.3683130741119385,
        "learning_rate": 1.683579335793358e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.2692,
        "grad_norm": 3.5029866695404053,
        "learning_rate": 1.6812730627306276e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.206,
        "grad_norm": 0.522794783115387,
        "learning_rate": 1.6789667896678967e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.256,
        "grad_norm": 8.874603271484375,
        "learning_rate": 1.676660516605166e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.2678,
        "grad_norm": 2.3728878498077393,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.3346,
        "grad_norm": 4.307319641113281,
        "learning_rate": 1.672047970479705e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.2708,
        "grad_norm": 1.8647122383117676,
        "learning_rate": 1.669741697416974e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.1704,
        "grad_norm": 8.711894035339355,
        "learning_rate": 1.6674354243542435e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.3431,
        "grad_norm": 9.710232734680176,
        "learning_rate": 1.665129151291513e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.2528,
        "grad_norm": 1.8503012657165527,
        "learning_rate": 1.6628228782287823e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.1716,
        "grad_norm": 2.2900912761688232,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.2794,
        "grad_norm": 2.4411821365356445,
        "learning_rate": 1.658210332103321e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.3394,
        "grad_norm": 18.297218322753906,
        "learning_rate": 1.6559040590405906e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.2216,
        "grad_norm": 5.077200412750244,
        "learning_rate": 1.6535977859778597e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2384,
        "grad_norm": 2.450960159301758,
        "learning_rate": 1.6512915129151295e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2407,
        "grad_norm": 3.4575304985046387,
        "learning_rate": 1.6489852398523985e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.3648,
        "grad_norm": 1.1575162410736084,
        "learning_rate": 1.646678966789668e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.24,
        "grad_norm": 4.161779880523682,
        "learning_rate": 1.6443726937269374e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.2558,
        "grad_norm": 6.97456169128418,
        "learning_rate": 1.6420664206642068e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.3413,
        "grad_norm": 1.229746699333191,
        "learning_rate": 1.6397601476014762e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.2388,
        "grad_norm": 5.868166446685791,
        "learning_rate": 1.6374538745387457e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.1908,
        "grad_norm": 9.709046363830566,
        "learning_rate": 1.6351476014760147e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.2854,
        "grad_norm": 4.869846820831299,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.2704,
        "grad_norm": 4.056964874267578,
        "learning_rate": 1.6305350553505536e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.4005,
        "grad_norm": 18.02484703063965,
        "learning_rate": 1.6282287822878227e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.3548,
        "grad_norm": 9.921513557434082,
        "learning_rate": 1.6259225092250924e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.5198307037353516,
        "eval_accuracy": 0.84686,
        "eval_precision": 0.79645,
        "eval_recall": 0.92495,
        "eval_f1": 0.8559,
        "eval_runtime": 18.1219,
        "eval_samples_per_second": 59.817,
        "eval_steps_per_second": 3.752,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.2012,
        "grad_norm": 1.887507677078247,
        "learning_rate": 1.6236162361623615e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.2578,
        "grad_norm": 4.380853652954102,
        "learning_rate": 1.6213099630996313e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.2114,
        "grad_norm": 0.723862886428833,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.3465,
        "grad_norm": 2.7438151836395264,
        "learning_rate": 1.6166974169741698e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.2279,
        "grad_norm": 1.1997509002685547,
        "learning_rate": 1.6143911439114392e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.2095,
        "grad_norm": 39.75096130371094,
        "learning_rate": 1.6120848708487086e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.2867,
        "grad_norm": 10.737540245056152,
        "learning_rate": 1.609778597785978e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.2561,
        "grad_norm": 2.9195291996002197,
        "learning_rate": 1.6074723247232475e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.3008,
        "grad_norm": 6.619718551635742,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.2585,
        "grad_norm": 7.452291011810303,
        "learning_rate": 1.602859778597786e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.2711,
        "grad_norm": 6.2129669189453125,
        "learning_rate": 1.6005535055350554e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.2798,
        "grad_norm": 7.670663833618164,
        "learning_rate": 1.5982472324723248e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.2618,
        "grad_norm": 1.3709256649017334,
        "learning_rate": 1.5959409594095942e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.2627,
        "grad_norm": 4.956383228302002,
        "learning_rate": 1.5936346863468633e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.2705,
        "grad_norm": 1.1123857498168945,
        "learning_rate": 1.591328413284133e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.2389,
        "grad_norm": 25.448822021484375,
        "learning_rate": 1.5890221402214022e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.2354,
        "grad_norm": 3.7110235691070557,
        "learning_rate": 1.5867158671586716e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.2221,
        "grad_norm": 1.8588234186172485,
        "learning_rate": 1.584409594095941e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.2865,
        "grad_norm": 1.64143705368042,
        "learning_rate": 1.5821033210332104e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.1878,
        "grad_norm": 17.325410842895508,
        "learning_rate": 1.57979704797048e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.2838,
        "grad_norm": 2.5790159702301025,
        "learning_rate": 1.5774907749077493e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.2242,
        "grad_norm": 2.562577962875366,
        "learning_rate": 1.5751845018450184e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.1989,
        "grad_norm": 1.7262424230575562,
        "learning_rate": 1.5728782287822878e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.2701,
        "grad_norm": 7.45124626159668,
        "learning_rate": 1.5705719557195572e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.231,
        "grad_norm": 12.962638854980469,
        "learning_rate": 1.5682656826568266e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.2989,
        "grad_norm": 14.996036529541016,
        "learning_rate": 1.565959409594096e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.1936,
        "grad_norm": 2.091407537460327,
        "learning_rate": 1.563653136531365e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.5349869728088379,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.82056,
        "eval_recall": 0.88368,
        "eval_f1": 0.85095,
        "eval_runtime": 18.1726,
        "eval_samples_per_second": 59.65,
        "eval_steps_per_second": 3.742,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.2377,
        "grad_norm": 13.702997207641602,
        "learning_rate": 1.561346863468635e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.1632,
        "grad_norm": 2.2672276496887207,
        "learning_rate": 1.559040590405904e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.2885,
        "grad_norm": 0.5855152010917664,
        "learning_rate": 1.5567343173431734e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.1895,
        "grad_norm": 11.763168334960938,
        "learning_rate": 1.554428044280443e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.298,
        "grad_norm": 2.090397596359253,
        "learning_rate": 1.5521217712177123e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.2644,
        "grad_norm": 11.968043327331543,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.3462,
        "grad_norm": 8.9714937210083,
        "learning_rate": 1.547509225092251e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.3014,
        "grad_norm": 23.464689254760742,
        "learning_rate": 1.5452029520295202e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.2361,
        "grad_norm": 8.97081470489502,
        "learning_rate": 1.54289667896679e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.2875,
        "grad_norm": 1.1334232091903687,
        "learning_rate": 1.540590405904059e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.2464,
        "grad_norm": 6.682180881500244,
        "learning_rate": 1.5382841328413285e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.2839,
        "grad_norm": 8.48630142211914,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.1966,
        "grad_norm": 15.71653938293457,
        "learning_rate": 1.533671586715867e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.2413,
        "grad_norm": 7.976804256439209,
        "learning_rate": 1.5313653136531367e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.2326,
        "grad_norm": 3.1024608612060547,
        "learning_rate": 1.5290590405904058e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.2733,
        "grad_norm": 1.2804654836654663,
        "learning_rate": 1.5267527675276756e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.2796,
        "grad_norm": 1.9047112464904785,
        "learning_rate": 1.5244464944649448e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2252,
        "grad_norm": 12.133282661437988,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.1776,
        "grad_norm": 12.341205596923828,
        "learning_rate": 1.5198339483394835e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.2325,
        "grad_norm": 1.7216815948486328,
        "learning_rate": 1.5175276752767528e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.2921,
        "grad_norm": 2.080019474029541,
        "learning_rate": 1.515221402214022e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.1738,
        "grad_norm": 1.386061191558838,
        "learning_rate": 1.5129151291512916e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.2481,
        "grad_norm": 7.989957809448242,
        "learning_rate": 1.5106088560885609e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.2654,
        "grad_norm": 2.5546884536743164,
        "learning_rate": 1.5083025830258305e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.2188,
        "grad_norm": 4.303913593292236,
        "learning_rate": 1.5059963099630997e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.2691,
        "grad_norm": 3.906287670135498,
        "learning_rate": 1.503690036900369e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.2469,
        "grad_norm": 3.275808811187744,
        "learning_rate": 1.5013837638376386e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.5368486642837524,
        "eval_accuracy": 0.8441,
        "eval_precision": 0.79545,
        "eval_recall": 0.91932,
        "eval_f1": 0.85292,
        "eval_runtime": 18.12,
        "eval_samples_per_second": 59.823,
        "eval_steps_per_second": 3.753,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.2414,
        "grad_norm": 2.267850637435913,
        "learning_rate": 1.4990774907749078e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.294,
        "grad_norm": 2.9133102893829346,
        "learning_rate": 1.4967712177121774e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.1723,
        "grad_norm": 7.974022388458252,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.144,
        "grad_norm": 0.8623368144035339,
        "learning_rate": 1.4921586715867159e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.3391,
        "grad_norm": 5.588095188140869,
        "learning_rate": 1.4898523985239853e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.2548,
        "grad_norm": 5.151693820953369,
        "learning_rate": 1.4875461254612546e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.2468,
        "grad_norm": 3.4766347408294678,
        "learning_rate": 1.485239852398524e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.199,
        "grad_norm": 1.2498624324798584,
        "learning_rate": 1.4829335793357934e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.2541,
        "grad_norm": 1.9234800338745117,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.1812,
        "grad_norm": 4.3066558837890625,
        "learning_rate": 1.4783210332103323e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.2729,
        "grad_norm": 1.7056591510772705,
        "learning_rate": 1.4760147601476015e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.2454,
        "grad_norm": 1.6233553886413574,
        "learning_rate": 1.4737084870848708e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.2511,
        "grad_norm": 3.292710065841675,
        "learning_rate": 1.4714022140221404e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.2793,
        "grad_norm": 1.3572028875350952,
        "learning_rate": 1.4690959409594096e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.2105,
        "grad_norm": 9.319679260253906,
        "learning_rate": 1.4667896678966792e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.1747,
        "grad_norm": 1.3556476831436157,
        "learning_rate": 1.4644833948339485e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.2933,
        "grad_norm": 0.9978235960006714,
        "learning_rate": 1.4621771217712177e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.2118,
        "grad_norm": 9.199002265930176,
        "learning_rate": 1.4598708487084871e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.2634,
        "grad_norm": 1.641216516494751,
        "learning_rate": 1.4575645756457566e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.2845,
        "grad_norm": 17.937406539916992,
        "learning_rate": 1.455258302583026e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.1577,
        "grad_norm": 1.0307462215423584,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.2961,
        "grad_norm": 15.619392395019531,
        "learning_rate": 1.4506457564575645e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.2755,
        "grad_norm": 3.0324490070343018,
        "learning_rate": 1.4483394833948341e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.1613,
        "grad_norm": 1.0287067890167236,
        "learning_rate": 1.4460332103321033e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.2796,
        "grad_norm": 2.509634256362915,
        "learning_rate": 1.4437269372693726e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.2431,
        "grad_norm": 1.2452633380889893,
        "learning_rate": 1.4414206642066422e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.2562,
        "grad_norm": 0.9862843155860901,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.5642119646072388,
        "eval_accuracy": 0.8441,
        "eval_precision": 0.80033,
        "eval_recall": 0.90994,
        "eval_f1": 0.85162,
        "eval_runtime": 18.1269,
        "eval_samples_per_second": 59.801,
        "eval_steps_per_second": 3.751,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.2442,
        "grad_norm": 3.0631842613220215,
        "learning_rate": 1.436808118081181e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.1654,
        "grad_norm": 3.7223827838897705,
        "learning_rate": 1.4345018450184503e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.1686,
        "grad_norm": 7.002819061279297,
        "learning_rate": 1.4321955719557195e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.1534,
        "grad_norm": 3.3874120712280273,
        "learning_rate": 1.4298892988929891e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.2364,
        "grad_norm": 3.5993282794952393,
        "learning_rate": 1.4275830258302584e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.196,
        "grad_norm": 1.5156723260879517,
        "learning_rate": 1.4252767527675278e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.24,
        "grad_norm": 9.303451538085938,
        "learning_rate": 1.422970479704797e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.1568,
        "grad_norm": 2.2328672409057617,
        "learning_rate": 1.4206642066420663e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2764,
        "grad_norm": 24.384544372558594,
        "learning_rate": 1.4183579335793359e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.2377,
        "grad_norm": 5.33380126953125,
        "learning_rate": 1.4160516605166052e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.3004,
        "grad_norm": 25.9704532623291,
        "learning_rate": 1.4137453874538744e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.2366,
        "grad_norm": 24.18107032775879,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.2425,
        "grad_norm": 37.34393310546875,
        "learning_rate": 1.4091328413284133e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.2942,
        "grad_norm": 2.8157052993774414,
        "learning_rate": 1.4068265682656829e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.2368,
        "grad_norm": 24.79387855529785,
        "learning_rate": 1.4045202952029521e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.1905,
        "grad_norm": 3.0887391567230225,
        "learning_rate": 1.4022140221402214e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.3002,
        "grad_norm": 10.660515785217285,
        "learning_rate": 1.399907749077491e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.228,
        "grad_norm": 4.070024490356445,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.2408,
        "grad_norm": 14.457047462463379,
        "learning_rate": 1.3952952029520296e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.3042,
        "grad_norm": 1.6887601613998413,
        "learning_rate": 1.3929889298892989e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.2842,
        "grad_norm": 14.789529800415039,
        "learning_rate": 1.3906826568265683e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.2165,
        "grad_norm": 3.203918695449829,
        "learning_rate": 1.3883763837638377e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.1924,
        "grad_norm": 2.961996555328369,
        "learning_rate": 1.386070110701107e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.1987,
        "grad_norm": 1.1628353595733643,
        "learning_rate": 1.3837638376383766e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.2426,
        "grad_norm": 2.5846402645111084,
        "learning_rate": 1.3814575645756458e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.1758,
        "grad_norm": 0.9451146125793457,
        "learning_rate": 1.3791512915129151e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.2689,
        "grad_norm": 21.59748077392578,
        "learning_rate": 1.3768450184501847e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.5394573211669922,
        "eval_accuracy": 0.85609,
        "eval_precision": 0.83481,
        "eval_recall": 0.8818,
        "eval_f1": 0.85766,
        "eval_runtime": 18.065,
        "eval_samples_per_second": 60.006,
        "eval_steps_per_second": 3.764,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.2955,
        "grad_norm": 7.274770259857178,
        "learning_rate": 1.374538745387454e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.2424,
        "grad_norm": 1.4056037664413452,
        "learning_rate": 1.3722324723247232e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.2852,
        "grad_norm": 2.8258731365203857,
        "learning_rate": 1.3699261992619928e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.2074,
        "grad_norm": 8.013792037963867,
        "learning_rate": 1.367619926199262e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2644,
        "grad_norm": 16.8326358795166,
        "learning_rate": 1.3653136531365315e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.2251,
        "grad_norm": 7.472456932067871,
        "learning_rate": 1.3630073800738009e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.2094,
        "grad_norm": 3.2811124324798584,
        "learning_rate": 1.3607011070110701e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2315,
        "grad_norm": 4.672579765319824,
        "learning_rate": 1.3583948339483396e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.2946,
        "grad_norm": 3.871004819869995,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.191,
        "grad_norm": 2.127669334411621,
        "learning_rate": 1.3537822878228784e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.2912,
        "grad_norm": 7.574763774871826,
        "learning_rate": 1.3514760147601477e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.2764,
        "grad_norm": 1.0661566257476807,
        "learning_rate": 1.3491697416974169e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.236,
        "grad_norm": 6.8360443115234375,
        "learning_rate": 1.3468634686346865e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.2566,
        "grad_norm": 1.491309404373169,
        "learning_rate": 1.3445571955719558e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.1449,
        "grad_norm": 3.4789984226226807,
        "learning_rate": 1.3422509225092253e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.2676,
        "grad_norm": 44.747657775878906,
        "learning_rate": 1.3399446494464946e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.2279,
        "grad_norm": 1.941760778427124,
        "learning_rate": 1.3376383763837639e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.2186,
        "grad_norm": 39.91227340698242,
        "learning_rate": 1.3353321033210334e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.1224,
        "grad_norm": 0.7705928087234497,
        "learning_rate": 1.3330258302583027e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.2573,
        "grad_norm": 1.0356345176696777,
        "learning_rate": 1.330719557195572e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.1915,
        "grad_norm": 1.1792247295379639,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.1606,
        "grad_norm": 0.997999906539917,
        "learning_rate": 1.3261070110701106e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.2961,
        "grad_norm": 6.731070518493652,
        "learning_rate": 1.3238007380073802e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2725,
        "grad_norm": 8.460692405700684,
        "learning_rate": 1.3214944649446495e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.2399,
        "grad_norm": 2.6543972492218018,
        "learning_rate": 1.3191881918819187e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2519,
        "grad_norm": 2.9691293239593506,
        "learning_rate": 1.3168819188191883e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.1956,
        "grad_norm": 11.631888389587402,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.5404900908470154,
        "eval_accuracy": 0.84963,
        "eval_precision": 0.81787,
        "eval_recall": 0.89306,
        "eval_f1": 0.85381,
        "eval_runtime": 18.0817,
        "eval_samples_per_second": 59.95,
        "eval_steps_per_second": 3.761,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.2172,
        "grad_norm": 4.771574020385742,
        "learning_rate": 1.3122693726937272e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.1132,
        "grad_norm": 2.537381410598755,
        "learning_rate": 1.3099630996309964e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.2118,
        "grad_norm": 0.5499517917633057,
        "learning_rate": 1.3076568265682657e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.253,
        "grad_norm": 11.010862350463867,
        "learning_rate": 1.3053505535055353e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.2114,
        "grad_norm": 1.0853928327560425,
        "learning_rate": 1.3030442804428045e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.184,
        "grad_norm": 2.247525453567505,
        "learning_rate": 1.3007380073800738e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.207,
        "grad_norm": 2.903104066848755,
        "learning_rate": 1.2984317343173432e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.1586,
        "grad_norm": 0.6540027260780334,
        "learning_rate": 1.2961254612546126e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.3305,
        "grad_norm": 12.768500328063965,
        "learning_rate": 1.293819188191882e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.1601,
        "grad_norm": 1.4861059188842773,
        "learning_rate": 1.2915129151291513e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.2439,
        "grad_norm": 1.6232256889343262,
        "learning_rate": 1.2892066420664205e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.2651,
        "grad_norm": 5.333373069763184,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.1777,
        "grad_norm": 1.691725730895996,
        "learning_rate": 1.2845940959409594e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2857,
        "grad_norm": 2.884247303009033,
        "learning_rate": 1.282287822878229e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.169,
        "grad_norm": 3.373871088027954,
        "learning_rate": 1.2799815498154982e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.2118,
        "grad_norm": 2.6945295333862305,
        "learning_rate": 1.2776752767527675e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.2394,
        "grad_norm": 2.293675184249878,
        "learning_rate": 1.2753690036900371e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.3532,
        "grad_norm": 9.1532621383667,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.1896,
        "grad_norm": 1.213813304901123,
        "learning_rate": 1.2707564575645758e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.1712,
        "grad_norm": 1.9004920721054077,
        "learning_rate": 1.2684501845018452e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.2578,
        "grad_norm": 2.907076597213745,
        "learning_rate": 1.2661439114391144e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.2335,
        "grad_norm": 1.0553916692733765,
        "learning_rate": 1.2638376383763839e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.1846,
        "grad_norm": 2.369826555252075,
        "learning_rate": 1.2615313653136531e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.3634,
        "grad_norm": 1.8516931533813477,
        "learning_rate": 1.2592250922509224e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.1674,
        "grad_norm": 0.3763332962989807,
        "learning_rate": 1.256918819188192e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.248,
        "grad_norm": 6.291445732116699,
        "learning_rate": 1.2546125461254612e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.275,
        "grad_norm": 5.004139423370361,
        "learning_rate": 1.2523062730627308e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.2238,
        "grad_norm": 11.751680374145508,
        "learning_rate": 1.25e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.575127124786377,
        "eval_accuracy": 0.83948,
        "eval_precision": 0.79967,
        "eval_recall": 0.89869,
        "eval_f1": 0.84629,
        "eval_runtime": 18.0627,
        "eval_samples_per_second": 60.013,
        "eval_steps_per_second": 3.765,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.1825,
        "grad_norm": 8.259119987487793,
        "learning_rate": 1.2476937269372695e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.2238,
        "grad_norm": 21.04119110107422,
        "learning_rate": 1.2453874538745389e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2504,
        "grad_norm": 2.7890543937683105,
        "learning_rate": 1.2430811808118082e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.1439,
        "grad_norm": 4.159104824066162,
        "learning_rate": 1.2407749077490776e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2207,
        "grad_norm": 5.890747547149658,
        "learning_rate": 1.238468634686347e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.2685,
        "grad_norm": 2.5944018363952637,
        "learning_rate": 1.2361623616236164e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.1494,
        "grad_norm": 5.553744792938232,
        "learning_rate": 1.2338560885608857e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.1874,
        "grad_norm": 1.4799655675888062,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.0883,
        "grad_norm": 9.486651420593262,
        "learning_rate": 1.2292435424354244e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.2642,
        "grad_norm": 1.4037936925888062,
        "learning_rate": 1.2269372693726938e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.2518,
        "grad_norm": 12.651925086975098,
        "learning_rate": 1.2246309963099632e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.1752,
        "grad_norm": 1.1109604835510254,
        "learning_rate": 1.2223247232472325e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.1888,
        "grad_norm": 13.343428611755371,
        "learning_rate": 1.2200184501845019e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.1127,
        "grad_norm": 0.8114248514175415,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.2521,
        "grad_norm": 10.335628509521484,
        "learning_rate": 1.2154059040590407e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.138,
        "grad_norm": 0.5430532097816467,
        "learning_rate": 1.21309963099631e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.1959,
        "grad_norm": 3.7030839920043945,
        "learning_rate": 1.2107933579335794e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.2566,
        "grad_norm": 5.147580146789551,
        "learning_rate": 1.2084870848708488e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.2485,
        "grad_norm": 5.170292854309082,
        "learning_rate": 1.2061808118081182e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.2785,
        "grad_norm": 1.0166653394699097,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.285,
        "grad_norm": 18.39731216430664,
        "learning_rate": 1.201568265682657e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.2658,
        "grad_norm": 1.623128056526184,
        "learning_rate": 1.1992619926199262e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.241,
        "grad_norm": 8.371294975280762,
        "learning_rate": 1.1969557195571956e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.3054,
        "grad_norm": 7.260687828063965,
        "learning_rate": 1.194649446494465e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.1992,
        "grad_norm": 3.7531354427337646,
        "learning_rate": 1.1923431734317343e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.2807,
        "grad_norm": 3.591646671295166,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.2431,
        "grad_norm": 1.2397491931915283,
        "learning_rate": 1.1877306273062731e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.5316165685653687,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.81695,
        "eval_recall": 0.90432,
        "eval_f1": 0.85841,
        "eval_runtime": 18.0798,
        "eval_samples_per_second": 59.956,
        "eval_steps_per_second": 3.761,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.2439,
        "grad_norm": 2.849458694458008,
        "learning_rate": 1.1854243542435425e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.1313,
        "grad_norm": 1.978948950767517,
        "learning_rate": 1.1831180811808118e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.1834,
        "grad_norm": 15.661166191101074,
        "learning_rate": 1.1808118081180812e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.298,
        "grad_norm": 55.50940704345703,
        "learning_rate": 1.1785055350553506e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.1767,
        "grad_norm": 10.335824966430664,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.24,
        "grad_norm": 8.059698104858398,
        "learning_rate": 1.1738929889298895e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.1627,
        "grad_norm": 1.7928493022918701,
        "learning_rate": 1.1715867158671587e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.1906,
        "grad_norm": 2.5976340770721436,
        "learning_rate": 1.1692804428044282e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.3253,
        "grad_norm": 13.530048370361328,
        "learning_rate": 1.1669741697416974e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.1635,
        "grad_norm": 2.6132497787475586,
        "learning_rate": 1.1646678966789668e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.2459,
        "grad_norm": 2.2111716270446777,
        "learning_rate": 1.1623616236162361e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.1548,
        "grad_norm": 2.110093355178833,
        "learning_rate": 1.1600553505535055e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.2551,
        "grad_norm": 0.40923741459846497,
        "learning_rate": 1.157749077490775e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.1133,
        "grad_norm": 2.6587233543395996,
        "learning_rate": 1.1554428044280444e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.2626,
        "grad_norm": 13.717053413391113,
        "learning_rate": 1.1531365313653138e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.1984,
        "grad_norm": 9.095632553100586,
        "learning_rate": 1.150830258302583e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.1891,
        "grad_norm": 1.1810832023620605,
        "learning_rate": 1.1485239852398525e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.2813,
        "grad_norm": 7.3443379402160645,
        "learning_rate": 1.1462177121771219e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.1737,
        "grad_norm": 2.8359928131103516,
        "learning_rate": 1.1439114391143913e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.2576,
        "grad_norm": 1.2524069547653198,
        "learning_rate": 1.1416051660516606e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.1533,
        "grad_norm": 14.07759952545166,
        "learning_rate": 1.13929889298893e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.208,
        "grad_norm": 2.2394654750823975,
        "learning_rate": 1.1369926199261992e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.2212,
        "grad_norm": 3.479097366333008,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.2064,
        "grad_norm": 9.298004150390625,
        "learning_rate": 1.1323800738007381e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.263,
        "grad_norm": 0.8017727732658386,
        "learning_rate": 1.1300738007380073e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.2148,
        "grad_norm": 4.670820236206055,
        "learning_rate": 1.1277675276752768e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.1859,
        "grad_norm": 9.531099319458008,
        "learning_rate": 1.1254612546125462e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.6190386414527893,
        "eval_accuracy": 0.85793,
        "eval_precision": 0.81219,
        "eval_recall": 0.92495,
        "eval_f1": 0.86491,
        "eval_runtime": 18.0776,
        "eval_samples_per_second": 59.964,
        "eval_steps_per_second": 3.762,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.1572,
        "grad_norm": 16.893024444580078,
        "learning_rate": 1.1231549815498156e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.2022,
        "grad_norm": 2.7337965965270996,
        "learning_rate": 1.1208487084870849e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.1209,
        "grad_norm": 6.576137542724609,
        "learning_rate": 1.1185424354243543e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.1622,
        "grad_norm": 0.7801787853240967,
        "learning_rate": 1.1162361623616237e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.175,
        "grad_norm": 9.176495552062988,
        "learning_rate": 1.1139298892988931e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.1791,
        "grad_norm": 0.3296630382537842,
        "learning_rate": 1.1116236162361624e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.1966,
        "grad_norm": 11.15062141418457,
        "learning_rate": 1.1093173431734318e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.2262,
        "grad_norm": 14.452068328857422,
        "learning_rate": 1.1070110701107012e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.2108,
        "grad_norm": 7.3986639976501465,
        "learning_rate": 1.1047047970479705e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.17,
        "grad_norm": 0.7146703600883484,
        "learning_rate": 1.1023985239852399e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.2962,
        "grad_norm": 1.2783571481704712,
        "learning_rate": 1.1000922509225092e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.1858,
        "grad_norm": 1.390412449836731,
        "learning_rate": 1.0977859778597786e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.1937,
        "grad_norm": 3.806501865386963,
        "learning_rate": 1.095479704797048e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.2237,
        "grad_norm": 2.84208083152771,
        "learning_rate": 1.0931734317343174e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.2044,
        "grad_norm": 5.837472915649414,
        "learning_rate": 1.0908671586715867e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.1808,
        "grad_norm": 1.1748356819152832,
        "learning_rate": 1.0885608856088561e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.1977,
        "grad_norm": 1.3132965564727783,
        "learning_rate": 1.0862546125461255e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.2014,
        "grad_norm": 1.505403757095337,
        "learning_rate": 1.083948339483395e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.1977,
        "grad_norm": 1.3076337575912476,
        "learning_rate": 1.0816420664206644e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.2728,
        "grad_norm": 5.957468032836914,
        "learning_rate": 1.0793357933579336e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.2512,
        "grad_norm": 1.0062676668167114,
        "learning_rate": 1.077029520295203e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.1664,
        "grad_norm": 1.0430361032485962,
        "learning_rate": 1.0747232472324725e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.1951,
        "grad_norm": 0.9657601118087769,
        "learning_rate": 1.0724169741697417e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.1733,
        "grad_norm": 7.1565632820129395,
        "learning_rate": 1.070110701107011e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.1634,
        "grad_norm": 1.5334781408309937,
        "learning_rate": 1.0678044280442804e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.2265,
        "grad_norm": 5.437020301818848,
        "learning_rate": 1.0654981549815498e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.2407,
        "grad_norm": 2.0715246200561523,
        "learning_rate": 1.0631918819188192e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.6728095412254333,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.80065,
        "eval_recall": 0.91932,
        "eval_f1": 0.8559,
        "eval_runtime": 18.0843,
        "eval_samples_per_second": 59.941,
        "eval_steps_per_second": 3.76,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.1703,
        "grad_norm": 2.140495777130127,
        "learning_rate": 1.0608856088560887e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.1962,
        "grad_norm": 2.4718382358551025,
        "learning_rate": 1.058579335793358e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.1365,
        "grad_norm": 0.869163990020752,
        "learning_rate": 1.0562730627306273e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.3001,
        "grad_norm": 7.135761737823486,
        "learning_rate": 1.0539667896678968e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.2202,
        "grad_norm": 0.4208119511604309,
        "learning_rate": 1.0516605166051662e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.1269,
        "grad_norm": 0.5747140645980835,
        "learning_rate": 1.0493542435424354e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.2047,
        "grad_norm": 3.3539392948150635,
        "learning_rate": 1.0470479704797049e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.1787,
        "grad_norm": 1.1551384925842285,
        "learning_rate": 1.0447416974169743e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.3523,
        "grad_norm": 12.863235473632812,
        "learning_rate": 1.0424354243542435e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.1844,
        "grad_norm": 1.4571317434310913,
        "learning_rate": 1.040129151291513e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.1409,
        "grad_norm": 5.972341537475586,
        "learning_rate": 1.0378228782287822e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.1138,
        "grad_norm": 0.39312443137168884,
        "learning_rate": 1.0355166051660516e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.3382,
        "grad_norm": 7.72688102722168,
        "learning_rate": 1.033210332103321e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.1946,
        "grad_norm": 1.4054217338562012,
        "learning_rate": 1.0309040590405905e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.1776,
        "grad_norm": 3.3312947750091553,
        "learning_rate": 1.0285977859778597e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.3467,
        "grad_norm": 6.16671085357666,
        "learning_rate": 1.0262915129151292e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.2692,
        "grad_norm": 44.38796615600586,
        "learning_rate": 1.0239852398523986e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.1934,
        "grad_norm": 2.857046365737915,
        "learning_rate": 1.021678966789668e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.251,
        "grad_norm": 7.607977390289307,
        "learning_rate": 1.0193726937269373e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.1506,
        "grad_norm": 1.1909183263778687,
        "learning_rate": 1.0170664206642067e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.1857,
        "grad_norm": 0.6827813982963562,
        "learning_rate": 1.0147601476014761e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.1578,
        "grad_norm": 0.5320639610290527,
        "learning_rate": 1.0124538745387455e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.1938,
        "grad_norm": 8.311385154724121,
        "learning_rate": 1.0101476014760148e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.2667,
        "grad_norm": 0.3189554214477539,
        "learning_rate": 1.0078413284132842e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.211,
        "grad_norm": 4.337710857391357,
        "learning_rate": 1.0055350553505535e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.1392,
        "grad_norm": 1.1869959831237793,
        "learning_rate": 1.0032287822878229e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.1145,
        "grad_norm": 1.4323327541351318,
        "learning_rate": 1.0009225092250923e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.6349191069602966,
        "eval_accuracy": 0.86624,
        "eval_precision": 0.82441,
        "eval_recall": 0.92495,
        "eval_f1": 0.87179,
        "eval_runtime": 18.0758,
        "eval_samples_per_second": 59.97,
        "eval_steps_per_second": 3.762,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "loss": 0.2319,
        "grad_norm": 6.638695240020752,
        "learning_rate": 9.986162361623616e-06,
        "epoch": 24.022140221402214,
        "step": 6510
    },
    {
        "loss": 0.2052,
        "grad_norm": 11.392062187194824,
        "learning_rate": 9.96309963099631e-06,
        "epoch": 24.059040590405903,
        "step": 6520
    },
    {
        "loss": 0.2494,
        "grad_norm": 2.3396337032318115,
        "learning_rate": 9.940036900369004e-06,
        "epoch": 24.095940959409592,
        "step": 6530
    },
    {
        "loss": 0.1428,
        "grad_norm": 8.60859489440918,
        "learning_rate": 9.916974169741698e-06,
        "epoch": 24.132841328413285,
        "step": 6540
    },
    {
        "loss": 0.1331,
        "grad_norm": 1.488785743713379,
        "learning_rate": 9.893911439114393e-06,
        "epoch": 24.169741697416974,
        "step": 6550
    },
    {
        "loss": 0.1655,
        "grad_norm": 14.46114730834961,
        "learning_rate": 9.870848708487085e-06,
        "epoch": 24.206642066420663,
        "step": 6560
    },
    {
        "loss": 0.2241,
        "grad_norm": 1.0240261554718018,
        "learning_rate": 9.84778597785978e-06,
        "epoch": 24.243542435424356,
        "step": 6570
    },
    {
        "loss": 0.2229,
        "grad_norm": 1.3397754430770874,
        "learning_rate": 9.824723247232474e-06,
        "epoch": 24.280442804428045,
        "step": 6580
    },
    {
        "loss": 0.1571,
        "grad_norm": 2.52101731300354,
        "learning_rate": 9.801660516605168e-06,
        "epoch": 24.317343173431734,
        "step": 6590
    },
    {
        "loss": 0.1803,
        "grad_norm": 4.137324810028076,
        "learning_rate": 9.77859778597786e-06,
        "epoch": 24.354243542435423,
        "step": 6600
    },
    {
        "loss": 0.1612,
        "grad_norm": 53.233612060546875,
        "learning_rate": 9.755535055350553e-06,
        "epoch": 24.391143911439116,
        "step": 6610
    },
    {
        "loss": 0.1364,
        "grad_norm": 1.5931814908981323,
        "learning_rate": 9.732472324723247e-06,
        "epoch": 24.428044280442805,
        "step": 6620
    },
    {
        "loss": 0.1987,
        "grad_norm": 3.6782991886138916,
        "learning_rate": 9.709409594095941e-06,
        "epoch": 24.464944649446494,
        "step": 6630
    },
    {
        "loss": 0.2363,
        "grad_norm": 2.1785037517547607,
        "learning_rate": 9.686346863468636e-06,
        "epoch": 24.501845018450183,
        "step": 6640
    },
    {
        "loss": 0.3189,
        "grad_norm": 0.5168723464012146,
        "learning_rate": 9.663284132841328e-06,
        "epoch": 24.538745387453876,
        "step": 6650
    },
    {
        "loss": 0.2176,
        "grad_norm": 1.6550966501235962,
        "learning_rate": 9.640221402214022e-06,
        "epoch": 24.575645756457565,
        "step": 6660
    },
    {
        "loss": 0.1846,
        "grad_norm": 0.8937863111495972,
        "learning_rate": 9.617158671586717e-06,
        "epoch": 24.612546125461254,
        "step": 6670
    },
    {
        "loss": 0.2121,
        "grad_norm": 1.5554410219192505,
        "learning_rate": 9.59409594095941e-06,
        "epoch": 24.649446494464943,
        "step": 6680
    },
    {
        "loss": 0.1329,
        "grad_norm": 2.078693389892578,
        "learning_rate": 9.571033210332103e-06,
        "epoch": 24.686346863468636,
        "step": 6690
    },
    {
        "loss": 0.1384,
        "grad_norm": 1.9696261882781982,
        "learning_rate": 9.547970479704798e-06,
        "epoch": 24.723247232472325,
        "step": 6700
    },
    {
        "loss": 0.1823,
        "grad_norm": 3.5819554328918457,
        "learning_rate": 9.524907749077492e-06,
        "epoch": 24.760147601476014,
        "step": 6710
    },
    {
        "loss": 0.1422,
        "grad_norm": 3.8228368759155273,
        "learning_rate": 9.501845018450186e-06,
        "epoch": 24.797047970479706,
        "step": 6720
    },
    {
        "loss": 0.2173,
        "grad_norm": 0.846406102180481,
        "learning_rate": 9.478782287822879e-06,
        "epoch": 24.833948339483396,
        "step": 6730
    },
    {
        "loss": 0.1823,
        "grad_norm": 3.676675796508789,
        "learning_rate": 9.455719557195573e-06,
        "epoch": 24.870848708487085,
        "step": 6740
    },
    {
        "loss": 0.1869,
        "grad_norm": 8.432088851928711,
        "learning_rate": 9.432656826568265e-06,
        "epoch": 24.907749077490774,
        "step": 6750
    },
    {
        "loss": 0.1833,
        "grad_norm": 1.2866580486297607,
        "learning_rate": 9.40959409594096e-06,
        "epoch": 24.944649446494466,
        "step": 6760
    },
    {
        "loss": 0.2133,
        "grad_norm": 0.3054085969924927,
        "learning_rate": 9.386531365313654e-06,
        "epoch": 24.981549815498155,
        "step": 6770
    },
    {
        "eval_loss": 0.6902577877044678,
        "eval_accuracy": 0.85055,
        "eval_precision": 0.80968,
        "eval_recall": 0.90994,
        "eval_f1": 0.85689,
        "eval_runtime": 18.0747,
        "eval_samples_per_second": 59.973,
        "eval_steps_per_second": 3.762,
        "epoch": 25.0,
        "step": 6775
    },
    {
        "loss": 0.2075,
        "grad_norm": 2.3607616424560547,
        "learning_rate": 9.363468634686346e-06,
        "epoch": 25.018450184501845,
        "step": 6780
    },
    {
        "loss": 0.1856,
        "grad_norm": 2.4493393898010254,
        "learning_rate": 9.34040590405904e-06,
        "epoch": 25.055350553505534,
        "step": 6790
    },
    {
        "loss": 0.1743,
        "grad_norm": 63.598960876464844,
        "learning_rate": 9.317343173431735e-06,
        "epoch": 25.092250922509226,
        "step": 6800
    },
    {
        "loss": 0.1825,
        "grad_norm": 0.9276240468025208,
        "learning_rate": 9.294280442804429e-06,
        "epoch": 25.129151291512915,
        "step": 6810
    },
    {
        "loss": 0.327,
        "grad_norm": 99.30753326416016,
        "learning_rate": 9.271217712177122e-06,
        "epoch": 25.166051660516604,
        "step": 6820
    },
    {
        "loss": 0.1751,
        "grad_norm": 3.334434747695923,
        "learning_rate": 9.248154981549816e-06,
        "epoch": 25.202952029520294,
        "step": 6830
    },
    {
        "loss": 0.1901,
        "grad_norm": 11.030777931213379,
        "learning_rate": 9.22509225092251e-06,
        "epoch": 25.239852398523986,
        "step": 6840
    },
    {
        "loss": 0.1604,
        "grad_norm": 1.304012656211853,
        "learning_rate": 9.202029520295204e-06,
        "epoch": 25.276752767527675,
        "step": 6850
    },
    {
        "loss": 0.1837,
        "grad_norm": 3.994746208190918,
        "learning_rate": 9.178966789667898e-06,
        "epoch": 25.313653136531364,
        "step": 6860
    },
    {
        "loss": 0.1939,
        "grad_norm": 14.978202819824219,
        "learning_rate": 9.155904059040591e-06,
        "epoch": 25.350553505535057,
        "step": 6870
    },
    {
        "loss": 0.1706,
        "grad_norm": 1.7588437795639038,
        "learning_rate": 9.132841328413285e-06,
        "epoch": 25.387453874538746,
        "step": 6880
    },
    {
        "loss": 0.1558,
        "grad_norm": 0.5799731612205505,
        "learning_rate": 9.109778597785978e-06,
        "epoch": 25.424354243542435,
        "step": 6890
    },
    {
        "loss": 0.1745,
        "grad_norm": 0.9693140387535095,
        "learning_rate": 9.086715867158672e-06,
        "epoch": 25.461254612546124,
        "step": 6900
    },
    {
        "loss": 0.1582,
        "grad_norm": 1.4444586038589478,
        "learning_rate": 9.063653136531364e-06,
        "epoch": 25.498154981549817,
        "step": 6910
    },
    {
        "loss": 0.2479,
        "grad_norm": 3.076366901397705,
        "learning_rate": 9.040590405904059e-06,
        "epoch": 25.535055350553506,
        "step": 6920
    },
    {
        "loss": 0.2165,
        "grad_norm": 1.5530977249145508,
        "learning_rate": 9.017527675276753e-06,
        "epoch": 25.571955719557195,
        "step": 6930
    },
    {
        "loss": 0.1756,
        "grad_norm": 0.8932713866233826,
        "learning_rate": 8.994464944649447e-06,
        "epoch": 25.608856088560884,
        "step": 6940
    },
    {
        "loss": 0.268,
        "grad_norm": 35.59623336791992,
        "learning_rate": 8.971402214022141e-06,
        "epoch": 25.645756457564577,
        "step": 6950
    },
    {
        "loss": 0.2135,
        "grad_norm": 0.440555602312088,
        "learning_rate": 8.948339483394834e-06,
        "epoch": 25.682656826568266,
        "step": 6960
    },
    {
        "loss": 0.2925,
        "grad_norm": 4.933950424194336,
        "learning_rate": 8.925276752767528e-06,
        "epoch": 25.719557195571955,
        "step": 6970
    },
    {
        "loss": 0.1668,
        "grad_norm": 0.6796351671218872,
        "learning_rate": 8.902214022140222e-06,
        "epoch": 25.756457564575644,
        "step": 6980
    },
    {
        "loss": 0.1527,
        "grad_norm": 13.276806831359863,
        "learning_rate": 8.879151291512917e-06,
        "epoch": 25.793357933579337,
        "step": 6990
    },
    {
        "loss": 0.2346,
        "grad_norm": 5.52744197845459,
        "learning_rate": 8.85608856088561e-06,
        "epoch": 25.830258302583026,
        "step": 7000
    },
    {
        "loss": 0.1424,
        "grad_norm": 0.5057370662689209,
        "learning_rate": 8.833025830258303e-06,
        "epoch": 25.867158671586715,
        "step": 7010
    },
    {
        "loss": 0.152,
        "grad_norm": 5.362256050109863,
        "learning_rate": 8.809963099630996e-06,
        "epoch": 25.904059040590404,
        "step": 7020
    },
    {
        "loss": 0.2752,
        "grad_norm": 1.852618932723999,
        "learning_rate": 8.78690036900369e-06,
        "epoch": 25.940959409594097,
        "step": 7030
    },
    {
        "loss": 0.0851,
        "grad_norm": 0.8508252501487732,
        "learning_rate": 8.763837638376384e-06,
        "epoch": 25.977859778597786,
        "step": 7040
    },
    {
        "eval_loss": 0.7752994298934937,
        "eval_accuracy": 0.84594,
        "eval_precision": 0.79902,
        "eval_recall": 0.91745,
        "eval_f1": 0.85415,
        "eval_runtime": 18.0755,
        "eval_samples_per_second": 59.971,
        "eval_steps_per_second": 3.762,
        "epoch": 26.0,
        "step": 7046
    },
    {
        "loss": 0.184,
        "grad_norm": 2.2393109798431396,
        "learning_rate": 8.740774907749077e-06,
        "epoch": 26.014760147601475,
        "step": 7050
    },
    {
        "loss": 0.2045,
        "grad_norm": 1.2919899225234985,
        "learning_rate": 8.717712177121771e-06,
        "epoch": 26.051660516605168,
        "step": 7060
    },
    {
        "loss": 0.2205,
        "grad_norm": 0.7590093016624451,
        "learning_rate": 8.694649446494465e-06,
        "epoch": 26.088560885608857,
        "step": 7070
    },
    {
        "loss": 0.1348,
        "grad_norm": 3.374052047729492,
        "learning_rate": 8.67158671586716e-06,
        "epoch": 26.125461254612546,
        "step": 7080
    },
    {
        "loss": 0.1283,
        "grad_norm": 1.2777256965637207,
        "learning_rate": 8.648523985239852e-06,
        "epoch": 26.162361623616235,
        "step": 7090
    },
    {
        "loss": 0.2098,
        "grad_norm": 13.742341041564941,
        "learning_rate": 8.625461254612546e-06,
        "epoch": 26.199261992619927,
        "step": 7100
    },
    {
        "loss": 0.1119,
        "grad_norm": 2.683279514312744,
        "learning_rate": 8.60239852398524e-06,
        "epoch": 26.236162361623617,
        "step": 7110
    },
    {
        "loss": 0.109,
        "grad_norm": 0.8460925817489624,
        "learning_rate": 8.579335793357935e-06,
        "epoch": 26.273062730627306,
        "step": 7120
    },
    {
        "loss": 0.1481,
        "grad_norm": 18.944931030273438,
        "learning_rate": 8.556273062730629e-06,
        "epoch": 26.309963099630995,
        "step": 7130
    },
    {
        "loss": 0.1254,
        "grad_norm": 1.7728290557861328,
        "learning_rate": 8.533210332103322e-06,
        "epoch": 26.346863468634687,
        "step": 7140
    },
    {
        "loss": 0.2802,
        "grad_norm": 0.9750019907951355,
        "learning_rate": 8.510147601476016e-06,
        "epoch": 26.383763837638377,
        "step": 7150
    },
    {
        "loss": 0.1486,
        "grad_norm": 26.491619110107422,
        "learning_rate": 8.487084870848708e-06,
        "epoch": 26.420664206642066,
        "step": 7160
    },
    {
        "loss": 0.2321,
        "grad_norm": 2.8343138694763184,
        "learning_rate": 8.464022140221403e-06,
        "epoch": 26.457564575645755,
        "step": 7170
    },
    {
        "loss": 0.1379,
        "grad_norm": 66.64128875732422,
        "learning_rate": 8.440959409594095e-06,
        "epoch": 26.494464944649447,
        "step": 7180
    },
    {
        "loss": 0.1573,
        "grad_norm": 0.5405457615852356,
        "learning_rate": 8.41789667896679e-06,
        "epoch": 26.531365313653136,
        "step": 7190
    },
    {
        "loss": 0.3079,
        "grad_norm": 5.556529521942139,
        "learning_rate": 8.394833948339484e-06,
        "epoch": 26.568265682656826,
        "step": 7200
    },
    {
        "loss": 0.1496,
        "grad_norm": 4.593047142028809,
        "learning_rate": 8.371771217712178e-06,
        "epoch": 26.605166051660518,
        "step": 7210
    },
    {
        "loss": 0.1562,
        "grad_norm": 1.4134315252304077,
        "learning_rate": 8.34870848708487e-06,
        "epoch": 26.642066420664207,
        "step": 7220
    },
    {
        "loss": 0.1663,
        "grad_norm": 0.8484271764755249,
        "learning_rate": 8.325645756457565e-06,
        "epoch": 26.678966789667896,
        "step": 7230
    },
    {
        "loss": 0.2066,
        "grad_norm": 1.1351256370544434,
        "learning_rate": 8.302583025830259e-06,
        "epoch": 26.715867158671585,
        "step": 7240
    },
    {
        "loss": 0.1705,
        "grad_norm": 1.077427625656128,
        "learning_rate": 8.279520295202953e-06,
        "epoch": 26.752767527675278,
        "step": 7250
    },
    {
        "loss": 0.2596,
        "grad_norm": 8.245457649230957,
        "learning_rate": 8.256457564575647e-06,
        "epoch": 26.789667896678967,
        "step": 7260
    },
    {
        "loss": 0.2156,
        "grad_norm": 12.791595458984375,
        "learning_rate": 8.23339483394834e-06,
        "epoch": 26.826568265682656,
        "step": 7270
    },
    {
        "loss": 0.1449,
        "grad_norm": 3.6385557651519775,
        "learning_rate": 8.210332103321034e-06,
        "epoch": 26.863468634686345,
        "step": 7280
    },
    {
        "loss": 0.185,
        "grad_norm": 2.3061909675598145,
        "learning_rate": 8.187269372693728e-06,
        "epoch": 26.900369003690038,
        "step": 7290
    },
    {
        "loss": 0.2354,
        "grad_norm": 1.3061800003051758,
        "learning_rate": 8.16420664206642e-06,
        "epoch": 26.937269372693727,
        "step": 7300
    },
    {
        "loss": 0.1926,
        "grad_norm": 4.432873249053955,
        "learning_rate": 8.141143911439113e-06,
        "epoch": 26.974169741697416,
        "step": 7310
    },
    {
        "eval_loss": 0.6763278841972351,
        "eval_accuracy": 0.85055,
        "eval_precision": 0.81387,
        "eval_recall": 0.90244,
        "eval_f1": 0.85587,
        "eval_runtime": 18.1135,
        "eval_samples_per_second": 59.845,
        "eval_steps_per_second": 3.754,
        "epoch": 27.0,
        "step": 7317
    },
    {
        "loss": 0.2211,
        "grad_norm": 1.4799118041992188,
        "learning_rate": 8.118081180811808e-06,
        "epoch": 27.011070110701105,
        "step": 7320
    },
    {
        "loss": 0.1668,
        "grad_norm": 1.3861451148986816,
        "learning_rate": 8.095018450184502e-06,
        "epoch": 27.047970479704798,
        "step": 7330
    },
    {
        "loss": 0.1616,
        "grad_norm": 1.628177523612976,
        "learning_rate": 8.071955719557196e-06,
        "epoch": 27.084870848708487,
        "step": 7340
    },
    {
        "loss": 0.1396,
        "grad_norm": 1.1942895650863647,
        "learning_rate": 8.04889298892989e-06,
        "epoch": 27.121771217712176,
        "step": 7350
    },
    {
        "loss": 0.1415,
        "grad_norm": 1.508668303489685,
        "learning_rate": 8.025830258302583e-06,
        "epoch": 27.15867158671587,
        "step": 7360
    },
    {
        "loss": 0.138,
        "grad_norm": 1.2179337739944458,
        "learning_rate": 8.002767527675277e-06,
        "epoch": 27.195571955719558,
        "step": 7370
    },
    {
        "loss": 0.1466,
        "grad_norm": 1.9863072633743286,
        "learning_rate": 7.979704797047971e-06,
        "epoch": 27.232472324723247,
        "step": 7380
    },
    {
        "loss": 0.228,
        "grad_norm": 6.286439418792725,
        "learning_rate": 7.956642066420665e-06,
        "epoch": 27.269372693726936,
        "step": 7390
    },
    {
        "loss": 0.237,
        "grad_norm": 3.507483959197998,
        "learning_rate": 7.933579335793358e-06,
        "epoch": 27.30627306273063,
        "step": 7400
    },
    {
        "loss": 0.168,
        "grad_norm": 4.742885589599609,
        "learning_rate": 7.910516605166052e-06,
        "epoch": 27.343173431734318,
        "step": 7410
    },
    {
        "loss": 0.2371,
        "grad_norm": 61.5074462890625,
        "learning_rate": 7.887453874538746e-06,
        "epoch": 27.380073800738007,
        "step": 7420
    },
    {
        "loss": 0.1645,
        "grad_norm": 1.456416368484497,
        "learning_rate": 7.864391143911439e-06,
        "epoch": 27.416974169741696,
        "step": 7430
    },
    {
        "loss": 0.2085,
        "grad_norm": 15.768828392028809,
        "learning_rate": 7.841328413284133e-06,
        "epoch": 27.45387453874539,
        "step": 7440
    },
    {
        "loss": 0.1532,
        "grad_norm": 2.900160074234009,
        "learning_rate": 7.818265682656826e-06,
        "epoch": 27.490774907749078,
        "step": 7450
    },
    {
        "loss": 0.1714,
        "grad_norm": 1.642250657081604,
        "learning_rate": 7.79520295202952e-06,
        "epoch": 27.527675276752767,
        "step": 7460
    },
    {
        "loss": 0.2053,
        "grad_norm": 1.2138607501983643,
        "learning_rate": 7.772140221402214e-06,
        "epoch": 27.564575645756456,
        "step": 7470
    },
    {
        "loss": 0.2123,
        "grad_norm": 0.6052730083465576,
        "learning_rate": 7.749077490774908e-06,
        "epoch": 27.60147601476015,
        "step": 7480
    },
    {
        "loss": 0.2157,
        "grad_norm": 3.2257776260375977,
        "learning_rate": 7.726014760147601e-06,
        "epoch": 27.638376383763838,
        "step": 7490
    },
    {
        "loss": 0.184,
        "grad_norm": 1.0996097326278687,
        "learning_rate": 7.702952029520295e-06,
        "epoch": 27.675276752767527,
        "step": 7500
    },
    {
        "loss": 0.2386,
        "grad_norm": 11.809630393981934,
        "learning_rate": 7.67988929889299e-06,
        "epoch": 27.71217712177122,
        "step": 7510
    },
    {
        "loss": 0.1935,
        "grad_norm": 6.645560264587402,
        "learning_rate": 7.656826568265684e-06,
        "epoch": 27.74907749077491,
        "step": 7520
    },
    {
        "loss": 0.1905,
        "grad_norm": 0.8712813258171082,
        "learning_rate": 7.633763837638378e-06,
        "epoch": 27.785977859778598,
        "step": 7530
    },
    {
        "loss": 0.2283,
        "grad_norm": 5.83756685256958,
        "learning_rate": 7.6107011070110704e-06,
        "epoch": 27.822878228782287,
        "step": 7540
    },
    {
        "loss": 0.2495,
        "grad_norm": 5.497577667236328,
        "learning_rate": 7.587638376383764e-06,
        "epoch": 27.85977859778598,
        "step": 7550
    },
    {
        "loss": 0.2323,
        "grad_norm": 6.03396463394165,
        "learning_rate": 7.564575645756458e-06,
        "epoch": 27.89667896678967,
        "step": 7560
    },
    {
        "loss": 0.1125,
        "grad_norm": 0.36410561203956604,
        "learning_rate": 7.541512915129152e-06,
        "epoch": 27.933579335793358,
        "step": 7570
    },
    {
        "loss": 0.1545,
        "grad_norm": 2.4513964653015137,
        "learning_rate": 7.518450184501845e-06,
        "epoch": 27.970479704797047,
        "step": 7580
    },
    {
        "eval_loss": 0.7402392029762268,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.80667,
        "eval_recall": 0.90807,
        "eval_f1": 0.85437,
        "eval_runtime": 18.1415,
        "eval_samples_per_second": 59.753,
        "eval_steps_per_second": 3.748,
        "epoch": 28.0,
        "step": 7588
    },
    {
        "loss": 0.2132,
        "grad_norm": 2.892436981201172,
        "learning_rate": 7.495387453874539e-06,
        "epoch": 28.00738007380074,
        "step": 7590
    },
    {
        "loss": 0.1596,
        "grad_norm": 1.8880577087402344,
        "learning_rate": 7.472324723247233e-06,
        "epoch": 28.04428044280443,
        "step": 7600
    },
    {
        "loss": 0.1933,
        "grad_norm": 0.8353331089019775,
        "learning_rate": 7.449261992619927e-06,
        "epoch": 28.081180811808117,
        "step": 7610
    },
    {
        "loss": 0.1172,
        "grad_norm": 0.9310335516929626,
        "learning_rate": 7.42619926199262e-06,
        "epoch": 28.118081180811807,
        "step": 7620
    },
    {
        "loss": 0.0958,
        "grad_norm": 4.945934295654297,
        "learning_rate": 7.403136531365313e-06,
        "epoch": 28.1549815498155,
        "step": 7630
    },
    {
        "loss": 0.1473,
        "grad_norm": 5.941086292266846,
        "learning_rate": 7.380073800738008e-06,
        "epoch": 28.19188191881919,
        "step": 7640
    },
    {
        "loss": 0.2237,
        "grad_norm": 8.814041137695312,
        "learning_rate": 7.357011070110702e-06,
        "epoch": 28.228782287822877,
        "step": 7650
    },
    {
        "loss": 0.1916,
        "grad_norm": 0.5207118391990662,
        "learning_rate": 7.333948339483396e-06,
        "epoch": 28.26568265682657,
        "step": 7660
    },
    {
        "loss": 0.1475,
        "grad_norm": 22.982101440429688,
        "learning_rate": 7.310885608856089e-06,
        "epoch": 28.30258302583026,
        "step": 7670
    },
    {
        "loss": 0.1865,
        "grad_norm": 2.6336703300476074,
        "learning_rate": 7.287822878228783e-06,
        "epoch": 28.339483394833948,
        "step": 7680
    },
    {
        "loss": 0.18,
        "grad_norm": 2.517165184020996,
        "learning_rate": 7.264760147601476e-06,
        "epoch": 28.376383763837637,
        "step": 7690
    },
    {
        "loss": 0.1977,
        "grad_norm": 22.198352813720703,
        "learning_rate": 7.2416974169741705e-06,
        "epoch": 28.41328413284133,
        "step": 7700
    },
    {
        "loss": 0.2266,
        "grad_norm": 8.79967212677002,
        "learning_rate": 7.218634686346863e-06,
        "epoch": 28.45018450184502,
        "step": 7710
    },
    {
        "loss": 0.194,
        "grad_norm": 1.244003176689148,
        "learning_rate": 7.195571955719557e-06,
        "epoch": 28.487084870848708,
        "step": 7720
    },
    {
        "loss": 0.1537,
        "grad_norm": 1.2805649042129517,
        "learning_rate": 7.1725092250922515e-06,
        "epoch": 28.523985239852397,
        "step": 7730
    },
    {
        "loss": 0.1251,
        "grad_norm": 0.4249172508716583,
        "learning_rate": 7.149446494464946e-06,
        "epoch": 28.56088560885609,
        "step": 7740
    },
    {
        "loss": 0.178,
        "grad_norm": 5.8605875968933105,
        "learning_rate": 7.126383763837639e-06,
        "epoch": 28.59778597785978,
        "step": 7750
    },
    {
        "loss": 0.183,
        "grad_norm": 4.776047706604004,
        "learning_rate": 7.103321033210332e-06,
        "epoch": 28.634686346863468,
        "step": 7760
    },
    {
        "loss": 0.1642,
        "grad_norm": 2.9616386890411377,
        "learning_rate": 7.080258302583026e-06,
        "epoch": 28.671586715867157,
        "step": 7770
    },
    {
        "loss": 0.1754,
        "grad_norm": 20.067855834960938,
        "learning_rate": 7.05719557195572e-06,
        "epoch": 28.70848708487085,
        "step": 7780
    },
    {
        "loss": 0.1791,
        "grad_norm": 3.4234039783477783,
        "learning_rate": 7.034132841328414e-06,
        "epoch": 28.74538745387454,
        "step": 7790
    },
    {
        "loss": 0.1492,
        "grad_norm": 0.26051321625709534,
        "learning_rate": 7.011070110701107e-06,
        "epoch": 28.782287822878228,
        "step": 7800
    },
    {
        "loss": 0.2201,
        "grad_norm": 9.6409273147583,
        "learning_rate": 6.988007380073801e-06,
        "epoch": 28.81918819188192,
        "step": 7810
    },
    {
        "loss": 0.1095,
        "grad_norm": 2.2505438327789307,
        "learning_rate": 6.9649446494464944e-06,
        "epoch": 28.85608856088561,
        "step": 7820
    },
    {
        "loss": 0.1328,
        "grad_norm": 0.7370920181274414,
        "learning_rate": 6.941881918819189e-06,
        "epoch": 28.8929889298893,
        "step": 7830
    },
    {
        "loss": 0.1355,
        "grad_norm": 0.37997469305992126,
        "learning_rate": 6.918819188191883e-06,
        "epoch": 28.929889298892988,
        "step": 7840
    },
    {
        "loss": 0.2169,
        "grad_norm": 7.195206165313721,
        "learning_rate": 6.8957564575645754e-06,
        "epoch": 28.96678966789668,
        "step": 7850
    },
    {
        "eval_loss": 0.7648581266403198,
        "eval_accuracy": 0.8524,
        "eval_precision": 0.81664,
        "eval_recall": 0.90244,
        "eval_f1": 0.8574,
        "eval_runtime": 18.1233,
        "eval_samples_per_second": 59.812,
        "eval_steps_per_second": 3.752,
        "epoch": 29.0,
        "step": 7859
    },
    {
        "loss": 0.1842,
        "grad_norm": 0.3431340754032135,
        "learning_rate": 6.87269372693727e-06,
        "epoch": 29.00369003690037,
        "step": 7860
    },
    {
        "loss": 0.0778,
        "grad_norm": 0.3539906144142151,
        "learning_rate": 6.849630996309964e-06,
        "epoch": 29.04059040590406,
        "step": 7870
    },
    {
        "loss": 0.1582,
        "grad_norm": 4.938048362731934,
        "learning_rate": 6.826568265682657e-06,
        "epoch": 29.077490774907748,
        "step": 7880
    },
    {
        "loss": 0.1326,
        "grad_norm": 0.8487045764923096,
        "learning_rate": 6.803505535055351e-06,
        "epoch": 29.11439114391144,
        "step": 7890
    },
    {
        "loss": 0.1855,
        "grad_norm": 0.4519001543521881,
        "learning_rate": 6.780442804428044e-06,
        "epoch": 29.15129151291513,
        "step": 7900
    },
    {
        "loss": 0.1033,
        "grad_norm": 4.537438869476318,
        "learning_rate": 6.757380073800738e-06,
        "epoch": 29.18819188191882,
        "step": 7910
    },
    {
        "loss": 0.157,
        "grad_norm": 0.3736262321472168,
        "learning_rate": 6.7343173431734325e-06,
        "epoch": 29.225092250922508,
        "step": 7920
    },
    {
        "loss": 0.2157,
        "grad_norm": 4.336919784545898,
        "learning_rate": 6.711254612546127e-06,
        "epoch": 29.2619926199262,
        "step": 7930
    },
    {
        "loss": 0.2564,
        "grad_norm": 1.3531169891357422,
        "learning_rate": 6.688191881918819e-06,
        "epoch": 29.29889298892989,
        "step": 7940
    },
    {
        "loss": 0.1533,
        "grad_norm": 28.952463150024414,
        "learning_rate": 6.6651291512915135e-06,
        "epoch": 29.33579335793358,
        "step": 7950
    },
    {
        "loss": 0.1308,
        "grad_norm": 9.741850852966309,
        "learning_rate": 6.642066420664207e-06,
        "epoch": 29.372693726937268,
        "step": 7960
    },
    {
        "loss": 0.2122,
        "grad_norm": 2.9639110565185547,
        "learning_rate": 6.619003690036901e-06,
        "epoch": 29.40959409594096,
        "step": 7970
    },
    {
        "loss": 0.1839,
        "grad_norm": 0.6012181639671326,
        "learning_rate": 6.595940959409594e-06,
        "epoch": 29.44649446494465,
        "step": 7980
    },
    {
        "loss": 0.1975,
        "grad_norm": 5.512086391448975,
        "learning_rate": 6.572878228782288e-06,
        "epoch": 29.48339483394834,
        "step": 7990
    },
    {
        "loss": 0.1618,
        "grad_norm": 2.1116678714752197,
        "learning_rate": 6.549815498154982e-06,
        "epoch": 29.52029520295203,
        "step": 8000
    },
    {
        "loss": 0.13,
        "grad_norm": 0.8205943703651428,
        "learning_rate": 6.526752767527676e-06,
        "epoch": 29.55719557195572,
        "step": 8010
    },
    {
        "loss": 0.1928,
        "grad_norm": 7.872729778289795,
        "learning_rate": 6.503690036900369e-06,
        "epoch": 29.59409594095941,
        "step": 8020
    },
    {
        "loss": 0.1435,
        "grad_norm": 7.3943705558776855,
        "learning_rate": 6.480627306273063e-06,
        "epoch": 29.6309963099631,
        "step": 8030
    },
    {
        "loss": 0.2539,
        "grad_norm": 0.8989716172218323,
        "learning_rate": 6.4575645756457565e-06,
        "epoch": 29.66789667896679,
        "step": 8040
    },
    {
        "loss": 0.1494,
        "grad_norm": 1.739079236984253,
        "learning_rate": 6.434501845018451e-06,
        "epoch": 29.70479704797048,
        "step": 8050
    },
    {
        "loss": 0.1708,
        "grad_norm": 0.6256440281867981,
        "learning_rate": 6.411439114391145e-06,
        "epoch": 29.74169741697417,
        "step": 8060
    },
    {
        "loss": 0.146,
        "grad_norm": 2.4920296669006348,
        "learning_rate": 6.3883763837638375e-06,
        "epoch": 29.77859778597786,
        "step": 8070
    },
    {
        "loss": 0.1469,
        "grad_norm": 2.0271079540252686,
        "learning_rate": 6.365313653136532e-06,
        "epoch": 29.81549815498155,
        "step": 8080
    },
    {
        "loss": 0.2421,
        "grad_norm": 1.2068356275558472,
        "learning_rate": 6.342250922509226e-06,
        "epoch": 29.85239852398524,
        "step": 8090
    },
    {
        "loss": 0.182,
        "grad_norm": 1.0624748468399048,
        "learning_rate": 6.319188191881919e-06,
        "epoch": 29.88929889298893,
        "step": 8100
    },
    {
        "loss": 0.1423,
        "grad_norm": 1.5814208984375,
        "learning_rate": 6.296125461254612e-06,
        "epoch": 29.92619926199262,
        "step": 8110
    },
    {
        "loss": 0.2078,
        "grad_norm": 4.828089237213135,
        "learning_rate": 6.273062730627306e-06,
        "epoch": 29.96309963099631,
        "step": 8120
    },
    {
        "loss": 0.245,
        "grad_norm": 1.6624470949172974,
        "learning_rate": 6.25e-06,
        "epoch": 30.0,
        "step": 8130
    },
    {
        "eval_loss": 0.7662353515625,
        "eval_accuracy": 0.84963,
        "eval_precision": 0.81356,
        "eval_recall": 0.90056,
        "eval_f1": 0.85485,
        "eval_runtime": 18.0918,
        "eval_samples_per_second": 59.917,
        "eval_steps_per_second": 3.759,
        "epoch": 30.0,
        "step": 8130
    },
    {
        "loss": 0.1089,
        "grad_norm": 15.47842788696289,
        "learning_rate": 6.2269372693726945e-06,
        "epoch": 30.03690036900369,
        "step": 8140
    },
    {
        "loss": 0.1337,
        "grad_norm": 13.099137306213379,
        "learning_rate": 6.203874538745388e-06,
        "epoch": 30.07380073800738,
        "step": 8150
    },
    {
        "loss": 0.1695,
        "grad_norm": 0.37804725766181946,
        "learning_rate": 6.180811808118082e-06,
        "epoch": 30.11070110701107,
        "step": 8160
    },
    {
        "loss": 0.1384,
        "grad_norm": 2.896250009536743,
        "learning_rate": 6.157749077490775e-06,
        "epoch": 30.14760147601476,
        "step": 8170
    },
    {
        "loss": 0.1317,
        "grad_norm": 1.0001376867294312,
        "learning_rate": 6.134686346863469e-06,
        "epoch": 30.18450184501845,
        "step": 8180
    },
    {
        "loss": 0.1624,
        "grad_norm": 1.809432029724121,
        "learning_rate": 6.111623616236162e-06,
        "epoch": 30.22140221402214,
        "step": 8190
    },
    {
        "loss": 0.189,
        "grad_norm": 55.99293518066406,
        "learning_rate": 6.0885608856088565e-06,
        "epoch": 30.25830258302583,
        "step": 8200
    },
    {
        "loss": 0.1689,
        "grad_norm": 1.1751905679702759,
        "learning_rate": 6.06549815498155e-06,
        "epoch": 30.29520295202952,
        "step": 8210
    },
    {
        "loss": 0.1464,
        "grad_norm": 5.769439220428467,
        "learning_rate": 6.042435424354244e-06,
        "epoch": 30.33210332103321,
        "step": 8220
    },
    {
        "loss": 0.2003,
        "grad_norm": 0.9357433915138245,
        "learning_rate": 6.0193726937269375e-06,
        "epoch": 30.3690036900369,
        "step": 8230
    },
    {
        "loss": 0.2106,
        "grad_norm": 2.487405300140381,
        "learning_rate": 5.996309963099631e-06,
        "epoch": 30.40590405904059,
        "step": 8240
    },
    {
        "loss": 0.1501,
        "grad_norm": 0.42420947551727295,
        "learning_rate": 5.973247232472325e-06,
        "epoch": 30.44280442804428,
        "step": 8250
    },
    {
        "loss": 0.2499,
        "grad_norm": 9.240561485290527,
        "learning_rate": 5.9501845018450185e-06,
        "epoch": 30.47970479704797,
        "step": 8260
    },
    {
        "loss": 0.1338,
        "grad_norm": 15.533337593078613,
        "learning_rate": 5.927121771217713e-06,
        "epoch": 30.51660516605166,
        "step": 8270
    },
    {
        "loss": 0.0795,
        "grad_norm": 0.4654878079891205,
        "learning_rate": 5.904059040590406e-06,
        "epoch": 30.55350553505535,
        "step": 8280
    },
    {
        "loss": 0.1621,
        "grad_norm": 3.2676873207092285,
        "learning_rate": 5.8809963099631e-06,
        "epoch": 30.59040590405904,
        "step": 8290
    },
    {
        "loss": 0.2123,
        "grad_norm": 7.98141622543335,
        "learning_rate": 5.857933579335794e-06,
        "epoch": 30.627306273062732,
        "step": 8300
    },
    {
        "loss": 0.129,
        "grad_norm": 0.716516375541687,
        "learning_rate": 5.834870848708487e-06,
        "epoch": 30.66420664206642,
        "step": 8310
    },
    {
        "loss": 0.2189,
        "grad_norm": 3.990476369857788,
        "learning_rate": 5.8118081180811805e-06,
        "epoch": 30.70110701107011,
        "step": 8320
    },
    {
        "loss": 0.1037,
        "grad_norm": 4.430789470672607,
        "learning_rate": 5.788745387453875e-06,
        "epoch": 30.7380073800738,
        "step": 8330
    },
    {
        "loss": 0.2561,
        "grad_norm": 2.4899301528930664,
        "learning_rate": 5.765682656826569e-06,
        "epoch": 30.774907749077492,
        "step": 8340
    },
    {
        "loss": 0.1522,
        "grad_norm": 1.0253523588180542,
        "learning_rate": 5.742619926199262e-06,
        "epoch": 30.81180811808118,
        "step": 8350
    },
    {
        "loss": 0.2061,
        "grad_norm": 16.13717269897461,
        "learning_rate": 5.7195571955719566e-06,
        "epoch": 30.84870848708487,
        "step": 8360
    },
    {
        "loss": 0.2305,
        "grad_norm": 11.341228485107422,
        "learning_rate": 5.69649446494465e-06,
        "epoch": 30.88560885608856,
        "step": 8370
    },
    {
        "loss": 0.197,
        "grad_norm": 1.8487094640731812,
        "learning_rate": 5.673431734317343e-06,
        "epoch": 30.922509225092252,
        "step": 8380
    },
    {
        "loss": 0.1678,
        "grad_norm": 3.4597978591918945,
        "learning_rate": 5.650369003690037e-06,
        "epoch": 30.95940959409594,
        "step": 8390
    },
    {
        "loss": 0.2424,
        "grad_norm": 3.92104172706604,
        "learning_rate": 5.627306273062731e-06,
        "epoch": 30.99630996309963,
        "step": 8400
    },
    {
        "eval_loss": 0.7157536149024963,
        "eval_accuracy": 0.85793,
        "eval_precision": 0.82504,
        "eval_recall": 0.90244,
        "eval_f1": 0.86201,
        "eval_runtime": 18.1085,
        "eval_samples_per_second": 59.861,
        "eval_steps_per_second": 3.755,
        "epoch": 31.0,
        "step": 8401
    },
    {
        "loss": 0.1696,
        "grad_norm": 5.072681427001953,
        "learning_rate": 5.604243542435424e-06,
        "epoch": 31.03321033210332,
        "step": 8410
    },
    {
        "loss": 0.0865,
        "grad_norm": 4.917440891265869,
        "learning_rate": 5.5811808118081185e-06,
        "epoch": 31.070110701107012,
        "step": 8420
    },
    {
        "loss": 0.1851,
        "grad_norm": 4.272695064544678,
        "learning_rate": 5.558118081180812e-06,
        "epoch": 31.1070110701107,
        "step": 8430
    },
    {
        "loss": 0.2573,
        "grad_norm": 16.21709442138672,
        "learning_rate": 5.535055350553506e-06,
        "epoch": 31.14391143911439,
        "step": 8440
    },
    {
        "loss": 0.187,
        "grad_norm": 3.5021536350250244,
        "learning_rate": 5.5119926199261995e-06,
        "epoch": 31.18081180811808,
        "step": 8450
    },
    {
        "loss": 0.1207,
        "grad_norm": 4.034608840942383,
        "learning_rate": 5.488929889298893e-06,
        "epoch": 31.217712177121772,
        "step": 8460
    },
    {
        "loss": 0.1265,
        "grad_norm": 1.7982460260391235,
        "learning_rate": 5.465867158671587e-06,
        "epoch": 31.25461254612546,
        "step": 8470
    },
    {
        "loss": 0.1307,
        "grad_norm": 0.5163264870643616,
        "learning_rate": 5.4428044280442805e-06,
        "epoch": 31.29151291512915,
        "step": 8480
    },
    {
        "loss": 0.1369,
        "grad_norm": 1.9568538665771484,
        "learning_rate": 5.419741697416975e-06,
        "epoch": 31.328413284132843,
        "step": 8490
    },
    {
        "loss": 0.2,
        "grad_norm": 6.926463603973389,
        "learning_rate": 5.396678966789668e-06,
        "epoch": 31.365313653136532,
        "step": 8500
    },
    {
        "loss": 0.2214,
        "grad_norm": 9.46789264678955,
        "learning_rate": 5.373616236162362e-06,
        "epoch": 31.40221402214022,
        "step": 8510
    },
    {
        "loss": 0.1489,
        "grad_norm": 8.325406074523926,
        "learning_rate": 5.350553505535055e-06,
        "epoch": 31.43911439114391,
        "step": 8520
    },
    {
        "loss": 0.1583,
        "grad_norm": 10.651646614074707,
        "learning_rate": 5.327490774907749e-06,
        "epoch": 31.476014760147603,
        "step": 8530
    },
    {
        "loss": 0.1953,
        "grad_norm": 0.534975528717041,
        "learning_rate": 5.304428044280443e-06,
        "epoch": 31.512915129151292,
        "step": 8540
    },
    {
        "loss": 0.0842,
        "grad_norm": 28.68838882446289,
        "learning_rate": 5.281365313653137e-06,
        "epoch": 31.54981549815498,
        "step": 8550
    },
    {
        "loss": 0.2596,
        "grad_norm": 4.950888156890869,
        "learning_rate": 5.258302583025831e-06,
        "epoch": 31.58671586715867,
        "step": 8560
    },
    {
        "loss": 0.243,
        "grad_norm": 1.557280421257019,
        "learning_rate": 5.235239852398524e-06,
        "epoch": 31.623616236162363,
        "step": 8570
    },
    {
        "loss": 0.1269,
        "grad_norm": 0.7769950032234192,
        "learning_rate": 5.212177121771218e-06,
        "epoch": 31.660516605166052,
        "step": 8580
    },
    {
        "loss": 0.2034,
        "grad_norm": 11.55051040649414,
        "learning_rate": 5.189114391143911e-06,
        "epoch": 31.69741697416974,
        "step": 8590
    },
    {
        "loss": 0.1412,
        "grad_norm": 4.616849899291992,
        "learning_rate": 5.166051660516605e-06,
        "epoch": 31.73431734317343,
        "step": 8600
    },
    {
        "loss": 0.1859,
        "grad_norm": 2.486804723739624,
        "learning_rate": 5.142988929889299e-06,
        "epoch": 31.771217712177123,
        "step": 8610
    },
    {
        "loss": 0.1345,
        "grad_norm": 1.231319546699524,
        "learning_rate": 5.119926199261993e-06,
        "epoch": 31.80811808118081,
        "step": 8620
    },
    {
        "loss": 0.1746,
        "grad_norm": 1.8589595556259155,
        "learning_rate": 5.096863468634686e-06,
        "epoch": 31.8450184501845,
        "step": 8630
    },
    {
        "loss": 0.2633,
        "grad_norm": 4.247391223907471,
        "learning_rate": 5.0738007380073806e-06,
        "epoch": 31.881918819188193,
        "step": 8640
    },
    {
        "loss": 0.2623,
        "grad_norm": 0.5576940774917603,
        "learning_rate": 5.050738007380074e-06,
        "epoch": 31.918819188191883,
        "step": 8650
    },
    {
        "loss": 0.1666,
        "grad_norm": 52.23822021484375,
        "learning_rate": 5.027675276752767e-06,
        "epoch": 31.95571955719557,
        "step": 8660
    },
    {
        "loss": 0.211,
        "grad_norm": 10.118916511535645,
        "learning_rate": 5.0046125461254616e-06,
        "epoch": 31.99261992619926,
        "step": 8670
    },
    {
        "eval_loss": 0.7595528960227966,
        "eval_accuracy": 0.8524,
        "eval_precision": 0.8188,
        "eval_recall": 0.89869,
        "eval_f1": 0.85689,
        "eval_runtime": 18.0808,
        "eval_samples_per_second": 59.953,
        "eval_steps_per_second": 3.761,
        "epoch": 32.0,
        "step": 8672
    },
    {
        "loss": 0.1436,
        "grad_norm": 2.4137094020843506,
        "learning_rate": 4.981549815498155e-06,
        "epoch": 32.02952029520295,
        "step": 8680
    },
    {
        "loss": 0.2117,
        "grad_norm": 17.947044372558594,
        "learning_rate": 4.958487084870849e-06,
        "epoch": 32.06642066420664,
        "step": 8690
    },
    {
        "loss": 0.121,
        "grad_norm": 4.764010429382324,
        "learning_rate": 4.9354243542435426e-06,
        "epoch": 32.103321033210335,
        "step": 8700
    },
    {
        "loss": 0.1795,
        "grad_norm": 3.3170578479766846,
        "learning_rate": 4.912361623616237e-06,
        "epoch": 32.140221402214024,
        "step": 8710
    },
    {
        "loss": 0.1348,
        "grad_norm": 6.880615711212158,
        "learning_rate": 4.88929889298893e-06,
        "epoch": 32.17712177121771,
        "step": 8720
    },
    {
        "loss": 0.165,
        "grad_norm": 26.232532501220703,
        "learning_rate": 4.8662361623616235e-06,
        "epoch": 32.2140221402214,
        "step": 8730
    },
    {
        "loss": 0.2101,
        "grad_norm": 1.398903250694275,
        "learning_rate": 4.843173431734318e-06,
        "epoch": 32.25092250922509,
        "step": 8740
    },
    {
        "loss": 0.151,
        "grad_norm": 3.477900743484497,
        "learning_rate": 4.820110701107011e-06,
        "epoch": 32.28782287822878,
        "step": 8750
    },
    {
        "loss": 0.1537,
        "grad_norm": 14.046688079833984,
        "learning_rate": 4.797047970479705e-06,
        "epoch": 32.32472324723247,
        "step": 8760
    },
    {
        "loss": 0.1245,
        "grad_norm": 0.6934323906898499,
        "learning_rate": 4.773985239852399e-06,
        "epoch": 32.36162361623616,
        "step": 8770
    },
    {
        "loss": 0.1904,
        "grad_norm": 9.11659049987793,
        "learning_rate": 4.750922509225093e-06,
        "epoch": 32.398523985239855,
        "step": 8780
    },
    {
        "loss": 0.2025,
        "grad_norm": 7.8166422843933105,
        "learning_rate": 4.727859778597786e-06,
        "epoch": 32.435424354243544,
        "step": 8790
    },
    {
        "loss": 0.0931,
        "grad_norm": 2.3803462982177734,
        "learning_rate": 4.70479704797048e-06,
        "epoch": 32.47232472324723,
        "step": 8800
    },
    {
        "loss": 0.1814,
        "grad_norm": 5.5509772300720215,
        "learning_rate": 4.681734317343173e-06,
        "epoch": 32.50922509225092,
        "step": 8810
    },
    {
        "loss": 0.1573,
        "grad_norm": 8.485629081726074,
        "learning_rate": 4.658671586715867e-06,
        "epoch": 32.54612546125461,
        "step": 8820
    },
    {
        "loss": 0.255,
        "grad_norm": 1.1356935501098633,
        "learning_rate": 4.635608856088561e-06,
        "epoch": 32.5830258302583,
        "step": 8830
    },
    {
        "loss": 0.1196,
        "grad_norm": 2.0536413192749023,
        "learning_rate": 4.612546125461255e-06,
        "epoch": 32.61992619926199,
        "step": 8840
    },
    {
        "loss": 0.1465,
        "grad_norm": 9.869577407836914,
        "learning_rate": 4.589483394833949e-06,
        "epoch": 32.656826568265686,
        "step": 8850
    },
    {
        "loss": 0.1661,
        "grad_norm": 1.7397069931030273,
        "learning_rate": 4.566420664206643e-06,
        "epoch": 32.693726937269375,
        "step": 8860
    },
    {
        "loss": 0.1428,
        "grad_norm": 0.5626528859138489,
        "learning_rate": 4.543357933579336e-06,
        "epoch": 32.730627306273064,
        "step": 8870
    },
    {
        "loss": 0.1662,
        "grad_norm": 1.751261591911316,
        "learning_rate": 4.520295202952029e-06,
        "epoch": 32.76752767527675,
        "step": 8880
    },
    {
        "loss": 0.1004,
        "grad_norm": 4.384768009185791,
        "learning_rate": 4.497232472324724e-06,
        "epoch": 32.80442804428044,
        "step": 8890
    },
    {
        "loss": 0.1714,
        "grad_norm": 2.816194534301758,
        "learning_rate": 4.474169741697417e-06,
        "epoch": 32.84132841328413,
        "step": 8900
    },
    {
        "loss": 0.1383,
        "grad_norm": 2.777904510498047,
        "learning_rate": 4.451107011070111e-06,
        "epoch": 32.87822878228782,
        "step": 8910
    },
    {
        "loss": 0.1068,
        "grad_norm": 1.9330371618270874,
        "learning_rate": 4.428044280442805e-06,
        "epoch": 32.91512915129151,
        "step": 8920
    },
    {
        "loss": 0.2185,
        "grad_norm": 1.2183191776275635,
        "learning_rate": 4.404981549815498e-06,
        "epoch": 32.952029520295206,
        "step": 8930
    },
    {
        "loss": 0.1835,
        "grad_norm": 4.084788799285889,
        "learning_rate": 4.381918819188192e-06,
        "epoch": 32.988929889298895,
        "step": 8940
    },
    {
        "eval_loss": 0.7542526125907898,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.82021,
        "eval_recall": 0.89869,
        "eval_f1": 0.85765,
        "eval_runtime": 18.122,
        "eval_samples_per_second": 59.817,
        "eval_steps_per_second": 3.752,
        "epoch": 33.0,
        "step": 8943
    },
    {
        "loss": 0.1415,
        "grad_norm": 7.716740131378174,
        "learning_rate": 4.358856088560886e-06,
        "epoch": 33.025830258302584,
        "step": 8950
    },
    {
        "loss": 0.1278,
        "grad_norm": 2.0133373737335205,
        "learning_rate": 4.33579335793358e-06,
        "epoch": 33.06273062730627,
        "step": 8960
    },
    {
        "loss": 0.1148,
        "grad_norm": 1.2379883527755737,
        "learning_rate": 4.312730627306273e-06,
        "epoch": 33.09963099630996,
        "step": 8970
    },
    {
        "loss": 0.2184,
        "grad_norm": 6.730008125305176,
        "learning_rate": 4.289667896678967e-06,
        "epoch": 33.13653136531365,
        "step": 8980
    },
    {
        "loss": 0.1299,
        "grad_norm": 7.786866664886475,
        "learning_rate": 4.266605166051661e-06,
        "epoch": 33.17343173431734,
        "step": 8990
    },
    {
        "loss": 0.1723,
        "grad_norm": 1.3666658401489258,
        "learning_rate": 4.243542435424354e-06,
        "epoch": 33.210332103321036,
        "step": 9000
    },
    {
        "loss": 0.1597,
        "grad_norm": 2.99237322807312,
        "learning_rate": 4.2204797047970476e-06,
        "epoch": 33.247232472324725,
        "step": 9010
    },
    {
        "loss": 0.2056,
        "grad_norm": 4.240833759307861,
        "learning_rate": 4.197416974169742e-06,
        "epoch": 33.284132841328415,
        "step": 9020
    },
    {
        "loss": 0.1776,
        "grad_norm": 0.3397708833217621,
        "learning_rate": 4.174354243542435e-06,
        "epoch": 33.321033210332104,
        "step": 9030
    },
    {
        "loss": 0.1765,
        "grad_norm": 7.69875955581665,
        "learning_rate": 4.151291512915129e-06,
        "epoch": 33.35793357933579,
        "step": 9040
    },
    {
        "loss": 0.1871,
        "grad_norm": 5.165705680847168,
        "learning_rate": 4.128228782287824e-06,
        "epoch": 33.39483394833948,
        "step": 9050
    },
    {
        "loss": 0.2053,
        "grad_norm": 4.115711688995361,
        "learning_rate": 4.105166051660517e-06,
        "epoch": 33.43173431734317,
        "step": 9060
    },
    {
        "loss": 0.2245,
        "grad_norm": 20.839265823364258,
        "learning_rate": 4.08210332103321e-06,
        "epoch": 33.46863468634686,
        "step": 9070
    },
    {
        "loss": 0.1223,
        "grad_norm": 2.3485867977142334,
        "learning_rate": 4.059040590405904e-06,
        "epoch": 33.505535055350556,
        "step": 9080
    },
    {
        "loss": 0.1788,
        "grad_norm": 1.5895737409591675,
        "learning_rate": 4.035977859778598e-06,
        "epoch": 33.542435424354245,
        "step": 9090
    },
    {
        "loss": 0.1311,
        "grad_norm": 2.7864787578582764,
        "learning_rate": 4.012915129151291e-06,
        "epoch": 33.579335793357934,
        "step": 9100
    },
    {
        "loss": 0.1716,
        "grad_norm": 23.269439697265625,
        "learning_rate": 3.989852398523986e-06,
        "epoch": 33.61623616236162,
        "step": 9110
    },
    {
        "loss": 0.2069,
        "grad_norm": 1.2035350799560547,
        "learning_rate": 3.966789667896679e-06,
        "epoch": 33.65313653136531,
        "step": 9120
    },
    {
        "loss": 0.1216,
        "grad_norm": 0.8044036626815796,
        "learning_rate": 3.943726937269373e-06,
        "epoch": 33.690036900369,
        "step": 9130
    },
    {
        "loss": 0.139,
        "grad_norm": 0.8956052660942078,
        "learning_rate": 3.920664206642067e-06,
        "epoch": 33.72693726937269,
        "step": 9140
    },
    {
        "loss": 0.1401,
        "grad_norm": 4.820018768310547,
        "learning_rate": 3.89760147601476e-06,
        "epoch": 33.76383763837639,
        "step": 9150
    },
    {
        "loss": 0.255,
        "grad_norm": 19.535850524902344,
        "learning_rate": 3.874538745387454e-06,
        "epoch": 33.800738007380076,
        "step": 9160
    },
    {
        "loss": 0.1651,
        "grad_norm": 3.4569902420043945,
        "learning_rate": 3.851476014760148e-06,
        "epoch": 33.837638376383765,
        "step": 9170
    },
    {
        "loss": 0.1329,
        "grad_norm": 0.9678484797477722,
        "learning_rate": 3.828413284132842e-06,
        "epoch": 33.874538745387454,
        "step": 9180
    },
    {
        "loss": 0.1592,
        "grad_norm": 0.6408455967903137,
        "learning_rate": 3.8053505535055352e-06,
        "epoch": 33.91143911439114,
        "step": 9190
    },
    {
        "loss": 0.1518,
        "grad_norm": 3.9522764682769775,
        "learning_rate": 3.782287822878229e-06,
        "epoch": 33.94833948339483,
        "step": 9200
    },
    {
        "loss": 0.1658,
        "grad_norm": 2.459040641784668,
        "learning_rate": 3.7592250922509224e-06,
        "epoch": 33.98523985239852,
        "step": 9210
    },
    {
        "eval_loss": 0.7674363255500793,
        "eval_accuracy": 0.85609,
        "eval_precision": 0.82333,
        "eval_recall": 0.90056,
        "eval_f1": 0.86022,
        "eval_runtime": 18.0875,
        "eval_samples_per_second": 59.931,
        "eval_steps_per_second": 3.759,
        "epoch": 34.0,
        "step": 9214
    },
    {
        "train_runtime": 7899.5653,
        "train_samples_per_second": 21.951,
        "train_steps_per_second": 1.372,
        "total_flos": 1.93899692247552e+16,
        "train_loss": 0.2553711532770177,
        "epoch": 34.0,
        "step": 9214
    }
]