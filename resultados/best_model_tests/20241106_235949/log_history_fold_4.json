[
    {
        "loss": 0.644,
        "grad_norm": 6.689562797546387,
        "learning_rate": 2.4976937269372695e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.5113,
        "grad_norm": 13.291897773742676,
        "learning_rate": 2.495387453874539e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.4693,
        "grad_norm": 9.568613052368164,
        "learning_rate": 2.493081180811808e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.6113,
        "grad_norm": 10.681076049804688,
        "learning_rate": 2.4907749077490778e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.7333,
        "grad_norm": 28.166292190551758,
        "learning_rate": 2.488468634686347e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.4531,
        "grad_norm": 4.533052444458008,
        "learning_rate": 2.4861623616236163e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.4777,
        "grad_norm": 7.596691131591797,
        "learning_rate": 2.4838560885608857e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.4402,
        "grad_norm": 6.8262128829956055,
        "learning_rate": 2.481549815498155e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.4492,
        "grad_norm": 2.216325044631958,
        "learning_rate": 2.4792435424354242e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.5861,
        "grad_norm": 4.97515344619751,
        "learning_rate": 2.476937269372694e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.434,
        "grad_norm": 2.2645561695098877,
        "learning_rate": 2.474630996309963e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.5296,
        "grad_norm": 3.223371744155884,
        "learning_rate": 2.472324723247233e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.4642,
        "grad_norm": 5.064701080322266,
        "learning_rate": 2.470018450184502e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.4947,
        "grad_norm": 4.813338279724121,
        "learning_rate": 2.4677121771217714e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.4084,
        "grad_norm": 4.263914108276367,
        "learning_rate": 2.4654059040590408e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.3965,
        "grad_norm": 5.4192681312561035,
        "learning_rate": 2.46309963099631e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.3614,
        "grad_norm": 5.3669610023498535,
        "learning_rate": 2.4607933579335796e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.594,
        "grad_norm": 9.358465194702148,
        "learning_rate": 2.4584870848708487e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.4243,
        "grad_norm": 3.4912309646606445,
        "learning_rate": 2.456180811808118e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.4687,
        "grad_norm": 5.736955165863037,
        "learning_rate": 2.4538745387453876e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.509,
        "grad_norm": 3.998936414718628,
        "learning_rate": 2.451568265682657e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.4726,
        "grad_norm": 3.2312095165252686,
        "learning_rate": 2.4492619926199264e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.4466,
        "grad_norm": 4.481929779052734,
        "learning_rate": 2.4469557195571958e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.4129,
        "grad_norm": 4.842406272888184,
        "learning_rate": 2.444649446494465e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.5178,
        "grad_norm": 3.8602488040924072,
        "learning_rate": 2.4423431734317347e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.4973,
        "grad_norm": 3.8611629009246826,
        "learning_rate": 2.4400369003690038e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.4181,
        "grad_norm": 2.200854778289795,
        "learning_rate": 2.4377306273062732e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.46250131726264954,
        "eval_accuracy": 0.81365,
        "eval_precision": 0.78319,
        "eval_recall": 0.86456,
        "eval_f1": 0.82187,
        "eval_runtime": 18.1137,
        "eval_samples_per_second": 59.844,
        "eval_steps_per_second": 3.754,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.5806,
        "grad_norm": 3.6381261348724365,
        "learning_rate": 2.4354243542435426e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.4403,
        "grad_norm": 4.803873062133789,
        "learning_rate": 2.4331180811808117e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.4057,
        "grad_norm": 2.1701409816741943,
        "learning_rate": 2.4308118081180815e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.441,
        "grad_norm": 5.363247871398926,
        "learning_rate": 2.4285055350553505e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.3577,
        "grad_norm": 2.262157917022705,
        "learning_rate": 2.42619926199262e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.4773,
        "grad_norm": 4.94021463394165,
        "learning_rate": 2.4238929889298894e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.4264,
        "grad_norm": 1.490281581878662,
        "learning_rate": 2.4215867158671588e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.4665,
        "grad_norm": 12.202421188354492,
        "learning_rate": 2.4192804428044282e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.4633,
        "grad_norm": 13.517775535583496,
        "learning_rate": 2.4169741697416977e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.6269,
        "grad_norm": 6.720949649810791,
        "learning_rate": 2.4146678966789667e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.4742,
        "grad_norm": 4.317954063415527,
        "learning_rate": 2.4123616236162365e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.4176,
        "grad_norm": 2.450795888900757,
        "learning_rate": 2.4100553505535056e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.4305,
        "grad_norm": 4.080053806304932,
        "learning_rate": 2.407749077490775e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.3698,
        "grad_norm": 1.936594009399414,
        "learning_rate": 2.4054428044280444e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.4556,
        "grad_norm": 2.9475817680358887,
        "learning_rate": 2.403136531365314e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.4139,
        "grad_norm": 4.654824256896973,
        "learning_rate": 2.4008302583025833e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.4525,
        "grad_norm": 2.271437644958496,
        "learning_rate": 2.3985239852398524e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.4265,
        "grad_norm": 2.876068115234375,
        "learning_rate": 2.3962177121771218e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.419,
        "grad_norm": 3.5292677879333496,
        "learning_rate": 2.3939114391143912e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.3963,
        "grad_norm": 4.0565643310546875,
        "learning_rate": 2.3916051660516606e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.4045,
        "grad_norm": 14.399368286132812,
        "learning_rate": 2.38929889298893e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4578,
        "grad_norm": 2.356153726577759,
        "learning_rate": 2.3869926199261995e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.4332,
        "grad_norm": 2.4977376461029053,
        "learning_rate": 2.3846863468634686e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.367,
        "grad_norm": 3.079354763031006,
        "learning_rate": 2.3823800738007383e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.3371,
        "grad_norm": 2.0307302474975586,
        "learning_rate": 2.3800738007380074e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.3558,
        "grad_norm": 2.36147403717041,
        "learning_rate": 2.377767527675277e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.2938,
        "grad_norm": 6.796723365783691,
        "learning_rate": 2.3754612546125462e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.4651482105255127,
        "eval_accuracy": 0.81919,
        "eval_precision": 0.76923,
        "eval_recall": 0.90909,
        "eval_f1": 0.83333,
        "eval_runtime": 18.0853,
        "eval_samples_per_second": 59.938,
        "eval_steps_per_second": 3.76,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.3159,
        "grad_norm": 3.465080499649048,
        "learning_rate": 2.3731549815498157e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.3545,
        "grad_norm": 2.173863410949707,
        "learning_rate": 2.370848708487085e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.3226,
        "grad_norm": 1.5107980966567993,
        "learning_rate": 2.3685424354243542e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.357,
        "grad_norm": 3.376124143600464,
        "learning_rate": 2.3662361623616236e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.3708,
        "grad_norm": 4.6456475257873535,
        "learning_rate": 2.363929889298893e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.4343,
        "grad_norm": 2.3479132652282715,
        "learning_rate": 2.3616236162361624e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.379,
        "grad_norm": 2.2059271335601807,
        "learning_rate": 2.359317343173432e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4006,
        "grad_norm": 2.0439000129699707,
        "learning_rate": 2.3570110701107013e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.4982,
        "grad_norm": 3.469966173171997,
        "learning_rate": 2.3547047970479704e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.3553,
        "grad_norm": 2.347581148147583,
        "learning_rate": 2.35239852398524e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.5259,
        "grad_norm": 1.9814631938934326,
        "learning_rate": 2.3500922509225092e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.4182,
        "grad_norm": 1.7710742950439453,
        "learning_rate": 2.347785977859779e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.3713,
        "grad_norm": 4.1638312339782715,
        "learning_rate": 2.345479704797048e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.3884,
        "grad_norm": 6.957355499267578,
        "learning_rate": 2.3431734317343175e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.3984,
        "grad_norm": 2.6260015964508057,
        "learning_rate": 2.340867158671587e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.4162,
        "grad_norm": 6.055692195892334,
        "learning_rate": 2.3385608856088563e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.3533,
        "grad_norm": 1.81559157371521,
        "learning_rate": 2.3362546125461258e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.4054,
        "grad_norm": 5.802371978759766,
        "learning_rate": 2.333948339483395e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.3187,
        "grad_norm": 4.792126655578613,
        "learning_rate": 2.3316420664206643e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4015,
        "grad_norm": 1.823968529701233,
        "learning_rate": 2.3293357933579337e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.3982,
        "grad_norm": 1.7172502279281616,
        "learning_rate": 2.327029520295203e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4034,
        "grad_norm": 2.5112452507019043,
        "learning_rate": 2.3247232472324722e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4335,
        "grad_norm": 4.413073539733887,
        "learning_rate": 2.322416974169742e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.4336,
        "grad_norm": 2.4504635334014893,
        "learning_rate": 2.320110701107011e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.379,
        "grad_norm": 5.613186836242676,
        "learning_rate": 2.3178044280442808e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.3968,
        "grad_norm": 4.528573036193848,
        "learning_rate": 2.31549815498155e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.4692,
        "grad_norm": 3.9026451110839844,
        "learning_rate": 2.3131918819188193e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.39777225255966187,
        "eval_accuracy": 0.82841,
        "eval_precision": 0.7815,
        "eval_recall": 0.90909,
        "eval_f1": 0.84048,
        "eval_runtime": 18.08,
        "eval_samples_per_second": 59.956,
        "eval_steps_per_second": 3.761,
        "epoch": 3.0,
        "step": 813
    },
    {
        "loss": 0.4093,
        "grad_norm": 1.7006213665008545,
        "learning_rate": 2.3108856088560887e-05,
        "epoch": 3.025830258302583,
        "step": 820
    },
    {
        "loss": 0.3474,
        "grad_norm": 2.7452826499938965,
        "learning_rate": 2.308579335793358e-05,
        "epoch": 3.062730627306273,
        "step": 830
    },
    {
        "loss": 0.3783,
        "grad_norm": 5.182934761047363,
        "learning_rate": 2.3062730627306276e-05,
        "epoch": 3.0996309963099633,
        "step": 840
    },
    {
        "loss": 0.378,
        "grad_norm": 4.3512654304504395,
        "learning_rate": 2.3039667896678967e-05,
        "epoch": 3.1365313653136533,
        "step": 850
    },
    {
        "loss": 0.4444,
        "grad_norm": 2.007906198501587,
        "learning_rate": 2.301660516605166e-05,
        "epoch": 3.1734317343173433,
        "step": 860
    },
    {
        "loss": 0.4377,
        "grad_norm": 1.4913872480392456,
        "learning_rate": 2.2993542435424355e-05,
        "epoch": 3.2103321033210332,
        "step": 870
    },
    {
        "loss": 0.3788,
        "grad_norm": 2.079470157623291,
        "learning_rate": 2.297047970479705e-05,
        "epoch": 3.2472324723247232,
        "step": 880
    },
    {
        "loss": 0.3441,
        "grad_norm": 2.5257930755615234,
        "learning_rate": 2.294741697416974e-05,
        "epoch": 3.284132841328413,
        "step": 890
    },
    {
        "loss": 0.4525,
        "grad_norm": 1.438981056213379,
        "learning_rate": 2.2924354243542438e-05,
        "epoch": 3.321033210332103,
        "step": 900
    },
    {
        "loss": 0.3739,
        "grad_norm": 0.9332534670829773,
        "learning_rate": 2.290129151291513e-05,
        "epoch": 3.357933579335793,
        "step": 910
    },
    {
        "loss": 0.3522,
        "grad_norm": 4.075337886810303,
        "learning_rate": 2.2878228782287826e-05,
        "epoch": 3.3948339483394836,
        "step": 920
    },
    {
        "loss": 0.4104,
        "grad_norm": 2.0454940795898438,
        "learning_rate": 2.2855166051660517e-05,
        "epoch": 3.4317343173431736,
        "step": 930
    },
    {
        "loss": 0.4806,
        "grad_norm": 2.251222610473633,
        "learning_rate": 2.283210332103321e-05,
        "epoch": 3.4686346863468636,
        "step": 940
    },
    {
        "loss": 0.3372,
        "grad_norm": 3.669229507446289,
        "learning_rate": 2.2809040590405906e-05,
        "epoch": 3.5055350553505535,
        "step": 950
    },
    {
        "loss": 0.4041,
        "grad_norm": 2.417821168899536,
        "learning_rate": 2.27859778597786e-05,
        "epoch": 3.5424354243542435,
        "step": 960
    },
    {
        "loss": 0.3699,
        "grad_norm": 3.092550039291382,
        "learning_rate": 2.2762915129151294e-05,
        "epoch": 3.5793357933579335,
        "step": 970
    },
    {
        "loss": 0.4126,
        "grad_norm": 2.005204439163208,
        "learning_rate": 2.2739852398523985e-05,
        "epoch": 3.6162361623616235,
        "step": 980
    },
    {
        "loss": 0.3061,
        "grad_norm": 5.271949768066406,
        "learning_rate": 2.271678966789668e-05,
        "epoch": 3.6531365313653135,
        "step": 990
    },
    {
        "loss": 0.5124,
        "grad_norm": 8.305621147155762,
        "learning_rate": 2.2693726937269373e-05,
        "epoch": 3.6900369003690034,
        "step": 1000
    },
    {
        "loss": 0.5517,
        "grad_norm": 1.2734001874923706,
        "learning_rate": 2.2670664206642068e-05,
        "epoch": 3.726937269372694,
        "step": 1010
    },
    {
        "loss": 0.3756,
        "grad_norm": 4.866008758544922,
        "learning_rate": 2.2647601476014762e-05,
        "epoch": 3.763837638376384,
        "step": 1020
    },
    {
        "loss": 0.3897,
        "grad_norm": 2.927565097808838,
        "learning_rate": 2.2624538745387456e-05,
        "epoch": 3.800738007380074,
        "step": 1030
    },
    {
        "loss": 0.3191,
        "grad_norm": 1.1960121393203735,
        "learning_rate": 2.2601476014760147e-05,
        "epoch": 3.837638376383764,
        "step": 1040
    },
    {
        "loss": 0.3468,
        "grad_norm": 4.495107650756836,
        "learning_rate": 2.2578413284132844e-05,
        "epoch": 3.874538745387454,
        "step": 1050
    },
    {
        "loss": 0.4739,
        "grad_norm": 7.518266201019287,
        "learning_rate": 2.2555350553505535e-05,
        "epoch": 3.911439114391144,
        "step": 1060
    },
    {
        "loss": 0.3327,
        "grad_norm": 1.3658461570739746,
        "learning_rate": 2.253228782287823e-05,
        "epoch": 3.948339483394834,
        "step": 1070
    },
    {
        "loss": 0.3399,
        "grad_norm": 2.928985118865967,
        "learning_rate": 2.2509225092250924e-05,
        "epoch": 3.985239852398524,
        "step": 1080
    },
    {
        "eval_loss": 0.440569669008255,
        "eval_accuracy": 0.83764,
        "eval_precision": 0.78227,
        "eval_recall": 0.93321,
        "eval_f1": 0.8511,
        "eval_runtime": 18.0775,
        "eval_samples_per_second": 59.964,
        "eval_steps_per_second": 3.762,
        "epoch": 4.0,
        "step": 1084
    },
    {
        "loss": 0.3406,
        "grad_norm": 1.0984944105148315,
        "learning_rate": 2.2486162361623618e-05,
        "epoch": 4.022140221402214,
        "step": 1090
    },
    {
        "loss": 0.3246,
        "grad_norm": 6.153700828552246,
        "learning_rate": 2.2463099630996312e-05,
        "epoch": 4.059040590405904,
        "step": 1100
    },
    {
        "loss": 0.4346,
        "grad_norm": 1.6348695755004883,
        "learning_rate": 2.2440036900369006e-05,
        "epoch": 4.095940959409594,
        "step": 1110
    },
    {
        "loss": 0.3739,
        "grad_norm": 1.5911747217178345,
        "learning_rate": 2.2416974169741697e-05,
        "epoch": 4.132841328413284,
        "step": 1120
    },
    {
        "loss": 0.2905,
        "grad_norm": 4.534834861755371,
        "learning_rate": 2.239391143911439e-05,
        "epoch": 4.169741697416974,
        "step": 1130
    },
    {
        "loss": 0.3764,
        "grad_norm": 3.0303568840026855,
        "learning_rate": 2.2370848708487086e-05,
        "epoch": 4.206642066420664,
        "step": 1140
    },
    {
        "loss": 0.3345,
        "grad_norm": 12.411394119262695,
        "learning_rate": 2.234778597785978e-05,
        "epoch": 4.243542435424354,
        "step": 1150
    },
    {
        "loss": 0.3597,
        "grad_norm": 1.1178863048553467,
        "learning_rate": 2.2324723247232474e-05,
        "epoch": 4.280442804428044,
        "step": 1160
    },
    {
        "loss": 0.3917,
        "grad_norm": 2.8000457286834717,
        "learning_rate": 2.2301660516605165e-05,
        "epoch": 4.317343173431734,
        "step": 1170
    },
    {
        "loss": 0.3613,
        "grad_norm": 1.4608560800552368,
        "learning_rate": 2.2278597785977863e-05,
        "epoch": 4.354243542435424,
        "step": 1180
    },
    {
        "loss": 0.3564,
        "grad_norm": 2.0131664276123047,
        "learning_rate": 2.2255535055350553e-05,
        "epoch": 4.391143911439114,
        "step": 1190
    },
    {
        "loss": 0.4384,
        "grad_norm": 4.277514934539795,
        "learning_rate": 2.2232472324723248e-05,
        "epoch": 4.428044280442805,
        "step": 1200
    },
    {
        "loss": 0.3464,
        "grad_norm": 2.7596726417541504,
        "learning_rate": 2.2209409594095942e-05,
        "epoch": 4.464944649446495,
        "step": 1210
    },
    {
        "loss": 0.2835,
        "grad_norm": 2.3958024978637695,
        "learning_rate": 2.2186346863468636e-05,
        "epoch": 4.501845018450185,
        "step": 1220
    },
    {
        "loss": 0.3176,
        "grad_norm": 2.9301326274871826,
        "learning_rate": 2.216328413284133e-05,
        "epoch": 4.538745387453875,
        "step": 1230
    },
    {
        "loss": 0.3166,
        "grad_norm": 1.1767597198486328,
        "learning_rate": 2.2140221402214025e-05,
        "epoch": 4.575645756457565,
        "step": 1240
    },
    {
        "loss": 0.4333,
        "grad_norm": 3.2791054248809814,
        "learning_rate": 2.2117158671586715e-05,
        "epoch": 4.612546125461255,
        "step": 1250
    },
    {
        "loss": 0.324,
        "grad_norm": 4.747604846954346,
        "learning_rate": 2.209409594095941e-05,
        "epoch": 4.649446494464945,
        "step": 1260
    },
    {
        "loss": 0.3644,
        "grad_norm": 2.4568793773651123,
        "learning_rate": 2.2071033210332104e-05,
        "epoch": 4.686346863468635,
        "step": 1270
    },
    {
        "loss": 0.2526,
        "grad_norm": 2.266815423965454,
        "learning_rate": 2.2047970479704798e-05,
        "epoch": 4.723247232472325,
        "step": 1280
    },
    {
        "loss": 0.3359,
        "grad_norm": 1.7186192274093628,
        "learning_rate": 2.2024907749077492e-05,
        "epoch": 4.760147601476015,
        "step": 1290
    },
    {
        "loss": 0.3996,
        "grad_norm": 3.5464227199554443,
        "learning_rate": 2.2001845018450183e-05,
        "epoch": 4.797047970479705,
        "step": 1300
    },
    {
        "loss": 0.4054,
        "grad_norm": 4.278067111968994,
        "learning_rate": 2.197878228782288e-05,
        "epoch": 4.833948339483395,
        "step": 1310
    },
    {
        "loss": 0.4399,
        "grad_norm": 3.6383979320526123,
        "learning_rate": 2.195571955719557e-05,
        "epoch": 4.870848708487085,
        "step": 1320
    },
    {
        "loss": 0.3912,
        "grad_norm": 1.8384480476379395,
        "learning_rate": 2.193265682656827e-05,
        "epoch": 4.907749077490775,
        "step": 1330
    },
    {
        "loss": 0.4173,
        "grad_norm": 2.2066922187805176,
        "learning_rate": 2.190959409594096e-05,
        "epoch": 4.944649446494465,
        "step": 1340
    },
    {
        "loss": 0.3534,
        "grad_norm": 6.6059699058532715,
        "learning_rate": 2.1886531365313654e-05,
        "epoch": 4.9815498154981555,
        "step": 1350
    },
    {
        "eval_loss": 0.40551257133483887,
        "eval_accuracy": 0.83764,
        "eval_precision": 0.81132,
        "eval_recall": 0.87755,
        "eval_f1": 0.84314,
        "eval_runtime": 18.0845,
        "eval_samples_per_second": 59.941,
        "eval_steps_per_second": 3.76,
        "epoch": 5.0,
        "step": 1355
    },
    {
        "loss": 0.341,
        "grad_norm": 2.7989652156829834,
        "learning_rate": 2.186346863468635e-05,
        "epoch": 5.018450184501845,
        "step": 1360
    },
    {
        "loss": 0.3973,
        "grad_norm": 4.72979736328125,
        "learning_rate": 2.1840405904059043e-05,
        "epoch": 5.055350553505535,
        "step": 1370
    },
    {
        "loss": 0.3383,
        "grad_norm": 1.4510518312454224,
        "learning_rate": 2.1817343173431734e-05,
        "epoch": 5.092250922509225,
        "step": 1380
    },
    {
        "loss": 0.3734,
        "grad_norm": 3.106400728225708,
        "learning_rate": 2.1794280442804428e-05,
        "epoch": 5.129151291512915,
        "step": 1390
    },
    {
        "loss": 0.3005,
        "grad_norm": 2.047098398208618,
        "learning_rate": 2.1771217712177122e-05,
        "epoch": 5.166051660516605,
        "step": 1400
    },
    {
        "loss": 0.3762,
        "grad_norm": 1.9589228630065918,
        "learning_rate": 2.1748154981549816e-05,
        "epoch": 5.202952029520295,
        "step": 1410
    },
    {
        "loss": 0.3115,
        "grad_norm": 2.187443494796753,
        "learning_rate": 2.172509225092251e-05,
        "epoch": 5.239852398523985,
        "step": 1420
    },
    {
        "loss": 0.2864,
        "grad_norm": 1.368087887763977,
        "learning_rate": 2.17020295202952e-05,
        "epoch": 5.276752767527675,
        "step": 1430
    },
    {
        "loss": 0.363,
        "grad_norm": 7.720425128936768,
        "learning_rate": 2.16789667896679e-05,
        "epoch": 5.313653136531365,
        "step": 1440
    },
    {
        "loss": 0.4193,
        "grad_norm": 5.904305458068848,
        "learning_rate": 2.165590405904059e-05,
        "epoch": 5.350553505535055,
        "step": 1450
    },
    {
        "loss": 0.4206,
        "grad_norm": 2.4488577842712402,
        "learning_rate": 2.1632841328413287e-05,
        "epoch": 5.387453874538745,
        "step": 1460
    },
    {
        "loss": 0.3243,
        "grad_norm": 2.7644307613372803,
        "learning_rate": 2.160977859778598e-05,
        "epoch": 5.424354243542435,
        "step": 1470
    },
    {
        "loss": 0.3239,
        "grad_norm": 4.282148361206055,
        "learning_rate": 2.1586715867158673e-05,
        "epoch": 5.461254612546125,
        "step": 1480
    },
    {
        "loss": 0.4341,
        "grad_norm": 6.474890232086182,
        "learning_rate": 2.1563653136531367e-05,
        "epoch": 5.498154981549815,
        "step": 1490
    },
    {
        "loss": 0.4047,
        "grad_norm": 2.953157663345337,
        "learning_rate": 2.154059040590406e-05,
        "epoch": 5.535055350553505,
        "step": 1500
    },
    {
        "loss": 0.3142,
        "grad_norm": 2.373333692550659,
        "learning_rate": 2.1517527675276755e-05,
        "epoch": 5.571955719557195,
        "step": 1510
    },
    {
        "loss": 0.4073,
        "grad_norm": 5.502266883850098,
        "learning_rate": 2.149446494464945e-05,
        "epoch": 5.608856088560886,
        "step": 1520
    },
    {
        "loss": 0.3583,
        "grad_norm": 4.41492223739624,
        "learning_rate": 2.147140221402214e-05,
        "epoch": 5.645756457564576,
        "step": 1530
    },
    {
        "loss": 0.346,
        "grad_norm": 9.90377140045166,
        "learning_rate": 2.1448339483394835e-05,
        "epoch": 5.682656826568266,
        "step": 1540
    },
    {
        "loss": 0.3599,
        "grad_norm": 2.759214162826538,
        "learning_rate": 2.142527675276753e-05,
        "epoch": 5.719557195571956,
        "step": 1550
    },
    {
        "loss": 0.3602,
        "grad_norm": 3.569424867630005,
        "learning_rate": 2.140221402214022e-05,
        "epoch": 5.756457564575646,
        "step": 1560
    },
    {
        "loss": 0.2672,
        "grad_norm": 1.467325210571289,
        "learning_rate": 2.1379151291512917e-05,
        "epoch": 5.793357933579336,
        "step": 1570
    },
    {
        "loss": 0.3081,
        "grad_norm": 2.0288314819335938,
        "learning_rate": 2.1356088560885608e-05,
        "epoch": 5.830258302583026,
        "step": 1580
    },
    {
        "loss": 0.3885,
        "grad_norm": 3.7381935119628906,
        "learning_rate": 2.1333025830258306e-05,
        "epoch": 5.867158671586716,
        "step": 1590
    },
    {
        "loss": 0.3351,
        "grad_norm": 2.197755813598633,
        "learning_rate": 2.1309963099630997e-05,
        "epoch": 5.904059040590406,
        "step": 1600
    },
    {
        "loss": 0.4219,
        "grad_norm": 1.5522950887680054,
        "learning_rate": 2.128690036900369e-05,
        "epoch": 5.940959409594096,
        "step": 1610
    },
    {
        "loss": 0.2881,
        "grad_norm": 2.023592233657837,
        "learning_rate": 2.1263837638376385e-05,
        "epoch": 5.977859778597786,
        "step": 1620
    },
    {
        "eval_loss": 0.4009248614311218,
        "eval_accuracy": 0.84225,
        "eval_precision": 0.79022,
        "eval_recall": 0.9295,
        "eval_f1": 0.85422,
        "eval_runtime": 18.1398,
        "eval_samples_per_second": 59.758,
        "eval_steps_per_second": 3.749,
        "epoch": 6.0,
        "step": 1626
    },
    {
        "loss": 0.3076,
        "grad_norm": 3.4482970237731934,
        "learning_rate": 2.124077490774908e-05,
        "epoch": 6.014760147601476,
        "step": 1630
    },
    {
        "loss": 0.3139,
        "grad_norm": 2.272364616394043,
        "learning_rate": 2.1217712177121773e-05,
        "epoch": 6.051660516605166,
        "step": 1640
    },
    {
        "loss": 0.3476,
        "grad_norm": 1.3477743864059448,
        "learning_rate": 2.1194649446494468e-05,
        "epoch": 6.088560885608856,
        "step": 1650
    },
    {
        "loss": 0.3001,
        "grad_norm": 3.706402540206909,
        "learning_rate": 2.117158671586716e-05,
        "epoch": 6.125461254612546,
        "step": 1660
    },
    {
        "loss": 0.3409,
        "grad_norm": 3.3535044193267822,
        "learning_rate": 2.1148523985239853e-05,
        "epoch": 6.162361623616236,
        "step": 1670
    },
    {
        "loss": 0.2687,
        "grad_norm": 0.7607954740524292,
        "learning_rate": 2.1125461254612547e-05,
        "epoch": 6.199261992619927,
        "step": 1680
    },
    {
        "loss": 0.3562,
        "grad_norm": 2.921299934387207,
        "learning_rate": 2.110239852398524e-05,
        "epoch": 6.236162361623617,
        "step": 1690
    },
    {
        "loss": 0.4006,
        "grad_norm": 2.088073253631592,
        "learning_rate": 2.1079335793357935e-05,
        "epoch": 6.273062730627307,
        "step": 1700
    },
    {
        "loss": 0.2666,
        "grad_norm": 3.098437547683716,
        "learning_rate": 2.1056273062730626e-05,
        "epoch": 6.3099630996309966,
        "step": 1710
    },
    {
        "loss": 0.3916,
        "grad_norm": 29.61199951171875,
        "learning_rate": 2.1033210332103324e-05,
        "epoch": 6.3468634686346865,
        "step": 1720
    },
    {
        "loss": 0.3334,
        "grad_norm": 4.166274070739746,
        "learning_rate": 2.1010147601476015e-05,
        "epoch": 6.3837638376383765,
        "step": 1730
    },
    {
        "loss": 0.2718,
        "grad_norm": 4.839085578918457,
        "learning_rate": 2.098708487084871e-05,
        "epoch": 6.4206642066420665,
        "step": 1740
    },
    {
        "loss": 0.4206,
        "grad_norm": 1.6263055801391602,
        "learning_rate": 2.0964022140221403e-05,
        "epoch": 6.4575645756457565,
        "step": 1750
    },
    {
        "loss": 0.3723,
        "grad_norm": 10.191004753112793,
        "learning_rate": 2.0940959409594097e-05,
        "epoch": 6.4944649446494465,
        "step": 1760
    },
    {
        "loss": 0.3269,
        "grad_norm": 20.061128616333008,
        "learning_rate": 2.091789667896679e-05,
        "epoch": 6.531365313653136,
        "step": 1770
    },
    {
        "loss": 0.3131,
        "grad_norm": 3.6869583129882812,
        "learning_rate": 2.0894833948339486e-05,
        "epoch": 6.568265682656826,
        "step": 1780
    },
    {
        "loss": 0.3515,
        "grad_norm": 1.4485474824905396,
        "learning_rate": 2.0871771217712177e-05,
        "epoch": 6.605166051660516,
        "step": 1790
    },
    {
        "loss": 0.4178,
        "grad_norm": 1.574808955192566,
        "learning_rate": 2.084870848708487e-05,
        "epoch": 6.642066420664206,
        "step": 1800
    },
    {
        "loss": 0.3405,
        "grad_norm": 2.759786605834961,
        "learning_rate": 2.0825645756457565e-05,
        "epoch": 6.678966789667896,
        "step": 1810
    },
    {
        "loss": 0.3642,
        "grad_norm": 2.05553936958313,
        "learning_rate": 2.080258302583026e-05,
        "epoch": 6.715867158671586,
        "step": 1820
    },
    {
        "loss": 0.3154,
        "grad_norm": 3.9268879890441895,
        "learning_rate": 2.0779520295202954e-05,
        "epoch": 6.752767527675276,
        "step": 1830
    },
    {
        "loss": 0.3342,
        "grad_norm": 3.2593579292297363,
        "learning_rate": 2.0756457564575644e-05,
        "epoch": 6.789667896678967,
        "step": 1840
    },
    {
        "loss": 0.3753,
        "grad_norm": 1.8622629642486572,
        "learning_rate": 2.0733394833948342e-05,
        "epoch": 6.826568265682657,
        "step": 1850
    },
    {
        "loss": 0.3025,
        "grad_norm": 6.170129776000977,
        "learning_rate": 2.0710332103321033e-05,
        "epoch": 6.863468634686347,
        "step": 1860
    },
    {
        "loss": 0.3723,
        "grad_norm": 3.8376219272613525,
        "learning_rate": 2.0687269372693727e-05,
        "epoch": 6.900369003690037,
        "step": 1870
    },
    {
        "loss": 0.318,
        "grad_norm": 1.5795962810516357,
        "learning_rate": 2.066420664206642e-05,
        "epoch": 6.937269372693727,
        "step": 1880
    },
    {
        "loss": 0.3153,
        "grad_norm": 1.0459990501403809,
        "learning_rate": 2.0641143911439116e-05,
        "epoch": 6.974169741697417,
        "step": 1890
    },
    {
        "eval_loss": 0.4451199471950531,
        "eval_accuracy": 0.83026,
        "eval_precision": 0.77266,
        "eval_recall": 0.93321,
        "eval_f1": 0.84538,
        "eval_runtime": 18.1232,
        "eval_samples_per_second": 59.813,
        "eval_steps_per_second": 3.752,
        "epoch": 7.0,
        "step": 1897
    },
    {
        "loss": 0.3931,
        "grad_norm": 3.141879081726074,
        "learning_rate": 2.061808118081181e-05,
        "epoch": 7.011070110701107,
        "step": 1900
    },
    {
        "loss": 0.2916,
        "grad_norm": 10.054607391357422,
        "learning_rate": 2.0595018450184504e-05,
        "epoch": 7.047970479704797,
        "step": 1910
    },
    {
        "loss": 0.3898,
        "grad_norm": 5.570621490478516,
        "learning_rate": 2.0571955719557195e-05,
        "epoch": 7.084870848708487,
        "step": 1920
    },
    {
        "loss": 0.2759,
        "grad_norm": 3.32609486579895,
        "learning_rate": 2.0548892988929893e-05,
        "epoch": 7.121771217712177,
        "step": 1930
    },
    {
        "loss": 0.3876,
        "grad_norm": 2.332671880722046,
        "learning_rate": 2.0525830258302583e-05,
        "epoch": 7.158671586715867,
        "step": 1940
    },
    {
        "loss": 0.3618,
        "grad_norm": 1.551063895225525,
        "learning_rate": 2.0502767527675278e-05,
        "epoch": 7.195571955719557,
        "step": 1950
    },
    {
        "loss": 0.3049,
        "grad_norm": 2.309278726577759,
        "learning_rate": 2.0479704797047972e-05,
        "epoch": 7.232472324723247,
        "step": 1960
    },
    {
        "loss": 0.3094,
        "grad_norm": 3.3112998008728027,
        "learning_rate": 2.0456642066420663e-05,
        "epoch": 7.269372693726937,
        "step": 1970
    },
    {
        "loss": 0.2991,
        "grad_norm": 2.9174811840057373,
        "learning_rate": 2.043357933579336e-05,
        "epoch": 7.306273062730627,
        "step": 1980
    },
    {
        "loss": 0.4115,
        "grad_norm": 6.7258453369140625,
        "learning_rate": 2.041051660516605e-05,
        "epoch": 7.343173431734318,
        "step": 1990
    },
    {
        "loss": 0.2862,
        "grad_norm": 1.072115182876587,
        "learning_rate": 2.0387453874538745e-05,
        "epoch": 7.380073800738008,
        "step": 2000
    },
    {
        "loss": 0.3491,
        "grad_norm": 1.100775122642517,
        "learning_rate": 2.036439114391144e-05,
        "epoch": 7.416974169741698,
        "step": 2010
    },
    {
        "loss": 0.2585,
        "grad_norm": 2.6357507705688477,
        "learning_rate": 2.0341328413284134e-05,
        "epoch": 7.453874538745388,
        "step": 2020
    },
    {
        "loss": 0.4083,
        "grad_norm": 5.94452428817749,
        "learning_rate": 2.0318265682656828e-05,
        "epoch": 7.490774907749078,
        "step": 2030
    },
    {
        "loss": 0.2821,
        "grad_norm": 7.964606285095215,
        "learning_rate": 2.0295202952029522e-05,
        "epoch": 7.527675276752768,
        "step": 2040
    },
    {
        "loss": 0.3213,
        "grad_norm": 2.079190254211426,
        "learning_rate": 2.0272140221402213e-05,
        "epoch": 7.564575645756458,
        "step": 2050
    },
    {
        "loss": 0.3359,
        "grad_norm": 8.129475593566895,
        "learning_rate": 2.024907749077491e-05,
        "epoch": 7.601476014760148,
        "step": 2060
    },
    {
        "loss": 0.2852,
        "grad_norm": 4.0223822593688965,
        "learning_rate": 2.02260147601476e-05,
        "epoch": 7.638376383763838,
        "step": 2070
    },
    {
        "loss": 0.355,
        "grad_norm": 11.423511505126953,
        "learning_rate": 2.0202952029520296e-05,
        "epoch": 7.675276752767528,
        "step": 2080
    },
    {
        "loss": 0.4336,
        "grad_norm": 3.3141791820526123,
        "learning_rate": 2.017988929889299e-05,
        "epoch": 7.712177121771218,
        "step": 2090
    },
    {
        "loss": 0.299,
        "grad_norm": 1.32688307762146,
        "learning_rate": 2.0156826568265684e-05,
        "epoch": 7.749077490774908,
        "step": 2100
    },
    {
        "loss": 0.2911,
        "grad_norm": 1.7577526569366455,
        "learning_rate": 2.013376383763838e-05,
        "epoch": 7.785977859778598,
        "step": 2110
    },
    {
        "loss": 0.3577,
        "grad_norm": 53.65961837768555,
        "learning_rate": 2.011070110701107e-05,
        "epoch": 7.822878228782288,
        "step": 2120
    },
    {
        "loss": 0.3707,
        "grad_norm": 5.155076026916504,
        "learning_rate": 2.0087638376383767e-05,
        "epoch": 7.8597785977859775,
        "step": 2130
    },
    {
        "loss": 0.3247,
        "grad_norm": 1.8893553018569946,
        "learning_rate": 2.0064575645756458e-05,
        "epoch": 7.8966789667896675,
        "step": 2140
    },
    {
        "loss": 0.3707,
        "grad_norm": 14.314990043640137,
        "learning_rate": 2.0041512915129152e-05,
        "epoch": 7.9335793357933575,
        "step": 2150
    },
    {
        "loss": 0.3885,
        "grad_norm": 6.061629772186279,
        "learning_rate": 2.0018450184501846e-05,
        "epoch": 7.970479704797048,
        "step": 2160
    },
    {
        "eval_loss": 0.4142785370349884,
        "eval_accuracy": 0.8441,
        "eval_precision": 0.79743,
        "eval_recall": 0.92022,
        "eval_f1": 0.85444,
        "eval_runtime": 18.1164,
        "eval_samples_per_second": 59.835,
        "eval_steps_per_second": 3.754,
        "epoch": 8.0,
        "step": 2168
    },
    {
        "loss": 0.3544,
        "grad_norm": 3.132169485092163,
        "learning_rate": 1.999538745387454e-05,
        "epoch": 8.007380073800737,
        "step": 2170
    },
    {
        "loss": 0.3878,
        "grad_norm": 5.158880710601807,
        "learning_rate": 1.997232472324723e-05,
        "epoch": 8.044280442804428,
        "step": 2180
    },
    {
        "loss": 0.3137,
        "grad_norm": 2.3855528831481934,
        "learning_rate": 1.994926199261993e-05,
        "epoch": 8.081180811808117,
        "step": 2190
    },
    {
        "loss": 0.3134,
        "grad_norm": 8.11861515045166,
        "learning_rate": 1.992619926199262e-05,
        "epoch": 8.118081180811808,
        "step": 2200
    },
    {
        "loss": 0.314,
        "grad_norm": 3.4110846519470215,
        "learning_rate": 1.9903136531365314e-05,
        "epoch": 8.154981549815497,
        "step": 2210
    },
    {
        "loss": 0.3921,
        "grad_norm": 2.6203856468200684,
        "learning_rate": 1.9880073800738008e-05,
        "epoch": 8.191881918819188,
        "step": 2220
    },
    {
        "loss": 0.3757,
        "grad_norm": 6.342016696929932,
        "learning_rate": 1.9857011070110702e-05,
        "epoch": 8.228782287822877,
        "step": 2230
    },
    {
        "loss": 0.3369,
        "grad_norm": 4.849009037017822,
        "learning_rate": 1.9833948339483397e-05,
        "epoch": 8.265682656826568,
        "step": 2240
    },
    {
        "loss": 0.2599,
        "grad_norm": 2.7254223823547363,
        "learning_rate": 1.9810885608856088e-05,
        "epoch": 8.302583025830259,
        "step": 2250
    },
    {
        "loss": 0.3621,
        "grad_norm": 5.874023914337158,
        "learning_rate": 1.9787822878228785e-05,
        "epoch": 8.339483394833948,
        "step": 2260
    },
    {
        "loss": 0.2572,
        "grad_norm": 14.450310707092285,
        "learning_rate": 1.9764760147601476e-05,
        "epoch": 8.376383763837639,
        "step": 2270
    },
    {
        "loss": 0.2805,
        "grad_norm": 7.387727737426758,
        "learning_rate": 1.974169741697417e-05,
        "epoch": 8.413284132841328,
        "step": 2280
    },
    {
        "loss": 0.2456,
        "grad_norm": 1.7813094854354858,
        "learning_rate": 1.9718634686346864e-05,
        "epoch": 8.450184501845019,
        "step": 2290
    },
    {
        "loss": 0.2776,
        "grad_norm": 24.17591094970703,
        "learning_rate": 1.969557195571956e-05,
        "epoch": 8.487084870848708,
        "step": 2300
    },
    {
        "loss": 0.4121,
        "grad_norm": 5.557632923126221,
        "learning_rate": 1.9672509225092253e-05,
        "epoch": 8.523985239852399,
        "step": 2310
    },
    {
        "loss": 0.3375,
        "grad_norm": 4.357684135437012,
        "learning_rate": 1.9649446494464947e-05,
        "epoch": 8.560885608856088,
        "step": 2320
    },
    {
        "loss": 0.3092,
        "grad_norm": 1.8224208354949951,
        "learning_rate": 1.9626383763837638e-05,
        "epoch": 8.597785977859779,
        "step": 2330
    },
    {
        "loss": 0.3453,
        "grad_norm": 2.064410924911499,
        "learning_rate": 1.9603321033210336e-05,
        "epoch": 8.634686346863468,
        "step": 2340
    },
    {
        "loss": 0.3052,
        "grad_norm": 10.944787979125977,
        "learning_rate": 1.9580258302583026e-05,
        "epoch": 8.671586715867159,
        "step": 2350
    },
    {
        "loss": 0.3114,
        "grad_norm": 2.0631330013275146,
        "learning_rate": 1.955719557195572e-05,
        "epoch": 8.708487084870848,
        "step": 2360
    },
    {
        "loss": 0.3274,
        "grad_norm": 3.390552043914795,
        "learning_rate": 1.9534132841328415e-05,
        "epoch": 8.745387453874539,
        "step": 2370
    },
    {
        "loss": 0.2854,
        "grad_norm": 1.392207384109497,
        "learning_rate": 1.9511070110701106e-05,
        "epoch": 8.782287822878228,
        "step": 2380
    },
    {
        "loss": 0.2968,
        "grad_norm": 3.9062671661376953,
        "learning_rate": 1.9488007380073803e-05,
        "epoch": 8.819188191881919,
        "step": 2390
    },
    {
        "loss": 0.3635,
        "grad_norm": 21.878320693969727,
        "learning_rate": 1.9464944649446494e-05,
        "epoch": 8.85608856088561,
        "step": 2400
    },
    {
        "loss": 0.2913,
        "grad_norm": 1.83197021484375,
        "learning_rate": 1.944188191881919e-05,
        "epoch": 8.892988929889299,
        "step": 2410
    },
    {
        "loss": 0.3218,
        "grad_norm": 2.35205078125,
        "learning_rate": 1.9418819188191883e-05,
        "epoch": 8.92988929889299,
        "step": 2420
    },
    {
        "loss": 0.3099,
        "grad_norm": 3.198242425918579,
        "learning_rate": 1.9395756457564577e-05,
        "epoch": 8.966789667896679,
        "step": 2430
    },
    {
        "eval_loss": 0.43418213725090027,
        "eval_accuracy": 0.83856,
        "eval_precision": 0.78349,
        "eval_recall": 0.93321,
        "eval_f1": 0.85182,
        "eval_runtime": 18.2353,
        "eval_samples_per_second": 59.445,
        "eval_steps_per_second": 3.729,
        "epoch": 9.0,
        "step": 2439
    },
    {
        "loss": 0.372,
        "grad_norm": 1.6270203590393066,
        "learning_rate": 1.937269372693727e-05,
        "epoch": 9.00369003690037,
        "step": 2440
    },
    {
        "loss": 0.3795,
        "grad_norm": 4.304459571838379,
        "learning_rate": 1.9349630996309965e-05,
        "epoch": 9.040590405904059,
        "step": 2450
    },
    {
        "loss": 0.3246,
        "grad_norm": 2.9169371128082275,
        "learning_rate": 1.9326568265682656e-05,
        "epoch": 9.07749077490775,
        "step": 2460
    },
    {
        "loss": 0.3268,
        "grad_norm": 4.167473316192627,
        "learning_rate": 1.9303505535055354e-05,
        "epoch": 9.114391143911439,
        "step": 2470
    },
    {
        "loss": 0.3462,
        "grad_norm": 1.451812982559204,
        "learning_rate": 1.9280442804428045e-05,
        "epoch": 9.15129151291513,
        "step": 2480
    },
    {
        "loss": 0.4116,
        "grad_norm": 12.551056861877441,
        "learning_rate": 1.925738007380074e-05,
        "epoch": 9.188191881918819,
        "step": 2490
    },
    {
        "loss": 0.3473,
        "grad_norm": 3.4759435653686523,
        "learning_rate": 1.9234317343173433e-05,
        "epoch": 9.22509225092251,
        "step": 2500
    },
    {
        "loss": 0.3547,
        "grad_norm": 11.588650703430176,
        "learning_rate": 1.9211254612546127e-05,
        "epoch": 9.261992619926199,
        "step": 2510
    },
    {
        "loss": 0.2843,
        "grad_norm": 3.0566818714141846,
        "learning_rate": 1.918819188191882e-05,
        "epoch": 9.29889298892989,
        "step": 2520
    },
    {
        "loss": 0.2779,
        "grad_norm": 1.753509759902954,
        "learning_rate": 1.9165129151291512e-05,
        "epoch": 9.335793357933579,
        "step": 2530
    },
    {
        "loss": 0.3172,
        "grad_norm": 7.93940544128418,
        "learning_rate": 1.9142066420664207e-05,
        "epoch": 9.37269372693727,
        "step": 2540
    },
    {
        "loss": 0.3359,
        "grad_norm": 2.4755914211273193,
        "learning_rate": 1.91190036900369e-05,
        "epoch": 9.40959409594096,
        "step": 2550
    },
    {
        "loss": 0.3506,
        "grad_norm": 2.7127645015716553,
        "learning_rate": 1.9095940959409595e-05,
        "epoch": 9.44649446494465,
        "step": 2560
    },
    {
        "loss": 0.2923,
        "grad_norm": 2.2310738563537598,
        "learning_rate": 1.907287822878229e-05,
        "epoch": 9.48339483394834,
        "step": 2570
    },
    {
        "loss": 0.3445,
        "grad_norm": 4.258629322052002,
        "learning_rate": 1.9049815498154984e-05,
        "epoch": 9.52029520295203,
        "step": 2580
    },
    {
        "loss": 0.2807,
        "grad_norm": 7.07318639755249,
        "learning_rate": 1.9026752767527674e-05,
        "epoch": 9.55719557195572,
        "step": 2590
    },
    {
        "loss": 0.236,
        "grad_norm": 1.4067014455795288,
        "learning_rate": 1.9003690036900372e-05,
        "epoch": 9.59409594095941,
        "step": 2600
    },
    {
        "loss": 0.3816,
        "grad_norm": 2.80935001373291,
        "learning_rate": 1.8980627306273063e-05,
        "epoch": 9.6309963099631,
        "step": 2610
    },
    {
        "loss": 0.2643,
        "grad_norm": 3.3672585487365723,
        "learning_rate": 1.8957564575645757e-05,
        "epoch": 9.66789667896679,
        "step": 2620
    },
    {
        "loss": 0.3412,
        "grad_norm": 5.161713600158691,
        "learning_rate": 1.893450184501845e-05,
        "epoch": 9.70479704797048,
        "step": 2630
    },
    {
        "loss": 0.3558,
        "grad_norm": 1.6697750091552734,
        "learning_rate": 1.8911439114391146e-05,
        "epoch": 9.74169741697417,
        "step": 2640
    },
    {
        "loss": 0.26,
        "grad_norm": 3.08524227142334,
        "learning_rate": 1.888837638376384e-05,
        "epoch": 9.77859778597786,
        "step": 2650
    },
    {
        "loss": 0.3199,
        "grad_norm": 1.5104821920394897,
        "learning_rate": 1.886531365313653e-05,
        "epoch": 9.81549815498155,
        "step": 2660
    },
    {
        "loss": 0.4137,
        "grad_norm": 2.083209276199341,
        "learning_rate": 1.8842250922509225e-05,
        "epoch": 9.85239852398524,
        "step": 2670
    },
    {
        "loss": 0.3437,
        "grad_norm": 2.1869523525238037,
        "learning_rate": 1.881918819188192e-05,
        "epoch": 9.88929889298893,
        "step": 2680
    },
    {
        "loss": 0.3281,
        "grad_norm": 4.740732192993164,
        "learning_rate": 1.8796125461254613e-05,
        "epoch": 9.92619926199262,
        "step": 2690
    },
    {
        "loss": 0.2371,
        "grad_norm": 6.951223373413086,
        "learning_rate": 1.8773062730627308e-05,
        "epoch": 9.96309963099631,
        "step": 2700
    },
    {
        "loss": 0.2483,
        "grad_norm": 13.565564155578613,
        "learning_rate": 1.8750000000000002e-05,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "eval_loss": 0.4446125626564026,
        "eval_accuracy": 0.85055,
        "eval_precision": 0.82669,
        "eval_recall": 0.88497,
        "eval_f1": 0.85484,
        "eval_runtime": 18.1968,
        "eval_samples_per_second": 59.571,
        "eval_steps_per_second": 3.737,
        "epoch": 10.0,
        "step": 2710
    },
    {
        "loss": 0.313,
        "grad_norm": 3.5457475185394287,
        "learning_rate": 1.8726937269372693e-05,
        "epoch": 10.03690036900369,
        "step": 2720
    },
    {
        "loss": 0.2925,
        "grad_norm": 1.3408348560333252,
        "learning_rate": 1.870387453874539e-05,
        "epoch": 10.07380073800738,
        "step": 2730
    },
    {
        "loss": 0.2407,
        "grad_norm": 1.503782868385315,
        "learning_rate": 1.868081180811808e-05,
        "epoch": 10.11070110701107,
        "step": 2740
    },
    {
        "loss": 0.2488,
        "grad_norm": 6.465453147888184,
        "learning_rate": 1.865774907749078e-05,
        "epoch": 10.14760147601476,
        "step": 2750
    },
    {
        "loss": 0.3534,
        "grad_norm": 2.779487371444702,
        "learning_rate": 1.863468634686347e-05,
        "epoch": 10.18450184501845,
        "step": 2760
    },
    {
        "loss": 0.3011,
        "grad_norm": 6.796178340911865,
        "learning_rate": 1.8611623616236164e-05,
        "epoch": 10.22140221402214,
        "step": 2770
    },
    {
        "loss": 0.3376,
        "grad_norm": 3.3458733558654785,
        "learning_rate": 1.8588560885608858e-05,
        "epoch": 10.25830258302583,
        "step": 2780
    },
    {
        "loss": 0.2959,
        "grad_norm": 2.08394193649292,
        "learning_rate": 1.856549815498155e-05,
        "epoch": 10.29520295202952,
        "step": 2790
    },
    {
        "loss": 0.2987,
        "grad_norm": 3.3245012760162354,
        "learning_rate": 1.8542435424354243e-05,
        "epoch": 10.33210332103321,
        "step": 2800
    },
    {
        "loss": 0.3065,
        "grad_norm": 2.6144042015075684,
        "learning_rate": 1.8519372693726937e-05,
        "epoch": 10.3690036900369,
        "step": 2810
    },
    {
        "loss": 0.3312,
        "grad_norm": 1.5081238746643066,
        "learning_rate": 1.849630996309963e-05,
        "epoch": 10.40590405904059,
        "step": 2820
    },
    {
        "loss": 0.3212,
        "grad_norm": 3.076917886734009,
        "learning_rate": 1.8473247232472326e-05,
        "epoch": 10.44280442804428,
        "step": 2830
    },
    {
        "loss": 0.1769,
        "grad_norm": 1.3811630010604858,
        "learning_rate": 1.845018450184502e-05,
        "epoch": 10.47970479704797,
        "step": 2840
    },
    {
        "loss": 0.3971,
        "grad_norm": 1.7106331586837769,
        "learning_rate": 1.842712177121771e-05,
        "epoch": 10.51660516605166,
        "step": 2850
    },
    {
        "loss": 0.3135,
        "grad_norm": 1.5190646648406982,
        "learning_rate": 1.840405904059041e-05,
        "epoch": 10.55350553505535,
        "step": 2860
    },
    {
        "loss": 0.2835,
        "grad_norm": 4.629943370819092,
        "learning_rate": 1.83809963099631e-05,
        "epoch": 10.59040590405904,
        "step": 2870
    },
    {
        "loss": 0.3432,
        "grad_norm": 3.654310464859009,
        "learning_rate": 1.8357933579335797e-05,
        "epoch": 10.62730627306273,
        "step": 2880
    },
    {
        "loss": 0.2612,
        "grad_norm": 2.4267425537109375,
        "learning_rate": 1.8334870848708488e-05,
        "epoch": 10.664206642066421,
        "step": 2890
    },
    {
        "loss": 0.2305,
        "grad_norm": 2.205143928527832,
        "learning_rate": 1.8311808118081182e-05,
        "epoch": 10.70110701107011,
        "step": 2900
    },
    {
        "loss": 0.2916,
        "grad_norm": 2.5414814949035645,
        "learning_rate": 1.8288745387453876e-05,
        "epoch": 10.738007380073801,
        "step": 2910
    },
    {
        "loss": 0.4298,
        "grad_norm": 1.2592997550964355,
        "learning_rate": 1.826568265682657e-05,
        "epoch": 10.77490774907749,
        "step": 2920
    },
    {
        "loss": 0.4255,
        "grad_norm": 2.7974724769592285,
        "learning_rate": 1.8242619926199265e-05,
        "epoch": 10.811808118081181,
        "step": 2930
    },
    {
        "loss": 0.2648,
        "grad_norm": 1.3809021711349487,
        "learning_rate": 1.8219557195571955e-05,
        "epoch": 10.84870848708487,
        "step": 2940
    },
    {
        "loss": 0.383,
        "grad_norm": 2.557152271270752,
        "learning_rate": 1.819649446494465e-05,
        "epoch": 10.885608856088561,
        "step": 2950
    },
    {
        "loss": 0.1924,
        "grad_norm": 11.298274993896484,
        "learning_rate": 1.8173431734317344e-05,
        "epoch": 10.92250922509225,
        "step": 2960
    },
    {
        "loss": 0.2819,
        "grad_norm": 2.0611093044281006,
        "learning_rate": 1.8150369003690038e-05,
        "epoch": 10.959409594095941,
        "step": 2970
    },
    {
        "loss": 0.3956,
        "grad_norm": 3.3090367317199707,
        "learning_rate": 1.812730627306273e-05,
        "epoch": 10.99630996309963,
        "step": 2980
    },
    {
        "eval_loss": 0.44794028997421265,
        "eval_accuracy": 0.85978,
        "eval_precision": 0.82852,
        "eval_recall": 0.90538,
        "eval_f1": 0.86525,
        "eval_runtime": 18.2723,
        "eval_samples_per_second": 59.325,
        "eval_steps_per_second": 3.721,
        "epoch": 11.0,
        "step": 2981
    },
    {
        "loss": 0.2689,
        "grad_norm": 1.7610421180725098,
        "learning_rate": 1.8104243542435427e-05,
        "epoch": 11.033210332103321,
        "step": 2990
    },
    {
        "loss": 0.2906,
        "grad_norm": 25.90010643005371,
        "learning_rate": 1.8081180811808117e-05,
        "epoch": 11.07011070110701,
        "step": 3000
    },
    {
        "loss": 0.3334,
        "grad_norm": 4.406385898590088,
        "learning_rate": 1.8058118081180815e-05,
        "epoch": 11.107011070110701,
        "step": 3010
    },
    {
        "loss": 0.2322,
        "grad_norm": 1.32614004611969,
        "learning_rate": 1.8035055350553506e-05,
        "epoch": 11.14391143911439,
        "step": 3020
    },
    {
        "loss": 0.3419,
        "grad_norm": 49.39510726928711,
        "learning_rate": 1.80119926199262e-05,
        "epoch": 11.180811808118081,
        "step": 3030
    },
    {
        "loss": 0.1999,
        "grad_norm": 3.343611001968384,
        "learning_rate": 1.7988929889298894e-05,
        "epoch": 11.217712177121772,
        "step": 3040
    },
    {
        "loss": 0.3703,
        "grad_norm": 5.398002624511719,
        "learning_rate": 1.796586715867159e-05,
        "epoch": 11.254612546125461,
        "step": 3050
    },
    {
        "loss": 0.3417,
        "grad_norm": 4.805206298828125,
        "learning_rate": 1.7942804428044283e-05,
        "epoch": 11.291512915129152,
        "step": 3060
    },
    {
        "loss": 0.2609,
        "grad_norm": 1.9561378955841064,
        "learning_rate": 1.7919741697416974e-05,
        "epoch": 11.328413284132841,
        "step": 3070
    },
    {
        "loss": 0.322,
        "grad_norm": 22.107437133789062,
        "learning_rate": 1.7896678966789668e-05,
        "epoch": 11.365313653136532,
        "step": 3080
    },
    {
        "loss": 0.2626,
        "grad_norm": 1.8571696281433105,
        "learning_rate": 1.7873616236162362e-05,
        "epoch": 11.402214022140221,
        "step": 3090
    },
    {
        "loss": 0.2969,
        "grad_norm": 2.2719712257385254,
        "learning_rate": 1.7850553505535056e-05,
        "epoch": 11.439114391143912,
        "step": 3100
    },
    {
        "loss": 0.2549,
        "grad_norm": 2.9808363914489746,
        "learning_rate": 1.7827490774907747e-05,
        "epoch": 11.476014760147601,
        "step": 3110
    },
    {
        "loss": 0.2862,
        "grad_norm": 8.822808265686035,
        "learning_rate": 1.7804428044280445e-05,
        "epoch": 11.512915129151292,
        "step": 3120
    },
    {
        "loss": 0.2346,
        "grad_norm": 2.281787633895874,
        "learning_rate": 1.7781365313653136e-05,
        "epoch": 11.549815498154981,
        "step": 3130
    },
    {
        "loss": 0.303,
        "grad_norm": 3.229217290878296,
        "learning_rate": 1.7758302583025833e-05,
        "epoch": 11.586715867158672,
        "step": 3140
    },
    {
        "loss": 0.2919,
        "grad_norm": 4.682319641113281,
        "learning_rate": 1.7735239852398524e-05,
        "epoch": 11.623616236162361,
        "step": 3150
    },
    {
        "loss": 0.3233,
        "grad_norm": 3.031719207763672,
        "learning_rate": 1.771217712177122e-05,
        "epoch": 11.660516605166052,
        "step": 3160
    },
    {
        "loss": 0.2331,
        "grad_norm": 0.7936564683914185,
        "learning_rate": 1.7689114391143913e-05,
        "epoch": 11.697416974169741,
        "step": 3170
    },
    {
        "loss": 0.3222,
        "grad_norm": 3.20267653465271,
        "learning_rate": 1.7666051660516607e-05,
        "epoch": 11.734317343173432,
        "step": 3180
    },
    {
        "loss": 0.2616,
        "grad_norm": 16.516864776611328,
        "learning_rate": 1.76429889298893e-05,
        "epoch": 11.771217712177123,
        "step": 3190
    },
    {
        "loss": 0.3313,
        "grad_norm": 1.695548176765442,
        "learning_rate": 1.7619926199261992e-05,
        "epoch": 11.808118081180812,
        "step": 3200
    },
    {
        "loss": 0.3424,
        "grad_norm": 24.973230361938477,
        "learning_rate": 1.7596863468634686e-05,
        "epoch": 11.845018450184503,
        "step": 3210
    },
    {
        "loss": 0.2427,
        "grad_norm": 3.947153091430664,
        "learning_rate": 1.757380073800738e-05,
        "epoch": 11.881918819188192,
        "step": 3220
    },
    {
        "loss": 0.3468,
        "grad_norm": 1.9233887195587158,
        "learning_rate": 1.7550738007380075e-05,
        "epoch": 11.918819188191883,
        "step": 3230
    },
    {
        "loss": 0.2971,
        "grad_norm": 2.9948112964630127,
        "learning_rate": 1.752767527675277e-05,
        "epoch": 11.955719557195572,
        "step": 3240
    },
    {
        "loss": 0.3438,
        "grad_norm": 1.1436165571212769,
        "learning_rate": 1.7504612546125463e-05,
        "epoch": 11.992619926199263,
        "step": 3250
    },
    {
        "eval_loss": 0.4611702859401703,
        "eval_accuracy": 0.84871,
        "eval_precision": 0.80291,
        "eval_recall": 0.92208,
        "eval_f1": 0.85838,
        "eval_runtime": 18.2391,
        "eval_samples_per_second": 59.433,
        "eval_steps_per_second": 3.728,
        "epoch": 12.0,
        "step": 3252
    },
    {
        "loss": 0.2451,
        "grad_norm": 2.269932985305786,
        "learning_rate": 1.7481549815498154e-05,
        "epoch": 12.029520295202952,
        "step": 3260
    },
    {
        "loss": 0.3127,
        "grad_norm": 4.752685070037842,
        "learning_rate": 1.745848708487085e-05,
        "epoch": 12.066420664206642,
        "step": 3270
    },
    {
        "loss": 0.2173,
        "grad_norm": 1.7224622964859009,
        "learning_rate": 1.7435424354243542e-05,
        "epoch": 12.103321033210332,
        "step": 3280
    },
    {
        "loss": 0.199,
        "grad_norm": 0.9419422149658203,
        "learning_rate": 1.7412361623616237e-05,
        "epoch": 12.140221402214022,
        "step": 3290
    },
    {
        "loss": 0.2359,
        "grad_norm": 1.1425749063491821,
        "learning_rate": 1.738929889298893e-05,
        "epoch": 12.177121771217712,
        "step": 3300
    },
    {
        "loss": 0.297,
        "grad_norm": 12.750417709350586,
        "learning_rate": 1.7366236162361625e-05,
        "epoch": 12.214022140221402,
        "step": 3310
    },
    {
        "loss": 0.3436,
        "grad_norm": 10.870991706848145,
        "learning_rate": 1.734317343173432e-05,
        "epoch": 12.250922509225092,
        "step": 3320
    },
    {
        "loss": 0.3276,
        "grad_norm": 10.161531448364258,
        "learning_rate": 1.7320110701107013e-05,
        "epoch": 12.287822878228782,
        "step": 3330
    },
    {
        "loss": 0.2588,
        "grad_norm": 28.297134399414062,
        "learning_rate": 1.7297047970479704e-05,
        "epoch": 12.324723247232471,
        "step": 3340
    },
    {
        "loss": 0.3842,
        "grad_norm": 2.9882802963256836,
        "learning_rate": 1.72739852398524e-05,
        "epoch": 12.361623616236162,
        "step": 3350
    },
    {
        "loss": 0.2088,
        "grad_norm": 10.144174575805664,
        "learning_rate": 1.7250922509225093e-05,
        "epoch": 12.398523985239853,
        "step": 3360
    },
    {
        "loss": 0.2867,
        "grad_norm": 17.685392379760742,
        "learning_rate": 1.7227859778597787e-05,
        "epoch": 12.435424354243542,
        "step": 3370
    },
    {
        "loss": 0.3112,
        "grad_norm": 14.920604705810547,
        "learning_rate": 1.720479704797048e-05,
        "epoch": 12.472324723247233,
        "step": 3380
    },
    {
        "loss": 0.2352,
        "grad_norm": 75.48838806152344,
        "learning_rate": 1.7181734317343172e-05,
        "epoch": 12.509225092250922,
        "step": 3390
    },
    {
        "loss": 0.283,
        "grad_norm": 8.276494979858398,
        "learning_rate": 1.715867158671587e-05,
        "epoch": 12.546125461254613,
        "step": 3400
    },
    {
        "loss": 0.2971,
        "grad_norm": 0.9448565244674683,
        "learning_rate": 1.713560885608856e-05,
        "epoch": 12.583025830258302,
        "step": 3410
    },
    {
        "loss": 0.3687,
        "grad_norm": 1.6101664304733276,
        "learning_rate": 1.7112546125461258e-05,
        "epoch": 12.619926199261993,
        "step": 3420
    },
    {
        "loss": 0.2424,
        "grad_norm": 1.3505817651748657,
        "learning_rate": 1.708948339483395e-05,
        "epoch": 12.656826568265682,
        "step": 3430
    },
    {
        "loss": 0.299,
        "grad_norm": 7.984592914581299,
        "learning_rate": 1.7066420664206643e-05,
        "epoch": 12.693726937269373,
        "step": 3440
    },
    {
        "loss": 0.3008,
        "grad_norm": 2.8648571968078613,
        "learning_rate": 1.7043357933579337e-05,
        "epoch": 12.730627306273062,
        "step": 3450
    },
    {
        "loss": 0.2908,
        "grad_norm": 1.268907070159912,
        "learning_rate": 1.702029520295203e-05,
        "epoch": 12.767527675276753,
        "step": 3460
    },
    {
        "loss": 0.3051,
        "grad_norm": 4.465703964233398,
        "learning_rate": 1.6997232472324722e-05,
        "epoch": 12.804428044280442,
        "step": 3470
    },
    {
        "loss": 0.3191,
        "grad_norm": 5.57435417175293,
        "learning_rate": 1.6974169741697417e-05,
        "epoch": 12.841328413284133,
        "step": 3480
    },
    {
        "loss": 0.2942,
        "grad_norm": 8.421504974365234,
        "learning_rate": 1.695110701107011e-05,
        "epoch": 12.878228782287822,
        "step": 3490
    },
    {
        "loss": 0.2918,
        "grad_norm": 9.390766143798828,
        "learning_rate": 1.6928044280442805e-05,
        "epoch": 12.915129151291513,
        "step": 3500
    },
    {
        "loss": 0.3498,
        "grad_norm": 1.3917258977890015,
        "learning_rate": 1.69049815498155e-05,
        "epoch": 12.952029520295202,
        "step": 3510
    },
    {
        "loss": 0.3076,
        "grad_norm": 16.65195655822754,
        "learning_rate": 1.688191881918819e-05,
        "epoch": 12.988929889298893,
        "step": 3520
    },
    {
        "eval_loss": 0.46591636538505554,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.8125,
        "eval_recall": 0.91651,
        "eval_f1": 0.86138,
        "eval_runtime": 18.0739,
        "eval_samples_per_second": 59.976,
        "eval_steps_per_second": 3.762,
        "epoch": 13.0,
        "step": 3523
    },
    {
        "loss": 0.2805,
        "grad_norm": 0.8372644782066345,
        "learning_rate": 1.6858856088560888e-05,
        "epoch": 13.025830258302584,
        "step": 3530
    },
    {
        "loss": 0.2369,
        "grad_norm": 3.113671064376831,
        "learning_rate": 1.683579335793358e-05,
        "epoch": 13.062730627306273,
        "step": 3540
    },
    {
        "loss": 0.286,
        "grad_norm": 0.6816962957382202,
        "learning_rate": 1.6812730627306276e-05,
        "epoch": 13.099630996309964,
        "step": 3550
    },
    {
        "loss": 0.2967,
        "grad_norm": 3.7007150650024414,
        "learning_rate": 1.6789667896678967e-05,
        "epoch": 13.136531365313653,
        "step": 3560
    },
    {
        "loss": 0.3362,
        "grad_norm": 8.742676734924316,
        "learning_rate": 1.676660516605166e-05,
        "epoch": 13.173431734317344,
        "step": 3570
    },
    {
        "loss": 0.2759,
        "grad_norm": 8.113621711730957,
        "learning_rate": 1.6743542435424356e-05,
        "epoch": 13.210332103321033,
        "step": 3580
    },
    {
        "loss": 0.3316,
        "grad_norm": 1.493974208831787,
        "learning_rate": 1.672047970479705e-05,
        "epoch": 13.247232472324724,
        "step": 3590
    },
    {
        "loss": 0.25,
        "grad_norm": 1.7554925680160522,
        "learning_rate": 1.669741697416974e-05,
        "epoch": 13.284132841328413,
        "step": 3600
    },
    {
        "loss": 0.2476,
        "grad_norm": 3.1884782314300537,
        "learning_rate": 1.6674354243542435e-05,
        "epoch": 13.321033210332104,
        "step": 3610
    },
    {
        "loss": 0.3059,
        "grad_norm": 8.625219345092773,
        "learning_rate": 1.665129151291513e-05,
        "epoch": 13.357933579335793,
        "step": 3620
    },
    {
        "loss": 0.2801,
        "grad_norm": 12.458377838134766,
        "learning_rate": 1.6628228782287823e-05,
        "epoch": 13.394833948339484,
        "step": 3630
    },
    {
        "loss": 0.3384,
        "grad_norm": 2.100055694580078,
        "learning_rate": 1.6605166051660518e-05,
        "epoch": 13.431734317343173,
        "step": 3640
    },
    {
        "loss": 0.2696,
        "grad_norm": 9.573668479919434,
        "learning_rate": 1.658210332103321e-05,
        "epoch": 13.468634686346864,
        "step": 3650
    },
    {
        "loss": 0.285,
        "grad_norm": 4.428220272064209,
        "learning_rate": 1.6559040590405906e-05,
        "epoch": 13.505535055350553,
        "step": 3660
    },
    {
        "loss": 0.2039,
        "grad_norm": 24.44161605834961,
        "learning_rate": 1.6535977859778597e-05,
        "epoch": 13.542435424354244,
        "step": 3670
    },
    {
        "loss": 0.2215,
        "grad_norm": 9.05246353149414,
        "learning_rate": 1.6512915129151295e-05,
        "epoch": 13.579335793357934,
        "step": 3680
    },
    {
        "loss": 0.2554,
        "grad_norm": 0.9576408863067627,
        "learning_rate": 1.6489852398523985e-05,
        "epoch": 13.616236162361623,
        "step": 3690
    },
    {
        "loss": 0.205,
        "grad_norm": 2.5447726249694824,
        "learning_rate": 1.646678966789668e-05,
        "epoch": 13.653136531365314,
        "step": 3700
    },
    {
        "loss": 0.346,
        "grad_norm": 46.07754135131836,
        "learning_rate": 1.6443726937269374e-05,
        "epoch": 13.690036900369003,
        "step": 3710
    },
    {
        "loss": 0.239,
        "grad_norm": 1.7667236328125,
        "learning_rate": 1.6420664206642068e-05,
        "epoch": 13.726937269372694,
        "step": 3720
    },
    {
        "loss": 0.3309,
        "grad_norm": 9.50839614868164,
        "learning_rate": 1.6397601476014762e-05,
        "epoch": 13.763837638376383,
        "step": 3730
    },
    {
        "loss": 0.3362,
        "grad_norm": 69.26834869384766,
        "learning_rate": 1.6374538745387457e-05,
        "epoch": 13.800738007380074,
        "step": 3740
    },
    {
        "loss": 0.2707,
        "grad_norm": 4.163329601287842,
        "learning_rate": 1.6351476014760147e-05,
        "epoch": 13.837638376383763,
        "step": 3750
    },
    {
        "loss": 0.2089,
        "grad_norm": 1.8433012962341309,
        "learning_rate": 1.632841328413284e-05,
        "epoch": 13.874538745387454,
        "step": 3760
    },
    {
        "loss": 0.314,
        "grad_norm": 1.2824562788009644,
        "learning_rate": 1.6305350553505536e-05,
        "epoch": 13.911439114391143,
        "step": 3770
    },
    {
        "loss": 0.26,
        "grad_norm": 1.7550629377365112,
        "learning_rate": 1.6282287822878227e-05,
        "epoch": 13.948339483394834,
        "step": 3780
    },
    {
        "loss": 0.2754,
        "grad_norm": 1.0126839876174927,
        "learning_rate": 1.6259225092250924e-05,
        "epoch": 13.985239852398523,
        "step": 3790
    },
    {
        "eval_loss": 0.4589492380619049,
        "eval_accuracy": 0.85517,
        "eval_precision": 0.81209,
        "eval_recall": 0.92208,
        "eval_f1": 0.8636,
        "eval_runtime": 18.1091,
        "eval_samples_per_second": 59.859,
        "eval_steps_per_second": 3.755,
        "epoch": 14.0,
        "step": 3794
    },
    {
        "loss": 0.3066,
        "grad_norm": 5.460875511169434,
        "learning_rate": 1.6236162361623615e-05,
        "epoch": 14.022140221402214,
        "step": 3800
    },
    {
        "loss": 0.2223,
        "grad_norm": 3.6803009510040283,
        "learning_rate": 1.6213099630996313e-05,
        "epoch": 14.059040590405903,
        "step": 3810
    },
    {
        "loss": 0.3308,
        "grad_norm": 3.1399974822998047,
        "learning_rate": 1.6190036900369004e-05,
        "epoch": 14.095940959409594,
        "step": 3820
    },
    {
        "loss": 0.3419,
        "grad_norm": 10.495455741882324,
        "learning_rate": 1.6166974169741698e-05,
        "epoch": 14.132841328413285,
        "step": 3830
    },
    {
        "loss": 0.2362,
        "grad_norm": 15.112741470336914,
        "learning_rate": 1.6143911439114392e-05,
        "epoch": 14.169741697416974,
        "step": 3840
    },
    {
        "loss": 0.3215,
        "grad_norm": 2.451021909713745,
        "learning_rate": 1.6120848708487086e-05,
        "epoch": 14.206642066420665,
        "step": 3850
    },
    {
        "loss": 0.2619,
        "grad_norm": 1.156121015548706,
        "learning_rate": 1.609778597785978e-05,
        "epoch": 14.243542435424354,
        "step": 3860
    },
    {
        "loss": 0.2376,
        "grad_norm": 1.559526801109314,
        "learning_rate": 1.6074723247232475e-05,
        "epoch": 14.280442804428045,
        "step": 3870
    },
    {
        "loss": 0.2264,
        "grad_norm": 15.417802810668945,
        "learning_rate": 1.6051660516605166e-05,
        "epoch": 14.317343173431734,
        "step": 3880
    },
    {
        "loss": 0.2765,
        "grad_norm": 16.589609146118164,
        "learning_rate": 1.602859778597786e-05,
        "epoch": 14.354243542435425,
        "step": 3890
    },
    {
        "loss": 0.3286,
        "grad_norm": 8.711041450500488,
        "learning_rate": 1.6005535055350554e-05,
        "epoch": 14.391143911439114,
        "step": 3900
    },
    {
        "loss": 0.3158,
        "grad_norm": 0.6063404679298401,
        "learning_rate": 1.5982472324723248e-05,
        "epoch": 14.428044280442805,
        "step": 3910
    },
    {
        "loss": 0.2909,
        "grad_norm": 2.096491813659668,
        "learning_rate": 1.5959409594095942e-05,
        "epoch": 14.464944649446494,
        "step": 3920
    },
    {
        "loss": 0.3149,
        "grad_norm": 50.10481643676758,
        "learning_rate": 1.5936346863468633e-05,
        "epoch": 14.501845018450185,
        "step": 3930
    },
    {
        "loss": 0.3273,
        "grad_norm": 3.3960659503936768,
        "learning_rate": 1.591328413284133e-05,
        "epoch": 14.538745387453874,
        "step": 3940
    },
    {
        "loss": 0.2328,
        "grad_norm": 6.655852794647217,
        "learning_rate": 1.5890221402214022e-05,
        "epoch": 14.575645756457565,
        "step": 3950
    },
    {
        "loss": 0.2397,
        "grad_norm": 31.871999740600586,
        "learning_rate": 1.5867158671586716e-05,
        "epoch": 14.612546125461254,
        "step": 3960
    },
    {
        "loss": 0.2351,
        "grad_norm": 24.95829963684082,
        "learning_rate": 1.584409594095941e-05,
        "epoch": 14.649446494464945,
        "step": 3970
    },
    {
        "loss": 0.3028,
        "grad_norm": 38.62693405151367,
        "learning_rate": 1.5821033210332104e-05,
        "epoch": 14.686346863468636,
        "step": 3980
    },
    {
        "loss": 0.2965,
        "grad_norm": 7.8604254722595215,
        "learning_rate": 1.57979704797048e-05,
        "epoch": 14.723247232472325,
        "step": 3990
    },
    {
        "loss": 0.2524,
        "grad_norm": 7.006964206695557,
        "learning_rate": 1.5774907749077493e-05,
        "epoch": 14.760147601476016,
        "step": 4000
    },
    {
        "loss": 0.2909,
        "grad_norm": 21.372051239013672,
        "learning_rate": 1.5751845018450184e-05,
        "epoch": 14.797047970479705,
        "step": 4010
    },
    {
        "loss": 0.3248,
        "grad_norm": 14.409794807434082,
        "learning_rate": 1.5728782287822878e-05,
        "epoch": 14.833948339483396,
        "step": 4020
    },
    {
        "loss": 0.2997,
        "grad_norm": 6.310110569000244,
        "learning_rate": 1.5705719557195572e-05,
        "epoch": 14.870848708487085,
        "step": 4030
    },
    {
        "loss": 0.2452,
        "grad_norm": 3.2408459186553955,
        "learning_rate": 1.5682656826568266e-05,
        "epoch": 14.907749077490775,
        "step": 4040
    },
    {
        "loss": 0.3124,
        "grad_norm": 32.968360900878906,
        "learning_rate": 1.565959409594096e-05,
        "epoch": 14.944649446494465,
        "step": 4050
    },
    {
        "loss": 0.2004,
        "grad_norm": 3.3728349208831787,
        "learning_rate": 1.563653136531365e-05,
        "epoch": 14.981549815498155,
        "step": 4060
    },
    {
        "eval_loss": 0.48379752039909363,
        "eval_accuracy": 0.85701,
        "eval_precision": 0.82323,
        "eval_recall": 0.90724,
        "eval_f1": 0.8632,
        "eval_runtime": 18.079,
        "eval_samples_per_second": 59.959,
        "eval_steps_per_second": 3.761,
        "epoch": 15.0,
        "step": 4065
    },
    {
        "loss": 0.3261,
        "grad_norm": 1.3315763473510742,
        "learning_rate": 1.561346863468635e-05,
        "epoch": 15.018450184501845,
        "step": 4070
    },
    {
        "loss": 0.2918,
        "grad_norm": 1.5077639818191528,
        "learning_rate": 1.559040590405904e-05,
        "epoch": 15.055350553505535,
        "step": 4080
    },
    {
        "loss": 0.2286,
        "grad_norm": 42.617923736572266,
        "learning_rate": 1.5567343173431734e-05,
        "epoch": 15.092250922509225,
        "step": 4090
    },
    {
        "loss": 0.2842,
        "grad_norm": 1.268725037574768,
        "learning_rate": 1.554428044280443e-05,
        "epoch": 15.129151291512915,
        "step": 4100
    },
    {
        "loss": 0.2451,
        "grad_norm": 5.187755584716797,
        "learning_rate": 1.5521217712177123e-05,
        "epoch": 15.166051660516604,
        "step": 4110
    },
    {
        "loss": 0.2527,
        "grad_norm": 4.3226542472839355,
        "learning_rate": 1.5498154981549817e-05,
        "epoch": 15.202952029520295,
        "step": 4120
    },
    {
        "loss": 0.3233,
        "grad_norm": 1.3028936386108398,
        "learning_rate": 1.547509225092251e-05,
        "epoch": 15.239852398523984,
        "step": 4130
    },
    {
        "loss": 0.2395,
        "grad_norm": 2.2328107357025146,
        "learning_rate": 1.5452029520295202e-05,
        "epoch": 15.276752767527675,
        "step": 4140
    },
    {
        "loss": 0.2984,
        "grad_norm": 3.6255271434783936,
        "learning_rate": 1.54289667896679e-05,
        "epoch": 15.313653136531366,
        "step": 4150
    },
    {
        "loss": 0.3191,
        "grad_norm": 3.1556222438812256,
        "learning_rate": 1.540590405904059e-05,
        "epoch": 15.350553505535055,
        "step": 4160
    },
    {
        "loss": 0.2575,
        "grad_norm": 1.2578376531600952,
        "learning_rate": 1.5382841328413285e-05,
        "epoch": 15.387453874538746,
        "step": 4170
    },
    {
        "loss": 0.2485,
        "grad_norm": 1.1908514499664307,
        "learning_rate": 1.535977859778598e-05,
        "epoch": 15.424354243542435,
        "step": 4180
    },
    {
        "loss": 0.2419,
        "grad_norm": 3.172041416168213,
        "learning_rate": 1.533671586715867e-05,
        "epoch": 15.461254612546126,
        "step": 4190
    },
    {
        "loss": 0.2735,
        "grad_norm": 1.9470502138137817,
        "learning_rate": 1.5313653136531367e-05,
        "epoch": 15.498154981549815,
        "step": 4200
    },
    {
        "loss": 0.2993,
        "grad_norm": 39.87228012084961,
        "learning_rate": 1.5290590405904058e-05,
        "epoch": 15.535055350553506,
        "step": 4210
    },
    {
        "loss": 0.2541,
        "grad_norm": 2.4172160625457764,
        "learning_rate": 1.5267527675276756e-05,
        "epoch": 15.571955719557195,
        "step": 4220
    },
    {
        "loss": 0.2301,
        "grad_norm": 1.0700867176055908,
        "learning_rate": 1.5244464944649448e-05,
        "epoch": 15.608856088560886,
        "step": 4230
    },
    {
        "loss": 0.2596,
        "grad_norm": 5.448837757110596,
        "learning_rate": 1.5221402214022141e-05,
        "epoch": 15.645756457564575,
        "step": 4240
    },
    {
        "loss": 0.29,
        "grad_norm": 15.412873268127441,
        "learning_rate": 1.5198339483394835e-05,
        "epoch": 15.682656826568266,
        "step": 4250
    },
    {
        "loss": 0.2225,
        "grad_norm": 2.936652183532715,
        "learning_rate": 1.5175276752767528e-05,
        "epoch": 15.719557195571955,
        "step": 4260
    },
    {
        "loss": 0.3041,
        "grad_norm": 3.2967636585235596,
        "learning_rate": 1.515221402214022e-05,
        "epoch": 15.756457564575646,
        "step": 4270
    },
    {
        "loss": 0.2404,
        "grad_norm": 4.351855754852295,
        "learning_rate": 1.5129151291512916e-05,
        "epoch": 15.793357933579335,
        "step": 4280
    },
    {
        "loss": 0.3228,
        "grad_norm": 10.057766914367676,
        "learning_rate": 1.5106088560885609e-05,
        "epoch": 15.830258302583026,
        "step": 4290
    },
    {
        "loss": 0.3056,
        "grad_norm": 13.798455238342285,
        "learning_rate": 1.5083025830258305e-05,
        "epoch": 15.867158671586715,
        "step": 4300
    },
    {
        "loss": 0.2297,
        "grad_norm": 5.591092586517334,
        "learning_rate": 1.5059963099630997e-05,
        "epoch": 15.904059040590406,
        "step": 4310
    },
    {
        "loss": 0.2706,
        "grad_norm": 7.577365398406982,
        "learning_rate": 1.503690036900369e-05,
        "epoch": 15.940959409594097,
        "step": 4320
    },
    {
        "loss": 0.3022,
        "grad_norm": 10.577619552612305,
        "learning_rate": 1.5013837638376386e-05,
        "epoch": 15.977859778597786,
        "step": 4330
    },
    {
        "eval_loss": 0.47007206082344055,
        "eval_accuracy": 0.85701,
        "eval_precision": 0.80968,
        "eval_recall": 0.93135,
        "eval_f1": 0.86626,
        "eval_runtime": 18.0784,
        "eval_samples_per_second": 59.961,
        "eval_steps_per_second": 3.761,
        "epoch": 16.0,
        "step": 4336
    },
    {
        "loss": 0.1611,
        "grad_norm": 1.6889528036117554,
        "learning_rate": 1.4990774907749078e-05,
        "epoch": 16.014760147601475,
        "step": 4340
    },
    {
        "loss": 0.3211,
        "grad_norm": 2.070732355117798,
        "learning_rate": 1.4967712177121774e-05,
        "epoch": 16.051660516605168,
        "step": 4350
    },
    {
        "loss": 0.2764,
        "grad_norm": 1.359472393989563,
        "learning_rate": 1.4944649446494467e-05,
        "epoch": 16.088560885608857,
        "step": 4360
    },
    {
        "loss": 0.1912,
        "grad_norm": 7.556057453155518,
        "learning_rate": 1.4921586715867159e-05,
        "epoch": 16.125461254612546,
        "step": 4370
    },
    {
        "loss": 0.2246,
        "grad_norm": 3.798323631286621,
        "learning_rate": 1.4898523985239853e-05,
        "epoch": 16.162361623616235,
        "step": 4380
    },
    {
        "loss": 0.2259,
        "grad_norm": 1.0015308856964111,
        "learning_rate": 1.4875461254612546e-05,
        "epoch": 16.199261992619927,
        "step": 4390
    },
    {
        "loss": 0.2176,
        "grad_norm": 2.704590320587158,
        "learning_rate": 1.485239852398524e-05,
        "epoch": 16.236162361623617,
        "step": 4400
    },
    {
        "loss": 0.3134,
        "grad_norm": 2.6076278686523438,
        "learning_rate": 1.4829335793357934e-05,
        "epoch": 16.273062730627306,
        "step": 4410
    },
    {
        "loss": 0.2455,
        "grad_norm": 11.876150131225586,
        "learning_rate": 1.4806273062730627e-05,
        "epoch": 16.309963099630995,
        "step": 4420
    },
    {
        "loss": 0.2567,
        "grad_norm": 2.661069869995117,
        "learning_rate": 1.4783210332103323e-05,
        "epoch": 16.346863468634687,
        "step": 4430
    },
    {
        "loss": 0.2698,
        "grad_norm": 47.185218811035156,
        "learning_rate": 1.4760147601476015e-05,
        "epoch": 16.383763837638377,
        "step": 4440
    },
    {
        "loss": 0.2531,
        "grad_norm": 1.2728718519210815,
        "learning_rate": 1.4737084870848708e-05,
        "epoch": 16.420664206642066,
        "step": 4450
    },
    {
        "loss": 0.3549,
        "grad_norm": 3.3494956493377686,
        "learning_rate": 1.4714022140221404e-05,
        "epoch": 16.457564575645755,
        "step": 4460
    },
    {
        "loss": 0.2535,
        "grad_norm": 2.9235270023345947,
        "learning_rate": 1.4690959409594096e-05,
        "epoch": 16.494464944649447,
        "step": 4470
    },
    {
        "loss": 0.2697,
        "grad_norm": 1.890320897102356,
        "learning_rate": 1.4667896678966792e-05,
        "epoch": 16.531365313653136,
        "step": 4480
    },
    {
        "loss": 0.1642,
        "grad_norm": 1.2857778072357178,
        "learning_rate": 1.4644833948339485e-05,
        "epoch": 16.568265682656826,
        "step": 4490
    },
    {
        "loss": 0.2869,
        "grad_norm": 7.141872882843018,
        "learning_rate": 1.4621771217712177e-05,
        "epoch": 16.605166051660518,
        "step": 4500
    },
    {
        "loss": 0.2163,
        "grad_norm": 4.448853492736816,
        "learning_rate": 1.4598708487084871e-05,
        "epoch": 16.642066420664207,
        "step": 4510
    },
    {
        "loss": 0.2952,
        "grad_norm": 3.807724952697754,
        "learning_rate": 1.4575645756457566e-05,
        "epoch": 16.678966789667896,
        "step": 4520
    },
    {
        "loss": 0.2596,
        "grad_norm": 2.498704671859741,
        "learning_rate": 1.455258302583026e-05,
        "epoch": 16.715867158671585,
        "step": 4530
    },
    {
        "loss": 0.2643,
        "grad_norm": 7.511801242828369,
        "learning_rate": 1.4529520295202952e-05,
        "epoch": 16.752767527675278,
        "step": 4540
    },
    {
        "loss": 0.3583,
        "grad_norm": 7.933478355407715,
        "learning_rate": 1.4506457564575645e-05,
        "epoch": 16.789667896678967,
        "step": 4550
    },
    {
        "loss": 0.3321,
        "grad_norm": 13.07502555847168,
        "learning_rate": 1.4483394833948341e-05,
        "epoch": 16.826568265682656,
        "step": 4560
    },
    {
        "loss": 0.2353,
        "grad_norm": 2.633387327194214,
        "learning_rate": 1.4460332103321033e-05,
        "epoch": 16.863468634686345,
        "step": 4570
    },
    {
        "loss": 0.2951,
        "grad_norm": 2.8525290489196777,
        "learning_rate": 1.4437269372693726e-05,
        "epoch": 16.900369003690038,
        "step": 4580
    },
    {
        "loss": 0.2203,
        "grad_norm": 23.803789138793945,
        "learning_rate": 1.4414206642066422e-05,
        "epoch": 16.937269372693727,
        "step": 4590
    },
    {
        "loss": 0.2635,
        "grad_norm": 2.5907742977142334,
        "learning_rate": 1.4391143911439114e-05,
        "epoch": 16.974169741697416,
        "step": 4600
    },
    {
        "eval_loss": 0.4994228780269623,
        "eval_accuracy": 0.84871,
        "eval_precision": 0.82051,
        "eval_recall": 0.89054,
        "eval_f1": 0.85409,
        "eval_runtime": 18.0774,
        "eval_samples_per_second": 59.964,
        "eval_steps_per_second": 3.762,
        "epoch": 17.0,
        "step": 4607
    },
    {
        "loss": 0.3362,
        "grad_norm": 5.1667375564575195,
        "learning_rate": 1.436808118081181e-05,
        "epoch": 17.011070110701105,
        "step": 4610
    },
    {
        "loss": 0.1772,
        "grad_norm": 3.2092223167419434,
        "learning_rate": 1.4345018450184503e-05,
        "epoch": 17.047970479704798,
        "step": 4620
    },
    {
        "loss": 0.2669,
        "grad_norm": 2.433840751647949,
        "learning_rate": 1.4321955719557195e-05,
        "epoch": 17.084870848708487,
        "step": 4630
    },
    {
        "loss": 0.2335,
        "grad_norm": 0.9806344509124756,
        "learning_rate": 1.4298892988929891e-05,
        "epoch": 17.121771217712176,
        "step": 4640
    },
    {
        "loss": 0.2197,
        "grad_norm": 2.3077404499053955,
        "learning_rate": 1.4275830258302584e-05,
        "epoch": 17.15867158671587,
        "step": 4650
    },
    {
        "loss": 0.2648,
        "grad_norm": 3.1887965202331543,
        "learning_rate": 1.4252767527675278e-05,
        "epoch": 17.195571955719558,
        "step": 4660
    },
    {
        "loss": 0.3084,
        "grad_norm": 2.3312573432922363,
        "learning_rate": 1.422970479704797e-05,
        "epoch": 17.232472324723247,
        "step": 4670
    },
    {
        "loss": 0.1452,
        "grad_norm": 4.836407661437988,
        "learning_rate": 1.4206642066420663e-05,
        "epoch": 17.269372693726936,
        "step": 4680
    },
    {
        "loss": 0.2965,
        "grad_norm": 2.2348086833953857,
        "learning_rate": 1.4183579335793359e-05,
        "epoch": 17.30627306273063,
        "step": 4690
    },
    {
        "loss": 0.3975,
        "grad_norm": 4.129106044769287,
        "learning_rate": 1.4160516605166052e-05,
        "epoch": 17.343173431734318,
        "step": 4700
    },
    {
        "loss": 0.173,
        "grad_norm": 1.2088518142700195,
        "learning_rate": 1.4137453874538744e-05,
        "epoch": 17.380073800738007,
        "step": 4710
    },
    {
        "loss": 0.2397,
        "grad_norm": 2.9475536346435547,
        "learning_rate": 1.411439114391144e-05,
        "epoch": 17.416974169741696,
        "step": 4720
    },
    {
        "loss": 0.2472,
        "grad_norm": 3.143235206604004,
        "learning_rate": 1.4091328413284133e-05,
        "epoch": 17.45387453874539,
        "step": 4730
    },
    {
        "loss": 0.2523,
        "grad_norm": 4.16811990737915,
        "learning_rate": 1.4068265682656829e-05,
        "epoch": 17.490774907749078,
        "step": 4740
    },
    {
        "loss": 0.24,
        "grad_norm": 1.1297932863235474,
        "learning_rate": 1.4045202952029521e-05,
        "epoch": 17.527675276752767,
        "step": 4750
    },
    {
        "loss": 0.2431,
        "grad_norm": 5.78102445602417,
        "learning_rate": 1.4022140221402214e-05,
        "epoch": 17.564575645756456,
        "step": 4760
    },
    {
        "loss": 0.1909,
        "grad_norm": 19.347110748291016,
        "learning_rate": 1.399907749077491e-05,
        "epoch": 17.60147601476015,
        "step": 4770
    },
    {
        "loss": 0.4052,
        "grad_norm": 65.07829284667969,
        "learning_rate": 1.3976014760147602e-05,
        "epoch": 17.638376383763838,
        "step": 4780
    },
    {
        "loss": 0.2282,
        "grad_norm": 4.319887161254883,
        "learning_rate": 1.3952952029520296e-05,
        "epoch": 17.675276752767527,
        "step": 4790
    },
    {
        "loss": 0.2305,
        "grad_norm": 1.7120141983032227,
        "learning_rate": 1.3929889298892989e-05,
        "epoch": 17.71217712177122,
        "step": 4800
    },
    {
        "loss": 0.2979,
        "grad_norm": 2.9705183506011963,
        "learning_rate": 1.3906826568265683e-05,
        "epoch": 17.74907749077491,
        "step": 4810
    },
    {
        "loss": 0.2377,
        "grad_norm": 2.4335238933563232,
        "learning_rate": 1.3883763837638377e-05,
        "epoch": 17.785977859778598,
        "step": 4820
    },
    {
        "loss": 0.198,
        "grad_norm": 15.976415634155273,
        "learning_rate": 1.386070110701107e-05,
        "epoch": 17.822878228782287,
        "step": 4830
    },
    {
        "loss": 0.285,
        "grad_norm": 1.0326745510101318,
        "learning_rate": 1.3837638376383766e-05,
        "epoch": 17.85977859778598,
        "step": 4840
    },
    {
        "loss": 0.3078,
        "grad_norm": 4.536804676055908,
        "learning_rate": 1.3814575645756458e-05,
        "epoch": 17.89667896678967,
        "step": 4850
    },
    {
        "loss": 0.3176,
        "grad_norm": 1.2796131372451782,
        "learning_rate": 1.3791512915129151e-05,
        "epoch": 17.933579335793358,
        "step": 4860
    },
    {
        "loss": 0.2977,
        "grad_norm": 5.191043376922607,
        "learning_rate": 1.3768450184501847e-05,
        "epoch": 17.970479704797047,
        "step": 4870
    },
    {
        "eval_loss": 0.4578213095664978,
        "eval_accuracy": 0.85424,
        "eval_precision": 0.80976,
        "eval_recall": 0.92393,
        "eval_f1": 0.86308,
        "eval_runtime": 18.0763,
        "eval_samples_per_second": 59.968,
        "eval_steps_per_second": 3.762,
        "epoch": 18.0,
        "step": 4878
    },
    {
        "loss": 0.302,
        "grad_norm": 23.855854034423828,
        "learning_rate": 1.374538745387454e-05,
        "epoch": 18.00738007380074,
        "step": 4880
    },
    {
        "loss": 0.2477,
        "grad_norm": 3.406611680984497,
        "learning_rate": 1.3722324723247232e-05,
        "epoch": 18.04428044280443,
        "step": 4890
    },
    {
        "loss": 0.2075,
        "grad_norm": 3.989316701889038,
        "learning_rate": 1.3699261992619928e-05,
        "epoch": 18.081180811808117,
        "step": 4900
    },
    {
        "loss": 0.2163,
        "grad_norm": 11.255906105041504,
        "learning_rate": 1.367619926199262e-05,
        "epoch": 18.118081180811807,
        "step": 4910
    },
    {
        "loss": 0.2763,
        "grad_norm": 0.37984463572502136,
        "learning_rate": 1.3653136531365315e-05,
        "epoch": 18.1549815498155,
        "step": 4920
    },
    {
        "loss": 0.216,
        "grad_norm": 1.3763502836227417,
        "learning_rate": 1.3630073800738009e-05,
        "epoch": 18.19188191881919,
        "step": 4930
    },
    {
        "loss": 0.299,
        "grad_norm": 7.441429615020752,
        "learning_rate": 1.3607011070110701e-05,
        "epoch": 18.228782287822877,
        "step": 4940
    },
    {
        "loss": 0.2488,
        "grad_norm": 0.4918178617954254,
        "learning_rate": 1.3583948339483396e-05,
        "epoch": 18.26568265682657,
        "step": 4950
    },
    {
        "loss": 0.252,
        "grad_norm": 4.582347393035889,
        "learning_rate": 1.3560885608856088e-05,
        "epoch": 18.30258302583026,
        "step": 4960
    },
    {
        "loss": 0.1616,
        "grad_norm": 2.1894850730895996,
        "learning_rate": 1.3537822878228784e-05,
        "epoch": 18.339483394833948,
        "step": 4970
    },
    {
        "loss": 0.3094,
        "grad_norm": 36.47304153442383,
        "learning_rate": 1.3514760147601477e-05,
        "epoch": 18.376383763837637,
        "step": 4980
    },
    {
        "loss": 0.1835,
        "grad_norm": 1.814760684967041,
        "learning_rate": 1.3491697416974169e-05,
        "epoch": 18.41328413284133,
        "step": 4990
    },
    {
        "loss": 0.1667,
        "grad_norm": 1.7682595252990723,
        "learning_rate": 1.3468634686346865e-05,
        "epoch": 18.45018450184502,
        "step": 5000
    },
    {
        "loss": 0.1883,
        "grad_norm": 4.4427809715271,
        "learning_rate": 1.3445571955719558e-05,
        "epoch": 18.487084870848708,
        "step": 5010
    },
    {
        "loss": 0.3537,
        "grad_norm": 2.578408718109131,
        "learning_rate": 1.3422509225092253e-05,
        "epoch": 18.523985239852397,
        "step": 5020
    },
    {
        "loss": 0.1737,
        "grad_norm": 1.7024776935577393,
        "learning_rate": 1.3399446494464946e-05,
        "epoch": 18.56088560885609,
        "step": 5030
    },
    {
        "loss": 0.1865,
        "grad_norm": 3.1003355979919434,
        "learning_rate": 1.3376383763837639e-05,
        "epoch": 18.59778597785978,
        "step": 5040
    },
    {
        "loss": 0.382,
        "grad_norm": 11.778373718261719,
        "learning_rate": 1.3353321033210334e-05,
        "epoch": 18.634686346863468,
        "step": 5050
    },
    {
        "loss": 0.2217,
        "grad_norm": 1.3591121435165405,
        "learning_rate": 1.3330258302583027e-05,
        "epoch": 18.671586715867157,
        "step": 5060
    },
    {
        "loss": 0.2955,
        "grad_norm": 3.8483071327209473,
        "learning_rate": 1.330719557195572e-05,
        "epoch": 18.70848708487085,
        "step": 5070
    },
    {
        "loss": 0.2783,
        "grad_norm": 1.1552866697311401,
        "learning_rate": 1.3284132841328414e-05,
        "epoch": 18.74538745387454,
        "step": 5080
    },
    {
        "loss": 0.2638,
        "grad_norm": 6.57138204574585,
        "learning_rate": 1.3261070110701106e-05,
        "epoch": 18.782287822878228,
        "step": 5090
    },
    {
        "loss": 0.3016,
        "grad_norm": 2.156256914138794,
        "learning_rate": 1.3238007380073802e-05,
        "epoch": 18.81918819188192,
        "step": 5100
    },
    {
        "loss": 0.2158,
        "grad_norm": 21.24082374572754,
        "learning_rate": 1.3214944649446495e-05,
        "epoch": 18.85608856088561,
        "step": 5110
    },
    {
        "loss": 0.2563,
        "grad_norm": 3.988185405731201,
        "learning_rate": 1.3191881918819187e-05,
        "epoch": 18.8929889298893,
        "step": 5120
    },
    {
        "loss": 0.2577,
        "grad_norm": 1.7915445566177368,
        "learning_rate": 1.3168819188191883e-05,
        "epoch": 18.929889298892988,
        "step": 5130
    },
    {
        "loss": 0.2488,
        "grad_norm": 8.153152465820312,
        "learning_rate": 1.3145756457564576e-05,
        "epoch": 18.96678966789668,
        "step": 5140
    },
    {
        "eval_loss": 0.5472039580345154,
        "eval_accuracy": 0.84686,
        "eval_precision": 0.80325,
        "eval_recall": 0.91651,
        "eval_f1": 0.85615,
        "eval_runtime": 18.0775,
        "eval_samples_per_second": 59.964,
        "eval_steps_per_second": 3.762,
        "epoch": 19.0,
        "step": 5149
    },
    {
        "loss": 0.3243,
        "grad_norm": 1.0799628496170044,
        "learning_rate": 1.3122693726937272e-05,
        "epoch": 19.00369003690037,
        "step": 5150
    },
    {
        "loss": 0.2313,
        "grad_norm": 2.391197443008423,
        "learning_rate": 1.3099630996309964e-05,
        "epoch": 19.04059040590406,
        "step": 5160
    },
    {
        "loss": 0.3149,
        "grad_norm": 15.760725021362305,
        "learning_rate": 1.3076568265682657e-05,
        "epoch": 19.077490774907748,
        "step": 5170
    },
    {
        "loss": 0.1407,
        "grad_norm": 0.343895822763443,
        "learning_rate": 1.3053505535055353e-05,
        "epoch": 19.11439114391144,
        "step": 5180
    },
    {
        "loss": 0.3178,
        "grad_norm": 7.622537136077881,
        "learning_rate": 1.3030442804428045e-05,
        "epoch": 19.15129151291513,
        "step": 5190
    },
    {
        "loss": 0.2248,
        "grad_norm": 4.700876235961914,
        "learning_rate": 1.3007380073800738e-05,
        "epoch": 19.18819188191882,
        "step": 5200
    },
    {
        "loss": 0.3332,
        "grad_norm": 12.425739288330078,
        "learning_rate": 1.2984317343173432e-05,
        "epoch": 19.225092250922508,
        "step": 5210
    },
    {
        "loss": 0.2792,
        "grad_norm": 3.6427876949310303,
        "learning_rate": 1.2961254612546126e-05,
        "epoch": 19.2619926199262,
        "step": 5220
    },
    {
        "loss": 0.2426,
        "grad_norm": 3.951634407043457,
        "learning_rate": 1.293819188191882e-05,
        "epoch": 19.29889298892989,
        "step": 5230
    },
    {
        "loss": 0.2204,
        "grad_norm": 2.365190029144287,
        "learning_rate": 1.2915129151291513e-05,
        "epoch": 19.33579335793358,
        "step": 5240
    },
    {
        "loss": 0.2288,
        "grad_norm": 6.291188716888428,
        "learning_rate": 1.2892066420664205e-05,
        "epoch": 19.372693726937268,
        "step": 5250
    },
    {
        "loss": 0.1997,
        "grad_norm": 6.455295085906982,
        "learning_rate": 1.2869003690036901e-05,
        "epoch": 19.40959409594096,
        "step": 5260
    },
    {
        "loss": 0.3007,
        "grad_norm": 20.550533294677734,
        "learning_rate": 1.2845940959409594e-05,
        "epoch": 19.44649446494465,
        "step": 5270
    },
    {
        "loss": 0.2658,
        "grad_norm": 2.645226240158081,
        "learning_rate": 1.282287822878229e-05,
        "epoch": 19.48339483394834,
        "step": 5280
    },
    {
        "loss": 0.2217,
        "grad_norm": 3.9130287170410156,
        "learning_rate": 1.2799815498154982e-05,
        "epoch": 19.52029520295203,
        "step": 5290
    },
    {
        "loss": 0.139,
        "grad_norm": 1.9055050611495972,
        "learning_rate": 1.2776752767527675e-05,
        "epoch": 19.55719557195572,
        "step": 5300
    },
    {
        "loss": 0.3648,
        "grad_norm": 9.402268409729004,
        "learning_rate": 1.2753690036900371e-05,
        "epoch": 19.59409594095941,
        "step": 5310
    },
    {
        "loss": 0.2453,
        "grad_norm": 9.08914566040039,
        "learning_rate": 1.2730627306273063e-05,
        "epoch": 19.6309963099631,
        "step": 5320
    },
    {
        "loss": 0.181,
        "grad_norm": 6.233390808105469,
        "learning_rate": 1.2707564575645758e-05,
        "epoch": 19.66789667896679,
        "step": 5330
    },
    {
        "loss": 0.1785,
        "grad_norm": 0.9190370440483093,
        "learning_rate": 1.2684501845018452e-05,
        "epoch": 19.70479704797048,
        "step": 5340
    },
    {
        "loss": 0.2161,
        "grad_norm": 89.32382202148438,
        "learning_rate": 1.2661439114391144e-05,
        "epoch": 19.74169741697417,
        "step": 5350
    },
    {
        "loss": 0.2573,
        "grad_norm": 27.000802993774414,
        "learning_rate": 1.2638376383763839e-05,
        "epoch": 19.77859778597786,
        "step": 5360
    },
    {
        "loss": 0.2797,
        "grad_norm": 1.6035248041152954,
        "learning_rate": 1.2615313653136531e-05,
        "epoch": 19.81549815498155,
        "step": 5370
    },
    {
        "loss": 0.1932,
        "grad_norm": 1.3371309041976929,
        "learning_rate": 1.2592250922509224e-05,
        "epoch": 19.85239852398524,
        "step": 5380
    },
    {
        "loss": 0.2314,
        "grad_norm": 2.091707944869995,
        "learning_rate": 1.256918819188192e-05,
        "epoch": 19.88929889298893,
        "step": 5390
    },
    {
        "loss": 0.2575,
        "grad_norm": 3.059311866760254,
        "learning_rate": 1.2546125461254612e-05,
        "epoch": 19.92619926199262,
        "step": 5400
    },
    {
        "loss": 0.2712,
        "grad_norm": 26.55954933166504,
        "learning_rate": 1.2523062730627308e-05,
        "epoch": 19.96309963099631,
        "step": 5410
    },
    {
        "loss": 0.2988,
        "grad_norm": 1.7540878057479858,
        "learning_rate": 1.25e-05,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "eval_loss": 0.5312360525131226,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.80844,
        "eval_recall": 0.92393,
        "eval_f1": 0.86234,
        "eval_runtime": 18.0216,
        "eval_samples_per_second": 60.15,
        "eval_steps_per_second": 3.773,
        "epoch": 20.0,
        "step": 5420
    },
    {
        "loss": 0.2738,
        "grad_norm": 6.068995475769043,
        "learning_rate": 1.2476937269372695e-05,
        "epoch": 20.03690036900369,
        "step": 5430
    },
    {
        "loss": 0.2436,
        "grad_norm": 4.646535396575928,
        "learning_rate": 1.2453874538745389e-05,
        "epoch": 20.07380073800738,
        "step": 5440
    },
    {
        "loss": 0.2272,
        "grad_norm": 7.542466163635254,
        "learning_rate": 1.2430811808118082e-05,
        "epoch": 20.11070110701107,
        "step": 5450
    },
    {
        "loss": 0.1588,
        "grad_norm": 2.7665114402770996,
        "learning_rate": 1.2407749077490776e-05,
        "epoch": 20.14760147601476,
        "step": 5460
    },
    {
        "loss": 0.2609,
        "grad_norm": 3.7751739025115967,
        "learning_rate": 1.238468634686347e-05,
        "epoch": 20.18450184501845,
        "step": 5470
    },
    {
        "loss": 0.1756,
        "grad_norm": 1.781480312347412,
        "learning_rate": 1.2361623616236164e-05,
        "epoch": 20.22140221402214,
        "step": 5480
    },
    {
        "loss": 0.2934,
        "grad_norm": 2.1514689922332764,
        "learning_rate": 1.2338560885608857e-05,
        "epoch": 20.25830258302583,
        "step": 5490
    },
    {
        "loss": 0.3256,
        "grad_norm": 1.7451894283294678,
        "learning_rate": 1.231549815498155e-05,
        "epoch": 20.29520295202952,
        "step": 5500
    },
    {
        "loss": 0.2452,
        "grad_norm": 5.486478805541992,
        "learning_rate": 1.2292435424354244e-05,
        "epoch": 20.33210332103321,
        "step": 5510
    },
    {
        "loss": 0.192,
        "grad_norm": 1.3201731443405151,
        "learning_rate": 1.2269372693726938e-05,
        "epoch": 20.3690036900369,
        "step": 5520
    },
    {
        "loss": 0.2329,
        "grad_norm": 4.767844200134277,
        "learning_rate": 1.2246309963099632e-05,
        "epoch": 20.40590405904059,
        "step": 5530
    },
    {
        "loss": 0.2369,
        "grad_norm": 27.557422637939453,
        "learning_rate": 1.2223247232472325e-05,
        "epoch": 20.44280442804428,
        "step": 5540
    },
    {
        "loss": 0.1815,
        "grad_norm": 4.383997440338135,
        "learning_rate": 1.2200184501845019e-05,
        "epoch": 20.47970479704797,
        "step": 5550
    },
    {
        "loss": 0.2579,
        "grad_norm": 3.320833921432495,
        "learning_rate": 1.2177121771217713e-05,
        "epoch": 20.51660516605166,
        "step": 5560
    },
    {
        "loss": 0.2873,
        "grad_norm": 4.856762409210205,
        "learning_rate": 1.2154059040590407e-05,
        "epoch": 20.55350553505535,
        "step": 5570
    },
    {
        "loss": 0.2151,
        "grad_norm": 2.225141763687134,
        "learning_rate": 1.21309963099631e-05,
        "epoch": 20.59040590405904,
        "step": 5580
    },
    {
        "loss": 0.2814,
        "grad_norm": 1.7706977128982544,
        "learning_rate": 1.2107933579335794e-05,
        "epoch": 20.627306273062732,
        "step": 5590
    },
    {
        "loss": 0.1578,
        "grad_norm": 2.506890058517456,
        "learning_rate": 1.2084870848708488e-05,
        "epoch": 20.66420664206642,
        "step": 5600
    },
    {
        "loss": 0.1789,
        "grad_norm": 8.96514892578125,
        "learning_rate": 1.2061808118081182e-05,
        "epoch": 20.70110701107011,
        "step": 5610
    },
    {
        "loss": 0.2929,
        "grad_norm": 9.821196556091309,
        "learning_rate": 1.2038745387453875e-05,
        "epoch": 20.7380073800738,
        "step": 5620
    },
    {
        "loss": 0.2396,
        "grad_norm": 0.8172739148139954,
        "learning_rate": 1.201568265682657e-05,
        "epoch": 20.774907749077492,
        "step": 5630
    },
    {
        "loss": 0.2995,
        "grad_norm": 1.5979843139648438,
        "learning_rate": 1.1992619926199262e-05,
        "epoch": 20.81180811808118,
        "step": 5640
    },
    {
        "loss": 0.3023,
        "grad_norm": 4.205807685852051,
        "learning_rate": 1.1969557195571956e-05,
        "epoch": 20.84870848708487,
        "step": 5650
    },
    {
        "loss": 0.1455,
        "grad_norm": 1.5637907981872559,
        "learning_rate": 1.194649446494465e-05,
        "epoch": 20.88560885608856,
        "step": 5660
    },
    {
        "loss": 0.1974,
        "grad_norm": 2.80043888092041,
        "learning_rate": 1.1923431734317343e-05,
        "epoch": 20.922509225092252,
        "step": 5670
    },
    {
        "loss": 0.301,
        "grad_norm": 0.8472114205360413,
        "learning_rate": 1.1900369003690037e-05,
        "epoch": 20.95940959409594,
        "step": 5680
    },
    {
        "loss": 0.2527,
        "grad_norm": 2.080099105834961,
        "learning_rate": 1.1877306273062731e-05,
        "epoch": 20.99630996309963,
        "step": 5690
    },
    {
        "eval_loss": 0.5273154377937317,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.80064,
        "eval_recall": 0.92393,
        "eval_f1": 0.85788,
        "eval_runtime": 18.0708,
        "eval_samples_per_second": 59.986,
        "eval_steps_per_second": 3.763,
        "epoch": 21.0,
        "step": 5691
    },
    {
        "loss": 0.24,
        "grad_norm": 6.712223052978516,
        "learning_rate": 1.1854243542435425e-05,
        "epoch": 21.03321033210332,
        "step": 5700
    },
    {
        "loss": 0.1921,
        "grad_norm": 7.602299690246582,
        "learning_rate": 1.1831180811808118e-05,
        "epoch": 21.070110701107012,
        "step": 5710
    },
    {
        "loss": 0.2196,
        "grad_norm": 2.4833784103393555,
        "learning_rate": 1.1808118081180812e-05,
        "epoch": 21.1070110701107,
        "step": 5720
    },
    {
        "loss": 0.3068,
        "grad_norm": 1.504125952720642,
        "learning_rate": 1.1785055350553506e-05,
        "epoch": 21.14391143911439,
        "step": 5730
    },
    {
        "loss": 0.2444,
        "grad_norm": 2.942366361618042,
        "learning_rate": 1.17619926199262e-05,
        "epoch": 21.18081180811808,
        "step": 5740
    },
    {
        "loss": 0.2369,
        "grad_norm": 22.88755226135254,
        "learning_rate": 1.1738929889298895e-05,
        "epoch": 21.217712177121772,
        "step": 5750
    },
    {
        "loss": 0.2051,
        "grad_norm": 2.339568614959717,
        "learning_rate": 1.1715867158671587e-05,
        "epoch": 21.25461254612546,
        "step": 5760
    },
    {
        "loss": 0.1525,
        "grad_norm": 6.9164628982543945,
        "learning_rate": 1.1692804428044282e-05,
        "epoch": 21.29151291512915,
        "step": 5770
    },
    {
        "loss": 0.2709,
        "grad_norm": 3.7072296142578125,
        "learning_rate": 1.1669741697416974e-05,
        "epoch": 21.328413284132843,
        "step": 5780
    },
    {
        "loss": 0.1946,
        "grad_norm": 133.57131958007812,
        "learning_rate": 1.1646678966789668e-05,
        "epoch": 21.365313653136532,
        "step": 5790
    },
    {
        "loss": 0.1338,
        "grad_norm": 12.041288375854492,
        "learning_rate": 1.1623616236162361e-05,
        "epoch": 21.40221402214022,
        "step": 5800
    },
    {
        "loss": 0.2955,
        "grad_norm": 2.9273412227630615,
        "learning_rate": 1.1600553505535055e-05,
        "epoch": 21.43911439114391,
        "step": 5810
    },
    {
        "loss": 0.1851,
        "grad_norm": 1.0997283458709717,
        "learning_rate": 1.157749077490775e-05,
        "epoch": 21.476014760147603,
        "step": 5820
    },
    {
        "loss": 0.2417,
        "grad_norm": 16.45266342163086,
        "learning_rate": 1.1554428044280444e-05,
        "epoch": 21.512915129151292,
        "step": 5830
    },
    {
        "loss": 0.272,
        "grad_norm": 63.48393630981445,
        "learning_rate": 1.1531365313653138e-05,
        "epoch": 21.54981549815498,
        "step": 5840
    },
    {
        "loss": 0.2665,
        "grad_norm": 1.1672687530517578,
        "learning_rate": 1.150830258302583e-05,
        "epoch": 21.58671586715867,
        "step": 5850
    },
    {
        "loss": 0.1383,
        "grad_norm": 0.9182229042053223,
        "learning_rate": 1.1485239852398525e-05,
        "epoch": 21.623616236162363,
        "step": 5860
    },
    {
        "loss": 0.181,
        "grad_norm": 1.0833677053451538,
        "learning_rate": 1.1462177121771219e-05,
        "epoch": 21.660516605166052,
        "step": 5870
    },
    {
        "loss": 0.3826,
        "grad_norm": 20.588279724121094,
        "learning_rate": 1.1439114391143913e-05,
        "epoch": 21.69741697416974,
        "step": 5880
    },
    {
        "loss": 0.3557,
        "grad_norm": 10.317645072937012,
        "learning_rate": 1.1416051660516606e-05,
        "epoch": 21.73431734317343,
        "step": 5890
    },
    {
        "loss": 0.2309,
        "grad_norm": 2.9306392669677734,
        "learning_rate": 1.13929889298893e-05,
        "epoch": 21.771217712177123,
        "step": 5900
    },
    {
        "loss": 0.1758,
        "grad_norm": 1.6524622440338135,
        "learning_rate": 1.1369926199261992e-05,
        "epoch": 21.80811808118081,
        "step": 5910
    },
    {
        "loss": 0.2478,
        "grad_norm": 11.94061279296875,
        "learning_rate": 1.1346863468634687e-05,
        "epoch": 21.8450184501845,
        "step": 5920
    },
    {
        "loss": 0.1785,
        "grad_norm": 2.7841567993164062,
        "learning_rate": 1.1323800738007381e-05,
        "epoch": 21.881918819188193,
        "step": 5930
    },
    {
        "loss": 0.208,
        "grad_norm": 78.62979125976562,
        "learning_rate": 1.1300738007380073e-05,
        "epoch": 21.918819188191883,
        "step": 5940
    },
    {
        "loss": 0.2408,
        "grad_norm": 11.488554000854492,
        "learning_rate": 1.1277675276752768e-05,
        "epoch": 21.95571955719557,
        "step": 5950
    },
    {
        "loss": 0.265,
        "grad_norm": 20.84555435180664,
        "learning_rate": 1.1254612546125462e-05,
        "epoch": 21.99261992619926,
        "step": 5960
    },
    {
        "eval_loss": 0.5077560544013977,
        "eval_accuracy": 0.85517,
        "eval_precision": 0.82483,
        "eval_recall": 0.89981,
        "eval_f1": 0.86069,
        "eval_runtime": 18.0726,
        "eval_samples_per_second": 59.98,
        "eval_steps_per_second": 3.763,
        "epoch": 22.0,
        "step": 5962
    },
    {
        "loss": 0.208,
        "grad_norm": 0.853455662727356,
        "learning_rate": 1.1231549815498156e-05,
        "epoch": 22.029520295202953,
        "step": 5970
    },
    {
        "loss": 0.1714,
        "grad_norm": 1.2910709381103516,
        "learning_rate": 1.1208487084870849e-05,
        "epoch": 22.066420664206642,
        "step": 5980
    },
    {
        "loss": 0.2135,
        "grad_norm": 3.144375801086426,
        "learning_rate": 1.1185424354243543e-05,
        "epoch": 22.10332103321033,
        "step": 5990
    },
    {
        "loss": 0.2511,
        "grad_norm": 6.6180419921875,
        "learning_rate": 1.1162361623616237e-05,
        "epoch": 22.14022140221402,
        "step": 6000
    },
    {
        "loss": 0.1546,
        "grad_norm": 0.9954055547714233,
        "learning_rate": 1.1139298892988931e-05,
        "epoch": 22.177121771217713,
        "step": 6010
    },
    {
        "loss": 0.2247,
        "grad_norm": 2.918804883956909,
        "learning_rate": 1.1116236162361624e-05,
        "epoch": 22.214022140221402,
        "step": 6020
    },
    {
        "loss": 0.2108,
        "grad_norm": 1.3478518724441528,
        "learning_rate": 1.1093173431734318e-05,
        "epoch": 22.25092250922509,
        "step": 6030
    },
    {
        "loss": 0.1498,
        "grad_norm": 1.1635432243347168,
        "learning_rate": 1.1070110701107012e-05,
        "epoch": 22.28782287822878,
        "step": 6040
    },
    {
        "loss": 0.4117,
        "grad_norm": 13.216774940490723,
        "learning_rate": 1.1047047970479705e-05,
        "epoch": 22.324723247232473,
        "step": 6050
    },
    {
        "loss": 0.1525,
        "grad_norm": 11.936097145080566,
        "learning_rate": 1.1023985239852399e-05,
        "epoch": 22.361623616236162,
        "step": 6060
    },
    {
        "loss": 0.2411,
        "grad_norm": 3.4943625926971436,
        "learning_rate": 1.1000922509225092e-05,
        "epoch": 22.39852398523985,
        "step": 6070
    },
    {
        "loss": 0.2361,
        "grad_norm": 26.76740837097168,
        "learning_rate": 1.0977859778597786e-05,
        "epoch": 22.435424354243544,
        "step": 6080
    },
    {
        "loss": 0.1886,
        "grad_norm": 2.7310593128204346,
        "learning_rate": 1.095479704797048e-05,
        "epoch": 22.472324723247233,
        "step": 6090
    },
    {
        "loss": 0.2951,
        "grad_norm": 0.6851230263710022,
        "learning_rate": 1.0931734317343174e-05,
        "epoch": 22.509225092250922,
        "step": 6100
    },
    {
        "loss": 0.2875,
        "grad_norm": 2.8108677864074707,
        "learning_rate": 1.0908671586715867e-05,
        "epoch": 22.54612546125461,
        "step": 6110
    },
    {
        "loss": 0.2858,
        "grad_norm": 8.570037841796875,
        "learning_rate": 1.0885608856088561e-05,
        "epoch": 22.583025830258304,
        "step": 6120
    },
    {
        "loss": 0.2797,
        "grad_norm": 0.8197014331817627,
        "learning_rate": 1.0862546125461255e-05,
        "epoch": 22.619926199261993,
        "step": 6130
    },
    {
        "loss": 0.2653,
        "grad_norm": 18.230289459228516,
        "learning_rate": 1.083948339483395e-05,
        "epoch": 22.656826568265682,
        "step": 6140
    },
    {
        "loss": 0.2388,
        "grad_norm": 8.451454162597656,
        "learning_rate": 1.0816420664206644e-05,
        "epoch": 22.69372693726937,
        "step": 6150
    },
    {
        "loss": 0.167,
        "grad_norm": 11.84046459197998,
        "learning_rate": 1.0793357933579336e-05,
        "epoch": 22.730627306273064,
        "step": 6160
    },
    {
        "loss": 0.3037,
        "grad_norm": 1.0280869007110596,
        "learning_rate": 1.077029520295203e-05,
        "epoch": 22.767527675276753,
        "step": 6170
    },
    {
        "loss": 0.2163,
        "grad_norm": 3.190648317337036,
        "learning_rate": 1.0747232472324725e-05,
        "epoch": 22.804428044280442,
        "step": 6180
    },
    {
        "loss": 0.2708,
        "grad_norm": 5.993993759155273,
        "learning_rate": 1.0724169741697417e-05,
        "epoch": 22.84132841328413,
        "step": 6190
    },
    {
        "loss": 0.2606,
        "grad_norm": 3.3511648178100586,
        "learning_rate": 1.070110701107011e-05,
        "epoch": 22.878228782287824,
        "step": 6200
    },
    {
        "loss": 0.1423,
        "grad_norm": 2.172105550765991,
        "learning_rate": 1.0678044280442804e-05,
        "epoch": 22.915129151291513,
        "step": 6210
    },
    {
        "loss": 0.2074,
        "grad_norm": 5.589158535003662,
        "learning_rate": 1.0654981549815498e-05,
        "epoch": 22.952029520295202,
        "step": 6220
    },
    {
        "loss": 0.259,
        "grad_norm": 0.9888314604759216,
        "learning_rate": 1.0631918819188192e-05,
        "epoch": 22.988929889298895,
        "step": 6230
    },
    {
        "eval_loss": 0.5758722424507141,
        "eval_accuracy": 0.85055,
        "eval_precision": 0.81895,
        "eval_recall": 0.89796,
        "eval_f1": 0.85664,
        "eval_runtime": 18.0818,
        "eval_samples_per_second": 59.95,
        "eval_steps_per_second": 3.761,
        "epoch": 23.0,
        "step": 6233
    },
    {
        "loss": 0.1588,
        "grad_norm": 8.189111709594727,
        "learning_rate": 1.0608856088560887e-05,
        "epoch": 23.025830258302584,
        "step": 6240
    },
    {
        "loss": 0.3114,
        "grad_norm": 2.651613473892212,
        "learning_rate": 1.058579335793358e-05,
        "epoch": 23.062730627306273,
        "step": 6250
    },
    {
        "loss": 0.157,
        "grad_norm": 7.050734519958496,
        "learning_rate": 1.0562730627306273e-05,
        "epoch": 23.099630996309962,
        "step": 6260
    },
    {
        "loss": 0.2628,
        "grad_norm": 3.386523723602295,
        "learning_rate": 1.0539667896678968e-05,
        "epoch": 23.136531365313655,
        "step": 6270
    },
    {
        "loss": 0.1882,
        "grad_norm": 6.620233058929443,
        "learning_rate": 1.0516605166051662e-05,
        "epoch": 23.173431734317344,
        "step": 6280
    },
    {
        "loss": 0.3094,
        "grad_norm": 5.383049488067627,
        "learning_rate": 1.0493542435424354e-05,
        "epoch": 23.210332103321033,
        "step": 6290
    },
    {
        "loss": 0.1899,
        "grad_norm": 4.782850742340088,
        "learning_rate": 1.0470479704797049e-05,
        "epoch": 23.247232472324722,
        "step": 6300
    },
    {
        "loss": 0.2769,
        "grad_norm": 1.454540729522705,
        "learning_rate": 1.0447416974169743e-05,
        "epoch": 23.284132841328415,
        "step": 6310
    },
    {
        "loss": 0.2266,
        "grad_norm": 3.88417387008667,
        "learning_rate": 1.0424354243542435e-05,
        "epoch": 23.321033210332104,
        "step": 6320
    },
    {
        "loss": 0.198,
        "grad_norm": 8.930274963378906,
        "learning_rate": 1.040129151291513e-05,
        "epoch": 23.357933579335793,
        "step": 6330
    },
    {
        "loss": 0.2248,
        "grad_norm": 15.532241821289062,
        "learning_rate": 1.0378228782287822e-05,
        "epoch": 23.394833948339482,
        "step": 6340
    },
    {
        "loss": 0.1999,
        "grad_norm": 4.439775466918945,
        "learning_rate": 1.0355166051660516e-05,
        "epoch": 23.431734317343174,
        "step": 6350
    },
    {
        "loss": 0.1506,
        "grad_norm": 2.3312411308288574,
        "learning_rate": 1.033210332103321e-05,
        "epoch": 23.468634686346864,
        "step": 6360
    },
    {
        "loss": 0.3294,
        "grad_norm": 0.5656141042709351,
        "learning_rate": 1.0309040590405905e-05,
        "epoch": 23.505535055350553,
        "step": 6370
    },
    {
        "loss": 0.1816,
        "grad_norm": 1.4018267393112183,
        "learning_rate": 1.0285977859778597e-05,
        "epoch": 23.542435424354245,
        "step": 6380
    },
    {
        "loss": 0.1862,
        "grad_norm": 15.186978340148926,
        "learning_rate": 1.0262915129151292e-05,
        "epoch": 23.579335793357934,
        "step": 6390
    },
    {
        "loss": 0.279,
        "grad_norm": 21.212249755859375,
        "learning_rate": 1.0239852398523986e-05,
        "epoch": 23.616236162361623,
        "step": 6400
    },
    {
        "loss": 0.165,
        "grad_norm": 32.76950454711914,
        "learning_rate": 1.021678966789668e-05,
        "epoch": 23.653136531365313,
        "step": 6410
    },
    {
        "loss": 0.1924,
        "grad_norm": 1.558984398841858,
        "learning_rate": 1.0193726937269373e-05,
        "epoch": 23.690036900369005,
        "step": 6420
    },
    {
        "loss": 0.309,
        "grad_norm": 22.257612228393555,
        "learning_rate": 1.0170664206642067e-05,
        "epoch": 23.726937269372694,
        "step": 6430
    },
    {
        "loss": 0.2918,
        "grad_norm": 1.0610898733139038,
        "learning_rate": 1.0147601476014761e-05,
        "epoch": 23.763837638376383,
        "step": 6440
    },
    {
        "loss": 0.1029,
        "grad_norm": 2.6850006580352783,
        "learning_rate": 1.0124538745387455e-05,
        "epoch": 23.800738007380073,
        "step": 6450
    },
    {
        "loss": 0.2751,
        "grad_norm": 1.5665618181228638,
        "learning_rate": 1.0101476014760148e-05,
        "epoch": 23.837638376383765,
        "step": 6460
    },
    {
        "loss": 0.1747,
        "grad_norm": 1.8255774974822998,
        "learning_rate": 1.0078413284132842e-05,
        "epoch": 23.874538745387454,
        "step": 6470
    },
    {
        "loss": 0.1638,
        "grad_norm": 1.8062647581100464,
        "learning_rate": 1.0055350553505535e-05,
        "epoch": 23.911439114391143,
        "step": 6480
    },
    {
        "loss": 0.3063,
        "grad_norm": 2.233917713165283,
        "learning_rate": 1.0032287822878229e-05,
        "epoch": 23.948339483394832,
        "step": 6490
    },
    {
        "loss": 0.2961,
        "grad_norm": 2.346250057220459,
        "learning_rate": 1.0009225092250923e-05,
        "epoch": 23.985239852398525,
        "step": 6500
    },
    {
        "eval_loss": 0.5818905830383301,
        "eval_accuracy": 0.84871,
        "eval_precision": 0.8,
        "eval_recall": 0.92764,
        "eval_f1": 0.85911,
        "eval_runtime": 18.0682,
        "eval_samples_per_second": 59.995,
        "eval_steps_per_second": 3.764,
        "epoch": 24.0,
        "step": 6504
    },
    {
        "loss": 0.1598,
        "grad_norm": 1.2858428955078125,
        "learning_rate": 9.986162361623616e-06,
        "epoch": 24.022140221402214,
        "step": 6510
    },
    {
        "loss": 0.2135,
        "grad_norm": 7.163441181182861,
        "learning_rate": 9.96309963099631e-06,
        "epoch": 24.059040590405903,
        "step": 6520
    },
    {
        "loss": 0.1796,
        "grad_norm": 1.210689663887024,
        "learning_rate": 9.940036900369004e-06,
        "epoch": 24.095940959409592,
        "step": 6530
    },
    {
        "loss": 0.1876,
        "grad_norm": 6.535627365112305,
        "learning_rate": 9.916974169741698e-06,
        "epoch": 24.132841328413285,
        "step": 6540
    },
    {
        "loss": 0.1884,
        "grad_norm": 1.8119169473648071,
        "learning_rate": 9.893911439114393e-06,
        "epoch": 24.169741697416974,
        "step": 6550
    },
    {
        "loss": 0.2083,
        "grad_norm": 1.3051258325576782,
        "learning_rate": 9.870848708487085e-06,
        "epoch": 24.206642066420663,
        "step": 6560
    },
    {
        "loss": 0.1654,
        "grad_norm": 26.00739860534668,
        "learning_rate": 9.84778597785978e-06,
        "epoch": 24.243542435424356,
        "step": 6570
    },
    {
        "loss": 0.2056,
        "grad_norm": 25.989105224609375,
        "learning_rate": 9.824723247232474e-06,
        "epoch": 24.280442804428045,
        "step": 6580
    },
    {
        "loss": 0.121,
        "grad_norm": 0.43267735838890076,
        "learning_rate": 9.801660516605168e-06,
        "epoch": 24.317343173431734,
        "step": 6590
    },
    {
        "loss": 0.1241,
        "grad_norm": 1.1495637893676758,
        "learning_rate": 9.77859778597786e-06,
        "epoch": 24.354243542435423,
        "step": 6600
    },
    {
        "loss": 0.2404,
        "grad_norm": 6.931694507598877,
        "learning_rate": 9.755535055350553e-06,
        "epoch": 24.391143911439116,
        "step": 6610
    },
    {
        "loss": 0.216,
        "grad_norm": 1.2538089752197266,
        "learning_rate": 9.732472324723247e-06,
        "epoch": 24.428044280442805,
        "step": 6620
    },
    {
        "loss": 0.2414,
        "grad_norm": 2.785216808319092,
        "learning_rate": 9.709409594095941e-06,
        "epoch": 24.464944649446494,
        "step": 6630
    },
    {
        "loss": 0.3381,
        "grad_norm": 8.143704414367676,
        "learning_rate": 9.686346863468636e-06,
        "epoch": 24.501845018450183,
        "step": 6640
    },
    {
        "loss": 0.3287,
        "grad_norm": 1.5597927570343018,
        "learning_rate": 9.663284132841328e-06,
        "epoch": 24.538745387453876,
        "step": 6650
    },
    {
        "loss": 0.1939,
        "grad_norm": 2.0379509925842285,
        "learning_rate": 9.640221402214022e-06,
        "epoch": 24.575645756457565,
        "step": 6660
    },
    {
        "loss": 0.2518,
        "grad_norm": 4.546820163726807,
        "learning_rate": 9.617158671586717e-06,
        "epoch": 24.612546125461254,
        "step": 6670
    },
    {
        "loss": 0.2626,
        "grad_norm": 23.74036407470703,
        "learning_rate": 9.59409594095941e-06,
        "epoch": 24.649446494464943,
        "step": 6680
    },
    {
        "loss": 0.1742,
        "grad_norm": 1.0855209827423096,
        "learning_rate": 9.571033210332103e-06,
        "epoch": 24.686346863468636,
        "step": 6690
    },
    {
        "loss": 0.2405,
        "grad_norm": 1.7630634307861328,
        "learning_rate": 9.547970479704798e-06,
        "epoch": 24.723247232472325,
        "step": 6700
    },
    {
        "loss": 0.1947,
        "grad_norm": 4.098705291748047,
        "learning_rate": 9.524907749077492e-06,
        "epoch": 24.760147601476014,
        "step": 6710
    },
    {
        "loss": 0.1726,
        "grad_norm": 1.9288380146026611,
        "learning_rate": 9.501845018450186e-06,
        "epoch": 24.797047970479706,
        "step": 6720
    },
    {
        "loss": 0.245,
        "grad_norm": 4.963428974151611,
        "learning_rate": 9.478782287822879e-06,
        "epoch": 24.833948339483396,
        "step": 6730
    },
    {
        "loss": 0.2842,
        "grad_norm": 12.614866256713867,
        "learning_rate": 9.455719557195573e-06,
        "epoch": 24.870848708487085,
        "step": 6740
    },
    {
        "loss": 0.1801,
        "grad_norm": 4.794894695281982,
        "learning_rate": 9.432656826568265e-06,
        "epoch": 24.907749077490774,
        "step": 6750
    },
    {
        "loss": 0.2514,
        "grad_norm": 5.509423732757568,
        "learning_rate": 9.40959409594096e-06,
        "epoch": 24.944649446494466,
        "step": 6760
    },
    {
        "loss": 0.2458,
        "grad_norm": 16.825681686401367,
        "learning_rate": 9.386531365313654e-06,
        "epoch": 24.981549815498155,
        "step": 6770
    },
    {
        "eval_loss": 0.5370188355445862,
        "eval_accuracy": 0.84963,
        "eval_precision": 0.80619,
        "eval_recall": 0.91837,
        "eval_f1": 0.85863,
        "eval_runtime": 18.0719,
        "eval_samples_per_second": 59.983,
        "eval_steps_per_second": 3.763,
        "epoch": 25.0,
        "step": 6775
    },
    {
        "loss": 0.1536,
        "grad_norm": 1.212030291557312,
        "learning_rate": 9.363468634686346e-06,
        "epoch": 25.018450184501845,
        "step": 6780
    },
    {
        "loss": 0.2139,
        "grad_norm": 3.0022642612457275,
        "learning_rate": 9.34040590405904e-06,
        "epoch": 25.055350553505534,
        "step": 6790
    },
    {
        "loss": 0.2212,
        "grad_norm": 8.15125846862793,
        "learning_rate": 9.317343173431735e-06,
        "epoch": 25.092250922509226,
        "step": 6800
    },
    {
        "loss": 0.1822,
        "grad_norm": 5.990250110626221,
        "learning_rate": 9.294280442804429e-06,
        "epoch": 25.129151291512915,
        "step": 6810
    },
    {
        "loss": 0.2389,
        "grad_norm": 0.9345170855522156,
        "learning_rate": 9.271217712177122e-06,
        "epoch": 25.166051660516604,
        "step": 6820
    },
    {
        "loss": 0.2655,
        "grad_norm": 1.5906230211257935,
        "learning_rate": 9.248154981549816e-06,
        "epoch": 25.202952029520294,
        "step": 6830
    },
    {
        "loss": 0.225,
        "grad_norm": 3.286468982696533,
        "learning_rate": 9.22509225092251e-06,
        "epoch": 25.239852398523986,
        "step": 6840
    },
    {
        "loss": 0.2436,
        "grad_norm": 6.595404624938965,
        "learning_rate": 9.202029520295204e-06,
        "epoch": 25.276752767527675,
        "step": 6850
    },
    {
        "loss": 0.2036,
        "grad_norm": 2.723172187805176,
        "learning_rate": 9.178966789667898e-06,
        "epoch": 25.313653136531364,
        "step": 6860
    },
    {
        "loss": 0.2017,
        "grad_norm": 14.525835990905762,
        "learning_rate": 9.155904059040591e-06,
        "epoch": 25.350553505535057,
        "step": 6870
    },
    {
        "loss": 0.2296,
        "grad_norm": 0.6164672374725342,
        "learning_rate": 9.132841328413285e-06,
        "epoch": 25.387453874538746,
        "step": 6880
    },
    {
        "loss": 0.1969,
        "grad_norm": 1.648498773574829,
        "learning_rate": 9.109778597785978e-06,
        "epoch": 25.424354243542435,
        "step": 6890
    },
    {
        "loss": 0.2036,
        "grad_norm": 1.9643115997314453,
        "learning_rate": 9.086715867158672e-06,
        "epoch": 25.461254612546124,
        "step": 6900
    },
    {
        "loss": 0.1392,
        "grad_norm": 2.3144397735595703,
        "learning_rate": 9.063653136531364e-06,
        "epoch": 25.498154981549817,
        "step": 6910
    },
    {
        "loss": 0.2896,
        "grad_norm": 4.023421287536621,
        "learning_rate": 9.040590405904059e-06,
        "epoch": 25.535055350553506,
        "step": 6920
    },
    {
        "loss": 0.3429,
        "grad_norm": 53.907649993896484,
        "learning_rate": 9.017527675276753e-06,
        "epoch": 25.571955719557195,
        "step": 6930
    },
    {
        "loss": 0.1109,
        "grad_norm": 1.1887562274932861,
        "learning_rate": 8.994464944649447e-06,
        "epoch": 25.608856088560884,
        "step": 6940
    },
    {
        "loss": 0.2416,
        "grad_norm": 1.1738959550857544,
        "learning_rate": 8.971402214022141e-06,
        "epoch": 25.645756457564577,
        "step": 6950
    },
    {
        "loss": 0.2036,
        "grad_norm": 1.5273205041885376,
        "learning_rate": 8.948339483394834e-06,
        "epoch": 25.682656826568266,
        "step": 6960
    },
    {
        "loss": 0.2079,
        "grad_norm": 4.127335071563721,
        "learning_rate": 8.925276752767528e-06,
        "epoch": 25.719557195571955,
        "step": 6970
    },
    {
        "loss": 0.2165,
        "grad_norm": 0.7489275336265564,
        "learning_rate": 8.902214022140222e-06,
        "epoch": 25.756457564575644,
        "step": 6980
    },
    {
        "loss": 0.3998,
        "grad_norm": 6.613985061645508,
        "learning_rate": 8.879151291512917e-06,
        "epoch": 25.793357933579337,
        "step": 6990
    },
    {
        "loss": 0.1415,
        "grad_norm": 0.9965340495109558,
        "learning_rate": 8.85608856088561e-06,
        "epoch": 25.830258302583026,
        "step": 7000
    },
    {
        "loss": 0.2145,
        "grad_norm": 25.90093231201172,
        "learning_rate": 8.833025830258303e-06,
        "epoch": 25.867158671586715,
        "step": 7010
    },
    {
        "loss": 0.2313,
        "grad_norm": 1.823596477508545,
        "learning_rate": 8.809963099630996e-06,
        "epoch": 25.904059040590404,
        "step": 7020
    },
    {
        "loss": 0.137,
        "grad_norm": 3.41093111038208,
        "learning_rate": 8.78690036900369e-06,
        "epoch": 25.940959409594097,
        "step": 7030
    },
    {
        "loss": 0.1683,
        "grad_norm": 1.6735135316848755,
        "learning_rate": 8.763837638376384e-06,
        "epoch": 25.977859778597786,
        "step": 7040
    },
    {
        "eval_loss": 0.5554469227790833,
        "eval_accuracy": 0.8607,
        "eval_precision": 0.82441,
        "eval_recall": 0.91466,
        "eval_f1": 0.86719,
        "eval_runtime": 18.0701,
        "eval_samples_per_second": 59.989,
        "eval_steps_per_second": 3.763,
        "epoch": 26.0,
        "step": 7046
    },
    {
        "loss": 0.1302,
        "grad_norm": 11.309101104736328,
        "learning_rate": 8.740774907749077e-06,
        "epoch": 26.014760147601475,
        "step": 7050
    },
    {
        "loss": 0.1858,
        "grad_norm": 2.6098549365997314,
        "learning_rate": 8.717712177121771e-06,
        "epoch": 26.051660516605168,
        "step": 7060
    },
    {
        "loss": 0.2822,
        "grad_norm": 1.0927983522415161,
        "learning_rate": 8.694649446494465e-06,
        "epoch": 26.088560885608857,
        "step": 7070
    },
    {
        "loss": 0.3577,
        "grad_norm": 33.28553009033203,
        "learning_rate": 8.67158671586716e-06,
        "epoch": 26.125461254612546,
        "step": 7080
    },
    {
        "loss": 0.1988,
        "grad_norm": 0.5092580318450928,
        "learning_rate": 8.648523985239852e-06,
        "epoch": 26.162361623616235,
        "step": 7090
    },
    {
        "loss": 0.1225,
        "grad_norm": 3.2603349685668945,
        "learning_rate": 8.625461254612546e-06,
        "epoch": 26.199261992619927,
        "step": 7100
    },
    {
        "loss": 0.2536,
        "grad_norm": 92.85218048095703,
        "learning_rate": 8.60239852398524e-06,
        "epoch": 26.236162361623617,
        "step": 7110
    },
    {
        "loss": 0.2361,
        "grad_norm": 1.2412290573120117,
        "learning_rate": 8.579335793357935e-06,
        "epoch": 26.273062730627306,
        "step": 7120
    },
    {
        "loss": 0.2553,
        "grad_norm": 17.635974884033203,
        "learning_rate": 8.556273062730629e-06,
        "epoch": 26.309963099630995,
        "step": 7130
    },
    {
        "loss": 0.2381,
        "grad_norm": 2.4753353595733643,
        "learning_rate": 8.533210332103322e-06,
        "epoch": 26.346863468634687,
        "step": 7140
    },
    {
        "loss": 0.2518,
        "grad_norm": 1.7418495416641235,
        "learning_rate": 8.510147601476016e-06,
        "epoch": 26.383763837638377,
        "step": 7150
    },
    {
        "loss": 0.1864,
        "grad_norm": 12.839753150939941,
        "learning_rate": 8.487084870848708e-06,
        "epoch": 26.420664206642066,
        "step": 7160
    },
    {
        "loss": 0.1857,
        "grad_norm": 1.09807288646698,
        "learning_rate": 8.464022140221403e-06,
        "epoch": 26.457564575645755,
        "step": 7170
    },
    {
        "loss": 0.1207,
        "grad_norm": 2.104241132736206,
        "learning_rate": 8.440959409594095e-06,
        "epoch": 26.494464944649447,
        "step": 7180
    },
    {
        "loss": 0.3095,
        "grad_norm": 1.753568410873413,
        "learning_rate": 8.41789667896679e-06,
        "epoch": 26.531365313653136,
        "step": 7190
    },
    {
        "loss": 0.2454,
        "grad_norm": 2.17030668258667,
        "learning_rate": 8.394833948339484e-06,
        "epoch": 26.568265682656826,
        "step": 7200
    },
    {
        "loss": 0.2225,
        "grad_norm": 1.0029338598251343,
        "learning_rate": 8.371771217712178e-06,
        "epoch": 26.605166051660518,
        "step": 7210
    },
    {
        "loss": 0.1977,
        "grad_norm": 1.8603713512420654,
        "learning_rate": 8.34870848708487e-06,
        "epoch": 26.642066420664207,
        "step": 7220
    },
    {
        "loss": 0.1763,
        "grad_norm": 0.540244996547699,
        "learning_rate": 8.325645756457565e-06,
        "epoch": 26.678966789667896,
        "step": 7230
    },
    {
        "loss": 0.1962,
        "grad_norm": 13.785195350646973,
        "learning_rate": 8.302583025830259e-06,
        "epoch": 26.715867158671585,
        "step": 7240
    },
    {
        "loss": 0.1971,
        "grad_norm": 8.328619956970215,
        "learning_rate": 8.279520295202953e-06,
        "epoch": 26.752767527675278,
        "step": 7250
    },
    {
        "loss": 0.1578,
        "grad_norm": 6.842489242553711,
        "learning_rate": 8.256457564575647e-06,
        "epoch": 26.789667896678967,
        "step": 7260
    },
    {
        "loss": 0.2189,
        "grad_norm": 2.1788330078125,
        "learning_rate": 8.23339483394834e-06,
        "epoch": 26.826568265682656,
        "step": 7270
    },
    {
        "loss": 0.2843,
        "grad_norm": 1.3359092473983765,
        "learning_rate": 8.210332103321034e-06,
        "epoch": 26.863468634686345,
        "step": 7280
    },
    {
        "loss": 0.2104,
        "grad_norm": 17.243947982788086,
        "learning_rate": 8.187269372693728e-06,
        "epoch": 26.900369003690038,
        "step": 7290
    },
    {
        "loss": 0.1636,
        "grad_norm": 3.504204034805298,
        "learning_rate": 8.16420664206642e-06,
        "epoch": 26.937269372693727,
        "step": 7300
    },
    {
        "loss": 0.1794,
        "grad_norm": 133.37039184570312,
        "learning_rate": 8.141143911439113e-06,
        "epoch": 26.974169741697416,
        "step": 7310
    },
    {
        "eval_loss": 0.613514244556427,
        "eval_accuracy": 0.84963,
        "eval_precision": 0.8165,
        "eval_recall": 0.89981,
        "eval_f1": 0.85613,
        "eval_runtime": 18.0685,
        "eval_samples_per_second": 59.994,
        "eval_steps_per_second": 3.763,
        "epoch": 27.0,
        "step": 7317
    },
    {
        "loss": 0.2124,
        "grad_norm": 19.506370544433594,
        "learning_rate": 8.118081180811808e-06,
        "epoch": 27.011070110701105,
        "step": 7320
    },
    {
        "loss": 0.1569,
        "grad_norm": 1.274064302444458,
        "learning_rate": 8.095018450184502e-06,
        "epoch": 27.047970479704798,
        "step": 7330
    },
    {
        "loss": 0.1969,
        "grad_norm": 16.551605224609375,
        "learning_rate": 8.071955719557196e-06,
        "epoch": 27.084870848708487,
        "step": 7340
    },
    {
        "loss": 0.2075,
        "grad_norm": 27.582244873046875,
        "learning_rate": 8.04889298892989e-06,
        "epoch": 27.121771217712176,
        "step": 7350
    },
    {
        "loss": 0.1715,
        "grad_norm": 1.1988228559494019,
        "learning_rate": 8.025830258302583e-06,
        "epoch": 27.15867158671587,
        "step": 7360
    },
    {
        "loss": 0.2018,
        "grad_norm": 0.5972139239311218,
        "learning_rate": 8.002767527675277e-06,
        "epoch": 27.195571955719558,
        "step": 7370
    },
    {
        "loss": 0.1909,
        "grad_norm": 9.209561347961426,
        "learning_rate": 7.979704797047971e-06,
        "epoch": 27.232472324723247,
        "step": 7380
    },
    {
        "loss": 0.2699,
        "grad_norm": 1.8656731843948364,
        "learning_rate": 7.956642066420665e-06,
        "epoch": 27.269372693726936,
        "step": 7390
    },
    {
        "loss": 0.2341,
        "grad_norm": 5.665223598480225,
        "learning_rate": 7.933579335793358e-06,
        "epoch": 27.30627306273063,
        "step": 7400
    },
    {
        "loss": 0.1939,
        "grad_norm": 1.4995225667953491,
        "learning_rate": 7.910516605166052e-06,
        "epoch": 27.343173431734318,
        "step": 7410
    },
    {
        "loss": 0.1743,
        "grad_norm": 8.116522789001465,
        "learning_rate": 7.887453874538746e-06,
        "epoch": 27.380073800738007,
        "step": 7420
    },
    {
        "loss": 0.192,
        "grad_norm": 0.5807507038116455,
        "learning_rate": 7.864391143911439e-06,
        "epoch": 27.416974169741696,
        "step": 7430
    },
    {
        "loss": 0.3213,
        "grad_norm": 2.7661194801330566,
        "learning_rate": 7.841328413284133e-06,
        "epoch": 27.45387453874539,
        "step": 7440
    },
    {
        "loss": 0.1434,
        "grad_norm": 2.80147385597229,
        "learning_rate": 7.818265682656826e-06,
        "epoch": 27.490774907749078,
        "step": 7450
    },
    {
        "loss": 0.1992,
        "grad_norm": 8.012014389038086,
        "learning_rate": 7.79520295202952e-06,
        "epoch": 27.527675276752767,
        "step": 7460
    },
    {
        "loss": 0.143,
        "grad_norm": 0.587570071220398,
        "learning_rate": 7.772140221402214e-06,
        "epoch": 27.564575645756456,
        "step": 7470
    },
    {
        "loss": 0.1444,
        "grad_norm": 1.7822299003601074,
        "learning_rate": 7.749077490774908e-06,
        "epoch": 27.60147601476015,
        "step": 7480
    },
    {
        "loss": 0.2966,
        "grad_norm": 56.30000686645508,
        "learning_rate": 7.726014760147601e-06,
        "epoch": 27.638376383763838,
        "step": 7490
    },
    {
        "loss": 0.2052,
        "grad_norm": 3.890756130218506,
        "learning_rate": 7.702952029520295e-06,
        "epoch": 27.675276752767527,
        "step": 7500
    },
    {
        "loss": 0.4131,
        "grad_norm": 5.220268726348877,
        "learning_rate": 7.67988929889299e-06,
        "epoch": 27.71217712177122,
        "step": 7510
    },
    {
        "loss": 0.205,
        "grad_norm": 1.8119831085205078,
        "learning_rate": 7.656826568265684e-06,
        "epoch": 27.74907749077491,
        "step": 7520
    },
    {
        "loss": 0.145,
        "grad_norm": 4.497974872589111,
        "learning_rate": 7.633763837638378e-06,
        "epoch": 27.785977859778598,
        "step": 7530
    },
    {
        "loss": 0.1871,
        "grad_norm": 9.443123817443848,
        "learning_rate": 7.6107011070110704e-06,
        "epoch": 27.822878228782287,
        "step": 7540
    },
    {
        "loss": 0.1731,
        "grad_norm": 5.1645188331604,
        "learning_rate": 7.587638376383764e-06,
        "epoch": 27.85977859778598,
        "step": 7550
    },
    {
        "loss": 0.2272,
        "grad_norm": 2.1274561882019043,
        "learning_rate": 7.564575645756458e-06,
        "epoch": 27.89667896678967,
        "step": 7560
    },
    {
        "loss": 0.1767,
        "grad_norm": 1.1635198593139648,
        "learning_rate": 7.541512915129152e-06,
        "epoch": 27.933579335793358,
        "step": 7570
    },
    {
        "loss": 0.2526,
        "grad_norm": 15.224811553955078,
        "learning_rate": 7.518450184501845e-06,
        "epoch": 27.970479704797047,
        "step": 7580
    },
    {
        "eval_loss": 0.6028520464897156,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.82646,
        "eval_recall": 0.89239,
        "eval_f1": 0.85816,
        "eval_runtime": 18.0748,
        "eval_samples_per_second": 59.973,
        "eval_steps_per_second": 3.762,
        "epoch": 28.0,
        "step": 7588
    },
    {
        "loss": 0.1772,
        "grad_norm": 1.1560156345367432,
        "learning_rate": 7.495387453874539e-06,
        "epoch": 28.00738007380074,
        "step": 7590
    },
    {
        "loss": 0.1561,
        "grad_norm": 19.74236297607422,
        "learning_rate": 7.472324723247233e-06,
        "epoch": 28.04428044280443,
        "step": 7600
    },
    {
        "loss": 0.1216,
        "grad_norm": 5.440332412719727,
        "learning_rate": 7.449261992619927e-06,
        "epoch": 28.081180811808117,
        "step": 7610
    },
    {
        "loss": 0.3442,
        "grad_norm": 1.9206445217132568,
        "learning_rate": 7.42619926199262e-06,
        "epoch": 28.118081180811807,
        "step": 7620
    },
    {
        "loss": 0.168,
        "grad_norm": 0.966783344745636,
        "learning_rate": 7.403136531365313e-06,
        "epoch": 28.1549815498155,
        "step": 7630
    },
    {
        "loss": 0.2465,
        "grad_norm": 1.2749714851379395,
        "learning_rate": 7.380073800738008e-06,
        "epoch": 28.19188191881919,
        "step": 7640
    },
    {
        "loss": 0.286,
        "grad_norm": 3.209688663482666,
        "learning_rate": 7.357011070110702e-06,
        "epoch": 28.228782287822877,
        "step": 7650
    },
    {
        "loss": 0.1733,
        "grad_norm": 19.773649215698242,
        "learning_rate": 7.333948339483396e-06,
        "epoch": 28.26568265682657,
        "step": 7660
    },
    {
        "loss": 0.2118,
        "grad_norm": 3.404026746749878,
        "learning_rate": 7.310885608856089e-06,
        "epoch": 28.30258302583026,
        "step": 7670
    },
    {
        "loss": 0.1132,
        "grad_norm": 17.370445251464844,
        "learning_rate": 7.287822878228783e-06,
        "epoch": 28.339483394833948,
        "step": 7680
    },
    {
        "loss": 0.1486,
        "grad_norm": 1.1090621948242188,
        "learning_rate": 7.264760147601476e-06,
        "epoch": 28.376383763837637,
        "step": 7690
    },
    {
        "loss": 0.2021,
        "grad_norm": 3.4232094287872314,
        "learning_rate": 7.2416974169741705e-06,
        "epoch": 28.41328413284133,
        "step": 7700
    },
    {
        "loss": 0.2458,
        "grad_norm": 1.241491436958313,
        "learning_rate": 7.218634686346863e-06,
        "epoch": 28.45018450184502,
        "step": 7710
    },
    {
        "loss": 0.1796,
        "grad_norm": 1.0930473804473877,
        "learning_rate": 7.195571955719557e-06,
        "epoch": 28.487084870848708,
        "step": 7720
    },
    {
        "loss": 0.2057,
        "grad_norm": 6.168301582336426,
        "learning_rate": 7.1725092250922515e-06,
        "epoch": 28.523985239852397,
        "step": 7730
    },
    {
        "loss": 0.198,
        "grad_norm": 3.7655887603759766,
        "learning_rate": 7.149446494464946e-06,
        "epoch": 28.56088560885609,
        "step": 7740
    },
    {
        "loss": 0.1919,
        "grad_norm": 3.585629940032959,
        "learning_rate": 7.126383763837639e-06,
        "epoch": 28.59778597785978,
        "step": 7750
    },
    {
        "loss": 0.3562,
        "grad_norm": 11.814323425292969,
        "learning_rate": 7.103321033210332e-06,
        "epoch": 28.634686346863468,
        "step": 7760
    },
    {
        "loss": 0.1999,
        "grad_norm": 5.98063850402832,
        "learning_rate": 7.080258302583026e-06,
        "epoch": 28.671586715867157,
        "step": 7770
    },
    {
        "loss": 0.2148,
        "grad_norm": 2.305258274078369,
        "learning_rate": 7.05719557195572e-06,
        "epoch": 28.70848708487085,
        "step": 7780
    },
    {
        "loss": 0.1649,
        "grad_norm": 2.040029525756836,
        "learning_rate": 7.034132841328414e-06,
        "epoch": 28.74538745387454,
        "step": 7790
    },
    {
        "loss": 0.2374,
        "grad_norm": 12.978090286254883,
        "learning_rate": 7.011070110701107e-06,
        "epoch": 28.782287822878228,
        "step": 7800
    },
    {
        "loss": 0.1135,
        "grad_norm": 2.772932291030884,
        "learning_rate": 6.988007380073801e-06,
        "epoch": 28.81918819188192,
        "step": 7810
    },
    {
        "loss": 0.2559,
        "grad_norm": 22.894895553588867,
        "learning_rate": 6.9649446494464944e-06,
        "epoch": 28.85608856088561,
        "step": 7820
    },
    {
        "loss": 0.2163,
        "grad_norm": 9.240188598632812,
        "learning_rate": 6.941881918819189e-06,
        "epoch": 28.8929889298893,
        "step": 7830
    },
    {
        "loss": 0.1903,
        "grad_norm": 2.637807846069336,
        "learning_rate": 6.918819188191883e-06,
        "epoch": 28.929889298892988,
        "step": 7840
    },
    {
        "loss": 0.1999,
        "grad_norm": 3.5116372108459473,
        "learning_rate": 6.8957564575645754e-06,
        "epoch": 28.96678966789668,
        "step": 7850
    },
    {
        "eval_loss": 0.6121930480003357,
        "eval_accuracy": 0.84779,
        "eval_precision": 0.81376,
        "eval_recall": 0.89981,
        "eval_f1": 0.85463,
        "eval_runtime": 18.0842,
        "eval_samples_per_second": 59.942,
        "eval_steps_per_second": 3.76,
        "epoch": 29.0,
        "step": 7859
    },
    {
        "loss": 0.1824,
        "grad_norm": 9.06900405883789,
        "learning_rate": 6.87269372693727e-06,
        "epoch": 29.00369003690037,
        "step": 7860
    },
    {
        "loss": 0.1874,
        "grad_norm": 1.1166365146636963,
        "learning_rate": 6.849630996309964e-06,
        "epoch": 29.04059040590406,
        "step": 7870
    },
    {
        "loss": 0.174,
        "grad_norm": 5.036260604858398,
        "learning_rate": 6.826568265682657e-06,
        "epoch": 29.077490774907748,
        "step": 7880
    },
    {
        "loss": 0.1687,
        "grad_norm": 4.096894264221191,
        "learning_rate": 6.803505535055351e-06,
        "epoch": 29.11439114391144,
        "step": 7890
    },
    {
        "loss": 0.093,
        "grad_norm": 0.896722674369812,
        "learning_rate": 6.780442804428044e-06,
        "epoch": 29.15129151291513,
        "step": 7900
    },
    {
        "loss": 0.2549,
        "grad_norm": 1.2065163850784302,
        "learning_rate": 6.757380073800738e-06,
        "epoch": 29.18819188191882,
        "step": 7910
    },
    {
        "loss": 0.1787,
        "grad_norm": 3.1118531227111816,
        "learning_rate": 6.7343173431734325e-06,
        "epoch": 29.225092250922508,
        "step": 7920
    },
    {
        "loss": 0.2257,
        "grad_norm": 4.601317882537842,
        "learning_rate": 6.711254612546127e-06,
        "epoch": 29.2619926199262,
        "step": 7930
    },
    {
        "loss": 0.2249,
        "grad_norm": 7.601508617401123,
        "learning_rate": 6.688191881918819e-06,
        "epoch": 29.29889298892989,
        "step": 7940
    },
    {
        "loss": 0.1901,
        "grad_norm": 1.028499960899353,
        "learning_rate": 6.6651291512915135e-06,
        "epoch": 29.33579335793358,
        "step": 7950
    },
    {
        "loss": 0.2079,
        "grad_norm": 3.74733567237854,
        "learning_rate": 6.642066420664207e-06,
        "epoch": 29.372693726937268,
        "step": 7960
    },
    {
        "loss": 0.1647,
        "grad_norm": 2.282064199447632,
        "learning_rate": 6.619003690036901e-06,
        "epoch": 29.40959409594096,
        "step": 7970
    },
    {
        "loss": 0.1415,
        "grad_norm": 1.6009342670440674,
        "learning_rate": 6.595940959409594e-06,
        "epoch": 29.44649446494465,
        "step": 7980
    },
    {
        "loss": 0.387,
        "grad_norm": 0.9220269322395325,
        "learning_rate": 6.572878228782288e-06,
        "epoch": 29.48339483394834,
        "step": 7990
    },
    {
        "loss": 0.1771,
        "grad_norm": 2.013025999069214,
        "learning_rate": 6.549815498154982e-06,
        "epoch": 29.52029520295203,
        "step": 8000
    },
    {
        "loss": 0.171,
        "grad_norm": 11.318208694458008,
        "learning_rate": 6.526752767527676e-06,
        "epoch": 29.55719557195572,
        "step": 8010
    },
    {
        "loss": 0.1638,
        "grad_norm": 1.9985677003860474,
        "learning_rate": 6.503690036900369e-06,
        "epoch": 29.59409594095941,
        "step": 8020
    },
    {
        "loss": 0.1791,
        "grad_norm": 0.7997126579284668,
        "learning_rate": 6.480627306273063e-06,
        "epoch": 29.6309963099631,
        "step": 8030
    },
    {
        "loss": 0.2147,
        "grad_norm": 2.082517147064209,
        "learning_rate": 6.4575645756457565e-06,
        "epoch": 29.66789667896679,
        "step": 8040
    },
    {
        "loss": 0.1424,
        "grad_norm": 1.073998212814331,
        "learning_rate": 6.434501845018451e-06,
        "epoch": 29.70479704797048,
        "step": 8050
    },
    {
        "loss": 0.1852,
        "grad_norm": 4.322993278503418,
        "learning_rate": 6.411439114391145e-06,
        "epoch": 29.74169741697417,
        "step": 8060
    },
    {
        "loss": 0.225,
        "grad_norm": 2.1572844982147217,
        "learning_rate": 6.3883763837638375e-06,
        "epoch": 29.77859778597786,
        "step": 8070
    },
    {
        "loss": 0.1829,
        "grad_norm": 0.6127549409866333,
        "learning_rate": 6.365313653136532e-06,
        "epoch": 29.81549815498155,
        "step": 8080
    },
    {
        "loss": 0.1945,
        "grad_norm": 1.4257652759552002,
        "learning_rate": 6.342250922509226e-06,
        "epoch": 29.85239852398524,
        "step": 8090
    },
    {
        "loss": 0.2159,
        "grad_norm": 1.0787140130996704,
        "learning_rate": 6.319188191881919e-06,
        "epoch": 29.88929889298893,
        "step": 8100
    },
    {
        "loss": 0.1573,
        "grad_norm": 9.059804916381836,
        "learning_rate": 6.296125461254612e-06,
        "epoch": 29.92619926199262,
        "step": 8110
    },
    {
        "loss": 0.2852,
        "grad_norm": 10.59543514251709,
        "learning_rate": 6.273062730627306e-06,
        "epoch": 29.96309963099631,
        "step": 8120
    },
    {
        "loss": 0.2787,
        "grad_norm": 1.161257028579712,
        "learning_rate": 6.25e-06,
        "epoch": 30.0,
        "step": 8130
    },
    {
        "eval_loss": 0.611047625541687,
        "eval_accuracy": 0.85332,
        "eval_precision": 0.81987,
        "eval_recall": 0.90353,
        "eval_f1": 0.85966,
        "eval_runtime": 18.058,
        "eval_samples_per_second": 60.029,
        "eval_steps_per_second": 3.766,
        "epoch": 30.0,
        "step": 8130
    },
    {
        "loss": 0.2172,
        "grad_norm": 1.0171451568603516,
        "learning_rate": 6.2269372693726945e-06,
        "epoch": 30.03690036900369,
        "step": 8140
    },
    {
        "loss": 0.1913,
        "grad_norm": 2.777095079421997,
        "learning_rate": 6.203874538745388e-06,
        "epoch": 30.07380073800738,
        "step": 8150
    },
    {
        "loss": 0.1744,
        "grad_norm": 0.9206192493438721,
        "learning_rate": 6.180811808118082e-06,
        "epoch": 30.11070110701107,
        "step": 8160
    },
    {
        "loss": 0.1664,
        "grad_norm": 11.58489990234375,
        "learning_rate": 6.157749077490775e-06,
        "epoch": 30.14760147601476,
        "step": 8170
    },
    {
        "loss": 0.2859,
        "grad_norm": 20.46723747253418,
        "learning_rate": 6.134686346863469e-06,
        "epoch": 30.18450184501845,
        "step": 8180
    },
    {
        "loss": 0.1723,
        "grad_norm": 47.48524475097656,
        "learning_rate": 6.111623616236162e-06,
        "epoch": 30.22140221402214,
        "step": 8190
    },
    {
        "loss": 0.0936,
        "grad_norm": 1.108385443687439,
        "learning_rate": 6.0885608856088565e-06,
        "epoch": 30.25830258302583,
        "step": 8200
    },
    {
        "loss": 0.2439,
        "grad_norm": 39.11835861206055,
        "learning_rate": 6.06549815498155e-06,
        "epoch": 30.29520295202952,
        "step": 8210
    },
    {
        "loss": 0.2058,
        "grad_norm": 6.5913519859313965,
        "learning_rate": 6.042435424354244e-06,
        "epoch": 30.33210332103321,
        "step": 8220
    },
    {
        "loss": 0.2039,
        "grad_norm": 24.332334518432617,
        "learning_rate": 6.0193726937269375e-06,
        "epoch": 30.3690036900369,
        "step": 8230
    },
    {
        "loss": 0.174,
        "grad_norm": 75.70352935791016,
        "learning_rate": 5.996309963099631e-06,
        "epoch": 30.40590405904059,
        "step": 8240
    },
    {
        "loss": 0.2119,
        "grad_norm": 1.5545536279678345,
        "learning_rate": 5.973247232472325e-06,
        "epoch": 30.44280442804428,
        "step": 8250
    },
    {
        "loss": 0.2759,
        "grad_norm": 1.2667121887207031,
        "learning_rate": 5.9501845018450185e-06,
        "epoch": 30.47970479704797,
        "step": 8260
    },
    {
        "loss": 0.1129,
        "grad_norm": 1.0200939178466797,
        "learning_rate": 5.927121771217713e-06,
        "epoch": 30.51660516605166,
        "step": 8270
    },
    {
        "loss": 0.1363,
        "grad_norm": 0.5721707344055176,
        "learning_rate": 5.904059040590406e-06,
        "epoch": 30.55350553505535,
        "step": 8280
    },
    {
        "loss": 0.3438,
        "grad_norm": 4.7855305671691895,
        "learning_rate": 5.8809963099631e-06,
        "epoch": 30.59040590405904,
        "step": 8290
    },
    {
        "loss": 0.135,
        "grad_norm": 4.671387672424316,
        "learning_rate": 5.857933579335794e-06,
        "epoch": 30.627306273062732,
        "step": 8300
    },
    {
        "loss": 0.2044,
        "grad_norm": 1.365456461906433,
        "learning_rate": 5.834870848708487e-06,
        "epoch": 30.66420664206642,
        "step": 8310
    },
    {
        "loss": 0.2456,
        "grad_norm": 1.6311591863632202,
        "learning_rate": 5.8118081180811805e-06,
        "epoch": 30.70110701107011,
        "step": 8320
    },
    {
        "loss": 0.1378,
        "grad_norm": 18.917295455932617,
        "learning_rate": 5.788745387453875e-06,
        "epoch": 30.7380073800738,
        "step": 8330
    },
    {
        "loss": 0.1799,
        "grad_norm": 1.4505019187927246,
        "learning_rate": 5.765682656826569e-06,
        "epoch": 30.774907749077492,
        "step": 8340
    },
    {
        "loss": 0.2237,
        "grad_norm": 10.158843994140625,
        "learning_rate": 5.742619926199262e-06,
        "epoch": 30.81180811808118,
        "step": 8350
    },
    {
        "loss": 0.2336,
        "grad_norm": 11.914138793945312,
        "learning_rate": 5.7195571955719566e-06,
        "epoch": 30.84870848708487,
        "step": 8360
    },
    {
        "loss": 0.213,
        "grad_norm": 8.317680358886719,
        "learning_rate": 5.69649446494465e-06,
        "epoch": 30.88560885608856,
        "step": 8370
    },
    {
        "loss": 0.2089,
        "grad_norm": 13.788655281066895,
        "learning_rate": 5.673431734317343e-06,
        "epoch": 30.922509225092252,
        "step": 8380
    },
    {
        "loss": 0.1318,
        "grad_norm": 2.6136975288391113,
        "learning_rate": 5.650369003690037e-06,
        "epoch": 30.95940959409594,
        "step": 8390
    },
    {
        "loss": 0.1928,
        "grad_norm": 1.3364508152008057,
        "learning_rate": 5.627306273062731e-06,
        "epoch": 30.99630996309963,
        "step": 8400
    },
    {
        "eval_loss": 0.6161778569221497,
        "eval_accuracy": 0.84225,
        "eval_precision": 0.81944,
        "eval_recall": 0.8757,
        "eval_f1": 0.84664,
        "eval_runtime": 18.0732,
        "eval_samples_per_second": 59.978,
        "eval_steps_per_second": 3.762,
        "epoch": 31.0,
        "step": 8401
    },
    {
        "loss": 0.1781,
        "grad_norm": 11.594980239868164,
        "learning_rate": 5.604243542435424e-06,
        "epoch": 31.03321033210332,
        "step": 8410
    },
    {
        "loss": 0.139,
        "grad_norm": 1.3463679552078247,
        "learning_rate": 5.5811808118081185e-06,
        "epoch": 31.070110701107012,
        "step": 8420
    },
    {
        "loss": 0.1644,
        "grad_norm": 0.9268835186958313,
        "learning_rate": 5.558118081180812e-06,
        "epoch": 31.1070110701107,
        "step": 8430
    },
    {
        "loss": 0.1033,
        "grad_norm": 29.682598114013672,
        "learning_rate": 5.535055350553506e-06,
        "epoch": 31.14391143911439,
        "step": 8440
    },
    {
        "loss": 0.2443,
        "grad_norm": 1.5242277383804321,
        "learning_rate": 5.5119926199261995e-06,
        "epoch": 31.18081180811808,
        "step": 8450
    },
    {
        "loss": 0.1211,
        "grad_norm": 2.357466459274292,
        "learning_rate": 5.488929889298893e-06,
        "epoch": 31.217712177121772,
        "step": 8460
    },
    {
        "loss": 0.1521,
        "grad_norm": 10.812411308288574,
        "learning_rate": 5.465867158671587e-06,
        "epoch": 31.25461254612546,
        "step": 8470
    },
    {
        "loss": 0.2271,
        "grad_norm": 2.121211528778076,
        "learning_rate": 5.4428044280442805e-06,
        "epoch": 31.29151291512915,
        "step": 8480
    },
    {
        "loss": 0.1635,
        "grad_norm": 19.65308952331543,
        "learning_rate": 5.419741697416975e-06,
        "epoch": 31.328413284132843,
        "step": 8490
    },
    {
        "loss": 0.1988,
        "grad_norm": 1.1186109781265259,
        "learning_rate": 5.396678966789668e-06,
        "epoch": 31.365313653136532,
        "step": 8500
    },
    {
        "loss": 0.2286,
        "grad_norm": 11.970780372619629,
        "learning_rate": 5.373616236162362e-06,
        "epoch": 31.40221402214022,
        "step": 8510
    },
    {
        "loss": 0.157,
        "grad_norm": 0.38525858521461487,
        "learning_rate": 5.350553505535055e-06,
        "epoch": 31.43911439114391,
        "step": 8520
    },
    {
        "loss": 0.2407,
        "grad_norm": 15.688791275024414,
        "learning_rate": 5.327490774907749e-06,
        "epoch": 31.476014760147603,
        "step": 8530
    },
    {
        "loss": 0.2999,
        "grad_norm": 18.21221351623535,
        "learning_rate": 5.304428044280443e-06,
        "epoch": 31.512915129151292,
        "step": 8540
    },
    {
        "loss": 0.2017,
        "grad_norm": 14.652573585510254,
        "learning_rate": 5.281365313653137e-06,
        "epoch": 31.54981549815498,
        "step": 8550
    },
    {
        "loss": 0.1644,
        "grad_norm": 0.8927881121635437,
        "learning_rate": 5.258302583025831e-06,
        "epoch": 31.58671586715867,
        "step": 8560
    },
    {
        "loss": 0.1782,
        "grad_norm": 27.681581497192383,
        "learning_rate": 5.235239852398524e-06,
        "epoch": 31.623616236162363,
        "step": 8570
    },
    {
        "loss": 0.1785,
        "grad_norm": 4.123054504394531,
        "learning_rate": 5.212177121771218e-06,
        "epoch": 31.660516605166052,
        "step": 8580
    },
    {
        "loss": 0.1914,
        "grad_norm": 26.190994262695312,
        "learning_rate": 5.189114391143911e-06,
        "epoch": 31.69741697416974,
        "step": 8590
    },
    {
        "loss": 0.2217,
        "grad_norm": 3.47579026222229,
        "learning_rate": 5.166051660516605e-06,
        "epoch": 31.73431734317343,
        "step": 8600
    },
    {
        "loss": 0.1556,
        "grad_norm": 4.02834939956665,
        "learning_rate": 5.142988929889299e-06,
        "epoch": 31.771217712177123,
        "step": 8610
    },
    {
        "loss": 0.1287,
        "grad_norm": 5.760511875152588,
        "learning_rate": 5.119926199261993e-06,
        "epoch": 31.80811808118081,
        "step": 8620
    },
    {
        "loss": 0.1627,
        "grad_norm": 5.005329608917236,
        "learning_rate": 5.096863468634686e-06,
        "epoch": 31.8450184501845,
        "step": 8630
    },
    {
        "loss": 0.2254,
        "grad_norm": 31.558021545410156,
        "learning_rate": 5.0738007380073806e-06,
        "epoch": 31.881918819188193,
        "step": 8640
    },
    {
        "loss": 0.1626,
        "grad_norm": 7.849024772644043,
        "learning_rate": 5.050738007380074e-06,
        "epoch": 31.918819188191883,
        "step": 8650
    },
    {
        "loss": 0.2291,
        "grad_norm": 1.2747377157211304,
        "learning_rate": 5.027675276752767e-06,
        "epoch": 31.95571955719557,
        "step": 8660
    },
    {
        "loss": 0.186,
        "grad_norm": 6.14563512802124,
        "learning_rate": 5.0046125461254616e-06,
        "epoch": 31.99261992619926,
        "step": 8670
    },
    {
        "eval_loss": 0.6316999197006226,
        "eval_accuracy": 0.85424,
        "eval_precision": 0.82343,
        "eval_recall": 0.89981,
        "eval_f1": 0.85993,
        "eval_runtime": 18.0731,
        "eval_samples_per_second": 59.979,
        "eval_steps_per_second": 3.763,
        "epoch": 32.0,
        "step": 8672
    },
    {
        "loss": 0.2217,
        "grad_norm": 6.382824420928955,
        "learning_rate": 4.981549815498155e-06,
        "epoch": 32.02952029520295,
        "step": 8680
    },
    {
        "loss": 0.1745,
        "grad_norm": 1.1610950231552124,
        "learning_rate": 4.958487084870849e-06,
        "epoch": 32.06642066420664,
        "step": 8690
    },
    {
        "loss": 0.1285,
        "grad_norm": 0.3383062481880188,
        "learning_rate": 4.9354243542435426e-06,
        "epoch": 32.103321033210335,
        "step": 8700
    },
    {
        "loss": 0.1887,
        "grad_norm": 8.47171688079834,
        "learning_rate": 4.912361623616237e-06,
        "epoch": 32.140221402214024,
        "step": 8710
    },
    {
        "loss": 0.2347,
        "grad_norm": 4.363241672515869,
        "learning_rate": 4.88929889298893e-06,
        "epoch": 32.17712177121771,
        "step": 8720
    },
    {
        "loss": 0.2367,
        "grad_norm": 3.67360258102417,
        "learning_rate": 4.8662361623616235e-06,
        "epoch": 32.2140221402214,
        "step": 8730
    },
    {
        "loss": 0.1954,
        "grad_norm": 1.9709874391555786,
        "learning_rate": 4.843173431734318e-06,
        "epoch": 32.25092250922509,
        "step": 8740
    },
    {
        "loss": 0.1769,
        "grad_norm": 19.813865661621094,
        "learning_rate": 4.820110701107011e-06,
        "epoch": 32.28782287822878,
        "step": 8750
    },
    {
        "loss": 0.1884,
        "grad_norm": 22.738014221191406,
        "learning_rate": 4.797047970479705e-06,
        "epoch": 32.32472324723247,
        "step": 8760
    },
    {
        "loss": 0.1696,
        "grad_norm": 11.638437271118164,
        "learning_rate": 4.773985239852399e-06,
        "epoch": 32.36162361623616,
        "step": 8770
    },
    {
        "loss": 0.1994,
        "grad_norm": 0.9001584053039551,
        "learning_rate": 4.750922509225093e-06,
        "epoch": 32.398523985239855,
        "step": 8780
    },
    {
        "loss": 0.2065,
        "grad_norm": 2.2845823764801025,
        "learning_rate": 4.727859778597786e-06,
        "epoch": 32.435424354243544,
        "step": 8790
    },
    {
        "loss": 0.1751,
        "grad_norm": 12.6376371383667,
        "learning_rate": 4.70479704797048e-06,
        "epoch": 32.47232472324723,
        "step": 8800
    },
    {
        "loss": 0.1936,
        "grad_norm": 1.8018170595169067,
        "learning_rate": 4.681734317343173e-06,
        "epoch": 32.50922509225092,
        "step": 8810
    },
    {
        "loss": 0.2014,
        "grad_norm": 3.609269142150879,
        "learning_rate": 4.658671586715867e-06,
        "epoch": 32.54612546125461,
        "step": 8820
    },
    {
        "loss": 0.1453,
        "grad_norm": 38.59014892578125,
        "learning_rate": 4.635608856088561e-06,
        "epoch": 32.5830258302583,
        "step": 8830
    },
    {
        "loss": 0.2441,
        "grad_norm": 15.782255172729492,
        "learning_rate": 4.612546125461255e-06,
        "epoch": 32.61992619926199,
        "step": 8840
    },
    {
        "loss": 0.1694,
        "grad_norm": 2.6316890716552734,
        "learning_rate": 4.589483394833949e-06,
        "epoch": 32.656826568265686,
        "step": 8850
    },
    {
        "loss": 0.1893,
        "grad_norm": 1.2267467975616455,
        "learning_rate": 4.566420664206643e-06,
        "epoch": 32.693726937269375,
        "step": 8860
    },
    {
        "loss": 0.224,
        "grad_norm": 1.7682212591171265,
        "learning_rate": 4.543357933579336e-06,
        "epoch": 32.730627306273064,
        "step": 8870
    },
    {
        "loss": 0.1846,
        "grad_norm": 3.6248939037323,
        "learning_rate": 4.520295202952029e-06,
        "epoch": 32.76752767527675,
        "step": 8880
    },
    {
        "loss": 0.0839,
        "grad_norm": 1.739830732345581,
        "learning_rate": 4.497232472324724e-06,
        "epoch": 32.80442804428044,
        "step": 8890
    },
    {
        "loss": 0.1149,
        "grad_norm": 0.6274784803390503,
        "learning_rate": 4.474169741697417e-06,
        "epoch": 32.84132841328413,
        "step": 8900
    },
    {
        "loss": 0.0645,
        "grad_norm": 0.9006376266479492,
        "learning_rate": 4.451107011070111e-06,
        "epoch": 32.87822878228782,
        "step": 8910
    },
    {
        "loss": 0.2225,
        "grad_norm": 7.1739678382873535,
        "learning_rate": 4.428044280442805e-06,
        "epoch": 32.91512915129151,
        "step": 8920
    },
    {
        "loss": 0.113,
        "grad_norm": 0.7998030185699463,
        "learning_rate": 4.404981549815498e-06,
        "epoch": 32.952029520295206,
        "step": 8930
    },
    {
        "loss": 0.2869,
        "grad_norm": 5.802362442016602,
        "learning_rate": 4.381918819188192e-06,
        "epoch": 32.988929889298895,
        "step": 8940
    },
    {
        "eval_loss": 0.6928113102912903,
        "eval_accuracy": 0.85517,
        "eval_precision": 0.81623,
        "eval_recall": 0.91466,
        "eval_f1": 0.86264,
        "eval_runtime": 18.0815,
        "eval_samples_per_second": 59.951,
        "eval_steps_per_second": 3.761,
        "epoch": 33.0,
        "step": 8943
    },
    {
        "loss": 0.2315,
        "grad_norm": 15.630620002746582,
        "learning_rate": 4.358856088560886e-06,
        "epoch": 33.025830258302584,
        "step": 8950
    },
    {
        "loss": 0.1604,
        "grad_norm": 2.9937562942504883,
        "learning_rate": 4.33579335793358e-06,
        "epoch": 33.06273062730627,
        "step": 8960
    },
    {
        "loss": 0.2601,
        "grad_norm": 2.166745185852051,
        "learning_rate": 4.312730627306273e-06,
        "epoch": 33.09963099630996,
        "step": 8970
    },
    {
        "loss": 0.1909,
        "grad_norm": 3.2905938625335693,
        "learning_rate": 4.289667896678967e-06,
        "epoch": 33.13653136531365,
        "step": 8980
    },
    {
        "loss": 0.1485,
        "grad_norm": 11.862471580505371,
        "learning_rate": 4.266605166051661e-06,
        "epoch": 33.17343173431734,
        "step": 8990
    },
    {
        "loss": 0.2457,
        "grad_norm": 36.82315444946289,
        "learning_rate": 4.243542435424354e-06,
        "epoch": 33.210332103321036,
        "step": 9000
    },
    {
        "loss": 0.2126,
        "grad_norm": 0.2244642674922943,
        "learning_rate": 4.2204797047970476e-06,
        "epoch": 33.247232472324725,
        "step": 9010
    },
    {
        "loss": 0.2676,
        "grad_norm": 8.554827690124512,
        "learning_rate": 4.197416974169742e-06,
        "epoch": 33.284132841328415,
        "step": 9020
    },
    {
        "loss": 0.2659,
        "grad_norm": 15.18305778503418,
        "learning_rate": 4.174354243542435e-06,
        "epoch": 33.321033210332104,
        "step": 9030
    },
    {
        "loss": 0.1683,
        "grad_norm": 0.27814674377441406,
        "learning_rate": 4.151291512915129e-06,
        "epoch": 33.35793357933579,
        "step": 9040
    },
    {
        "loss": 0.1378,
        "grad_norm": 12.470154762268066,
        "learning_rate": 4.128228782287824e-06,
        "epoch": 33.39483394833948,
        "step": 9050
    },
    {
        "loss": 0.1579,
        "grad_norm": 0.6872873902320862,
        "learning_rate": 4.105166051660517e-06,
        "epoch": 33.43173431734317,
        "step": 9060
    },
    {
        "loss": 0.1522,
        "grad_norm": 101.33558654785156,
        "learning_rate": 4.08210332103321e-06,
        "epoch": 33.46863468634686,
        "step": 9070
    },
    {
        "loss": 0.181,
        "grad_norm": 5.7209343910217285,
        "learning_rate": 4.059040590405904e-06,
        "epoch": 33.505535055350556,
        "step": 9080
    },
    {
        "loss": 0.1729,
        "grad_norm": 0.19212177395820618,
        "learning_rate": 4.035977859778598e-06,
        "epoch": 33.542435424354245,
        "step": 9090
    },
    {
        "loss": 0.2449,
        "grad_norm": 6.108219623565674,
        "learning_rate": 4.012915129151291e-06,
        "epoch": 33.579335793357934,
        "step": 9100
    },
    {
        "loss": 0.1097,
        "grad_norm": 7.27243185043335,
        "learning_rate": 3.989852398523986e-06,
        "epoch": 33.61623616236162,
        "step": 9110
    },
    {
        "loss": 0.1201,
        "grad_norm": 0.5333852767944336,
        "learning_rate": 3.966789667896679e-06,
        "epoch": 33.65313653136531,
        "step": 9120
    },
    {
        "loss": 0.2497,
        "grad_norm": 3.122556686401367,
        "learning_rate": 3.943726937269373e-06,
        "epoch": 33.690036900369,
        "step": 9130
    },
    {
        "loss": 0.2563,
        "grad_norm": 0.6177552342414856,
        "learning_rate": 3.920664206642067e-06,
        "epoch": 33.72693726937269,
        "step": 9140
    },
    {
        "loss": 0.2149,
        "grad_norm": 1.7199379205703735,
        "learning_rate": 3.89760147601476e-06,
        "epoch": 33.76383763837639,
        "step": 9150
    },
    {
        "loss": 0.1398,
        "grad_norm": 0.9974103569984436,
        "learning_rate": 3.874538745387454e-06,
        "epoch": 33.800738007380076,
        "step": 9160
    },
    {
        "loss": 0.2198,
        "grad_norm": 11.93475341796875,
        "learning_rate": 3.851476014760148e-06,
        "epoch": 33.837638376383765,
        "step": 9170
    },
    {
        "loss": 0.1693,
        "grad_norm": 2.8442840576171875,
        "learning_rate": 3.828413284132842e-06,
        "epoch": 33.874538745387454,
        "step": 9180
    },
    {
        "loss": 0.1278,
        "grad_norm": 22.534509658813477,
        "learning_rate": 3.8053505535055352e-06,
        "epoch": 33.91143911439114,
        "step": 9190
    },
    {
        "loss": 0.2224,
        "grad_norm": 62.67747497558594,
        "learning_rate": 3.782287822878229e-06,
        "epoch": 33.94833948339483,
        "step": 9200
    },
    {
        "loss": 0.1732,
        "grad_norm": 0.7816296219825745,
        "learning_rate": 3.7592250922509224e-06,
        "epoch": 33.98523985239852,
        "step": 9210
    },
    {
        "eval_loss": 0.6783933043479919,
        "eval_accuracy": 0.84871,
        "eval_precision": 0.82051,
        "eval_recall": 0.89054,
        "eval_f1": 0.85409,
        "eval_runtime": 18.0882,
        "eval_samples_per_second": 59.928,
        "eval_steps_per_second": 3.759,
        "epoch": 34.0,
        "step": 9214
    },
    {
        "loss": 0.2251,
        "grad_norm": 0.7537129521369934,
        "learning_rate": 3.7361623616236166e-06,
        "epoch": 34.02214022140221,
        "step": 9220
    },
    {
        "loss": 0.2455,
        "grad_norm": 5.978053092956543,
        "learning_rate": 3.71309963099631e-06,
        "epoch": 34.05904059040591,
        "step": 9230
    },
    {
        "loss": 0.1915,
        "grad_norm": 61.65450668334961,
        "learning_rate": 3.690036900369004e-06,
        "epoch": 34.095940959409596,
        "step": 9240
    },
    {
        "loss": 0.1445,
        "grad_norm": 0.7723815441131592,
        "learning_rate": 3.666974169741698e-06,
        "epoch": 34.132841328413285,
        "step": 9250
    },
    {
        "loss": 0.1762,
        "grad_norm": 1.207262635231018,
        "learning_rate": 3.6439114391143914e-06,
        "epoch": 34.169741697416974,
        "step": 9260
    },
    {
        "loss": 0.2066,
        "grad_norm": 0.5333674550056458,
        "learning_rate": 3.6208487084870852e-06,
        "epoch": 34.20664206642066,
        "step": 9270
    },
    {
        "loss": 0.2211,
        "grad_norm": 0.21939530968666077,
        "learning_rate": 3.5977859778597786e-06,
        "epoch": 34.24354243542435,
        "step": 9280
    },
    {
        "loss": 0.1343,
        "grad_norm": 6.862422943115234,
        "learning_rate": 3.574723247232473e-06,
        "epoch": 34.28044280442804,
        "step": 9290
    },
    {
        "loss": 0.2086,
        "grad_norm": 5.294185161590576,
        "learning_rate": 3.551660516605166e-06,
        "epoch": 34.31734317343174,
        "step": 9300
    },
    {
        "loss": 0.2248,
        "grad_norm": 6.838074207305908,
        "learning_rate": 3.52859778597786e-06,
        "epoch": 34.35424354243543,
        "step": 9310
    },
    {
        "loss": 0.1504,
        "grad_norm": 5.249134063720703,
        "learning_rate": 3.5055350553505534e-06,
        "epoch": 34.391143911439116,
        "step": 9320
    },
    {
        "loss": 0.1415,
        "grad_norm": 0.9041547179222107,
        "learning_rate": 3.4824723247232472e-06,
        "epoch": 34.428044280442805,
        "step": 9330
    },
    {
        "loss": 0.13,
        "grad_norm": 0.43152880668640137,
        "learning_rate": 3.4594095940959415e-06,
        "epoch": 34.464944649446494,
        "step": 9340
    },
    {
        "loss": 0.1499,
        "grad_norm": 0.20399893820285797,
        "learning_rate": 3.436346863468635e-06,
        "epoch": 34.50184501845018,
        "step": 9350
    },
    {
        "loss": 0.2268,
        "grad_norm": 2.6285574436187744,
        "learning_rate": 3.4132841328413286e-06,
        "epoch": 34.53874538745387,
        "step": 9360
    },
    {
        "loss": 0.1759,
        "grad_norm": 10.394515037536621,
        "learning_rate": 3.390221402214022e-06,
        "epoch": 34.57564575645756,
        "step": 9370
    },
    {
        "loss": 0.2416,
        "grad_norm": 9.13580322265625,
        "learning_rate": 3.3671586715867163e-06,
        "epoch": 34.61254612546126,
        "step": 9380
    },
    {
        "loss": 0.2046,
        "grad_norm": 1.7052756547927856,
        "learning_rate": 3.3440959409594096e-06,
        "epoch": 34.64944649446495,
        "step": 9390
    },
    {
        "loss": 0.2341,
        "grad_norm": 1.8576571941375732,
        "learning_rate": 3.3210332103321034e-06,
        "epoch": 34.686346863468636,
        "step": 9400
    },
    {
        "loss": 0.1604,
        "grad_norm": 0.3274087607860565,
        "learning_rate": 3.297970479704797e-06,
        "epoch": 34.723247232472325,
        "step": 9410
    },
    {
        "loss": 0.2652,
        "grad_norm": 10.287471771240234,
        "learning_rate": 3.274907749077491e-06,
        "epoch": 34.760147601476014,
        "step": 9420
    },
    {
        "loss": 0.0901,
        "grad_norm": 2.001965045928955,
        "learning_rate": 3.2518450184501844e-06,
        "epoch": 34.7970479704797,
        "step": 9430
    },
    {
        "loss": 0.1712,
        "grad_norm": 276.33917236328125,
        "learning_rate": 3.2287822878228782e-06,
        "epoch": 34.83394833948339,
        "step": 9440
    },
    {
        "loss": 0.1439,
        "grad_norm": 3.25207781791687,
        "learning_rate": 3.2057195571955725e-06,
        "epoch": 34.87084870848709,
        "step": 9450
    },
    {
        "loss": 0.1818,
        "grad_norm": 0.6721572875976562,
        "learning_rate": 3.182656826568266e-06,
        "epoch": 34.90774907749078,
        "step": 9460
    },
    {
        "loss": 0.222,
        "grad_norm": 5.529130458831787,
        "learning_rate": 3.1595940959409597e-06,
        "epoch": 34.944649446494466,
        "step": 9470
    },
    {
        "loss": 0.1246,
        "grad_norm": 0.7035744786262512,
        "learning_rate": 3.136531365313653e-06,
        "epoch": 34.981549815498155,
        "step": 9480
    },
    {
        "eval_loss": 0.6836439967155457,
        "eval_accuracy": 0.8524,
        "eval_precision": 0.81956,
        "eval_recall": 0.90167,
        "eval_f1": 0.85866,
        "eval_runtime": 18.1003,
        "eval_samples_per_second": 59.888,
        "eval_steps_per_second": 3.757,
        "epoch": 35.0,
        "step": 9485
    },
    {
        "loss": 0.1798,
        "grad_norm": 36.82310104370117,
        "learning_rate": 3.1134686346863473e-06,
        "epoch": 35.018450184501845,
        "step": 9490
    },
    {
        "loss": 0.1487,
        "grad_norm": 2.9430017471313477,
        "learning_rate": 3.090405904059041e-06,
        "epoch": 35.055350553505534,
        "step": 9500
    },
    {
        "loss": 0.2051,
        "grad_norm": 34.902305603027344,
        "learning_rate": 3.0673431734317345e-06,
        "epoch": 35.09225092250922,
        "step": 9510
    },
    {
        "loss": 0.3365,
        "grad_norm": 8.240684509277344,
        "learning_rate": 3.0442804428044283e-06,
        "epoch": 35.12915129151291,
        "step": 9520
    },
    {
        "loss": 0.1282,
        "grad_norm": 0.4994467496871948,
        "learning_rate": 3.021217712177122e-06,
        "epoch": 35.16605166051661,
        "step": 9530
    },
    {
        "loss": 0.1933,
        "grad_norm": 7.736709117889404,
        "learning_rate": 2.9981549815498154e-06,
        "epoch": 35.2029520295203,
        "step": 9540
    },
    {
        "loss": 0.2001,
        "grad_norm": 2.3774490356445312,
        "learning_rate": 2.9750922509225093e-06,
        "epoch": 35.239852398523986,
        "step": 9550
    },
    {
        "loss": 0.1507,
        "grad_norm": 1.6020439863204956,
        "learning_rate": 2.952029520295203e-06,
        "epoch": 35.276752767527675,
        "step": 9560
    },
    {
        "loss": 0.0863,
        "grad_norm": 2.3370354175567627,
        "learning_rate": 2.928966789667897e-06,
        "epoch": 35.313653136531364,
        "step": 9570
    },
    {
        "loss": 0.1305,
        "grad_norm": 0.4822234511375427,
        "learning_rate": 2.9059040590405902e-06,
        "epoch": 35.35055350553505,
        "step": 9580
    },
    {
        "loss": 0.146,
        "grad_norm": 37.3916015625,
        "learning_rate": 2.8828413284132845e-06,
        "epoch": 35.38745387453874,
        "step": 9590
    },
    {
        "loss": 0.2685,
        "grad_norm": 8.296401023864746,
        "learning_rate": 2.8597785977859783e-06,
        "epoch": 35.42435424354244,
        "step": 9600
    },
    {
        "loss": 0.226,
        "grad_norm": 25.656848907470703,
        "learning_rate": 2.8367158671586717e-06,
        "epoch": 35.46125461254613,
        "step": 9610
    },
    {
        "loss": 0.2195,
        "grad_norm": 3.0851821899414062,
        "learning_rate": 2.8136531365313655e-06,
        "epoch": 35.49815498154982,
        "step": 9620
    },
    {
        "loss": 0.196,
        "grad_norm": 42.03635787963867,
        "learning_rate": 2.7905904059040593e-06,
        "epoch": 35.535055350553506,
        "step": 9630
    },
    {
        "loss": 0.2141,
        "grad_norm": 0.23212042450904846,
        "learning_rate": 2.767527675276753e-06,
        "epoch": 35.571955719557195,
        "step": 9640
    },
    {
        "loss": 0.1201,
        "grad_norm": 0.5270605683326721,
        "learning_rate": 2.7444649446494465e-06,
        "epoch": 35.608856088560884,
        "step": 9650
    },
    {
        "loss": 0.1509,
        "grad_norm": 37.85536193847656,
        "learning_rate": 2.7214022140221403e-06,
        "epoch": 35.64575645756457,
        "step": 9660
    },
    {
        "loss": 0.1437,
        "grad_norm": 0.5648980736732483,
        "learning_rate": 2.698339483394834e-06,
        "epoch": 35.68265682656826,
        "step": 9670
    },
    {
        "loss": 0.1533,
        "grad_norm": 32.33064651489258,
        "learning_rate": 2.6752767527675275e-06,
        "epoch": 35.71955719557196,
        "step": 9680
    },
    {
        "loss": 0.1634,
        "grad_norm": 0.677585244178772,
        "learning_rate": 2.6522140221402217e-06,
        "epoch": 35.75645756457565,
        "step": 9690
    },
    {
        "loss": 0.1526,
        "grad_norm": 19.14986801147461,
        "learning_rate": 2.6291512915129155e-06,
        "epoch": 35.79335793357934,
        "step": 9700
    },
    {
        "loss": 0.2634,
        "grad_norm": 10.500837326049805,
        "learning_rate": 2.606088560885609e-06,
        "epoch": 35.830258302583026,
        "step": 9710
    },
    {
        "loss": 0.1105,
        "grad_norm": 2.9670467376708984,
        "learning_rate": 2.5830258302583027e-06,
        "epoch": 35.867158671586715,
        "step": 9720
    },
    {
        "loss": 0.1876,
        "grad_norm": 1.0987781286239624,
        "learning_rate": 2.5599630996309965e-06,
        "epoch": 35.904059040590404,
        "step": 9730
    },
    {
        "loss": 0.1116,
        "grad_norm": 1.8427281379699707,
        "learning_rate": 2.5369003690036903e-06,
        "epoch": 35.94095940959409,
        "step": 9740
    },
    {
        "loss": 0.1859,
        "grad_norm": 4.845617294311523,
        "learning_rate": 2.5138376383763837e-06,
        "epoch": 35.97785977859779,
        "step": 9750
    },
    {
        "eval_loss": 0.7205827832221985,
        "eval_accuracy": 0.85424,
        "eval_precision": 0.81803,
        "eval_recall": 0.90909,
        "eval_f1": 0.86116,
        "eval_runtime": 18.0969,
        "eval_samples_per_second": 59.9,
        "eval_steps_per_second": 3.758,
        "epoch": 36.0,
        "step": 9756
    },
    {
        "train_runtime": 8390.5,
        "train_samples_per_second": 20.666,
        "train_steps_per_second": 1.292,
        "total_flos": 2.05305556497408e+16,
        "train_loss": 0.2719494559179324,
        "epoch": 36.0,
        "step": 9756
    }
]