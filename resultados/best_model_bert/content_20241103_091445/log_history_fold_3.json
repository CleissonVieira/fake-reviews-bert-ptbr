[
    {
        "loss": 0.6722,
        "grad_norm": 2.5778515338897705,
        "learning_rate": 2.9841855561412756e-05,
        "epoch": 0.03690036900369004,
        "step": 10
    },
    {
        "loss": 0.6598,
        "grad_norm": 2.66621470451355,
        "learning_rate": 2.9683711122825515e-05,
        "epoch": 0.07380073800738007,
        "step": 20
    },
    {
        "loss": 0.6305,
        "grad_norm": 2.7956461906433105,
        "learning_rate": 2.952556668423827e-05,
        "epoch": 0.11070110701107011,
        "step": 30
    },
    {
        "loss": 0.6488,
        "grad_norm": 6.675173282623291,
        "learning_rate": 2.9367422245651026e-05,
        "epoch": 0.14760147601476015,
        "step": 40
    },
    {
        "loss": 0.6249,
        "grad_norm": 1.394151210784912,
        "learning_rate": 2.9209277807063785e-05,
        "epoch": 0.18450184501845018,
        "step": 50
    },
    {
        "loss": 0.6711,
        "grad_norm": 3.667923927307129,
        "learning_rate": 2.905113336847654e-05,
        "epoch": 0.22140221402214022,
        "step": 60
    },
    {
        "loss": 0.6248,
        "grad_norm": 3.1923842430114746,
        "learning_rate": 2.8892988929889297e-05,
        "epoch": 0.25830258302583026,
        "step": 70
    },
    {
        "loss": 0.6603,
        "grad_norm": 2.007185935974121,
        "learning_rate": 2.873484449130206e-05,
        "epoch": 0.2952029520295203,
        "step": 80
    },
    {
        "loss": 0.6532,
        "grad_norm": 2.750535488128662,
        "learning_rate": 2.8576700052714815e-05,
        "epoch": 0.33210332103321033,
        "step": 90
    },
    {
        "loss": 0.6334,
        "grad_norm": 2.0769336223602295,
        "learning_rate": 2.841855561412757e-05,
        "epoch": 0.36900369003690037,
        "step": 100
    },
    {
        "loss": 0.5946,
        "grad_norm": 3.8252034187316895,
        "learning_rate": 2.826041117554033e-05,
        "epoch": 0.4059040590405904,
        "step": 110
    },
    {
        "loss": 0.5829,
        "grad_norm": 2.5850090980529785,
        "learning_rate": 2.8102266736953085e-05,
        "epoch": 0.44280442804428044,
        "step": 120
    },
    {
        "loss": 0.5893,
        "grad_norm": 1.8959245681762695,
        "learning_rate": 2.794412229836584e-05,
        "epoch": 0.4797047970479705,
        "step": 130
    },
    {
        "loss": 0.6279,
        "grad_norm": 3.361309766769409,
        "learning_rate": 2.77859778597786e-05,
        "epoch": 0.5166051660516605,
        "step": 140
    },
    {
        "loss": 0.5555,
        "grad_norm": 4.388755798339844,
        "learning_rate": 2.7627833421191355e-05,
        "epoch": 0.5535055350553506,
        "step": 150
    },
    {
        "loss": 0.611,
        "grad_norm": 2.0792715549468994,
        "learning_rate": 2.746968898260411e-05,
        "epoch": 0.5904059040590406,
        "step": 160
    },
    {
        "loss": 0.5639,
        "grad_norm": 1.5309048891067505,
        "learning_rate": 2.731154454401687e-05,
        "epoch": 0.6273062730627307,
        "step": 170
    },
    {
        "loss": 0.6256,
        "grad_norm": 1.90525484085083,
        "learning_rate": 2.7153400105429625e-05,
        "epoch": 0.6642066420664207,
        "step": 180
    },
    {
        "loss": 0.5374,
        "grad_norm": 3.5252299308776855,
        "learning_rate": 2.699525566684238e-05,
        "epoch": 0.7011070110701108,
        "step": 190
    },
    {
        "loss": 0.512,
        "grad_norm": 1.9588514566421509,
        "learning_rate": 2.683711122825514e-05,
        "epoch": 0.7380073800738007,
        "step": 200
    },
    {
        "loss": 0.5813,
        "grad_norm": 4.1245574951171875,
        "learning_rate": 2.6678966789667895e-05,
        "epoch": 0.7749077490774908,
        "step": 210
    },
    {
        "loss": 0.5853,
        "grad_norm": 3.561347484588623,
        "learning_rate": 2.6520822351080654e-05,
        "epoch": 0.8118081180811808,
        "step": 220
    },
    {
        "loss": 0.617,
        "grad_norm": 2.153125762939453,
        "learning_rate": 2.6362677912493413e-05,
        "epoch": 0.8487084870848709,
        "step": 230
    },
    {
        "loss": 0.6136,
        "grad_norm": 2.7070538997650146,
        "learning_rate": 2.620453347390617e-05,
        "epoch": 0.8856088560885609,
        "step": 240
    },
    {
        "loss": 0.6345,
        "grad_norm": 2.8680975437164307,
        "learning_rate": 2.6046389035318924e-05,
        "epoch": 0.922509225092251,
        "step": 250
    },
    {
        "loss": 0.6111,
        "grad_norm": 1.6540793180465698,
        "learning_rate": 2.5888244596731683e-05,
        "epoch": 0.959409594095941,
        "step": 260
    },
    {
        "loss": 0.6065,
        "grad_norm": 3.206547498703003,
        "learning_rate": 2.573010015814444e-05,
        "epoch": 0.996309963099631,
        "step": 270
    },
    {
        "eval_loss": 0.5983260273933411,
        "eval_accuracy": 0.70111,
        "eval_precision": 0.67216,
        "eval_recall": 0.76548,
        "eval_f1": 0.71579,
        "eval_runtime": 18.0909,
        "eval_samples_per_second": 59.92,
        "eval_steps_per_second": 3.759,
        "epoch": 1.0,
        "step": 271
    },
    {
        "loss": 0.5456,
        "grad_norm": 3.0833356380462646,
        "learning_rate": 2.5571955719557198e-05,
        "epoch": 1.033210332103321,
        "step": 280
    },
    {
        "loss": 0.5419,
        "grad_norm": 1.924325942993164,
        "learning_rate": 2.5413811280969953e-05,
        "epoch": 1.070110701107011,
        "step": 290
    },
    {
        "loss": 0.6133,
        "grad_norm": 5.630168437957764,
        "learning_rate": 2.525566684238271e-05,
        "epoch": 1.1070110701107012,
        "step": 300
    },
    {
        "loss": 0.5606,
        "grad_norm": 1.9981114864349365,
        "learning_rate": 2.5097522403795468e-05,
        "epoch": 1.1439114391143912,
        "step": 310
    },
    {
        "loss": 0.5617,
        "grad_norm": 3.4599528312683105,
        "learning_rate": 2.4939377965208224e-05,
        "epoch": 1.1808118081180812,
        "step": 320
    },
    {
        "loss": 0.5572,
        "grad_norm": 3.964602470397949,
        "learning_rate": 2.478123352662098e-05,
        "epoch": 1.2177121771217712,
        "step": 330
    },
    {
        "loss": 0.4924,
        "grad_norm": 2.486112117767334,
        "learning_rate": 2.4623089088033738e-05,
        "epoch": 1.2546125461254611,
        "step": 340
    },
    {
        "loss": 0.57,
        "grad_norm": 3.6720685958862305,
        "learning_rate": 2.4464944649446494e-05,
        "epoch": 1.2915129151291513,
        "step": 350
    },
    {
        "loss": 0.5058,
        "grad_norm": 3.650513172149658,
        "learning_rate": 2.4306800210859253e-05,
        "epoch": 1.3284132841328413,
        "step": 360
    },
    {
        "loss": 0.5884,
        "grad_norm": 4.27209997177124,
        "learning_rate": 2.4148655772272012e-05,
        "epoch": 1.3653136531365313,
        "step": 370
    },
    {
        "loss": 0.6292,
        "grad_norm": 3.9453482627868652,
        "learning_rate": 2.3990511333684767e-05,
        "epoch": 1.4022140221402215,
        "step": 380
    },
    {
        "loss": 0.5492,
        "grad_norm": 3.022310495376587,
        "learning_rate": 2.3832366895097523e-05,
        "epoch": 1.4391143911439115,
        "step": 390
    },
    {
        "loss": 0.5406,
        "grad_norm": 5.946396827697754,
        "learning_rate": 2.3674222456510282e-05,
        "epoch": 1.4760147601476015,
        "step": 400
    },
    {
        "loss": 0.4712,
        "grad_norm": 4.768568992614746,
        "learning_rate": 2.3516078017923037e-05,
        "epoch": 1.5129151291512914,
        "step": 410
    },
    {
        "loss": 0.5509,
        "grad_norm": 7.267161846160889,
        "learning_rate": 2.3357933579335793e-05,
        "epoch": 1.5498154981549814,
        "step": 420
    },
    {
        "loss": 0.5971,
        "grad_norm": 3.908944606781006,
        "learning_rate": 2.3199789140748552e-05,
        "epoch": 1.5867158671586716,
        "step": 430
    },
    {
        "loss": 0.5441,
        "grad_norm": 3.3876571655273438,
        "learning_rate": 2.3041644702161308e-05,
        "epoch": 1.6236162361623616,
        "step": 440
    },
    {
        "loss": 0.6253,
        "grad_norm": 2.8405284881591797,
        "learning_rate": 2.2883500263574063e-05,
        "epoch": 1.6605166051660518,
        "step": 450
    },
    {
        "loss": 0.5502,
        "grad_norm": 3.434880256652832,
        "learning_rate": 2.2725355824986822e-05,
        "epoch": 1.6974169741697418,
        "step": 460
    },
    {
        "loss": 0.5015,
        "grad_norm": 3.2865772247314453,
        "learning_rate": 2.2567211386399578e-05,
        "epoch": 1.7343173431734318,
        "step": 470
    },
    {
        "loss": 0.5792,
        "grad_norm": 3.0241973400115967,
        "learning_rate": 2.2409066947812333e-05,
        "epoch": 1.7712177121771218,
        "step": 480
    },
    {
        "loss": 0.4995,
        "grad_norm": 4.3624444007873535,
        "learning_rate": 2.2250922509225092e-05,
        "epoch": 1.8081180811808117,
        "step": 490
    },
    {
        "loss": 0.5782,
        "grad_norm": 3.608940362930298,
        "learning_rate": 2.209277807063785e-05,
        "epoch": 1.8450184501845017,
        "step": 500
    },
    {
        "loss": 0.5191,
        "grad_norm": 4.510030269622803,
        "learning_rate": 2.1934633632050607e-05,
        "epoch": 1.881918819188192,
        "step": 510
    },
    {
        "loss": 0.5421,
        "grad_norm": 9.621585845947266,
        "learning_rate": 2.1776489193463366e-05,
        "epoch": 1.918819188191882,
        "step": 520
    },
    {
        "loss": 0.5207,
        "grad_norm": 3.589655637741089,
        "learning_rate": 2.161834475487612e-05,
        "epoch": 1.9557195571955721,
        "step": 530
    },
    {
        "loss": 0.5636,
        "grad_norm": 3.3849751949310303,
        "learning_rate": 2.1460200316288877e-05,
        "epoch": 1.992619926199262,
        "step": 540
    },
    {
        "eval_loss": 0.5696731805801392,
        "eval_accuracy": 0.69004,
        "eval_precision": 0.69201,
        "eval_recall": 0.66604,
        "eval_f1": 0.67878,
        "eval_runtime": 18.0963,
        "eval_samples_per_second": 59.902,
        "eval_steps_per_second": 3.758,
        "epoch": 2.0,
        "step": 542
    },
    {
        "loss": 0.443,
        "grad_norm": 6.97313117980957,
        "learning_rate": 2.1302055877701636e-05,
        "epoch": 2.029520295202952,
        "step": 550
    },
    {
        "loss": 0.4423,
        "grad_norm": 5.021368980407715,
        "learning_rate": 2.114391143911439e-05,
        "epoch": 2.066420664206642,
        "step": 560
    },
    {
        "loss": 0.4769,
        "grad_norm": 9.10016918182373,
        "learning_rate": 2.0985767000527147e-05,
        "epoch": 2.103321033210332,
        "step": 570
    },
    {
        "loss": 0.4164,
        "grad_norm": 6.9947919845581055,
        "learning_rate": 2.0827622561939906e-05,
        "epoch": 2.140221402214022,
        "step": 580
    },
    {
        "loss": 0.4858,
        "grad_norm": 9.50106430053711,
        "learning_rate": 2.0669478123352662e-05,
        "epoch": 2.177121771217712,
        "step": 590
    },
    {
        "loss": 0.4023,
        "grad_norm": 10.226358413696289,
        "learning_rate": 2.0511333684765417e-05,
        "epoch": 2.2140221402214024,
        "step": 600
    },
    {
        "loss": 0.3971,
        "grad_norm": 9.290312767028809,
        "learning_rate": 2.0353189246178176e-05,
        "epoch": 2.2509225092250924,
        "step": 610
    },
    {
        "loss": 0.4262,
        "grad_norm": 14.581243515014648,
        "learning_rate": 2.0195044807590932e-05,
        "epoch": 2.2878228782287824,
        "step": 620
    },
    {
        "loss": 0.4728,
        "grad_norm": 7.2825093269348145,
        "learning_rate": 2.0036900369003687e-05,
        "epoch": 2.3247232472324724,
        "step": 630
    },
    {
        "loss": 0.4429,
        "grad_norm": 3.251005172729492,
        "learning_rate": 1.987875593041645e-05,
        "epoch": 2.3616236162361623,
        "step": 640
    },
    {
        "loss": 0.3899,
        "grad_norm": 9.787646293640137,
        "learning_rate": 1.9720611491829205e-05,
        "epoch": 2.3985239852398523,
        "step": 650
    },
    {
        "loss": 0.4663,
        "grad_norm": 9.88984203338623,
        "learning_rate": 1.956246705324196e-05,
        "epoch": 2.4354243542435423,
        "step": 660
    },
    {
        "loss": 0.4658,
        "grad_norm": 6.07450532913208,
        "learning_rate": 1.940432261465472e-05,
        "epoch": 2.4723247232472323,
        "step": 670
    },
    {
        "loss": 0.4316,
        "grad_norm": 8.05235481262207,
        "learning_rate": 1.9246178176067476e-05,
        "epoch": 2.5092250922509223,
        "step": 680
    },
    {
        "loss": 0.513,
        "grad_norm": 7.3260111808776855,
        "learning_rate": 1.908803373748023e-05,
        "epoch": 2.5461254612546127,
        "step": 690
    },
    {
        "loss": 0.3745,
        "grad_norm": 9.936895370483398,
        "learning_rate": 1.892988929889299e-05,
        "epoch": 2.5830258302583027,
        "step": 700
    },
    {
        "loss": 0.4357,
        "grad_norm": 9.619536399841309,
        "learning_rate": 1.8771744860305746e-05,
        "epoch": 2.6199261992619927,
        "step": 710
    },
    {
        "loss": 0.5627,
        "grad_norm": 10.80423355102539,
        "learning_rate": 1.86136004217185e-05,
        "epoch": 2.6568265682656826,
        "step": 720
    },
    {
        "loss": 0.4698,
        "grad_norm": 6.335037708282471,
        "learning_rate": 1.845545598313126e-05,
        "epoch": 2.6937269372693726,
        "step": 730
    },
    {
        "loss": 0.4576,
        "grad_norm": 8.373242378234863,
        "learning_rate": 1.8297311544544016e-05,
        "epoch": 2.7306273062730626,
        "step": 740
    },
    {
        "loss": 0.4379,
        "grad_norm": 11.050938606262207,
        "learning_rate": 1.8139167105956775e-05,
        "epoch": 2.767527675276753,
        "step": 750
    },
    {
        "loss": 0.4638,
        "grad_norm": 4.688260078430176,
        "learning_rate": 1.798102266736953e-05,
        "epoch": 2.804428044280443,
        "step": 760
    },
    {
        "loss": 0.4557,
        "grad_norm": 7.0928192138671875,
        "learning_rate": 1.7822878228782286e-05,
        "epoch": 2.841328413284133,
        "step": 770
    },
    {
        "loss": 0.3974,
        "grad_norm": 7.2502851486206055,
        "learning_rate": 1.766473379019505e-05,
        "epoch": 2.878228782287823,
        "step": 780
    },
    {
        "loss": 0.5009,
        "grad_norm": 9.972661972045898,
        "learning_rate": 1.7506589351607804e-05,
        "epoch": 2.915129151291513,
        "step": 790
    },
    {
        "loss": 0.4577,
        "grad_norm": 11.930816650390625,
        "learning_rate": 1.734844491302056e-05,
        "epoch": 2.952029520295203,
        "step": 800
    },
    {
        "loss": 0.4801,
        "grad_norm": 7.481871604919434,
        "learning_rate": 1.719030047443332e-05,
        "epoch": 2.988929889298893,
        "step": 810
    },
    {
        "eval_loss": 0.6273950338363647,
        "eval_accuracy": 0.68358,
        "eval_precision": 0.72727,
        "eval_recall": 0.57036,
        "eval_f1": 0.63933,
        "eval_runtime": 18.1009,
        "eval_samples_per_second": 59.886,
        "eval_steps_per_second": 3.757,
        "epoch": 3.0,
        "step": 813
    },
    {
        "train_runtime": 722.029,
        "train_samples_per_second": 42.027,
        "train_steps_per_second": 2.627,
        "total_flos": 1710879637478400.0,
        "train_loss": 0.5376579125135734,
        "epoch": 3.0,
        "step": 813
    }
]