{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 - df_balanceado | 2500 registros\n",
      "\n",
      "Fold 1\n",
      "Epoch 1, Loss: 0.6296\n",
      "Epoch 2, Loss: 0.5669\n",
      "Epoch 3, Loss: 0.4935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 213\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         results_real_fake\u001b[38;5;241m.\u001b[39mto_csv(file_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 213\u001b[0m \u001b[43mTreinoEValidacao\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_balanceado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1 - df_balanceado\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 151\u001b[0m, in \u001b[0;36mTreinoEValidacao\u001b[0;34m(dfUtilizado, mensagem)\u001b[0m\n\u001b[1;32m    149\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m--> 151\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[3], line 66\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Mover para GPU se disponível\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n",
      "Cell \u001b[0;32mIn[3], line 66\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Mover para GPU se disponível\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carregar o dataset\n",
    "url = 'https://raw.githubusercontent.com/CleissonVieira/fake-reviews-bert-ptbr/main/datasets/yelp-fake-reviews-dataset-pt.csv'\n",
    "df = pd.read_csv(url)\n",
    "df = df[['content', 'fake_review']]\n",
    "\n",
    "df_real = df[df.fake_review == False].sample(n=1250, random_state=42)\n",
    "df_fakes = df[df.fake_review == True].sample(n=1250, random_state=42)\n",
    "df_balanceado = pd.concat([df_real, df_fakes]) \n",
    "df_balanceado['fake_review'] = df_balanceado['fake_review'].astype(int)\n",
    "\n",
    "results_real_fake = []\n",
    "\n",
    "# Inicializar tokenizer e modelo\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', num_labels=2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Função para tokenização\n",
    "def tokenize_data(texts, labels, max_len=128):\n",
    "    inputs = tokenizer(texts.tolist(), max_length=max_len, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs['labels'] = torch.tensor(labels)\n",
    "    return inputs\n",
    "\n",
    "# Definir dataset customizado\n",
    "class FakeReviewsDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "# Definir otimizador, função de perda e scheduler\n",
    "def configure_optimizer_scheduler(model, train_loader, epochs=5):\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Função de treino\n",
    "def train_one_epoch(model, train_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mover para GPU se disponível\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Função de avaliação\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            preds.extend(torch.argmax(logits, axis=-1).cpu().numpy())\n",
    "            true_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    # Métricas globais\n",
    "    accuracy = accuracy_score(true_labels, preds)\n",
    "    precision = precision_score(true_labels, preds)\n",
    "    recall = recall_score(true_labels, preds)\n",
    "    f1 = f1_score(true_labels, preds)\n",
    "\n",
    "    # Métricas por classe\n",
    "    precision_real = precision_score(true_labels, preds, pos_label=0)\n",
    "    precision_fake = precision_score(true_labels, preds, pos_label=1)\n",
    "    recall_real = recall_score(true_labels, preds, pos_label=0)\n",
    "    recall_fake = recall_score(true_labels, preds, pos_label=1)\n",
    "    f1_real = f1_score(true_labels, preds, pos_label=0)\n",
    "    f1_fake = f1_score(true_labels, preds, pos_label=1)\n",
    "\n",
    "    return accuracy, precision, recall, f1, precision_real, precision_fake, recall_real, recall_fake, f1_real, f1_fake\n",
    "\n",
    "def TreinoEValidacao(dfUtilizado, mensagem):\n",
    "    print(f'\\n{mensagem} | {len(dfUtilizado)} registros')\n",
    "    \n",
    "    # Configurar Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Inicializar listas para armazenar as métricas\n",
    "    metrics = {\n",
    "        'Precision_Real': [], 'Precision_Fake': [], 'Precision': [],\n",
    "        'F1_Score_Real': [], 'F1_Score_Fake': [], 'F1_Score': [],\n",
    "        'Recall_Real': [], 'Recall_Fake': [], 'Recall': [],\n",
    "        'Accuracy': []\n",
    "    }\n",
    "    \n",
    "    # Inicializar listas para métricas de cada fold\n",
    "    \n",
    "    X = dfUtilizado['content'].values\n",
    "    y = dfUtilizado['fake_review'].values\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "    \n",
    "        # Dividir os dados\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        # Tokenizar os dados\n",
    "        train_encodings = tokenize_data(X_train, y_train)\n",
    "        val_encodings = tokenize_data(X_test, y_test)\n",
    "    \n",
    "        # Criar datasets\n",
    "        train_dataset = FakeReviewsDataset(train_encodings)\n",
    "        val_dataset = FakeReviewsDataset(val_encodings)\n",
    "    \n",
    "        # Criar DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "    \n",
    "        # Configurar otimizador e scheduler\n",
    "        optimizer, scheduler = configure_optimizer_scheduler(model, train_loader)\n",
    "    \n",
    "        # Treino por 5 epochs\n",
    "        start_time = time.time()\n",
    "        for epoch in range(5):\n",
    "            train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {train_loss:.4f}\")\n",
    "    \n",
    "        train_time = time.time() - start_time\n",
    "    \n",
    "        # Avaliar o modelo\n",
    "        accuracy, precision, recall, f1, precision_real, precision_fake, recall_real, recall_fake, f1_real, f1_fake = evaluate_model(model, val_loader, device)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "        # Armazenar métricas\n",
    "        metrics['Precision_Real'].append(precision_real)\n",
    "        metrics['Precision_Fake'].append(precision_fake)\n",
    "        metrics['Recall_Real'].append(recall_real)\n",
    "        metrics['Recall_Fake'].append(recall_fake)\n",
    "        metrics['F1_Score_Real'].append(f1_real)\n",
    "        metrics['F1_Score_Fake'].append(f1_fake)\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['F1_Score'].append(f1)\n",
    "        metrics['Accuracy'].append(accuracy)\n",
    "        \n",
    "    # Calcular médias e variâncias\n",
    "    final_results = {\n",
    "        'tamanho_dataLoader': len(dfUtilizado),\n",
    "        'scenario': 'Review',\n",
    "        'classifier': 'bert-base-multilingual-uncased',\n",
    "        'features_used': 'content',\n",
    "        'Precision_Real': np.mean(metrics['Precision_Real']),\n",
    "        'Precision_Fake': np.mean(metrics['Precision_Fake']),\n",
    "        'Precision': np.mean(metrics['Precision']),\n",
    "        'precision_variance': np.var(metrics['Precision'], ddof=1),\n",
    "        'precision_min': np.min(metrics['Precision']),\n",
    "        'precision_max': np.max(metrics['Precision']),\n",
    "        'F1_Score_Real': np.mean(metrics['F1_Score_Real']),\n",
    "        'F1_Score_Fake': np.mean(metrics['F1_Score_Fake']),\n",
    "        'F1_Score': np.mean(metrics['F1_Score']),\n",
    "        'f1_score_variance': np.var(metrics['F1_Score'], ddof=1),\n",
    "        'f1_score_min': np.min(metrics['F1_Score']),\n",
    "        'f1_score_max': np.max(metrics['F1_Score']),\n",
    "        'Recall_Real': np.mean(metrics['Recall_Real']),\n",
    "        'Recall_Fake': np.mean(metrics['Recall_Fake']),\n",
    "        'Recall': np.mean(metrics['Recall']),\n",
    "        'recall_variance': np.var(metrics['Recall'], ddof=1),\n",
    "        'recall_min': np.min(metrics['Recall']),\n",
    "        'recall_max': np.max(metrics['Recall']),\n",
    "        'Accuracy': np.mean(metrics['Accuracy']),\n",
    "        'accuracy_variance': np.var(metrics['Accuracy'], ddof=1),\n",
    "        'accuracy_min': np.min(metrics['Accuracy']),\n",
    "        'accuracy_max': np.max(metrics['Accuracy'])\n",
    "    }\n",
    "    \n",
    "    results_real_fake = pd.DataFrame([final_results]).round(5)\n",
    "    \n",
    "    file_path = 'bert_final_results.csv'\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        results_real_fake.to_csv(file_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        results_real_fake.to_csv(file_path, mode='w', header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "TreinoEValidacao(df_balanceado, '1 - df_balanceado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
